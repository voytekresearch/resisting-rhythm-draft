
@article{Ivanov,
  langid = {english},
  title = {Axonal {{Conduction Velocity Impacts Neuronal Network Oscillations}}},
  abstract = {Increasing experimental evidence suggests that axonal action potential conduction velocity is a highly adaptive parameter in the adult central nervous system. Yet, the effects of this newfound plasticity on global brain dynamics is poorly understood. In this work, we analyzed oscillations in biologically plausible neuronal networks with different conduction velocity distributions. Changes of \dbend\dbend\dbend\dbend\dbend\dbend{} - \dbend\dbend\dbend\dbend\dbend\dbend{} (ms) in network mean signal transmission time resulted in substantial network oscillation frequency changes ranging in \dbend\dbend\dbend\dbend\dbend\dbend{} - \dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend\dbend{} (Hz). Our results suggest that changes in axonal conduction velocity may significantly affect both the frequency and synchrony of brain rhythms, which have well established connections to learning, memory, and other cognitive processes.},
  pages = {4},
  author = {Ivanov, Vladimir A and Polykretis, Ioannis E and Michmizos, Konstantinos P},
  file = {/Users/qualia/Documents/Papers/Ivanov et al. - Axonal Conduction Velocity Impacts Neuronal Networ.pdf;/Users/qualia/Downloads/lee2011.pdf}
}

@article{Lee2011a,
  langid = {english},
  title = {Psychological Models of Human and Optimal Performance in Bandit Problems},
  volume = {12},
  issn = {13890417},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1389041710000550},
  doi = {10.1016/j.cogsys.2010.07.007},
  abstract = {In bandit problems, a decision-maker must choose between a set of alternatives, each of which has a fixed but unknown rate of reward, to maximize their total number of rewards over a sequence of trials. Performing well in these problems requires balancing the need to search for highly-rewarding alternatives, with the need to capitalize on those alternatives already known to be reasonably good. Consistent with this motivation, we develop a new psychological model that relies on switching between latent exploration and exploitation states. We test the model over a range of two-alternative bandit problems, against both human and optimal decision-making data, comparing it to benchmark models from the reinforcement learning literature. By making inferences about the latent states from optimal decision-making behavior, we characterize how people should switch between exploration and exploitation. By making inferences from human data, we begin to characterize how people actually do switch. We discuss the implications of these findings for understanding and measuring the competing demands of exploration and exploitation in sequential decision-making.},
  number = {2},
  journaltitle = {Cognitive Systems Research},
  urldate = {2019-03-29},
  date = {2011-06},
  pages = {164-174},
  author = {Lee, Michael D. and Zhang, Shunan and Munro, Miles and Steyvers, Mark},
  file = {/Users/qualia/Documents/Papers/2011 - Lee et al. - Psychological models of human and optimal performance in bandit problems.pdf;/Users/qualia/Downloads/Lee et al. - 2011 - Psychological models of human and optimal performa.pdf}
}

@article{Schmidhuber2010,
  langid = {english},
  title = {Formal {{Theory}} of {{Creativity}}, {{Fun}}, and {{Intrinsic Motivation}} (1990\textendash{}2010)},
  volume = {2},
  issn = {1943-0604, 1943-0612},
  url = {http://ieeexplore.ieee.org/document/5508364/},
  doi = {10.1109/TAMD.2010.2056368},
  abstract = {The simple but general formal theory of fun \& intrinsic motivation \& creativity (1990-) is based on the concept of maximizing intrinsic reward for the active creation or discovery of novel, surprising patterns allowing for improved prediction or data compression. It generalizes the traditional field of active learning, and is related to old but less formal ideas in aesthetics theory and developmental psychology. It has been argued that the theory explains many essential aspects of intelligence including autonomous development, science, art, music, humor. This overview first describes theoretically optimal (but not necessarily practical) ways of implementing the basic computational principles on exploratory, intrinsically motivated agents or robots, encouraging them to provoke event sequences exhibiting previously unknown but learnable algorithmic regularities. Emphasis is put on the importance of limited computational resources for online prediction and compression. Discrete and continuous time formulations are given. Previous practical but non-optimal implementations (1991, 1995, 1997-2002) are reviewed, as well as several recent variants by others (2005-). A simplified typology addresses current confusion concerning the precise nature of intrinsic motivation.},
  number = {3},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  urldate = {2019-03-29},
  date = {2010-09},
  pages = {230-247},
  author = {Schmidhuber, J\"urgen},
  file = {/Users/qualia/Documents/Papers/Schmidhuber - 2010 - Formal Theory of Creativity, Fun, and Intrinsic Mo.pdf}
}

@article{Doya2000,
  langid = {english},
  title = {Complementary Roles of Basal Ganglia and Cerebellum in Learning and Motor Control},
  volume = {10},
  issn = {09594388},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438800001537},
  doi = {10.1016/S0959-4388(00)00153-7},
  number = {6},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-29},
  date = {2000-12-01},
  pages = {732-739},
  author = {Doya, K},
  file = {/Users/qualia/Documents/Papers/Doya - 2000 - Complementary roles of basal ganglia and cerebellu.pdf}
}

@article{Liu2019,
  langid = {english},
  title = {Mouse Navigation Strategies for Odor Source Localization},
  url = {http://biorxiv.org/lookup/doi/10.1101/558643},
  doi = {10.1101/558643},
  abstract = {Navigating an odor landscape is a critical behavior for the survival of many species, including mice. One ethologically relevant mouse behavior is locating food using odor concentration gradients. To model this behavior, we use a naturalistic open field odor-based spot-finding task, examining navigation strategies as mice search for and approach an odor source. Mice were trained to navigate to odor sources paired with food reward. We detected behavioral changes consistent with localization of the odor source when mice were 10cm away from the source. These behaviors included both orientation towards the source and increased exploration time. We found that the amplitude of "casting," lateral back and forth head movement, increased exponentially with proximity to the source. We then created concentration-dependent models to simulate mouse behavior, which provided evidence for a serial-sniffing strategy (sampling concentration, moving in space, then sampling again) and a stereo-sniffing strategy (inter-nostril comparison of concentration in a single sniff). Together, these results elucidate key components of behavioral strategies for odor-based navigation.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-29},
  date = {2019-02-22},
  author = {Liu, Annie and Papale, Andrew and Hengenius, James and Patel, Khusbu and Ermentrout, Bard and Urban, Nathaniel},
  file = {/Users/qualia/Documents/Papers/Liu et al. - 2019 - Mouse navigation strategies for odor source locali.pdf;/Users/qualia/Documents/Papers/Liu et al. - 2019 - Mouse navigation strategies for odor source locali.pdf}
}

@article{Zylberberg2017,
  langid = {english},
  title = {Counterfactual Reasoning Underlies the Learning of Priors in Decision Making},
  url = {http://biorxiv.org/lookup/doi/10.1101/227421},
  doi = {10.1101/227421},
  abstract = {Accurate decisions require knowledge of prior probabilities (e.g., prevalence or base rate) but it is unclear how prior probability is learned in the absence of a teacher. We hypothesized that humans could learn base rates from experience making decisions, even without feedback. Participants made difficult decisions about the direction of dynamic random dot motion. For each block of 15-42 trials, the base rate favored left or right by a different amount. Participants were not informed of the base rate, yet they gradually biased their choices and thereby increased accuracy and confidence in their decisions. They achieved this by updating knowledge of base rate after each decision, using a counterfactual representation of confidence that simulates a neutral prior. The strategy is consistent with Bayesian updating of belief and suggests that humans represent both true confidence, that incorporates the evolving belief of the prior, and counterfactual confidence that discounts the prior.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-11-30},
  author = {Zylberberg, Ariel and Wolpert, Daniel M and Shadlen, Michael N},
  file = {/Users/qualia/Documents/Papers/Zylberberg et al. - 2017 - Counterfactual reasoning underlies the learning of.pdf}
}

@article{Welford1962,
  langid = {english},
  title = {Note on a {{Method}} for {{Calculating Corrected Sums}} of {{Squares}} and {{Products}}},
  volume = {4},
  issn = {0040-1706, 1537-2723},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1962.10490022},
  doi = {10.1080/00401706.1962.10490022},
  number = {3},
  journaltitle = {Technometrics},
  urldate = {2019-03-30},
  date = {1962-08},
  pages = {419-420},
  author = {Welford, B. P.},
  file = {/Users/qualia/Documents/Papers/1962 - Welford - Note on a Method for Calculating Corrected Sums of Squares and Products.pdf;/Users/qualia/Documents/Papers/Welford - 1962 - Note on a Method for Calculating Corrected Sums of.pdf}
}

@article{Zhang2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1710.09412},
  primaryClass = {cs, stat},
  langid = {english},
  title = {Mixup: {{Beyond Empirical Risk Minimization}}},
  url = {http://arxiv.org/abs/1710.09412},
  shorttitle = {Mixup},
  abstract = {Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.},
  urldate = {2019-03-30},
  date = {2017-10-25},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
  file = {/Users/qualia/Documents/Papers/Zhang et al. - 2017 - mixup Beyond Empirical Risk Minimization.pdf}
}

@article{Tishby,
  langid = {english},
  title = {The {{Information Bottleneck Method}}},
  abstract = {We define the relevant information in a signal x {$\in$} X as being the information that this signal provides about another signal y {$\in$} Y . Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal x requires more than just predicting y, it also requires specifying which features of X play a role in the prediction. We formalize the problem as that of finding a short code for X that preserves the maximum information about Y . That is, we squeeze the information that X provides about Y through a `bottleneck' formed by a limited set of codewords X\texttildelow{} . This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure d(x, x\texttildelow{}) emerges from the joint statistics of X and Y . The approach yields an exact set of self-consistent equations for the coding rules X {$\rightarrow$} X\texttildelow{} and X\texttildelow{} {$\rightarrow$} Y . Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut\textendash{}Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.},
  pages = {11},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks,Nonlinear Sciences - Adaptation and Self-Organizing Systems,Physics - Data Analysis; Statistics and Probability},
  author = {Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  file = {/Users/qualia/Documents/Papers/2000 - Tishby, Pereira, Bialek - The information bottleneck method.pdf;/Users/qualia/Documents/Papers/2011 - Thomas - The Knowledge Link How Firms Compete through Strategic Alliances.pdf;/Users/qualia/Documents/Papers/Tishby et al. - The Information Bottleneck Method.pdf}
}

@article{Suttona,
  langid = {english},
  title = {Policy {{Gradient Methods}} for {{Reinforcement Learning}} with {{Function Approximation}}},
  abstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor-critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy.},
  pages = {7},
  author = {Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  file = {/Users/qualia/Documents/Papers/1999 - Sutton et al. - Policy Gradient Methods for Reinforcement Learning with Function Approximation.pdf;/Users/qualia/Documents/Papers/Sutton et al. - Policy Gradient Methods for Reinforcement Learning.pdf}
}

@article{Sompolinsky1988,
  langid = {english},
  title = {Chaos in {{Random Neural Networks}}},
  volume = {61},
  issn = {0031-9007},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.61.259},
  doi = {10.1103/PhysRevLett.61.259},
  number = {3},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {1988-07-18},
  pages = {259-262},
  author = {Sompolinsky, H. and Crisanti, A. and Sommers, H. J.},
  file = {/Users/qualia/Documents/Papers/1988 - Sompolinsky, Crisanti, Sommers - Chaos in random neural networks.pdf;/Users/qualia/Documents/Papers/Sompolinsky et al. - 1988 - Chaos in Random Neural Networks.pdf}
}

@article{Skarda1987,
  langid = {english},
  title = {How Brains Make Chaos in Order to Make Sense of the World},
  volume = {10},
  issn = {0140-525X, 1469-1825},
  url = {http://www.journals.cambridge.org/abstract_S0140525X00047336},
  doi = {10.1017/S0140525X00047336},
  abstract = {Recent "connectionist" models provide a new explanatory alternative to the digital computer as a model for brain function. Evidence from our EEG research on the olfactory bulb suggests that the brain may indeed use computational mechanisms like those found in connectionist models. In the present paper we discuss our data and develop a model to describe the neural dynamics responsible for odor recognition and discrimination. The results indicate the existence of sensory- and motor-specific information in the spatial dimension of EEG activity and call for new physiological metaphors and techniques of analysis. Special emphasis is placed in our model on chaotic neural activity. We hypothesize that chaotic behavior serves as the essential ground state for the neural perceptual apparatus, and we propose a mechanism for acquiring new forms of patterned activity corresponding to new learned odors. Finally, some of the implications of our neural model for behavioral theories are briefly discussed. Our research, in concert with the connectionist work, encourages a reevaluation of explanatory models that are based only on the digital computer metaphor.},
  number = {02},
  journaltitle = {Behavioral and Brain Sciences},
  urldate = {2019-03-30},
  date = {1987-06},
  pages = {161},
  author = {Skarda, Christine A. and Freeman, Walter J.},
  file = {/Users/qualia/Documents/Papers/1987 - Skarda, Freeman - How brains make chaos in order to make sense of the world.pdf;/Users/qualia/Documents/Papers/Skarda and Freeman - 1987 - How brains make chaos in order to make sense of th.pdf}
}

@article{Shepherd1987,
  langid = {english},
  title = {Logic Operations Are Properties of Computer-Simulated Interactions between Excitable Dendritic Spines},
  volume = {21},
  issn = {03064522},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0306452287903290},
  doi = {10.1016/0306-4522(87)90329-0},
  abstract = {Neurons in the central nervous system of mammals and many other species receive most of their synaptic inputs in their dendritic branches and spines, but the precise manner in which this information is processed in the dendrites is not understood. In order to gain insight into these mechanisms, simulations of interactions between distal dendritic spines with an excitable membrane have been carried out, using an electrical circuit analysis program for the compartmental representation of a dendrite and several spines. Interactions between responses to single and paired excitatory and inhibitory synaptic inputs have been analyzed. Basic logic operations, including AND gates, OR gates and ANDNOT gates, arise from these interactions.},
  number = {1},
  journaltitle = {Neuroscience},
  urldate = {2019-03-30},
  date = {1987-04},
  pages = {151-165},
  author = {Shepherd, Gordon M. and Brayton, Robert K.},
  file = {/Users/qualia/Documents/Papers/1987 - Shepherd, Brayton - M. and.pdf;/Users/qualia/Documents/Papers/Shepherd and Brayton - 1987 - Logic operations are properties of computer-simula.pdf}
}

@article{Rosenblatt,
  langid = {english},
  title = {A {{COMPARISON OF SEVERAL PERCEPTRON MODELS}} \textbullet{}},
  pages = {23},
  author = {Rosenblatt, Frank and Ym, New},
  file = {/Users/qualia/Documents/Papers/1981 - Rosenblatt - A comparison of several perceptron models.pdf;/Users/qualia/Documents/Papers/Rosenblatt and Ym - A COMPARISON OF SEVERAL PERCEPTRON MODELS •.pdf}
}

@article{Rattay1989,
  langid = {english},
  title = {Analysis of Models for Extracellular Fiber Stimulation},
  volume = {36},
  issn = {00189294},
  url = {http://ieeexplore.ieee.org/document/32099/},
  doi = {10.1109/10.32099},
  abstract = {This paper presents the mathematical basis for analysis as well as for the computer simulation of the stimulus/response characteristics of nerve or muscle fibers. The results follow from the extracellular potential along the fiber as a function of electrode geometry. The theory is of a general nature but special investigations are made on monopolar, bipolar, and ring electrodes. Stimulations with monopolar electrodes show better recruitment characteristics than ring electrodes.},
  number = {7},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  urldate = {2019-03-30},
  date = {1989-07},
  pages = {676-682},
  author = {Rattay, F.},
  file = {/Users/qualia/Documents/Papers/1989 - Rattay - Analysis of Models for Extracellular Fiber Stimulation.pdf;/Users/qualia/Documents/Papers/Rattay - 1989 - Analysis of models for extracellular fiber stimula.pdf}
}

@article{Rafols1976,
  langid = {english},
  title = {The Neurons in the Primate Subthalamic Nucleus: {{A Golgi}} and Electron Microscopic Study},
  volume = {168},
  issn = {0021-9967, 1096-9861},
  url = {http://doi.wiley.com/10.1002/cne.901680105},
  doi = {10.1002/cne.901680105},
  shorttitle = {The Neurons in the Primate Subthalamic Nucleus},
  abstract = {In Golgi preparations of the adult monkey (Macaca mulatta) local interneurons and two varieties of principal neurons, radiating and elongated fusiform, are found in the subthalamic nucleus. The cell bodies of the radiating neurons have a few delicate, somatic spines some of which are occasionally bilobed and trilobed. Five to eight dendritic trunks give rise to branching, tapering dendrites, which may extend for over 400 microns. These dendrites are much thinner than the dendrites in the globus pallidus and the substantia nigra. Some neurons have many and some neurons have few dendritic spines. When numerous the dendritic spines are concentrated on the dendritic trunks and proximal dendrites. The relatively few elongated fusiform neurons are found not only in the capsule but also i n the center of the nucleus. Most dendrites emerge from the opposite poles of their smooth surfaced cell bodies. They have a few dendritic spines. Some of these dendrites extend for more than 750 microns. In 1-micron thick plastic sections lipofuscin granules are present i n some but not all principal neuron cell bodies of the monkey (Macaca mulatta); but these granules are present i n all principal neuron cell bodies of the pig-tail monkey (Macaca nemestrina) and of the squirrel monkey ( S a i m i r i sciureus).},
  number = {1},
  journaltitle = {The Journal of Comparative Neurology},
  urldate = {2019-03-30},
  date = {1976-07-01},
  pages = {75-111},
  author = {Rafols, Jos\dbend{} A. and Fox, Clement A.},
  file = {/Users/qualia/Documents/Papers/1976 - Rafols, Fox - The neurons in the primate subthalamic nucleus a Golgi and electron microscopic study.pdf;/Users/qualia/Documents/Papers/Rafols and Fox - 1976 - The neurons in the primate subthalamic nucleus A .pdf}
}

@article{Wickham,
  langid = {english},
  title = {A Grammar of Graphics: Past, Present, and Future},
  pages = {45},
  author = {Wickham, Hadley},
  file = {/Users/qualia/Documents/Papers/Wickham - A grammar of graphics past, present, and future.pdf}
}

@article{Posner1980,
  langid = {english},
  title = {Orienting of Attention},
  volume = {32},
  issn = {0033-555X},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00335558008248231},
  doi = {10.1080/00335558008248231},
  number = {1},
  journaltitle = {Quarterly Journal of Experimental Psychology},
  urldate = {2019-03-30},
  date = {1980-02},
  pages = {3-25},
  author = {Posner, Michael I.},
  file = {/Users/qualia/Documents/Papers/1980 - Posner - ORIENTING OF ATTENTION.pdf;/Users/qualia/Documents/Papers/Posner - 1980 - Orienting of attention.pdf}
}

@article{Neyman1976,
  langid = {english},
  title = {Tests of Statistical Hypotheses and Their Use in Studies of Natural Phenomena},
  volume = {5},
  issn = {0361-0926, 1532-415X},
  url = {http://www.tandfonline.com/doi/abs/10.1080/03610927608827392},
  doi = {10.1080/03610927608827392},
  abstract = {Contrary t o ideas suggested by the t i t l e o f the conference a t which t h e present paper was presented, t h e a u t h o r i s n o t aware o f a conceptual difference between a " t e s t o f a s t a t i s t i c a l hypothesis" and a " t e s t o f s i g n i f i c a n c e " and uses these terms i n t e r changeably. A study o f any serious substantive problem involves a sequence o f i n c i d e n t s a t which one i s forced t o pause and cons i d e r what t o do next. I n an e f f o r t t o reduce the frequency o f misdirected a c t i v i t i e s one uses s t a t i s t i c a l tests. The procedure i s i l l u s t r a t e d on two examples: (i)Le Cam's (and a s s o c i a t e s ' ) study o f imnunotherapy o f cancer and (ii)a socio-economic experiment r e l a t i n g t o low-income homeownership problems.},
  number = {8},
  journaltitle = {Communications in Statistics - Theory and Methods},
  urldate = {2019-03-30},
  date = {1976-01},
  pages = {737-751},
  author = {Neyman, Jerzy},
  file = {/Users/qualia/Documents/Papers/1976 - Neyman - Tests of statistical hypotheses and their use in studies of natural phenomena.pdf;/Users/qualia/Documents/Papers/Neyman - 1976 - Tests of statistical hypotheses and their use in s.pdf}
}

@incollection{Newell1973,
  langid = {english},
  title = {{{YOU CAN}}'{{T PLAY}} 20 {{QUESTIONS WITH NATURE AND WIN}}: {{PROJECTIVE COMMENTS ON THE PAPERS OF THIS SYMPOSIUM}}},
  isbn = {978-0-12-170150-5},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B9780121701505500123},
  shorttitle = {{{YOU CAN}}'{{T PLAY}} 20 {{QUESTIONS WITH NATURE AND WIN}}},
  booktitle = {Visual {{Information Processing}}},
  publisher = {{Elsevier}},
  urldate = {2019-03-30},
  date = {1973},
  pages = {283-308},
  author = {Newell, Allen},
  file = {/Users/qualia/Documents/Papers/1973 - Newell - You can't play 20 questions with nature and win Projective comments on the papers of this symposium.pdf;/Users/qualia/Documents/Papers/Newell - 1973 - YOU CAN'T PLAY 20 QUESTIONS WITH NATURE AND WIN P.pdf},
  doi = {10.1016/B978-0-12-170150-5.50012-3}
}

@article{Nauta1978,
  langid = {english},
  title = {Efferent Projections of the Subthalamic Nucleus: {{An}} Autoradiographic Study in Monkey and Cat},
  volume = {180},
  issn = {0021-9967, 1096-9861},
  url = {http://doi.wiley.com/10.1002/cne.901800102},
  doi = {10.1002/cne.901800102},
  shorttitle = {Efferent Projections of the Subthalamic Nucleus},
  abstract = {The efferent projections of the subthalamic nucleus were studied with the autoradiographic tracing technique in Rhesus monkey and cat. From the data i t appears that the major efferent projections of the nucleus are to the pallidal complex and the substantia nigra. In both monkey and cat, the projection to the pallidal complex is truly massive and is directed a t both pallidal segments. The projection field includes an infracommissural part of the pallidal complex bordering on the substantia innominata. In the monkey the termination in the pallidal complex is organized in several characteristic bands oriented parallel to the medullary laminae. The subthalamo-pallidal projection in monkey further appears to be topographically organized. The projections to the substantia nigra is prominent in both cat and monkey though not as massive as that to the pallidal complex. The distribution of termination in the substantia nigra favors the more ventral strata near the cerebral peduncle. In the monkey the terminal distribution appears to avoid regions of the substantia nigra containing pigmented neurons and it is suggested that the subthalamonigral pathway may prefer non-dopaminergic neurons. In addition to the above major projections, sparse projections were noted to the thalamic nuclei ventralis lateralis and ventralis anterior, to the putamen, and to the mesencephalic nucleus tegmenti pedunculopontinus, pars compacta. The findings are discussed.},
  number = {1},
  journaltitle = {The Journal of Comparative Neurology},
  urldate = {2019-03-30},
  date = {1978-07-01},
  pages = {1-16},
  author = {Nauta, Haring J. W. and Cole, Monroe},
  file = {/Users/qualia/Documents/Papers/1978 - Nauta, Cole - Efferent projections of the subthalamic nucleus An autoradiographic study in monkey and cat.pdf;/Users/qualia/Documents/Papers/Nauta and Cole - 1978 - Efferent projections of the subthalamic nucleus A.pdf}
}

@article{Morris1981,
  langid = {english},
  title = {Voltage Oscillations in the Barnacle Giant Muscle Fiber},
  volume = {35},
  issn = {00063495},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0006349581847820},
  doi = {10.1016/S0006-3495(81)84782-0},
  abstract = {Barnacle muscle fibers subjected to constant current stimulation produce a variety of types of oscillatory behavior when the internal medium contains the Ca"+ chelator EGTA. Oscillations are abolished if Ca"+ is removed from the external medium, or if the K+ conductance is blocked. Available voltage-clamp data indicate that the cell's active conductance systems are exceptionally simple. Given the complexity of barnacle fiber voltage behavior, this seems paradoxical. This paper presents an analysis of the possible modes of behavior available to a system of two noninactivating conductance mechanisms, and indicates a good correspondence to the types of behavior exhibited by barnacle fiber. The differential equations of a simple equivalent circuit for the fiber are dealt with by means of some of the mathematical techniques of nonlinear mechanics. General features of the system are (a) a propensity to produce damped or sustained oscillations over a rather broad parameter range, and (b) considerable latitude in the shape of the oscillatory potentials. It is concluded that for cells subject to changeable parameters (either from cell to cell or with time during cellular activity), a system dominated by two noninactivating conductances can exhibit varied oscillatory and bistable behavior.},
  number = {1},
  journaltitle = {Biophysical Journal},
  urldate = {2019-03-30},
  date = {1981-07},
  pages = {193-213},
  author = {Morris, C. and Lecar, H.},
  file = {/Users/qualia/Documents/Papers/1981 - Morris, Lecar - Voltage oscillations in the barnacle giant muscle fiber.pdf;/Users/qualia/Documents/Papers/Morris and Lecar - 1981 - Voltage oscillations in the barnacle giant muscle .pdf}
}

@article{McNeal1976,
  langid = {english},
  title = {Analysis of a {{Model}} for {{Excitation}} of {{Myelinated Nerve}}},
  volume = {BME-23},
  issn = {0018-9294},
  url = {http://ieeexplore.ieee.org/document/4121058/},
  doi = {10.1109/TBME.1976.324593},
  abstract = {Excellent models have been presented in the literature which relate membrane potential to transverse membrane current and which describe the propagation of action potentials along the axon, for both myelinated and nonmyelinated fibers. There is not, however, an adequate model for nerve excitation which allows one to compute the threshold of a nerve fiber for pulses of finite duration using electrodes that are not in direct contact with the fiber. This paper considers this problem and presents a model of the electrical properties of myelinated nerve which describes the time course of events following stimulus application up to the initiation of the action potential. The time-varying current and potential at all nodes can be computed from the model, and the strength-duration curve can be determined for arbitrary electrode geometries, although only the case of a monopolar electrode is considered in this paper. It is shown that even when the stimulus is a constant-current pulse, the membrane current at the nodes varies considerably with time. The strength-duration curve calculated from the model is consistent with previously published experimental data, and the model provides a quantitative relationship between threshold and fiber diameter which shows there is less selectivity among fibers of large diameter than those of small diameter.},
  number = {4},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  urldate = {2019-03-30},
  date = {1976-07},
  pages = {329-337},
  author = {McNeal, Donald R.},
  file = {/Users/qualia/Documents/Papers/1976 - Mcneal - Analysis of a Model for Excitation of Myelinated Nerve.pdf;/Users/qualia/Documents/Papers/McNeal - 1976 - Analysis of a Model for Excitation of Myelinated N.pdf}
}

@article{McGill1978,
  langid = {english},
  title = {Variations of {{Box Plots}}},
  volume = {32},
  issn = {00031305},
  url = {https://www.jstor.org/stable/2683468?origin=crossref},
  doi = {10.2307/2683468},
  number = {1},
  journaltitle = {The American Statistician},
  urldate = {2019-03-30},
  date = {1978-02},
  pages = {12},
  author = {McGill, Robert and Tukey, John W. and Larsen, Wayne A.},
  file = {/Users/qualia/Documents/Papers/1978 - McGill, Tukey, Larsen - Variations of box plots.pdf;/Users/qualia/Documents/Papers/McGill et al. - 1978 - Variations of Box Plots.pdf}
}

@article{LopesdaSilva1973,
  langid = {english},
  title = {Organization of Thalamic and Cortical Alpha Rhythms: {{Spectra}} and Coherences},
  volume = {35},
  issn = {00134694},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0013469473902162},
  doi = {10.1016/0013-4694(73)90216-2},
  shorttitle = {Organization of Thalamic and Cortical Alpha Rhythms},
  number = {6},
  journaltitle = {Electroencephalography and Clinical Neurophysiology},
  urldate = {2019-03-30},
  date = {1973-12},
  pages = {627-639},
  author = {Lopes da Silva, F.H and van Lierop, T.H.M.T and Schrijer, C.F and Storm van Leeuwen, W},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/1973 - Lierop, Schrijer, Leeuwen - 1973b). Notwithstanding recent advances on physio- logical data on thalamic rhythmic activity in anim.pdf;/Users/qualia/Documents/Papers/Lopes da Silva et al. - 1973 - Organization of thalamic and cortical alpha rhythm.pdf}
}

@article{Kita1983,
  langid = {english},
  title = {The Morphology of Intracellularly Labeled Rat Subthalamic Neurons: {{A}} Light Microscopic Analysis},
  volume = {215},
  issn = {0021-9967, 1096-9861},
  url = {http://doi.wiley.com/10.1002/cne.902150302},
  doi = {10.1002/cne.902150302},
  shorttitle = {The Morphology of Intracellularly Labeled Rat Subthalamic Neurons},
  abstract = {Light microscopic analysis of rat subthalamic (STH) neurons which were intracellularly labeled with horseradish peroxidase, following the acquisition of electrophysiologicaldata, revealed the following: (1)The somata of STH neurons were polygonal or oval with occasionally a few somatic spines. Uusally three or four primary dendrites arose from the soma. Dendritic trunks tapered slightly and divided into long, thin, sparsely spined branches. Dendrites of some STH neurons extended into the cerebral peduncle. (2) Reconstruction of the dendritic field was made in three different planes. In either sagittal or frontal planes, the dendritic field was usually oval and the long axis was parallel to the main axis of STH. In the horizontal plane, the dendritic field of all neurons was polygonal. (3)The axons of all the neurons analyzed originated from the soma and were traced beyond the borders of STH, thus indicating that they were projection neurons. All the parent axons bifurcated at least once. After bifurcation, one axon branch coursed dorsolaterally within the cerebral peduncle and terminated in the globus pallidus. The other branch coursed caudally or mediocaudally and arborized in the substantia nigra. Frequently, the axon branches projecting toward the globus pallidus emitted fine axon collaterals within the entopeduncular nucleus. (4)About one-half of the analyzed STH neurons had intranuclear axon collaterals. The neurons with intranuclear collaterals had a higher dendritic tipslstems ratio than neurons without intranuclear collatera l \textasciitilde{}T. his observation indicated that STH neurons could be divided into two groups according to their axonal morphology. (5)The axonal terminal arborization observed in all the target sites (i.e., globus pallidus, entopeduncular nucleus, STH, and substantia nigra) were formed with varicose collateral branches which also gave rise to short filaments with beaded endings. Some of these projection neurons could therefore communicate with the target neurons in the globus pallidus, substantia nigra, entopeduncular nucleus, as well as STH through their collateral system.},
  number = {3},
  journaltitle = {The Journal of Comparative Neurology},
  urldate = {2019-03-30},
  date = {1983-04-10},
  pages = {245-257},
  author = {Kita, H. and Chang, H. T. and Kitai, S. T.},
  file = {/Users/qualia/Documents/Papers/1983 - Kita, Chang, Kitai - The morphology of intracellularly labelled rat subthalamic nucleus a light microscopic analysis.pdf;/Users/qualia/Documents/Papers/Kita et al. - 1983 - The morphology of intracellularly labeled rat subt.pdf}
}

@article{Freeman1972,
  langid = {english},
  title = {Linear {{Analysis}} of the {{Dynamics}} of {{Neural Masses}}},
  volume = {1},
  issn = {0084-6589, 0084-6589},
  url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.bb.01.060172.001301},
  doi = {10.1146/annurev.bb.01.060172.001301},
  number = {1},
  journaltitle = {Annual Review of Biophysics and Bioengineering},
  urldate = {2019-03-30},
  date = {1972-06},
  pages = {225-256},
  author = {Freeman, W J},
  file = {/Users/qualia/Documents/Papers/1972 - Freeman - Linear analysis of the dynamics of neural masses.pdf;/Users/qualia/Documents/Papers/Freeman - 1972 - Linear Analysis of the Dynamics of Neural Masses.pdf}
}

@article{Fowler,
  langid = {english},
  title = {Data {{Assimilation}} Tutorial on the {{Kalman}} filter},
  pages = {14},
  author = {Fowler, A},
  file = {/Users/qualia/Documents/Papers/1963 - Fowler - Data Assimilation tutorial on the Kalman filter.pdf;/Users/qualia/Documents/Papers/Fowler - Data Assimilation tutorial on the Kalman ﬁlter.pdf}
}

@book{Crank1975,
  langid = {english},
  location = {{Oxford, [Eng]}},
  title = {The Mathematics of Diffusion},
  edition = {2d ed},
  isbn = {978-0-19-853344-3},
  pagetotal = {414},
  publisher = {{Clarendon Press}},
  date = {1975},
  keywords = {Diffusion},
  author = {Crank, John},
  file = {/Users/qualia/Documents/Papers/1975 - Crank - THE MATHEMATICS OF DIFFUSION.pdf;/Users/qualia/Documents/Papers/Crank - 1975 - The mathematics of diffusion.pdf}
}

@article{Chernoff1986,
  langid = {english},
  title = {Numerical {{Solutions}} for {{Bayes Sequential Decision Problems}}},
  volume = {7},
  issn = {0196-5204, 2168-3417},
  url = {http://epubs.siam.org/doi/10.1137/0907003},
  doi = {10.1137/0907003},
  abstract = {Certain sequential decision problems involving normal random variables reduce to optimal stopping problems which can be related to the solution of corresponding free boundary problems for the heat equation. The numerical solution of these free boundary problems can then be approximated by calculating the solution of simpler optimal stopping problems by backward induction. This approach is not well adapted for very precise results but is surprisingly effective for rough approximations. An estimate of the difference between the solutions of the related problems permits one to make continuity corrections which provide considerably improved accuracy. Further reductions in the necessary computational effort are possible by considering truncated procedures for one-sided boundaries and by exploiting monotone and symmetric boundaries.},
  number = {1},
  journaltitle = {SIAM Journal on Scientific and Statistical Computing},
  urldate = {2019-03-30},
  date = {1986-01},
  pages = {46-59},
  author = {Chernoff, Herman and Petkau, A. John},
  file = {/Users/qualia/Documents/Papers/1986 - Chernoff, Petkaut - Numerical solutions for bayes sequential decision.pdf;/Users/qualia/Documents/Papers/Chernoff and Petkau - 1986 - Numerical Solutions for Bayes Sequential Decision .pdf}
}

@article{Canteras1990,
  langid = {english},
  title = {Afferent Connections of the Subthalamic Nucleus: A Combined Retrograde and Anterograde Horseradish Peroxidase Study in the Rat},
  volume = {513},
  issn = {00068993},
  url = {https://linkinghub.elsevier.com/retrieve/pii/000689939091087W},
  doi = {10.1016/0006-8993(90)91087-W},
  shorttitle = {Afferent Connections of the Subthalamic Nucleus},
  number = {1},
  journaltitle = {Brain Research},
  urldate = {2019-03-30},
  date = {1990-04},
  pages = {43-59},
  author = {Canteras, Newton S. and Shammah-Lagnado, Sara J. and Silva, Bomfim A. and Ricardo, Juarez A.},
  file = {/Users/qualia/Documents/Papers/1988 - Canteras et al. - Somatosensory Inputs To the Subthalamic Nucleus - a Combined Retrograde and Anterograde Horseradish-Peroxidase.pdf;/Users/qualia/Documents/Papers/Canteras et al. - 1990 - Afferent connections of the subthalamic nucleus a.pdf}
}

@article{Burke1956,
  langid = {english},
  title = {The Electrical Properties of the Slow Muscle Fibre Membrane},
  volume = {132},
  issn = {00223751},
  url = {http://doi.wiley.com/10.1113/jphysiol.1956.sp005551},
  doi = {10.1113/jphysiol.1956.sp005551},
  number = {3},
  journaltitle = {The Journal of Physiology},
  urldate = {2019-03-30},
  date = {1956-06-28},
  pages = {586-598},
  author = {Burke, W. and Ginsborg, B. L.},
  file = {/Users/qualia/Documents/Papers/1956 - Burke, Ginsborg - THlE ELECTRICAL PROPERTIES OF THE SLOW MUSCLE FIBRE MEMBRANE From the Biophysics Department , University Colleg.pdf;/Users/qualia/Documents/Papers/Burke and Ginsborg - 1956 - The electrical properties of the slow muscle fibre.pdf}
}

@article{Burch1959,
  langid = {english},
  title = {Automatic Analysis of the Electroencephalogram: A Review and Classification of Systems},
  volume = {11},
  issn = {00134694},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0013469459901336},
  doi = {10.1016/0013-4694(59)90133-6},
  shorttitle = {Automatic Analysis of the Electroencephalogram},
  number = {4},
  journaltitle = {Electroencephalography and Clinical Neurophysiology},
  urldate = {2019-03-30},
  date = {1959-11},
  pages = {827-834},
  author = {Burch, Neil R},
  file = {/Users/qualia/Documents/Papers/1958 - Burch - ANALYSIS OF THE ELECTROENCEPHALOGRAM.pdf;/Users/qualia/Documents/Papers/Burch - 1959 - Automatic analysis of the electroencephalogram a .pdf}
}

@book{Braun1983,
  langid = {english},
  location = {{New York, NY}},
  title = {Differential {{Equation Models}}},
  isbn = {978-1-4612-5427-0 978-1-4612-5429-4},
  url = {http://dx.doi.org/10.1007/978-1-4612-5427-0},
  abstract = {The purpose of this four volume series is to make available for college teachers and students samples of important and realistic applications of mathematics which can be covered in undergraduate programs. The goal is to provide illustrations of how modem mathematics is actually employed to solve relevant contemporary problems. Although these independent chapters were prepared primarily for teachers in the general mathematical sciences, they should prove valuable to students, teachers, and research scientists in many of the fields of application as well. Prerequisites for each chapter and suggestions for the teacher are provided. Several of these chapters have been tested in a variety of classroom settings, and all have undergone extensive peer review and revision. Illustrations and exercises are included in most chapters. Some units can be covered in one class, whereas others provide sufficient material for a few weeks of class time. Volume 1 contains 23 chapters and deals with differential equations and, in the last four chapters, problems leading to partial differential equations. Applications are taken from medicine, biology, traffic systems and several other fields. The 14 chapters in Volume 2 are devoted mostly to problems arising in political science, but they also address questions appearing in sociology and ecology. Topics covered include voting systems, weighted voting, proportional representation, coalitional values, and committees. The 14 chapters in Volume 3 emphasize discrete mathematical methods such as those which arise in graph theory, combinatorics, and networks.},
  publisher = {{Springer New York}},
  urldate = {2019-03-30},
  date = {1983},
  author = {Braun, Martin and Coleman, Courtney S and Drew, Donald A},
  file = {/Users/qualia/Documents/Papers/1983 - Lucas - Differential Equation Models.pdf;/Users/qualia/Documents/Papers/Braun et al. - 1983 - Differential Equation Models.pdf},
  note = {OCLC: 840280008}
}

@article{Bjursten1976,
  langid = {english},
  title = {Behavioural Repertory of Cats without Cerebral Cortex from Infancy},
  volume = {25},
  issn = {0014-4819, 1432-1106},
  url = {http://link.springer.com/10.1007/BF00234897},
  doi = {10.1007/BF00234897},
  abstract = {Bilateral removal of the cerebral cortex was made in cats neonatally. Spontaneous and imposed behaviour was studied while they were growing up and after they had become adult. Special emphasis was put on the utilization of visual cues and on learning. The cats ate, drank and groomed themselves adequately. Adequate maternal and female sexual behaviour was observed. They utilized the visual and haptic senses with respect to external space. Two cats were trained to perform visual discrimination in a T-maze. The adequacy of the behaviour of these cats is compared to that of animals with similar lesions made at maturity.},
  number = {2},
  journaltitle = {Experimental Brain Research},
  urldate = {2019-03-30},
  date = {1976-05},
  author = {Bjursten, L.-M. and Norrsell, K. and Norrsell, U.},
  file = {/Users/qualia/Documents/Papers/Bjursten et al. - 1976 - Behavioural repertory of cats without cerebral cor.pdf}
}

@article{Wang2019,
  langid = {english},
  title = {Monkeys Are Curious about Counterfactual Outcomes},
  volume = {189},
  issn = {00100277},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027719300642},
  doi = {10.1016/j.cognition.2019.03.009},
  abstract = {Many non-human animals show exploratory behaviors. It remains unclear whether any possess human-like curiosity. We previously proposed three criteria for applying the term curiosity to animal behavior: (1) the subject is willing to sacrifice reward to obtain information, (2) the information provides no immediate instrumental or strategic benefit, and (3) the amount the subject is willing to pay depends systematically on the amount of information available. In previous work on information-seeking in animals, information generally predicts upcoming rewards, and animals' decisions may therefore be a byproduct of reinforcement processes. Here we get around this potential confound by taking advantage of macaques' ability to reason counterfactually (that is, about outcomes that could have occurred had the subject chosen differently). Specifically, macaques sacrificed fluid reward to obtain information about counterfactual outcomes. Moreover, their willingness to pay scaled with the information (Shannon entropy) offered by the counterfactual option. These results demonstrate the existence of human-like curiosity in non-human primates according to our criteria, which circumvent several confounds associated with less stringent criteria.},
  journaltitle = {Cognition},
  urldate = {2019-03-30},
  date = {2019-08},
  pages = {1-10},
  author = {Wang, Maya Zhe and Hayden, Benjamin Y.},
  file = {/Users/qualia/Documents/Papers/Wang and Hayden - 2019 - Monkeys are curious about counterfactual outcomes.pdf}
}

@article{Radulescu2019,
  langid = {english},
  title = {Holistic {{Reinforcement Learning}}: {{The Role}} of {{Structure}} and {{Attention}}},
  volume = {23},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661319300361},
  doi = {10.1016/j.tics.2019.01.010},
  shorttitle = {Holistic {{Reinforcement Learning}}},
  number = {4},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2019-04},
  pages = {278-292},
  author = {Radulescu, Angela and Niv, Yael and Ballard, Ian},
  file = {/Users/qualia/Documents/Papers/Radulescu et al. - 2019 - Holistic Reinforcement Learning The Role of Struc.pdf}
}

@article{Neftci,
  langid = {english},
  title = {Surrogate {{Gradient Learning}} in {{Spiking Neural Networks}}},
  abstract = {A growing number of neuromorphic spiking neural network processors that emulate biological neural networks create an imminent need for methods and tools to enable them to solve real-world signal processing problems. Like conventional neural networks, spiking neural networks are particularly efficient when trained on real, domain specific data. However, their training requires overcoming a number of challenges linked to their binary and dynamical nature. This tutorial elucidates step-by-step the problems typically encountered when training spiking neural networks, and guides the reader through the key concepts of synaptic plasticity and datadriven learning in the spiking setting. To that end, it gives an overview of existing approaches and provides an introduction to surrogate gradient methods, specifically, as a particularly flexible and efficient method to overcome the aforementioned challenges.},
  pages = {21},
  author = {Neftci, Emre O and Mostafa, Hesham and Zenke, Friedemann},
  file = {/Users/qualia/Documents/Papers/Neftci et al. - Surrogate Gradient Learning in Spiking Neural Netw.pdf}
}

@article{Howard2019,
  langid = {english},
  title = {Numerical Cognition in Honeybees Enables Addition and Subtraction},
  volume = {5},
  issn = {2375-2548},
  url = {http://advances.sciencemag.org/lookup/doi/10.1126/sciadv.aav0961},
  doi = {10.1126/sciadv.aav0961},
  number = {2},
  journaltitle = {Science Advances},
  urldate = {2019-03-30},
  date = {2019-02},
  pages = {eaav0961},
  author = {Howard, Scarlett R. and Avargu\`es-Weber, Aurore and Garcia, Jair E. and Greentree, Andrew D. and Dyer, Adrian G.},
  file = {/Users/qualia/Documents/Papers/Howard et al. - 2019 - Numerical cognition in honeybees enables addition .pdf}
}

@article{Hocker2019,
  langid = {english},
  title = {Myopic Control of Neural Dynamics},
  url = {http://biorxiv.org/lookup/doi/10.1101/241299},
  doi = {10.1101/241299},
  abstract = {Manipulating the dynamics of neural systems through targeted stimulation is a frontier of research and clinical neuroscience; however, the control schemes considered for neural systems are mismatched for the unique needs of manipulating neural dynamics. An appropriate control method should respect the variability in neural systems, incorporating moment to moment ``input'' to the neural dynamics and behaving based on the current neural state, irrespective of the past trajectory. We propose such a controller under a nonlinear state-space feedback framework that steers one dynamical system to function as through it were another dynamical system entirely. This ``myopic'' controller is formulated through a novel variant of a model reference control cost that manipulates dynamics in a short-sighted manner that only sets a target trajectory of a single time step into the future (hence its myopic nature), which omits the need to pre-calculate a rigid and computationally costly neural feedback control solution. To demonstrate the breadth of this control's utility, two examples with distinctly different applications in neuroscience are studied. First, we show the myopic control's utility to probe the causal link between dynamics and behavior for cognitive processes by transforming a winnertake-all decision-making system to operate as a robust neural integrator of evidence. Second, an unhealthy motor-like system containing an unwanted beta-oscillation spiral attractor is controlled to function as a healthy motor system, a relevant clinical example for neurological disorders.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2019-01-15},
  author = {Hocker, David and Park, Il Memming},
  file = {/Users/qualia/Documents/Papers/Hocker and Park - 2019 - Myopic control of neural dynamics 2.pdf;/Users/qualia/Documents/Papers/Hocker and Park - 2019 - Myopic control of neural dynamics.pdf}
}

@article{Insanally2019,
  langid = {english},
  title = {Spike-Timing-Dependent Ensemble Encoding by Non-Classically Responsive Cortical Neurons},
  volume = {8},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/42409},
  doi = {10.7554/eLife.42409},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2019-01-28},
  author = {Insanally, Michele N and Carcea, Ioana and Field, Rachel E and Rodgers, Chris C and DePasquale, Brian and Rajan, Kanaka and DeWeese, Michael R and Albanna, Badr F and Froemke, Robert C},
  file = {/Users/qualia/Documents/Papers/Insanally et al. - 2019 - Spike-timing-dependent ensemble encoding by non-cl.pdf;/Users/qualia/Documents/Papers/Insanally et al. - 2019 - Spike-timing-dependent ensemble encoding by non-cl.pdf}
}

@article{Zhang,
  langid = {english},
  title = {A {{Study}} on {{Overfitting}} in {{Deep Reinforcement Learning}}},
  abstract = {Recent years have witnessed significant progresses in deep Reinforcement Learning (RL). Empowered with large scale neural networks, carefully designed architectures, novel training algorithms and massively parallel computing devices, researchers are able to attack many challenging RL problems. However, in machine learning, more training power comes with a potential risk of more overfitting. As deep RL techniques are being applied to critical problems such as healthcare and finance, it is important to understand the generalization behaviors of the trained agents. In this paper, we conduct a systematic study of standard RL agents and find that they could overfit in various ways. Moreover, overfitting could happen ``robustly'': commonly used techniques in RL that add stochasticity do not necessarily prevent or detect overfitting. In particular, the same agents and learning algorithms could have drastically different test performance, even when all of them achieve optimal rewards during training. The observations call for more principled and careful evaluation protocols in RL. We conclude with a general discussion on overfitting in RL and a study of the generalization behaviors from the perspective of inductive bias.},
  pages = {25},
  author = {Zhang, Chiyuan and Vinyals, Oriol and Munos, Remi and Bengio, Samy},
  file = {/Users/qualia/Documents/Papers/Zhang et al. - A Study on Overfitting in Deep Reinforcement Learn.pdf}
}

@article{Zhang2018,
  langid = {english},
  title = {Theta and {{Alpha Oscillations Are Traveling Waves}} in the {{Human Neocortex}}},
  volume = {98},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627318304173},
  doi = {10.1016/j.neuron.2018.05.019},
  abstract = {Human cognition requires the coordination of neural activity across widespread brain networks. Here, we describe a new mechanism for large-scale coordination in the human brain: traveling waves of theta and alpha oscillations. Examining direct brain recordings from neurosurgical patients performing a memory task, we found contiguous clusters of cortex in individual patients with oscillations at specific frequencies within 2 to 15 Hz. These oscillatory clusters displayed spatial phase gradients, indicating that they formed traveling waves that propagated at \$0.25\textendash{}0.75 m/s. Traveling waves were relevant behaviorally because their propagation correlated with task events and was more consistent when subjects performed the task well. Human traveling theta and alpha waves can be modeled by a network of coupled oscillators because the direction of wave propagation correlated with the spatial orientation of local frequency gradients. Our findings suggest that oscillations support brain connectivity by organizing neural processes across space and time.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2018-06},
  pages = {1269-1281.e4},
  author = {Zhang, Honghui and Watrous, Andrew J. and Patel, Ansh and Jacobs, Joshua},
  file = {/Users/qualia/Documents/Papers/Zhang et al. - 2018 - Theta and Alpha Oscillations Are Traveling Waves i.pdf}
}

@article{Yochum2018,
  langid = {english},
  title = {Reconstruction of Post-Synaptic Potentials by Reverse Modeling of Local Field Potentials},
  url = {http://biorxiv.org/lookup/doi/10.1101/346148},
  doi = {10.1101/346148},
  abstract = {Among electrophysiological signals, Local Field Potentials (LFPs) are extensively used to study brain activity, either in vivo or in vitro. LFPs are recorded with extracellular electrodes implanted in brain tissue. They reflect intermingled excitatory and inhibitory processes in neuronal assemblies. In cortical structures, LFPs mainly originate from the summation of post-synaptic potentials (PSPs), either excitatory (ePSPs) and inhibitory (iPSPs) generated at the level of pyramidal cells. The challenging issue, addressed in this paper, is to estimate, from a single extracellularly-recorded signal, both ePSP and iPSP components of the LFP. The proposed method is based on a model-based reverse engineering approach in which the measured LFP is fed into a physiologically-grounded neural mass model (mesoscopic level) in order to estimate the synaptic activity of a sub-population of pyramidal cells interacting with local GABAergic interneurons. The method was first validated using simulated LFPs for which excitatory and inhibitory components are known a priori and can thus serve as a ground truth. It was then evaluated on in vivo data (PTZ-induced seizures, rat; PTZ-induced excitability increase, mouse; epileptiform discharges, mouse) and on in clinico data (human seizures recorded with depth-EEG electrodes). Under these various conditions, results showed that the proposed reverse engineering method provides a reliable estimation of the average excitatory and inhibitory post-synaptic potentials at the origin of the measured LFPs. They also indicated that the method allows for monitoring of the excitation/inhibition ratio. The method has potential for multiple applications in neuroscience, typically when a time tracking of local excitability changes is required.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2018-09-20},
  author = {Yochum, Maxime and Modolo, Julien and Benquet, Pascal and Wendling, Fabrice},
  file = {/Users/qualia/Documents/Papers/Yochum et al. - 2018 - Reconstruction of post-synaptic potentials by reve.pdf}
}

@article{Yang,
  langid = {english},
  title = {Deep {{Neural Decision Trees}}},
  abstract = {Deep neural networks have been proven powerful at processing perceptual data, such as images and audio. However for tabular data, tree-based models are more popular. A nice property of tree-based models is their natural interpretability. In this work, we present Deep Neural Decision Trees (DNDT) \textendash{} tree models realised by neural networks. A DNDT is intrinsically interpretable, as it is a tree. Yet as it is also a neural network (NN), it can be easily implemented in NN toolkits, and trained with gradient descent rather than greedy splitting. We evaluate DNDT on several tabular datasets, verify its efficacy, and investigate similarities and differences between DNDT and vanilla decision trees. Interestingly, DNDT self-prunes at both split and feature-level.},
  pages = {7},
  author = {Yang, Yongxin and Morillo, Irene Garcia and Hospedales, Timothy M},
  file = {/Users/qualia/Documents/Papers/Yang et al. - Deep Neural Decision Trees.pdf}
}

@article{Wu2018,
  langid = {english},
  title = {Generalization Guides Human Exploration in Vast Decision Spaces},
  volume = {2},
  issn = {2397-3374},
  url = {http://www.nature.com/articles/s41562-018-0467-4},
  doi = {10.1038/s41562-018-0467-4},
  number = {12},
  journaltitle = {Nature Human Behaviour},
  urldate = {2019-03-30},
  date = {2018-12},
  pages = {915-924},
  author = {Wu, Charley M. and Schulz, Eric and Speekenbrink, Maarten and Nelson, Jonathan D. and Meder, Bj\"orn},
  file = {/Users/qualia/Documents/Papers/Wu et al. - 2018 - Generalization guides human exploration in vast de.pdf}
}

@inproceedings{Wilson2018,
  langid = {english},
  location = {{Kyoto, Japan}},
  title = {Evolving Simple Programs for Playing Atari Games},
  isbn = {978-1-4503-5618-3},
  url = {http://dl.acm.org/citation.cfm?doid=3205455.3205578},
  doi = {10.1145/3205455.3205578},
  abstract = {Cartesian Genetic Programming (CGP) has previously shown capabilities in image processing tasks by evolving programs with a function set specialized for computer vision. A similar approach can be applied to Atari playing. Programs are evolved using mixed type CGP with a function set suited for matrix operations, including image processing, but allowing for controller behavior to emerge. While the programs are relatively small, many controllers are competitive with state of the art methods for the Atari benchmark set and require less training time. By evaluating the programs of the best evolved individuals, simple but e ective strategies can be found.},
  eventtitle = {The {{Genetic}} and {{Evolutionary Computation Conference}}},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference}} on   - {{GECCO}} '18},
  publisher = {{ACM Press}},
  urldate = {2019-03-30},
  date = {2018},
  pages = {229-236},
  author = {Wilson, Dennis G and Cussat-Blanc, Sylvain and Luga, Herv\'e and Miller, Julian F},
  file = {/Users/qualia/Documents/Papers/Wilson et al. - 2018 - Evolving simple programs for playing atari games.pdf}
}

@article{Wayne,
  langid = {english},
  title = {Unsupervised {{Predictive Memory}} in a {{Goal}}-{{Directed Agent}}},
  pages = {57},
  author = {Wayne, Greg and Hung, Chia-Chun and Amos, David and Mirza, Mehdi and Ahuja, Arun and Grabska-Barwinska, Agnieszka and Rae, Jack and Mirowski, Piotr and Leibo, Joel Z and Santoro, Adam and Gemici, Mevlana and Reynolds, Malcolm and Harley, Tim and Abramson, Josh and Mohamed, Shakir and Rezende, Danilo and Saxton, David and Cain, Adam and Hillier, Chloe and Silver, David and Kavukcuoglu, Koray and Botvinick, Matt and Hassabis, Demis and Lillicrap, Timothy},
  file = {/Users/qualia/Documents/Papers/Wayne et al. - Unsupervised Predictive Memory in a Goal-Directed .pdf}
}

@article{vanEde2018,
  langid = {english},
  title = {Neural {{Oscillations}}: {{Sustained Rhythms}} or {{Transient Burst}}-{{Events}}?},
  volume = {41},
  issn = {01662236},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223618301036},
  doi = {10.1016/j.tins.2018.04.004},
  shorttitle = {Neural {{Oscillations}}},
  number = {7},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {2018-07},
  pages = {415-417},
  author = {van Ede, Freek and Quinn, Andrew J. and Woolrich, Mark W. and Nobre, Anna C.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/van Ede et al. - 2018 - Neural Oscillations Sustained Rhythms or Transien.pdf}
}

@article{Tuyls2018,
  langid = {english},
  title = {Symmetric {{Decomposition}} of {{Asymmetric Games}}},
  volume = {8},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/s41598-018-19194-4},
  doi = {10.1038/s41598-018-19194-4},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2018-12},
  author = {Tuyls, Karl and P\'erolat, Julien and Lanctot, Marc and Ostrovski, Georg and Savani, Rahul and Leibo, Joel Z and Ord, Toby and Graepel, Thore and Legg, Shane},
  file = {/Users/qualia/Documents/Papers/Tuyls et al. - 2018 - Symmetric Decomposition of Asymmetric Games.pdf}
}

@book{Sutton1998,
  langid = {english},
  location = {{Cambridge, Mass}},
  title = {Reinforcement Learning: An Introduction},
  isbn = {978-0-262-19398-6},
  shorttitle = {Reinforcement Learning},
  pagetotal = {322},
  series = {Adaptive Computation and Machine Learning},
  publisher = {{MIT Press}},
  date = {1998},
  keywords = {Reinforcement learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  file = {/Users/qualia/Documents/Papers/Sutton and Barto - 1998 - Reinforcement learning an introduction.pdf}
}

@article{Steinmetz2018,
  langid = {english},
  title = {Distributed Correlates of Visually-Guided Behavior across the Mouse Brain},
  url = {http://biorxiv.org/lookup/doi/10.1101/474437},
  doi = {10.1101/474437},
  abstract = {Behavior arises from neuronal activity, but it is not known how the active neurons are distributed across brain regions and how their activity unfolds in time. Here, we used high-density Neuropixels probes to record from \textasciitilde{}30,000 neurons in mice performing a visual contrast discrimination task. The task activated 60\% of the neurons, involving nearly all 42 recorded brain regions, well beyond the regions activated by passive visual stimulation. However, neurons selective for choice (left vs. right) were rare, and found mostly in midbrain, striatum, and frontal cortex. Those in midbrain were typically activated prior to contralateral choices and suppressed prior to ipsilateral choices, consistent with a competitive midbrain circuit for adjudicating the subject's choice. A brain-wide state shift distinguished trials in which visual stimuli led to movement. These results reveal concurrent representations of movement and choice in neurons widely distributed across the brain.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2018-11-20},
  author = {Steinmetz, Nicholas and Zatka-Haas, Peter and Carandini, Matteo and Harris, Kenneth},
  file = {/Users/qualia/Documents/Papers/Steinmetz et al. - 2018 - Distributed correlates of visually-guided behavior.pdf}
}

@article{Sims2018,
  langid = {english},
  title = {Efficient Coding Explains the Universal Law of Generalization in Human Perception},
  volume = {360},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aaq1118},
  doi = {10.1126/science.aaq1118},
  number = {6389},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2018-05-11},
  pages = {652-656},
  author = {Sims, Chris R.},
  file = {/Users/qualia/Documents/Papers/Sims - 2018 - Efficient coding explains the universal law of gen.pdf}
}

@article{Schuman2019,
  langid = {english},
  title = {Four {{Unique Interneuron Populations Reside}} in {{Neocortical Layer}} 1},
  volume = {39},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1613-18.2018},
  doi = {10.1523/JNEUROSCI.1613-18.2018},
  number = {1},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2019-01-02},
  pages = {125-139},
  author = {Schuman, Benjamin and Machold, Robert P. and Hashikawa, Yoshiko and Fuzik, J\'anos and Fishell, Gord J. and Rudy, Bernardo},
  file = {/Users/qualia/Documents/Papers/Schuman et al. - 2019 - Four Unique Interneuron Populations Reside in Neoc.pdf}
}

@article{Schulz2018,
  langid = {english},
  title = {Finding Structure in Multi-Armed Bandits},
  url = {http://biorxiv.org/lookup/doi/10.1101/432534},
  doi = {10.1101/432534},
  abstract = {How do humans search for rewards? This question is commonly studied using multi-armed bandit tasks, which require participants to trade off exploration and exploitation. Standard multi-armed bandits assume that each option has an independent reward distribution. However, learning about options independently is unrealistic, since in the real world options often share an underlying structure. We introduce a class of structured bandit tasks, which we use to probe how generalization guides exploration. In a structured multi-armed bandit, options have a correlation structure dictated by a latent function. We focus on bandits in which rewards are linear functions of an option's spatial position. Across 5 experiments, we find evidence that participants utilize functional structure to guide their exploration, and also exhibit a learning-to-learn effect across rounds, becoming progressively faster at identifying the latent function. The experiments rule out several heuristic explanations, and show that the same findings obtain with non-linear functions. Comparing several models of learning and decision making, we find that the best model of human behavior in our tasks combines three computational mechanisms: (1) function learning, (2) clustering of reward distributions across rounds, and (3) uncertainty-guided exploration. Our results suggest that human reinforcement learning can utilize latent structure in sophisticated ways to improve efficiency.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2018-12-29},
  author = {Schulz, Eric and Franklin, Nicholas T and Gershman, Samuel J},
  file = {/Users/qualia/Documents/Papers/Schulz et al. - 2018 - Finding structure in multi-armed bandits.pdf}
}

@article{Phillips2018,
  langid = {english},
  title = {Face Recognition Accuracy of Forensic Examiners, Superrecognizers, and Face Recognition Algorithms},
  volume = {115},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1721355115},
  doi = {10.1073/pnas.1721355115},
  number = {24},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2018-06-12},
  pages = {6171-6176},
  author = {Phillips, P. Jonathon and Yates, Amy N. and Hu, Ying and Hahn, Carina A. and Noyes, Eilidh and Jackson, Kelsey and Cavazos, Jacqueline G. and Jeckeln, G\'eraldine and Ranjan, Rajeev and Sankaranarayanan, Swami and Chen, Jun-Cheng and Castillo, Carlos D. and Chellappa, Rama and White, David and O'Toole, Alice J.},
  file = {/Users/qualia/Documents/Papers/Phillips et al. - 2018 - Face recognition accuracy of forensic examiners, s.pdf}
}

@article{Pathak2018,
  langid = {english},
  title = {Model-{{Free Prediction}} of {{Large Spatiotemporally Chaotic Systems}} from {{Data}}: {{A Reservoir Computing Approach}}},
  volume = {120},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.120.024102},
  doi = {10.1103/PhysRevLett.120.024102},
  shorttitle = {Model-{{Free Prediction}} of {{Large Spatiotemporally Chaotic Systems}} from {{Data}}},
  number = {2},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2018-01-12},
  author = {Pathak, Jaideep and Hunt, Brian and Girvan, Michelle and Lu, Zhixin and Ott, Edward},
  file = {/Users/qualia/Documents/Papers/Pathak et al. - 2018 - Model-Free Prediction of Large Spatiotemporally Ch.pdf}
}

@article{Parpart2018,
  langid = {english},
  title = {Heuristics as {{Bayesian}} Inference under Extreme Priors},
  volume = {102},
  issn = {00100285},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028517303286},
  doi = {10.1016/j.cogpsych.2017.11.006},
  abstract = {Simple heuristics are often regarded as tractable decision strategies because they ignore a great deal of information in the input data. One puzzle is why heuristics can outperform full-information models, such as linear regression, which make full use of the available information. These ``lessis-more'' effects, in which a relatively simpler model outperforms a more complex model, are prevalent throughout cognitive science, and are frequently argued to demonstrate an inherent advantage of simplifying computation or ignoring information. In contrast, we show at the computational level (where algorithmic restrictions are set aside) that it is never optimal to discard information. Through a formal Bayesian analysis, we prove that popular heuristics, such as tallying and take-the-best, are formally equivalent to Bayesian inference under the limit of infinitely strong priors. Varying the strength of the prior yields a continuum of Bayesian models with the heuristics at one end and ordinary regression at the other. Critically, intermediate models perform better across all our simulations, suggesting that down-weighting information with the appropriate prior is preferable to entirely ignoring it. Rather than because of their simplicity, our analyses suggest heuristics perform well because they implement strong priors that approximate the actual structure of the environment. We end by considering how new heuristics could be derived by infinitely strengthening the priors of other Bayesian models. These formal results have implications for work in psychology, machine learning and economics.},
  journaltitle = {Cognitive Psychology},
  urldate = {2019-03-30},
  date = {2018-05},
  pages = {127-144},
  author = {Parpart, Paula and Jones, Matt and Love, Bradley C.},
  file = {/Users/qualia/Documents/Papers/Parpart et al. - 2018 - Heuristics as Bayesian inference under extreme pri.pdf;/Users/qualia/Documents/Papers/Parpart et al. - Heuristics as Bayesian inference under extreme pri.pdf}
}

@article{Nolte2018,
  langid = {english},
  title = {Cortical Reliability amid Noise and Chaos},
  url = {http://biorxiv.org/lookup/doi/10.1101/304121},
  doi = {10.1101/304121},
  abstract = {Typical responses of cortical neurons to identical sensory stimuli are highly variable. It has thus been proposed that the cortex primarily uses a rate code. However, other studies have argued for spike-time coding under certain conditions. The potential role of spike-time coding is constrained by the intrinsic variability of cortical circuits, which remains largely unexplored. Here, we quantified this intrinsic variability using a biophysical model of rat neocortical microcircuitry with biologically realistic noise sources. We found that stochastic neurotransmitter release is a critical component of this variability, which, amplified by recurrent connectivity, causes rapid chaotic divergence with a time constant on the order of 10-20 milliseconds. Surprisingly, weak thalamocortical stimuli can transiently overcome the chaos, and induce reliable spike times with millisecond precision. We show that this effect relies on recurrent cortical connectivity, and is not a simple effect of feed-forward thalamocortical input. We conclude that recurrent cortical architecture supports millisecond spike-time reliability amid noise and chaotic network dynamics, resolving a long-standing debate.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2018-06-06},
  author = {Nolte, Max and Reimann, Michael W and King, James G and Markram, Henry and Muller, Eilif B},
  file = {/Users/qualia/Documents/Papers/Nolte et al. - 2018 - Cortical reliability amid noise and chaos.pdf}
}

@article{Newman,
  langid = {english},
  title = {Limitations of the Asymptotic Approach to Dynamics},
  pages = {13},
  author = {Newman, Julian and Lucas, Maxime and Stefanovska, Aneta},
  file = {/Users/qualia/Documents/Papers/Newman et al. - Limitations of the asymptotic approach to dynamics.pdf}
}

@article{Muyesser,
  langid = {english},
  title = {Learning Model-Based Strategies in Simple Environments with Hierarchical q-Networks},
  abstract = {Recent advances in deep learning have allowed artificial agents to rival human-level performance on a wide range of complex tasks; however, the ability of these networks to learn generalizable strategies remains a pressing challenge. This critical limitation is due in part to two factors: the opaque information representation in deep neural networks and the complexity of the task environments in which they are typically deployed. Here we propose a novel Hierarchical Q-Network (HQN), motivated by theories of the hierarchical organization of the human prefrontal cortex, that attempts to identify lower dimensional patterns in the value landscape that can be exploited to construct an internal model of rules in simple environments. We draw on combinatorial games, where there exists a single optimal strategy for winning that generalizes across other features of the game, to probe the strategy generalization of the HQN and other reinforcement learning (RL) agents using variations of Wythoff's game. Traditional RL approaches failed to reach satisfactory performance on variants of Wythoff's Game; however, the HQN learned heuristic-like strategies that generalized across changes in board configuration. More importantly, the HQN allowed for transparent inspection of the agent's internal model of the game following training. Our results show how a biologically inspired hierarchical learner can facilitate learning abstract rules to promote robust and flexible action policies in simplified training environments with clearly delineated optimal strategies.},
  pages = {29},
  author = {Muyesser, Necati Alp and Dunovan, Kyle and Verstynen, Timothy},
  file = {/Users/qualia/Documents/Papers/Muyesser et al. - Learning model-based strategies in simple environm.pdf}
}

@article{Miller,
  langid = {english},
  title = {When {{Recurrent Models Don}}'t {{Need To Be Recurrent}}},
  abstract = {We prove stable recurrent neural networks are well approximated by feed-forward networks for the purpose of both inference and training by gradient descent. Our result applies to a broad range of non-linear recurrent neural networks under a natural stability condition, which we observe is also necessary. Complementing our theoretical findings, we verify the conclusions of our theory on both real and synthetic tasks. Furthermore, we demonstrate recurrent models satisfying the stability assumption of our theory can have excellent performance on real sequence learning tasks.},
  pages = {23},
  author = {Miller, John and Hardt, Moritz},
  file = {/Users/qualia/Documents/Papers/Miller and Hardt - When Recurrent Models Don’t Need To Be Recurrent.pdf}
}

@article{Martin2018,
  langid = {english},
  title = {Differential Contributions of Subthalamic Beta Rhythms and 1/f Broadband Activity to Motor Symptoms in {{Parkinson}}'s Disease},
  volume = {4},
  issn = {2373-8057},
  url = {http://www.nature.com/articles/s41531-018-0068-y},
  doi = {10.1038/s41531-018-0068-y},
  number = {1},
  journaltitle = {npj Parkinson's Disease},
  urldate = {2019-03-30},
  date = {2018-12},
  author = {Martin, Stephanie and Iturrate, I\~naki and Chavarriaga, Ricardo and Leeb, Robert and Sobolewski, Aleksander and Li, Andrew M. and Zaldivar, Julien and Peciu-Florianu, Iulia and Pralong, Etienne and Castro-Jim\'enez, Mayte and Benninger, David and Vingerhoets, Fran{\c c}ois and Knight, Robert T. and Bloch, Jocelyne and Mill\'an, Jos\'e del R.},
  file = {/Users/qualia/Documents/Papers/Martin et al. - 2018 - Differential contributions of subthalamic beta rhy.pdf}
}

@article{Mania,
  langid = {english},
  title = {Simple Random Search Provides a Competitive Approach to Reinforcement Learning},
  abstract = {A common belief in model-free reinforcement learning is that methods based on random search in the parameter space of policies exhibit significantly worse sample complexity than those that explore the space of actions. We dispel such beliefs by introducing a random search method for training static, linear policies for continuous control problems, matching state-ofthe-art sample efficiency on the benchmark MuJoCo locomotion tasks. Our method also finds a nearly optimal controller for a challenging instance of the Linear Quadratic Regulator, a classical problem in control theory, when the dynamics are not known. Computationally, our random search algorithm is at least 15 times more efficient than the fastest competing model-free methods on these benchmarks. We take advantage of this computational efficiency to evaluate the performance of our method over hundreds of random seeds and many different hyperparameter configurations for each benchmark task. Our simulations highlight a high variability in performance in these benchmark tasks, suggesting that commonly used estimations of sample efficiency do not adequately evaluate the performance of RL algorithms.},
  pages = {22},
  author = {Mania, Horia and Guy, Aurelia and Recht, Benjamin},
  file = {/Users/qualia/Documents/Papers/Mania et al. - Simple random search provides a competitive approa.pdf}
}

@article{Lizbinski2018,
  langid = {english},
  title = {Intrinsic and {{Extrinsic Neuromodulation}} of {{Olfactory Processing}}},
  volume = {11},
  issn = {1662-5102},
  url = {http://journal.frontiersin.org/article/10.3389/fncel.2017.00424/full},
  doi = {10.3389/fncel.2017.00424},
  abstract = {Neuromodulation is a ubiquitous feature of neural systems, allowing flexible, context specific control over network dynamics. Neuromodulation was first described in invertebrate motor systems and early work established a basic dichotomy for neuromodulation as having either an intrinsic origin (i.e., neurons that participate in network coding) or an extrinsic origin (i.e., neurons from independent networks). In this conceptual dichotomy, intrinsic sources of neuromodulation provide a ``memory'' by adjusting network dynamics based upon previous and ongoing activation of the network itself, while extrinsic neuromodulators provide the context of ongoing activity of other neural networks. Although this dichotomy has been thoroughly considered in motor systems, it has received far less attention in sensory systems. In this review, we discuss intrinsic and extrinsic modulation in the context of olfactory processing in invertebrate and vertebrate model systems. We begin by discussing presynaptic modulation of olfactory sensory neurons by local interneurons (LNs) as a mechanism for gain control based on ongoing network activation. We then discuss the cell-class specific effects of serotonergic centrifugal neurons on olfactory processing. Finally, we briefly discuss the integration of intrinsic and extrinsic neuromodulation (metamodulation) as an effective mechanism for exerting global control over olfactory network dynamics. The heterogeneous nature of neuromodulation is a recurring theme throughout this review as the effects of both intrinsic and extrinsic modulation are generally non-uniform.},
  journaltitle = {Frontiers in Cellular Neuroscience},
  urldate = {2019-03-30},
  date = {2018-01-09},
  author = {Lizbinski, Kristyn M. and Dacks, Andrew M.},
  file = {/Users/qualia/Documents/Papers/Lizbinski and Dacks - 2018 - Intrinsic and Extrinsic Neuromodulation of Olfacto.pdf}
}

@article{Lin2018,
  langid = {english},
  title = {All-Optical Machine Learning Using Diffractive Deep Neural Networks},
  volume = {361},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aat8084},
  doi = {10.1126/science.aat8084},
  number = {6406},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2018-09-07},
  pages = {1004-1008},
  author = {Lin, Xing and Rivenson, Yair and Yardimci, Nezih T. and Veli, Muhammed and Luo, Yi and Jarrahi, Mona and Ozcan, Aydogan},
  file = {/Users/qualia/Documents/Papers/Lin et al. - 2018 - All-optical machine learning using diffractive dee.pdf}
}

@article{Leibo,
  langid = {english},
  title = {Psychlab: {{A Psychology Laboratory}} for {{Deep Reinforcement Learning Agents}}},
  abstract = {Psychlab is a simulated psychology laboratory inside the first-person 3D game world of DeepMind Lab (Beattie et al., 2016). Psychlab enables implementations of classical laboratory psychological experiments so that they work with both human and artificial agents. Psychlab has a simple and flexible API that enables users to easily create their own tasks. As examples, we are releasing Psychlab implementations of several classical experimental paradigms including visual search, change detection, random dot motion discrimination, and multiple object tracking. We also contribute a study of the visual psychophysics of a specific state-of-the-art deep reinforcement learning agent: UNREAL (Jaderberg et al., 2016). This study leads to the surprising conclusion that UNREAL learns more quickly about larger target stimuli than it does about smaller stimuli. In turn, this insight motivates a specific improvement in the form of a simple model of foveal vision that turns out to significantly boost UNREAL's performance, both on Psychlab tasks, and on standard DeepMind Lab tasks. By open-sourcing Psychlab we hope to facilitate a range of future such studies that simultaneously advance deep reinforcement learning and improve its links with cognitive science.},
  pages = {28},
  author = {Leibo, Joel Z and Beattie, Charles and Anderson, Keith and Casta\~neda, Antonio Garc\'ia and Sanchez, Manuel and Green, Simon and Gruslys, Audrunas and Legg, Shane and Hassabis, Demis and Botvinick, Matthew M},
  file = {/Users/qualia/Documents/Papers/Leibo et al. - Psychlab A Psychology Laboratory for Deep Reinfor.pdf}
}

@article{Lansdell2019,
  langid = {english},
  title = {Spiking Allows Neurons to Estimate Their Causal Effect},
  url = {http://biorxiv.org/lookup/doi/10.1101/253351},
  doi = {10.1101/253351},
  abstract = {Neural plasticity can be seen as ultimately aiming at the maximization of reward. However, the world is complicated and nonlinear and so are neurons' firing properties. A neuron learning to make changes that lead to the maximization of reward is an estimation problem: would there be more reward if the neural activity had been different? Statistically, this is a causal inference problem. Here we show how the spiking discontinuity of neurons can be a tool to estimate the causal influence of a neuron's activity on reward. We show how it can be used to derive a novel learning rule that can operate in the presence of non-linearities and the confounding influence of other neurons. We establish a link between simple learning rules and an existing causal inference method from econometrics.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2019-02-06},
  author = {Lansdell, Benjamin James and Kording, Konrad Paul},
  file = {/Users/qualia/Documents/Papers/Lansdell and Kording - 2019 - Spiking allows neurons to estimate their causal ef.pdf}
}

@article{Kriegeskorte2018,
  langid = {english},
  title = {Cognitive Computational Neuroscience},
  volume = {21},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/s41593-018-0210-5},
  doi = {10.1038/s41593-018-0210-5},
  number = {9},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2018-09},
  pages = {1148-1160},
  author = {Kriegeskorte, Nikolaus and Douglas, Pamela K.},
  file = {/Users/qualia/Documents/Papers/Kriegeskorte and Douglas - 2018 - Cognitive computational neuroscience.pdf}
}

@article{Kolchinsky2018,
  langid = {english},
  title = {Semantic Information, Autonomous Agency and Non-Equilibrium Statistical Physics},
  volume = {8},
  issn = {2042-8898, 2042-8901},
  url = {http://www.royalsocietypublishing.org/doi/10.1098/rsfs.2018.0041},
  doi = {10.1098/rsfs.2018.0041},
  number = {6},
  journaltitle = {Interface Focus},
  urldate = {2019-03-30},
  date = {2018-12-06},
  pages = {20180041},
  author = {Kolchinsky, Artemy and Wolpert, David H.},
  file = {/Users/qualia/Documents/Papers/Kolchinsky and Wolpert - 2018 - Semantic information, autonomous agency and non-eq.pdf}
}

@article{Katz,
  langid = {english},
  title = {Embodying Probabilistic Inference in Biochemical Circuits},
  abstract = {Probabilistic inference provides a language for describing how organisms may learn from and adapt to their environment. The computations needed to implement probabilistic inference often require specific representations, akin to having the suitable data structures for implementing certain algorithms in computer programming. Yet it is unclear how such representations can be instantiated in the stochastic, parallel-running biochemical machinery found in cells (such as single-celled organisms). Here, we show how representations for supporting inference in Markov models can be embodied in cellular circuits, by combining a concentration-dependent scheme for encoding probabilities with a mechanism for directional counting. We show how the logic of protein production and degradation constrains the computation we set out to implement. We argue that this process by which an abstract computation is shaped by its biochemical realization strikes a compromise between ``rationalistic'' information-processing perspectives and alternative approaches that emphasize embodiment.},
  pages = {23},
  author = {Katz, Yarden and Springer, Michael and Fontana, Walter},
  file = {/Users/qualia/Documents/Papers/Katz et al. - Embodying probabilistic inference in biochemical c.pdf}
}

@inproceedings{Juefei-Xu2018,
  langid = {english},
  location = {{Salt Lake City, UT}},
  title = {Perturbative {{Neural Networks}}},
  isbn = {978-1-5386-6420-9},
  url = {https://ieeexplore.ieee.org/document/8578447/},
  doi = {10.1109/CVPR.2018.00349},
  abstract = {Convolutional neural networks are witnessing wide adoption in computer vision systems with numerous applications across a range of visual recognition tasks. Much of this progress is fueled through advances in convolutional neural network architectures and learning algorithms even as the basic premise of a convolutional layer has remained unchanged. In this paper, we seek to revisit the convolutional layer that has been the workhorse of state-of-the-art visual recognition models. We introduce a very simple, yet effective, module called a perturbation layer as an alternative to a convolutional layer. The perturbation layer does away with convolution in the traditional sense and instead computes its response as a weighted linear combination of non-linearly activated additive noise perturbed inputs. We demonstrate both analytically and empirically that this perturbation layer can be an effective replacement for a standard convolutional layer. Empirically, deep neural networks with perturbation layers, called Perturbative Neural Networks (PNNs), in lieu of convolutional layers perform comparably with standard CNNs on a range of visual datasets (MNIST, CIFAR-10, PASCAL VOC, and ImageNet) with fewer parameters.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  publisher = {{IEEE}},
  urldate = {2019-03-30},
  date = {2018-06},
  pages = {3310-3318},
  author = {Juefei-Xu, Felix and Boddeti, Vishnu Naresh and Savvides, Marios},
  file = {/Users/qualia/Documents/Papers/Juefei-Xu et al. - 2018 - Perturbative Neural Networks.pdf}
}

@article{Belghazi,
  langid = {english},
  title = {Mutual {{Information Neural Estimation}}},
  abstract = {We argue that the estimation of mutual information between high dimensional continuous random variables can be achieved by gradient descent over neural networks. We present a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size, trainable through back-prop, and strongly consistent. We present a handful of applications on which MINE can be used to minimize or maximize mutual information. We apply MINE to improve adversarially trained generative models. We also use MINE to implement the Information Bottleneck, applying it to supervised classification; our results demonstrate substantial improvement in flexibility and performance in these settings.},
  pages = {18},
  author = {Belghazi, Mohamed Ishmael and Baratin, Aristide and Rajeswar, Sai and Ozair, Sherjil and Bengio, Yoshua and Courville, Aaron and Hjelm, R Devon},
  file = {/Users/qualia/Documents/Papers/Belghazi et al. - Mutual Information Neural Estimation.pdf}
}

@article{Henderson,
  langid = {english},
  title = {Deep {{Reinforcement Learning}} That {{Matters}}},
  abstract = {In recent years, significant progress has been made in solving challenging problems across various domains using deep reinforcement learning (RL). Reproducing existing work and accurately judging the improvements offered by novel methods is vital to sustaining this progress. Unfortunately, reproducing results for state-of-the-art deep RL methods is seldom straightforward. In particular, non-determinism in standard benchmark environments, combined with variance intrinsic to the methods, can make reported results tough to interpret. Without significance metrics and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the prior state-of-the-art are meaningful. In this paper, we investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures. We illustrate the variability in reported metrics and results when comparing against common baselines and suggest guidelines to make future results in deep RL more reproducible. We aim to spur discussion about how to ensure continued progress in the field by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted.},
  pages = {26},
  author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  file = {/Users/qualia/Documents/Papers/Henderson et al. - Deep Reinforcement Learning that Matters.pdf}
}

@article{Halgren2018,
  langid = {english},
  title = {The {{Generation}} and {{Propagation}} of the {{Human Alpha Rhythm}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/202564},
  doi = {10.1101/202564},
  abstract = {The alpha rhythm is the longest studied brain oscillation and has been theorized to play a key role in cognition. Still, its physiology is poorly understood. In this study, we used micro and macro electrodes in surgical epilepsy patients to measure the intracortical and thalamic generators of the alpha rhythm during quiet wakefulness. We first found that alpha in posterior cortex propagates from higher-order anterosuperior areas towards the occipital pole, consistent with alpha effecting top-down processing. This cortical alpha leads pulvinar alpha, complicating prevailing theories of a thalamic pacemaker. Finally, alpha is dominated by currents and firing in supragranular cortical layers. Together, these results suggest that the alpha rhythm likely reflects short-range supragranular feedback which propagates from higher to lower-order cortex and cortex to thalamus. These physiological insights suggest how alpha could mediate feedback throughout the thalamocortical system.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2018-06-05},
  author = {Halgren, Milan and Ulbert, Istvan and Bastuji, Helene and Fabo, Daniel and Eross, Lorand and Rey, Marc and Devinsky, Orrin and Doyle, Werner K and Mak-McCully, Rachel and Halgren, Eric and Wittner, Lucia and Chauvel, Patrick and Heit, Gary and Eskandar, Emad and Mandell, Arnold and Cash, Sydney S},
  file = {/Users/qualia/Documents/Papers/Halgren et al. - 2018 - The Generation and Propagation of the Human Alpha .pdf}
}

@article{Haarnojaa,
  langid = {english},
  title = {Soft {{Actor}}-{{Critic}}:  {{Off}}-{{Policy Maximum Entropy Deep Reinforcement Learning}} with a {{Stochastic Actor}}},
  abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an offpolicy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
  pages = {14},
  author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  file = {/Users/qualia/Documents/Papers/Haarnoja et al. - Soft Actor-Critic  Off-Policy Maximum Entropy Dee.pdf}
}

@article{Furlanello,
  langid = {english},
  title = {Born-{{Again Neural Networks}}},
  abstract = {Knowledge Distillation (KD) consists of transferring ``knowledge'' from one machine learning model (the teacher) to another (the student). Commonly, the teacher is a high-capacity model with formidable performance, while the student is more compact. By transferring knowledge, one hopes to benefit from the student's compactness, without sacrificing too much performance. We study KD from a new perspective: rather than compressing models, we train students parameterized identically to their teachers. Surprisingly, these Born-Again Networks (BANs), outperform their teachers significantly, both on computer vision and language modeling tasks. Our experiments with BANs based on DenseNets demonstrate state-of-the-art performance on the CIFAR-10 (3.5\%) and CIFAR-100 (15.5\%) datasets, by validation error. Additional experiments explore two distillation objectives: (i) Confidence-Weighted by Teacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP). Both methods elucidate the essential components of KD, demonstrating the effect of the teacher outputs on both predicted and nonpredicted classes.},
  pages = {10},
  author = {Furlanello, Tommaso and Lipton, Zachary C and Tschannen, Michael and Itti, Laurent and Anandkumar, Anima},
  file = {/Users/qualia/Documents/Papers/Furlanello et al. - Born-Again Neural Networks.pdf}
}

@article{Dehmamy2018,
  langid = {english},
  title = {A Structural Transition in Physical Networks},
  volume = {563},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/s41586-018-0726-6},
  doi = {10.1038/s41586-018-0726-6},
  number = {7733},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2018-11},
  pages = {676-680},
  author = {Dehmamy, Nima and Milanlouei, Soodabeh and Barab\'asi, Albert-L\'aszl\'o},
  file = {/Users/qualia/Documents/Papers/Dehmamy et al. - 2018 - A structural transition in physical networks.pdf}
}

@article{Cugno2018,
  langid = {english},
  title = {Geometric Principles of Second Messenger Dynamics in Dendritic Spines},
  url = {http://biorxiv.org/lookup/doi/10.1101/444489},
  doi = {10.1101/444489},
  abstract = {Dendritic spines are small, bulbous protrusions along dendrites in neurons and play a critical role in synaptic transmission. Dendritic spines come in a variety of shapes that depend on their developmental state. Additionally, roughly 14{$\sim$}19\% of mature spines have a specialized endoplasmic reticulum called the spine apparatus. How do the shape of a postsynaptic spine and its internal organization affect the spatiotemporal dynamics of short timescale signaling? This question is central for understanding the beginnings of synaptic transmission, learning, and memory formation. In this work, we used mathematical modeling using reaction-diffusion equations in idealized geometries (ellipsoids and spheres) to characterize the effect of spine and spine apparatus geometries on the spatio-temporal dynamics of second messengers. Our analyses and simulations showed that in the short timescale, spine size and shape coupled with the spine apparatus geometries govern the spatiotemporal chemical dynamics of second messengers within the cell. We showed that the curvature of the geometries gives rise to pseudoharmonic functions, which predict the locations of maximum and minimum concentrations. Furthermore, we showed that the lifetime of the chemical gradient can be fine-tuned by localization of fluxes on the spine head and varying the relative curvatures and distances between the spine apparatus and the spine head. Thus, we identified some of the key geometric determinants of how spine head and spine apparatus may regulate the short timescale chemical dynamics of small molecules.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2018-10-20},
  author = {Cugno, Andrea and Bartol, Thomas M. and Sejnowski, Terrence J. and Iyengar, Ravi and Rangamani, Padmini},
  file = {/Users/qualia/Documents/Papers/Cugno et al. - 2018 - Geometric principles of second messenger dynamics .pdf}
}

@article{Cheng,
  langid = {english},
  title = {Polynomial {{Regression As}} an {{Alternative}} to {{Neural Nets}}},
  abstract = {Despite the success of neural networks (NNs), there is still a concern among many over their ``black box'' nature. Why do they work? Here we present a simple analytic argument that NNs are in fact essentially polynomial regression models. This view will have various implications for NNs, e.g. providing an explanation for why convergence problems arise in NNs, and it gives rough guidance on avoiding overfitting. In addition, we use this phenomenon to predict and confirm a multicollinearity property of NNs not previously reported in the literature. Most importantly, given this loose correspondence, one may choose to routinely use polynomial models instead of NNs, thus avoiding some major problems of the latter, such as having to set many tuning parameters and dealing with convergence issues. We present a number of empirical results; in each case, the accuracy of the polynomial approach matches or exceeds that of NN approaches. A many-featured, open-source software package, polyreg, is available.},
  pages = {23},
  author = {Cheng, Xi and Khomtchouk, Bohdan and Matloff, Norman and Mohanty, Pete},
  file = {/Users/qualia/Documents/Papers/Cheng et al. - Polynomial Regression As an Alternative to Neural .pdf}
}

@article{Chen,
  langid = {english},
  title = {Neural {{Ordinary Differential Equations}}},
  abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a blackbox differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  pages = {12},
  author = {Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  file = {/Users/qualia/Documents/Papers/Chen et al. - Neural Ordinary Differential Equations.pdf}
}

@article{Chandrasekaran2018,
  langid = {english},
  title = {Brittleness in Model Selection Analysis of Single Neuron Firing Rates},
  url = {http://biorxiv.org/lookup/doi/10.1101/430710},
  doi = {10.1101/430710},
  abstract = {Models of complex heterogeneous systems like the brain are inescapably incomplete, and thus always falsified with enough data. As neural data grow in volume and complexity, absolute measures of adequacy are being replaced by model selection methods that rank the relative accuracy of competing theories. Selection still depends on incomplete mathematical instantiations, but the implicit expectation is that ranking is robust to their details. Here we highlight a contrary finding of ``brittleness,'' where data matching one theory conceptually are ranked closer to an instance of another. In particular, selection between recent models of decision making is conceptually misleading when data are simulated with minor distributional mismatch, with mixed secondary signals, or with non-stationary parameters; and decision-related responses in macaque cortex show features suggesting that these effects may impact empirical results. We conclude with recommendations to mitigate such brittleness when using model selection to study neural signals.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2018-09-29},
  author = {Chandrasekaran, Chandramouli and Soldado-Magraner, Joana and Peixoto, Diogo and Newsome, William T and Shenoy, Krishna and Sahani, Maneesh},
  file = {/Users/qualia/Documents/Papers/Chandrasekaran et al. - 2018 - Brittleness in model selection analysis of single .pdf}
}

@article{Cantero2018,
  langid = {english},
  title = {Bundles of {{Brain Microtubules Generate Electrical Oscillations}}},
  volume = {8},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/s41598-018-30453-2},
  doi = {10.1038/s41598-018-30453-2},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2018-12},
  author = {Cantero, Mar\'ia del Roc\'io and Villa Etchegoyen, Cecilia and Perez, Paula L. and Scarinci, Noelia and Cantiello, Horacio F.},
  file = {/Users/qualia/Documents/Papers/Cantero et al. - 2018 - Bundles of Brain Microtubules Generate Electrical .pdf}
}

@article{Bartunov,
  langid = {english},
  title = {Assessing the {{Scalability}} of {{Biologically}}-{{Motivated}}  {{Deep Learning Algorithms}} and {{Architectures}}},
  abstract = {The backpropagation of error algorithm (BP) is often said to be impossible to implement in a real brain. The recent success of deep networks in machine learning and AI, however, has inspired proposals for understanding how the brain might learn across multiple layers, and hence how it might implement or approximate BP. As of yet, none of these proposals have been rigorously evaluated on tasks where BP-guided deep learning has proved critical, or in architectures more structured than simple fully-connected networks. Here we present the first results on scaling up biologically motivated models of deep learning on datasets which need deep networks with appropriate architectures to achieve good performance. We present results on the MNIST, CIFAR10, and ImageNet datasets and explore variants of target-propagation (TP) and feedback alignment (FA) algorithms, and explore performance in both fully- and locally-connected architectures. We also introduce weight-transport-free variants of difference target propagation (DTP) modified to remove backpropagation from the penultimate layer. Many of these algorithms perform well for MNIST, but for CIFAR and ImageNet we find that TP and FA variants perform significantly worse than BP, especially for networks composed of locally connected units, opening questions about whether new architectures and algorithms are required to scale these approaches. Our results and implementation details help establish baselines for biologically motivated deep learning schemes going forward.},
  pages = {14},
  author = {Bartunov, Sergey and Santoro, Adam and Richards, Blake A and Hinton, Geoffrey E and Lillicrap, Timothy P},
  file = {/Users/qualia/Documents/Papers/Bartunov et al. - Assessing the Scalability of Biologically-Motivate.pdf}
}

@article{Zhang2017a,
  langid = {english},
  title = {Theta and Alpha Oscillations Are Traveling Waves in the Human Neocortex},
  url = {http://biorxiv.org/lookup/doi/10.1101/218198},
  doi = {10.1101/218198},
  abstract = {Human cognition requires the coordination of neural activity across widespread brain networks. Here we describe a new mechanism for large-scale coordination in the human brain: traveling waves of theta and alpha oscillations. Examining direct brain recordings from neurosurgical patients performing a memory task, we found that contiguous clusters of cortex in individual patients showed oscillations at specific frequencies in the range of 2 to 15 Hz. These clusters displayed spatial phase gradients, indicating that individual oscillation cycles moved across the cortex at {$\sim$}0.25\textendash{}0.75 m/s. We found that traveling waves were relevant behaviorally because their propagation correlated with task events and was more consistent during good performance. Traveling waves showed a correlation between propagation speed and temporal frequency, which suggests that they propagate across the cortex following principles of phasecoupled oscillatory networks. By demonstrating that theta and alpha traveling waves are widespread and behaviorally relevant, our results suggest a broad role for brain oscillations in supporting cortical connectivity by organizing neural activity across space and time.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-12-12},
  author = {Zhang, Honghui and Watrous, Andrew J. and Patel, Ansh and Jacobs, Joshua},
  file = {/Users/qualia/Documents/Papers/Zhang et al. - 2017 - Theta and alpha oscillations are traveling waves i.pdf}
}

@article{Zhanga,
  langid = {english},
  title = {Theory of {{Deep Learning III}}: {{Generalization Properties}} of {{SGD}}},
  pages = {38},
  author = {Zhang, Chiyuan and Liao, Qianli and Rakhlin, Alexander and Miranda, Brando and Golowich, Noah and Poggio, Tomaso},
  file = {/Users/qualia/Documents/Papers/Zhang et al. - Theory of Deep Learning III Generalization Proper.pdf}
}

@article{Zenke,
  langid = {english},
  title = {Improved Multitask Learning through Synaptic Intelligence},
  abstract = {Deep learning has led to remarkable advances when applied to problems where the data distribution does not change over the course of learning. In stark contrast, biological neural networks continually adapt to changing domains, and solve a diversity of tasks simultaneously. Furthermore, synapses in biological neurons are not simply real-valued scalars, but possess complex molecular machinery enabling non-trivial learning dynamics. In this study, we take a first step toward bringing this biological complexity into artificial neural networks. We introduce a model of intelligent synapses that accumulate task relevant information over time, and exploit this information to efficiently consolidate memories of old tasks to protect them from being overwritten as new tasks are learned. We apply our framework to learning sequences of related classification problems, and show that it dramatically reduces catastrophic forgetting while maintaining computational efficiency.},
  pages = {8},
  author = {Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  file = {/Users/qualia/Documents/Papers/Zenke et al. - Improved multitask learning through synaptic intel.pdf}
}

@article{Zenke2018,
  langid = {english},
  title = {{{SuperSpike}}: {{Supervised Learning}} in {{Multilayer Spiking Neural Networks}}},
  volume = {30},
  issn = {0899-7667, 1530-888X},
  url = {https://www.mitpressjournals.org/doi/abs/10.1162/neco_a_01086},
  doi = {10.1162/neco_a_01086},
  shorttitle = {{{SuperSpike}}},
  abstract = {A vast majority of computation in the brain is performed by spiking neural networks. Despite the ubiquity of such spiking, we currently lack an understanding of how biological spiking neural circuits learn and compute in-vivo, as well as how we can instantiate such capabilities in artificial spiking circuits in-silico. Here we revisit the problem of supervised learning in temporally coding multi-layer spiking neural networks. First, by using a surrogate gradient approach, we derive SuperSpike, a nonlinear voltage-based three factor learning rule capable of training multi-layer networks of deterministic integrateand-fire neurons to perform nonlinear computations on spatiotemporal spike patterns. Second, inspired by recent results on feedback alignment, we compare the performance of our learning rule under different credit assignment strategies for propagating output errors to hidden units. Specifically, we test uniform, symmetric and random feedback, finding that simpler tasks can be solved with any type of feedback, while more complex tasks require symmetric feedback. In summary, our results open the door to obtaining a better scientific understanding of learning and computation in spiking neural networks by advancing our ability to train them to solve nonlinear problems involving transformations between different spatiotemporal spike-time patterns.},
  number = {6},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2018-06},
  pages = {1514-1541},
  author = {Zenke, Friedemann and Ganguli, Surya},
  file = {/Users/qualia/Documents/Papers/Zenke and Ganguli - 2018 - SuperSpike Supervised Learning in Multilayer Spik.pdf}
}

@article{Zavala2017,
  langid = {english},
  title = {Human Subthalamic Nucleus Activity during Non-Motor Decision Making},
  volume = {6},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/31007},
  doi = {10.7554/eLife.31007},
  abstract = {Recent studies have implicated the subthalamic nucleus (STN) in decisions that involve 7 inhibiting movements. Many of the decisions that we make in our daily lives, however, do not 8 involve any motor actions. We studied non-motor decision making by recording intraoperative STN 9 and prefrontal cortex (PFC) electrophysiology as participants perform a novel task that required 10 them to decide whether to encode items into working memory. During all encoding trials, beta 11 band (15-30 Hz) activity decreased in the STN and PFC, and this decrease was progressively 12 enhanced as more items were stored into working memory. Crucially, the STN and lateral PFC beta 13 decrease was significantly attenuated during the trials in which participants were instructed not to 14 encode the presented stimulus. These changes were associated with increase lateral PFC-STN 15 coherence and altered STN neuronal spiking. Our results shed light on why states of altered basal 16 ganglia activity disrupt both motor function and cognition.},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2017-12-15},
  author = {Zavala, Baltazar A and Jang, Anthony I and Zaghloul, Kareem A},
  file = {/Users/qualia/Documents/Papers/Zavala et al. - 2017 - Human subthalamic nucleus activity during non-moto.pdf}
}

@article{Yi2017,
  langid = {english},
  title = {Morphology Controls How Hippocampal {{CA1}} Pyramidal Neuron Responds to Uniform Electric Fields: A Biophysical Modeling Study},
  volume = {7},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/s41598-017-03547-6},
  doi = {10.1038/s41598-017-03547-6},
  shorttitle = {Morphology Controls How Hippocampal {{CA1}} Pyramidal Neuron Responds to Uniform Electric Fields},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2017-12},
  author = {Yi, Guo-Sheng and Wang, Jiang and Deng, Bin and Wei, Xi-Le},
  file = {/Users/qualia/Documents/Papers/Yi et al. - 2017 - Morphology controls how hippocampal CA1 pyramidal .pdf}
}

@article{Waschke2017,
  langid = {english},
  title = {States and Traits of Neural Irregularity in the Age-Varying Human Brain},
  url = {http://biorxiv.org/lookup/doi/10.1101/103432},
  doi = {10.1101/103432},
  abstract = {Humans sometimes do perceive differences where physically there are none. It is thus tenable that perception is susceptible to seemingly random fluctuations in brain activity or ``neural noise''. Here, we demonstrate the potency of both trial-aggregated as well as trial-by-trial measures in the human electroencephalogram (EEG) to characterize neural noise as (i) a trait of individuals of varying age (n = 19; 19\textendash{}74 years), and (ii) a brain state that predicts an individual's impending perceptual decision. Human participants were instructed to discriminate two identical, consecutively presented pure tones. Behaviorally, all participants reported perceiving pitch differences of first versus second tone. Neurally, decisions for the first versus the second tone were preceded by more consistently phase-locked responses to the first tone in the theta (4\textendash{}9 Hz) band at central scalp electrodes. Second, a trial-wise information-theoretic measure quantifying the irregularity of broadband EEG, Weighted Permutation Entropy (WPE), prior to stimulus onset allowed to classify a listener's impending decision on this trial. Average entropy not only increased with participants' age, but correlated with previously suggested measures of an altered excitation\textendash{}inhibition balance in the aging brain. Therefore, neural noise is best conceived not only as a state variable that can shape perceptual decisions but moreover can capture trait-like changes with age.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-05-19},
  author = {Waschke, Leonhard and Woestmann, Malte and Obleser, Jonas},
  file = {/Users/qualia/Documents/Papers/Waschke et al. - 2017 - States and traits of neural irregularity in the ag 2.pdf;/Users/qualia/Documents/Papers/Waschke et al. - 2017 - States and traits of neural irregularity in the ag.pdf}
}

@article{Woodgate2017,
  langid = {english},
  title = {Continuous {{Radar Tracking Illustrates}} the {{Development}} of {{Multi}}-Destination {{Routes}} of {{Bumblebees}}},
  volume = {7},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/s41598-017-17553-1},
  doi = {10.1038/s41598-017-17553-1},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2017-12},
  author = {Woodgate, Joseph L. and Makinson, James C. and Lim, Ka S. and Reynolds, Andrew M. and Chittka, Lars},
  file = {/Users/qualia/Documents/Papers/Woodgate et al. - 2017 - Continuous Radar Tracking Illustrates the Developm.pdf}
}

@article{Winder2017,
  langid = {english},
  title = {Weak Correlations between Hemodynamic Signals and Ongoing Neural Activity during the Resting State},
  volume = {20},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/s41593-017-0007-y},
  doi = {10.1038/s41593-017-0007-y},
  number = {12},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2017-12},
  pages = {1761-1769},
  author = {Winder, Aaron T. and Echagarruga, Christina and Zhang, Qingguang and Drew, Patrick J.},
  file = {/Users/qualia/Documents/Papers/Winder et al. - 2017 - Weak correlations between hemodynamic signals and .pdf}
}

@article{Weinstein,
  langid = {english},
  title = {Structure {{Learning}} in {{Motor Control}}: {{A Deep Reinforcement Learning Model}}},
  abstract = {Motor adaptation displays a structure-learning effect: adaptation to a new perturbation occurs more quickly when the subject has prior exposure to perturbations with related structure. Although this `learning-to-learn' effect is well documented, its underlying computational mechanisms are poorly understood. We present a new model of motor structure learning, approaching it from the point of view of deep reinforcement learning. Previous work outside of motor control has shown how recurrent neural networks can account for learning-to-learn effects. We leverage this insight to address motor learning, by importing it into the setting of model-based reinforcement learning. We apply the resulting processing architecture to empirical findings from a landmark study of structure learning in targetdirected reaching (Braun et al., 2009), and discuss its implications for a wider range of learning-to-learn phenomena.},
  pages = {6},
  author = {Weinstein, Ari and Botvinick, Matthew M},
  file = {/Users/qualia/Documents/Papers/Weinstein and Botvinick - Structure Learning in Motor Control A Deep Reinfo.pdf}
}

@article{Weber,
  langid = {english},
  title = {Imagination-{{Augmented Agents}} for {{Deep Reinforcement Learning}}},
  abstract = {We introduce Imagination-Augmented Agents (I2As), a novel architecture for deep reinforcement learning combining model-free and model-based aspects. In contrast to most existing model-based reinforcement learning and planning methods, which prescribe how a model should be used to arrive at a policy, I2As learn to interpret predictions from a learned environment model to construct implicit plans in arbitrary ways, by using the predictions as additional context in deep policy networks. I2As show improved data efficiency, performance, and robustness to model misspecification compared to several baselines.},
  pages = {20},
  author = {Weber, Th\'eophane and Racani\`ere, S\'ebastien and Reichert, David P and Buesing, Lars and Guez, Arthur and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
  file = {/Users/qualia/Documents/Papers/Weber et al. - Imagination-Augmented Agents for Deep Reinforcemen.pdf}
}

@article{Wang2017,
  langid = {english},
  title = {{{SAMPLE EFFICIENT ACTOR}}-{{CRITIC WITH EXPERIENCE REPLAY}}},
  abstract = {This paper presents an actor-critic deep reinforcement learning agent with experience replay that is stable, sample efficient, and performs remarkably well on challenging environments, including the discrete 57-game Atari domain and several continuous control problems. To achieve this, the paper introduces several innovations, including truncated importance sampling with bias correction, stochastic dueling network architectures, and a new trust region policy optimization method.},
  date = {2017},
  pages = {20},
  author = {Wang, Ziyu and Bapst, Victor and Mnih, Volodymyr and Munos, Remi and de Freitas, Nando and Heess, Nicolas and Kavukcuoglu, Koray},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Wang et al. - 2017 - SAMPLE EFFICIENT ACTOR-CRITIC WITH EXPERIENCE REPL.pdf}
}

@article{Vinyals,
  langid = {english},
  title = {{{StarCraft II}}: {{A New Challenge}} for {{Reinforcement Learning}}},
  abstract = {This paper introduces SC2LE (StarCraft II Learning Environment), a reinforcement learning environment based on the game StarCraft II. This domain poses a new grand challenge for reinforcement learning, representing a more difficult class of problems than considered in most prior work. It is a multi-agent problem with multiple players interacting; there is imperfect information due to a partially observed map; it has a large action space involving the selection and control of hundreds of units; it has a large state space that must be observed solely from raw input feature planes; and it has delayed credit assignment requiring long-term strategies over thousands of steps. We describe the observation, action, and reward specification for the StarCraft II domain and provide an open source Python-based interface for communicating with the game engine. In addition to the main game maps, we provide a suite of mini-games focusing on different elements of StarCraft II gameplay. For the main game maps, we also provide an accompanying dataset of game replay data from human expert players. We give initial baseline results for neural networks trained from this data to predict game outcomes and player actions. Finally, we present initial baseline results for canonical deep reinforcement learning agents applied to the StarCraft II domain. On the mini-games, these agents learn to achieve a level of play that is comparable to a novice player. However, when trained on the main game, these agents are unable to make significant progress. Thus, SC2LE offers a new and challenging environment for exploring deep reinforcement learning algorithms and architectures.},
  pages = {20},
  author = {Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and Agapiou, John and Schrittwieser, Julian and Quan, John and Gaffney, Stephen and Petersen, Stig and Simonyan, Karen and Schaul, Tom and van Hasselt, Hado and Silver, David and Lillicrap, Timothy and Calderone, Kevin and Keet, Paul and Brunasso, Anthony and Lawrence, David and Ekermo, Anders and Repp, Jacob and Tsing, Rodney},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Vinyals et al. - StarCraft II A New Challenge for Reinforcement Le.pdf}
}

@article{Vilares2017,
  langid = {english},
  title = {Dopaminergic Medication Increases Reliance on Current Information in {{Parkinson}}'s Disease},
  volume = {1},
  issn = {2397-3374},
  url = {http://www.nature.com/articles/s41562-017-0129},
  doi = {10.1038/s41562-017-0129},
  number = {8},
  journaltitle = {Nature Human Behaviour},
  urldate = {2019-03-30},
  date = {2017-08},
  author = {Vilares, Iris and Kording, Konrad P.},
  file = {/Users/qualia/Documents/Papers/Vilares and Kording - 2017 - Dopaminergic medication increases reliance on curr.pdf}
}

@article{Vezhnevets,
  langid = {english},
  title = {{{FeUdal Networks}} for {{Hierarchical Reinforcement Learning}}},
  abstract = {We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical reinforcement learning. Our approach is inspired by the feudal reinforcement learning proposal of Dayan and Hinton, and gains power and efficacy by decoupling end-to-end learning across multiple levels \textendash{} allowing it to utilise different resolutions of time. Our framework employs a Manager module and a Worker module. The Manager operates at a lower temporal resolution and sets abstract goals which are conveyed to and enacted by the Worker. The Worker generates primitive actions at every tick of the environment. The decoupled structure of FuN conveys several benefits \textendash{} in addition to facilitating very long timescale credit assignment it also encourages the emergence of sub-policies associated with different goals set by the Manager. These properties allow FuN to dramatically outperform a strong baseline agent on tasks that involve long-term credit assignment or memorisation. We demonstrate the performance of our proposed system on a range of tasks from the ATARI suite and also from a 3D DeepMind Lab environment.},
  pages = {12},
  author = {Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  file = {/Users/qualia/Documents/Papers/Vezhnevets et al. - FeUdal Networks for Hierarchical Reinforcement Lea.pdf}
}

@article{Veness,
  langid = {english},
  title = {Online {{Learning}} with {{Gated Linear Networks}}},
  abstract = {This paper describes a family of probabilistic architectures designed for online learning under the logarithmic loss. Rather than relying on non-linear transfer functions, our method gains representational power by the use of data conditioning. We state under general conditions a learnable capacity theorem that shows this approach can in principle learn any bounded Borel-measurable function on a compact subset of euclidean space; the result is stronger than many universality results for connectionist architectures because we provide both the model and the learning procedure for which convergence is guaranteed.},
  pages = {40},
  author = {Veness, Joel and Lattimore, Tor and Bhoopchand, Avishkar and Grabska-Barwinska, Agnieszka and Mattern, Christopher and Toth, Peter},
  file = {/Users/qualia/Documents/Papers/Veness et al. - Online Learning with Gated Linear Networks.pdf}
}

@article{Vegue2017,
  langid = {english},
  title = {On {{The Structure Of Cortical Micro}}-{{Circuits Inferred From Small Sample Sizes}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/118471},
  doi = {10.1101/118471},
  abstract = {The structure in cortical micro-circuits deviates from what would be expected in a purely random network, which has been seen as evidence of clustering. To address this issue we sought to reproduce the non-random features of cortical circuits by considering several distinct classes of network topology, including clustered networks, networks with distance-dependent connectivity and those with broad degree distributions. To our surprise we found that all these qualitatively distinct topologies could account equally well for all reported non-random features, despite being easily distinguishable from one another at the network level. This apparent paradox was a consequence of estimating network properties given only small sample sizes. In other words, networks which differ markedly in their global structure can look quite similar locally. This makes inferring network structure from small sample sizes, a necessity given the technical difficulty inherent in simultaneous intracellular recordings, problematic. We found that a network statistic called the sample degree correlation (SDC) overcomes this difficulty. The SDC depends only on parameters which can be reliably estimated given small sample sizes, and is an accurate fingerprint of every topological family. We applied the SDC criterion to data from rat visual and somatosensory cortex and discovered that the connectivity was not consistent with any of these main topological classes. However, we were able to fit the experimental data with a more general network class, of which all previous topologies were special cases. The resulting network topology could be interpreted as a combination of physical spatial dependence and non-spatial, hierarchical clustering.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-04-05},
  author = {Vegue, Marina and Perin, Rodrigo and Roxin, Alex},
  file = {/Users/qualia/Documents/Papers/Vegue et al. - 2017 - On The Structure Of Cortical Micro-Circuits Inferr.pdf}
}

@article{Ravi2018,
  langid = {english},
  title = {Homeostatic Feedback Modulates the Development of Two-State Patterned Activity in a Model Serotonin Motor Circuit In},
  url = {http://biorxiv.org/lookup/doi/10.1101/202507},
  doi = {10.1101/202507},
  abstract = {Neuron activity accompanies synapse formation and maintenance, but how early circuit activity contributes to behavior development is not well understood. Here, we use the
            
            egg-laying motor circuit as a model to understand how coordinated cell and circuit activity develops and drives a robust two-state behavior in adults. Using calcium imaging in behaving animals, we find the serotonergic Hermaphrodite Specific Neurons (HSNs) and vulval muscles show rhythmic calcium transients in L4 larvae before eggs are produced. HSN activity in L4 is tonic and lacks the alternating burst-firing/quiescent pattern seen in egg-laying adults. Vulval muscle activity in L4 is initially uncoordinated but becomes synchronous as the anterior and posterior muscle arms meet at HSN synaptic release sites. However, coordinated muscle activity does not require presynaptic HSN input. Using reversible silencing experiments, we show that neuronal and vulval muscle activity in L4 is not required for the onset of adult behavior. Instead, the accumulation of eggs in the adult uterus renders the muscles sensitive to HSN input. Sterilization or acute electrical silencing of the vulval muscles inhibits presynaptic HSN activity, and reversal of muscle silencing triggers a homeostatic increase in HSN activity and egg release that maintains \textasciitilde{}12-15 eggs in the uterus. Feedback of egg accumulation depends upon the vulval muscle postsynaptic terminus, suggesting a retrograde signal sustains HSN synaptic activity and egg release. Our results show that egg-laying behavior in
            
            is driven by a homeostat that scales serotonin motor neuron activity in response to postsynaptic muscle feedback.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2018-05-07},
  author = {Ravi, Bhavya and Garcia, Jessica and Collins, Kevin M.},
  file = {/Users/qualia/Documents/Papers/Ravi et al. - 2018 - Homeostatic feedback modulates the development of .pdf}
}

@article{Lempitsky,
  langid = {english},
  title = {Andrea {{Vedaldi University}} of {{Oxford}}},
  abstract = {Deep convolutional networks have become a popular tool for image generation and restoration. Generally, their excellent performance is imputed to their ability to learn realistic image priors from a large number of example images. In this paper, we show that, on the contrary, the structure of a generator network is sufficient to capture a great deal of low-level image statistics prior to any learning. In order to do so, we show that a randomly-initialized neural network can be used as a handcrafted prior with excellent results in standard inverse problems such as denoising, superresolution, and inpainting. Furthermore, the same prior can be used to invert deep neural representations to diagnose them, and to restore images based on flash-no flash input pairs.},
  pages = {10},
  author = {Lempitsky, Victor},
  file = {/Users/qualia/Documents/Papers/Lempitsky - Andrea Vedaldi University of Oxford.pdf}
}

@article{Turnquist2017,
  langid = {english},
  title = {Quadratization: {{From Conductance}}-{{Based Models To Caricature Models With Parabolic Nonlinearities}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/137422},
  doi = {10.1101/137422},
  shorttitle = {Quadratization},
  abstract = {Quadratization of biophysical (conductance-based) models having a parabolic-like voltage nullcline in the subthreshold voltage regime refers to the process by which these models are substituted by ``caricature'' models having a strictly parabolic voltage nullcline and a linear nullcline  for the recovery variable. We refer to the latter as quadratic or parabolic models. The parabolic-like and strictly parabolic voltage nullclines coincide at their extrema (minima or maxima) and  are well approximated by each other in vicinities of these extrema whose size depend on the model parameters. Quadratic models are simplified by a change of variables that translates these extrema into the origin of the phase-plane diagram. A further simplification (parameter reduction) can be achieved by nondimensionalizing  the quadratic models. This procedure can be extended to three-dimensional models having a parabolic-cylinder-like shaped voltage nullsurface and to models having time-dependent inputs and synaptic currents.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-05-12},
  author = {Turnquist, Axel G. R. and Rotstein, Horacio},
  file = {/Users/qualia/Documents/Papers/Turnquist and Rotstein - 2017 - Quadratization From Conductance-Based Models To C.pdf}
}

@article{Tripathy,
  langid = {english},
  title = {Transcriptomic Correlates of Neuron Electrophysiological Diversity},
  abstract = {How neuronal diversity emerges from complex patterns of gene expression remains poorly understood. Here we present an approach to understand electrophysiological diversity through gene expression by integrating pooled- and single-cell transcriptomics with intracellular electrophysiology. Using neuroinformatics methods, we compiled a brain-wide dataset of 34 neuron types with paired gene expression and intrinsic electrophysiological features from publically accessible sources, the largest such collection to date. We identified 420 genes whose expression levels significantly correlated with variability in one or more of 11 physiological parameters. We next trained statistical models to infer cellular features from multivariate gene expression patterns. Such models were predictive of gene-electrophysiological relationships in an independent collection of 12 visual cortex cell types from the Allen Institute, suggesting that these correlations might reflect general principles relating expression patterns to phenotypic diversity across very different cell types. Many associations reported here have the potential to provide new insights into how neurons generate functional diversity, and correlations of ion channel genes like Gabrd and Scn1a (Nav1.1) with resting potential and spiking frequency are consistent with known causal mechanisms. Our work highlights the promise and inherent challenges in using cell type-specific transcriptomics to understand the mechanistic origins of neuronal diversity.},
  pages = {28},
  author = {Tripathy, Shreejoy J and Toker, Lilah and Li, Brenna and Crichlow, Cindy-Lee and Tebaykin, Dmitry and Mancarci, B Ogan and Pavlidis, Paul},
  file = {/Users/qualia/Documents/Papers/Tripathy et al. - Transcriptomic correlates of neuron electrophysiol.pdf}
}

@article{Trautmann2017,
  langid = {english},
  title = {Accurate Estimation of Neural Population Dynamics without Spike Sorting},
  url = {http://biorxiv.org/lookup/doi/10.1101/229252},
  doi = {10.1101/229252},
  abstract = {A central goal of systems neuroscience is to relate an organism's neural activity to behavior. Neural population analysis often begins by reducing the dimensionality of the data to focus on the patterns most relevant to a given task. A major practical hurdle to data analysis is spike sorting, and this problem is growing rapidly as the number of neurons measured increases. Here, we investigate whether spike sorting is necessary to estimate neural dynamics. The theory of random projections suggests that we can accurately estimate the geometry of low-dimensional manifolds from a small number of linear projections of the data. We re-analyzed data from three previous studies and found that neural dynamics and scientific conclusions are quite similar using multi-unit threshold crossings in place of sorted neurons. This finding unlocks existing data for new analyses and informs the design and use of new electrode arrays for laboratory and clinical use.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-12-05},
  author = {Trautmann, Eric and Stavisky, Sergey and Lahiri, Subhaneil and Ames, Katherine and Kaufman, Matthew and Ryu, Stephen and Ganguli, Surya and Shenoy, Krishna},
  file = {/Users/qualia/Documents/Papers/Trautmann et al. - 2017 - Accurate estimation of neural population dynamics .pdf}
}

@article{Tort2018,
  langid = {english},
  title = {Parallel Detection of Theta and Respiration-Coupled Oscillations throughout the Mouse Brain},
  volume = {8},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/s41598-018-24629-z},
  doi = {10.1038/s41598-018-24629-z},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2018-12},
  author = {Tort, Adriano B. L. and Ponsel, Simon and Jessberger, Jakob and Yanovsky, Yevgenij and Branka{\v c}k, Jurij and Draguhn, Andreas},
  file = {/Users/qualia/Documents/Papers/Tort et al. - 2018 - Parallel detection of theta and respiration-couple.pdf}
}

@article{Thura2017,
  langid = {english},
  title = {The {{Basal Ganglia Do Not Select Reach Targets}} but {{Control}} the {{Urgency}} of {{Commitment}}},
  volume = {95},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627317306876},
  doi = {10.1016/j.neuron.2017.07.039},
  abstract = {Prominent theories of decision making suggest that the basal ganglia (BG) play a causal role in deliberation between action choices. An alternative hypothesis is that deliberation occurs in cortical regions, while the BG control the speed-accuracy trade-off (SAT) between committing to a choice versus continuing to deliberate. Here, we test these hypotheses by recording activity in the internal and external segments of the globus pallidus (GPi/GPe) while monkeys perform a task dissociating the process of deliberation, the moment of commitment, and adjustment of the SAT. Our data suggest that unlike premotor and motor cortical regions, pallidal output does not contribute to the process of deliberation but instead provides a time-varying signal that controls the SAT and reflects the growing urgency to commit to a choice. Once a target is selected by cortical regions, GP activity confirms commitment to the decision and invigorates the subsequent movement.},
  number = {5},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2017-08},
  pages = {1160-1170.e5},
  author = {Thura, David and Cisek, Paul},
  file = {/Users/qualia/Documents/Papers/Thura and Cisek - 2017 - The Basal Ganglia Do Not Select Reach Targets but .pdf}
}

@article{Tasic2017,
  langid = {english},
  title = {Shared and Distinct Transcriptomic Cell Types across Neocortical Areas},
  url = {http://biorxiv.org/lookup/doi/10.1101/229542},
  doi = {10.1101/229542},
  abstract = {Neocortex contains a multitude of cell types segregated into layers and functionally distinct regions. To investigate the diversity of cell types across the mouse neocortex, we analyzed 12,714 cells from the primary visual cortex (VISp), and 9,035 cells from the anterior lateral motor cortex (ALM) by deep single-cell RNA-sequencing (scRNA-seq), identifying 116 transcriptomic cell types. These two regions represent distant poles of the neocortex and perform distinct functions. We define 50 inhibitory transcriptomic cell types, all of which are shared across both cortical regions. In contrast, 49 of 52 excitatory transcriptomic types were found in either VISp or ALM, with only three present in both. By combining single cell RNA-seq and retrograde labeling, we demonstrate correspondence between excitatory transcriptomic types and their region-specific long-range target specificity. This study establishes a combined transcriptomic and projectional taxonomy of cortical cell types from functionally distinct regions of the mouse cortex.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-12-06},
  author = {Tasic, Bosiljka and Yao, Zizhen and Smith, Kimberly A and Graybuck, Lucas and Nguyen, Thuc Nghi and Bertagnolli, Darren and Goldy, Jeff and Garren, Emma and Economo, Michael N and Viswanathan, Sarada and Penn, Osnat and Bakken, Trygve and Menon, Vilas and Miller, Jeremy A and Fong, Olivia and Hirokawa, Karla E and Lathia, Kanan and Rimorin, Christine and Tieu, Michael and Larsen, Rachael and Casper, Tamara and Barkan, Eliza and Kroll, Matthew and Parry, Seana and Shapovalova, Nadiya V and Hirchstein, Daniel and Pendergraft, Julie and Kim, Tae Kyung and Szafer, Aaron and Dee, Nick and Groblewski, Peter and Wickersham, Ian and Cetin, Ali and Harris, Julie A and Levi, Boaz P and Sunkin, Susan M and Madisen, Linda and Daigle, Tanya L and Looger, Loren and Bernard, Amy and Phillips, John and Lein, Ed and Hawrylycz, Michael and Svoboda, Karel and Jones, Allan R and Koch, Christof and Zeng, Hongkui},
  file = {/Users/qualia/Documents/Papers/Tasic et al. - 2017 - Shared and distinct transcriptomic cell types acro.pdf}
}

@article{Tang,
  langid = {english},
  title = {Control of {{Dynamics}} in {{Brain Networks}}},
  pages = {21},
  author = {Tang, Evelyn and Bassett, Danielle S},
  file = {/Users/qualia/Documents/Papers/Tang and Bassett - Control of Dynamics in Brain Networks.pdf}
}

@article{Tachet2017,
  langid = {english},
  title = {Scaling {{Law}} of {{Urban Ride Sharing}}},
  volume = {7},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/srep42868},
  doi = {10.1038/srep42868},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2017-12},
  author = {Tachet, R. and Sagarra, O. and Santi, P. and Resta, G. and Szell, M. and Strogatz, S. H. and Ratti, C.},
  file = {/Users/qualia/Documents/Papers/Tachet et al. - 2017 - Scaling Law of Urban Ride Sharing.pdf}
}

@article{Such,
  langid = {english},
  title = {Deep {{Neuroevolution}}: {{Genetic Algorithms}} Are a {{Competitive Alternative}} for {{Training Deep Neural Networks}} for {{Reinforcement Learning}}},
  abstract = {Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation. Evolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems. However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient. That raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales. Here we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, population-based genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of techniques that have been developed in the neuroevolution community to improve performance on RL problems. To demonstrate the latter, we show that combining DNNs with novelty search, which was designed to encourage exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g. DQN, A3C, ES, and the GA) fail. Additionally, the Deep GA parallelizes better than ES, A3C, and DQN, and enables a state-of-the-art compact encoding technique that can represent million-parameter DNNs in thousands of bytes.},
  pages = {15},
  author = {Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  file = {/Users/qualia/Documents/Papers/Such et al. - Deep Neuroevolution Genetic Algorithms are a Comp.pdf}
}

@article{Stimberg2017,
  langid = {english},
  title = {Modeling Neuron\textendash{}Glia Interactions with the                          Simulator},
  url = {http://biorxiv.org/lookup/doi/10.1101/198366},
  doi = {10.1101/198366},
  abstract = {Despite compelling evidence that glial cells could crucially regulate neural network activity, the vast majority of available neural simulators ignores the possible contribution of glia to neuronal physiology. Here, we show how to model glial physiology and neuron-glia interactions in the Brian 2 simulator. Brian 2 offers facilities to explicitly describe any model in mathematical terms with limited and simple simulator-specific syntax, automatically generating high-performance code from the user-provided descriptions. The flexibility of this approach allows us to model not only networks of neurons, but also individual glial cells, electrical coupling of glial cells, and the interaction between glial cells and synapses. We therefore conclude that Brian 2 provides an ideal platform to efficiently simulate glial physiology, and specifically, the influence of astrocytes on neural activity.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-10-05},
  author = {Stimberg, Marcel and Goodman, Dan F. M. and Brette, Romain and De Pitt\`a, Maurizio},
  file = {/Users/qualia/Documents/Papers/Stimberg et al. - 2017 - Modeling neuron–glia interactions with the        .pdf}
}

@article{Starkweather2017,
  langid = {english},
  title = {Dopamine Reward Prediction Errors Reflect Hidden-State Inference across Time},
  volume = {20},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4520},
  doi = {10.1038/nn.4520},
  number = {4},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2017-04},
  pages = {581-589},
  author = {Starkweather, Clara Kwon and Babayan, Benedicte M and Uchida, Naoshige and Gershman, Samuel J},
  file = {/Users/qualia/Documents/Papers/Starkweather et al. - 2017 - Dopamine reward prediction errors reflect hidden-s.pdf}
}

@article{Spoerer2017,
  langid = {english},
  title = {Recurrent Convolutional Neural Networks: A Better Model of Biological Object Recognition},
  url = {http://biorxiv.org/lookup/doi/10.1101/133330},
  doi = {10.1101/133330},
  shorttitle = {Recurrent Convolutional Neural Networks},
  abstract = {Feedforward neural networks provide the dominant model of how the brain performs visual object recognition. However, these networks lack the lateral and feedback connections, and the resulting recurrent neuronal dynamics, of the ventral visual pathway in the human and nonhuman primate brain. Here we investigate recurrent convolutional neural networks with bottom-up (B), lateral (L), and top-down (T) connections. Combining these types of connections yields four architectures (B, BT, BL, and BLT), which we systematically test and compare. We hypothesized that recurrent dynamics might improve recognition performance in the challenging scenario of partial occlusion. We introduce two novel occluded object recognition tasks to test the efficacy of the models, digit clutter (where multiple target digits occlude one another) and digit debris (where target digits are occluded by digit fragments). We find that recurrent neural networks outperform feedforward control models (approximately matched in parametric complexity) at recognising objects, both in the absence of occlusion and in all occlusion conditions. Recurrent networks were also found to be more robust to the inclusion of additive Gaussian noise. Recurrent neural networks are better in two respects: (1) they are more neurobiologically realistic than their feedforward counterparts; (2) they are better in terms of their ability to recognise objects, especially under challenging conditions. This work shows that computer vision can benefit from using recurrent convolutional architectures and suggests that the ubiquitous recurrent connections in biological brains are essential for task performance.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-08-07},
  author = {Spoerer, Courtney J and McClure, Patrick and Kriegeskorte, Nikolaus},
  file = {/Users/qualia/Documents/Papers/Spoerer et al. - 2017 - Recurrent convolutional neural networks a better  2.pdf;/Users/qualia/Documents/Papers/Spoerer et al. - 2017 - Recurrent convolutional neural networks a better .pdf}
}

@article{Silver,
  langid = {english},
  title = {Mastering {{Chess}} and {{Shogi}} by {{Self}}-{{Play}} with a {{General Reinforcement Learning Algorithm}}},
  abstract = {The game of chess is the most widely-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. In contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go, by tabula rasa reinforcement learning from games of self-play. In this paper, we generalise this approach into a single AlphaZero algorithm that can achieve, tabula rasa, superhuman performance in many challenging domains. Starting from random play, and given no domain knowledge except the game rules, AlphaZero achieved within 24 hours a superhuman level of play in the games of chess and shogi (Japanese chess) as well as Go, and convincingly defeated a world-champion program in each case.},
  pages = {19},
  author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
  file = {/Users/qualia/Documents/Papers/Silver et al. - Mastering Chess and Shogi by Self-Play with a Gene.pdf}
}

@article{Schwartz-Ziv,
  langid = {english},
  title = {Opening the Black Box of {{Deep Neural Networks}} via {{Information}}},
  abstract = {Despite their great success, there is still no comprehensive theoretical understanding of learning with Deep Neural Networks (DNNs) or their inner organization. Previous work [Tishby and Zaslavsky (2015)] proposed to analyze DNNs in the Information Plane; i.e., the plane of the Mutual Information values that each layer preserves on the input and output variables. They suggested that the goal of the network is to optimize the Information Bottleneck (IB) tradeoff between compression and prediction, successively, for each layer.},
  pages = {19},
  author = {Schwartz-Ziv, Ravid and Tishby, Naftali},
  file = {/Users/qualia/Documents/Papers/Schwartz-Ziv and Tishby - Opening the black box of Deep Neural Networks via .pdf}
}

@article{Shin2017,
  langid = {english},
  title = {The Rate of Transient Beta Frequency Events Predicts Behavior across Tasks and Species},
  volume = {6},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/29086},
  doi = {10.7554/eLife.29086},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2017-11-06},
  author = {Shin, Hyeyoung and Law, Robert and Tsutsui, Shawn and Moore, Christopher I and Jones, Stephanie R},
  file = {/Users/qualia/Documents/Papers/Shin et al. - 2017 - The rate of transient beta frequency events predic.pdf}
}

@article{Shazeer2017,
  langid = {english},
  title = {{{OUTRAGEOUSLY LARGE NEURAL NETWORKS}}: {{THE SPARSELY}}-{{GATED MIXTURE}}-{{OF}}-{{EXPERTS LAYER}}},
  abstract = {The capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks. A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. We present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost.},
  date = {2017},
  pages = {19},
  author = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Dean, Jeff},
  file = {/Users/qualia/Documents/Papers/Shazeer et al. - 2017 - OUTRAGEOUSLY LARGE NEURAL NETWORKS THE SPARSELY-G.pdf}
}

@article{Schulman,
  langid = {english},
  title = {Proximal {{Policy Optimization Algorithms}}},
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a ``surrogate'' objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  pages = {12},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  file = {/Users/qualia/Documents/Papers/Schulman et al. - Proximal Policy Optimization Algorithms.pdf}
}

@article{Scholte2017,
  langid = {english},
  title = {Visual Pathways from the Perspective of Cost Functions and Multi-Task Deep Neural Networks},
  url = {http://biorxiv.org/lookup/doi/10.1101/146472},
  doi = {10.1101/146472},
  abstract = {Vision research has been shaped by the seminal insight that we can understand higher-tier visual cortex from the perspective of multiple functional pathways with different goals. In this paper we try to give a computational account of the functional organization of this system by reasoning from the perspective of multi-task deep neural networks. Machine learning has shown that tasks become easier to solve when they are decomposed into subtasks with their own cost function. We hypothesise that the visual system optimizes multiple cost functions of unrelated tasks and this causes the emergence of the ventral pathway, dedicated to vision for perception and dorsal pathway, dedicated to vision for action. To evaluate the functional organization in multi-task deep neural networks we propose a method that measures the contribution of a unit towards each task and apply it to two networks that have been trained on either two related or two unrelated tasks using an identical stimulus set. Results show that the network trained on the unrelated tasks shows a decreasing degree of feature representation sharing towards higher-tier layers while the network trained on related tasks uniformly shows high degree of sharing. We conjecture that the method we propose can be used to reason about the anatomical and functional organization of the visual system and beyond as we predict that the degree to which tasks are related is a good descriptor of the degree to which they can share downstream corticalunits.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-09-16},
  author = {Scholte, H. Steven and Losch, Max M. and Ramakrishnan, Kandan and de Haan, Edward and Bohte, Sander},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Scholte et al. - 2017 - Visual pathways from the perspective of cost funct.pdf}
}

@article{Saenger2017,
  langid = {english},
  title = {Uncovering the Underlying Mechanisms and Whole-Brain Dynamics of Deep Brain Stimulation for {{Parkinson}}'s Disease},
  volume = {7},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/s41598-017-10003-y},
  doi = {10.1038/s41598-017-10003-y},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2017-12},
  author = {Saenger, Victor M. and Kahan, Joshua and Foltynie, Tom and Friston, Karl and Aziz, Tipu Z. and Green, Alexander L. and van Hartevelt, Tim J. and Cabral, Joana and Stevner, Angus B. A. and Fernandes, Henrique M. and Mancini, Laura and Thornton, John and Yousry, Tarek and Limousin, Patricia and Zrinzo, Ludvic and Hariz, Marwan and Marques, Paulo and Sousa, Nuno and Kringelbach, Morten L. and Deco, Gustavo},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Saenger et al. - 2017 - Uncovering the underlying mechanisms and whole-bra.pdf}
}

@article{Saeb2017,
  langid = {english},
  title = {The Need to Approximate the Use-Case in Clinical Machine Learning},
  volume = {6},
  issn = {2047-217X},
  url = {https://academic.oup.com/gigascience/article/doi/10.1093/gigascience/gix019/3071704},
  doi = {10.1093/gigascience/gix019},
  abstract = {Background. The availability of smartphone and wearable sensor technology is leading to a rapid accumulation of human subject data, and machine learning is emerging as a technique to map that data into clinical predictions. As machine learning algorithms are increasingly used to support clinical decision making, it is vital to reliably quantify their prediction accuracy. Cross-validation is the standard approach where the accuracy of such algorithms is evaluated on data the algorithm has not seen during training. However, for this procedure to be meaningful, the relationship between the training and validation set should mimic the relationship between the training set and the dataset expected for the clinical use. Here we compared two popular cross-validation methods: record-wise and subject-wise. The subjectwise procedure mirrors the clinically relevant use-case scenario of diagnosing/identifying patterns in newly recruited subjects. The record-wise strategy has no such interpretation.
Results. Using both a publicly available dataset and a simulation, we found that record-wise crossvalidation often massively overestimates the prediction accuracy of the algorithms. We also conducted a systematic review of the relevant literature, and found that this overly optimistic method is used by almost half of the retrieved studies that used accelerometers, wearable sensors, or smartphones to predict clinical outcomes.
Conclusions. As we move towards an era of machine learning based diagnosis and treatment, using proper methods to evaluate their accuracy is crucial, as results that are overly optimistic can mislead both clinicians and data scientists.},
  number = {5},
  journaltitle = {GigaScience},
  urldate = {2019-03-30},
  date = {2017-05-01},
  author = {Saeb, Sohrab and Lonini, Luca and Jayaraman, Arun and Mohr, David C. and Kording, Konrad P.},
  file = {/Users/qualia/Documents/Papers/Saeb et al. - 2017 - The need to approximate the use-case in clinical m.pdf}
}

@article{Runyan2017,
  langid = {english},
  title = {Distinct Timescales of Population Coding across Cortex},
  volume = {548},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature23020},
  doi = {10.1038/nature23020},
  number = {7665},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2017-08},
  pages = {92-96},
  author = {Runyan, Caroline A. and Piasini, Eugenio and Panzeri, Stefano and Harvey, Christopher D.},
  file = {/Users/qualia/Documents/Papers/Runyan et al. - 2017 - Distinct timescales of population coding across co.pdf}
}

@article{Raghu,
  langid = {english},
  title = {Can {{Deep Reinforcement Learning Solve Erdos}}-{{Selfridge}}-{{Spencer Games}}?},
  abstract = {Deep reinforcement learning has achieved many recent successes, but our understanding of its strengths and limitations is hampered by the lack of rich environments in which we can fully characterize optimal behavior, and correspondingly diagnose individual actions against such a characterization. Here we consider a family of combinatorial games, arising from work of Erdos, Selfridge, and Spencer, and we propose their use as environments for evaluating and comparing different approaches to reinforcement learning. These games have a number of appealing features: they are challenging for current learning approaches, but they form (i) a low-dimensional, simply parametrized environment where (ii) there is a linear closed form solution for optimal behavior from any state, and (iii) the difficulty of the game can be tuned by changing environment parameters in an interpretable way. We use these Erdos-Selfridge-Spencer games not only to compare different algorithms, but test for generalization, make comparisons to supervised learning, analyze multiagent play, and even develop a self play algorithm.},
  pages = {13},
  author = {Raghu, Maithra and Irpan, Alex and Andreas, Jacob and Kleinberg, Robert and Le, Quoc and Kleinberg, Jon},
  file = {/Users/qualia/Documents/Papers/Raghu et al. - Can Deep Reinforcement Learning Solve Erdos-Selfri.pdf}
}

@article{Podlaski2017,
  langid = {english},
  title = {Mapping the Function of Neuronal Ion Channels in Model and Experiment},
  volume = {6},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/22152},
  doi = {10.7554/eLife.22152},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2017-03-06},
  author = {Podlaski, William F and Seeholzer, Alexander and Groschner, Lukas N and Miesenb\"ock, Gero and Ranjan, Rajnish and Vogels, Tim P},
  file = {/Users/qualia/Documents/Papers/Podlaski et al. - 2017 - Mapping the function of neuronal ion channels in m.pdf}
}

@article{Pena2017,
  langid = {english},
  title = {Particle Swarm Optimization for Programming Deep Brain Stimulation Arrays},
  volume = {14},
  issn = {1741-2560, 1741-2552},
  url = {http://stacks.iop.org/1741-2552/14/i=1/a=016014?key=crossref.b39776968202b505d97fb3c851d7035d},
  doi = {10.1088/1741-2552/aa52d1},
  abstract = {Objective. Deep brain stimulation (DBS) therapy relies on both precise neurosurgical targeting and systematic optimization of stimulation settings to achieve beneficial clinical outcomes. One recent advance to improve targeting is the development of DBS arrays (DBSAs) with electrodes segmented both along and around the DBS lead. However, increasing the number of independent electrodes creates the logistical challenge of optimizing stimulation parameters efficiently. Approach. Solving such complex problems with multiple solutions and objectives is well known to occur in biology, in which complex collective behaviors emerge out of swarms of individual organisms engaged in learning through social interactions. Here, we developed a particle swarm optimization (PSO) algorithm to program DBSAs using a swarm of individual particles representing electrode configurations and stimulation amplitudes. Using a finite element model of motor thalamic DBS, we demonstrate how the PSO algorithm can efficiently optimize a multi-objective function that maximizes predictions of axonal activation in regions of interest (ROI, cerebellar-receiving area of motor thalamus), minimizes predictions of axonal activation in regions of avoidance (ROA, somatosensory thalamus), and minimizes power consumption. Main results. The algorithm solved the multi-objective problem by producing a Pareto front. ROI and ROA activation predictions were consistent across swarms ({$<$}1\% median discrepancy in axon activation). The algorithm was able to accommodate for (1) lead displacement (1 mm) with relatively small ROI ({$\leqslant$}9.2\%) and ROA ({$\leqslant$}1\%) activation changes, irrespective of shift direction; (2) reduction in maximum per-electrode current (by 50\% and 80\%) with ROI activation decreasing by 5.6\% and 16\%, respectively; and (3) disabling electrodes (n = 3 and 12) with ROI activation reduction by 1.8\% and 14\%, respectively. Additionally, comparison between PSO predictions and multicompartment axon model simulations showed discrepancies of {$<$}1\% between approaches. Significance. The PSO algorithm provides a computationally efficient way to program DBS systems especially those with higher electrode counts.},
  number = {1},
  journaltitle = {Journal of Neural Engineering},
  urldate = {2019-03-30},
  date = {2017-02-01},
  pages = {016014},
  author = {Pe\~na, Edgar and Zhang, Simeng and Deyo, Steve and Xiao, YiZi and Johnson, Matthew D},
  file = {/Users/qualia/Documents/Papers/Peña et al. - 2017 - Particle swarm optimization for programming deep b.pdf}
}

@inproceedings{Pearl2018,
  langid = {english},
  location = {{Marina Del Rey, CA, USA}},
  title = {Theoretical {{Impediments}} to {{Machine Learning With Seven Sparks}} from the {{Causal Revolution}}},
  isbn = {978-1-4503-5581-0},
  url = {http://dl.acm.org/citation.cfm?doid=3159652.3176182},
  doi = {10.1145/3159652.3176182},
  abstract = {Current machine learning systems operate, almost exclusively, in a statistical, or modelblind mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal inference.},
  eventtitle = {The {{Eleventh ACM International Conference}}},
  booktitle = {Proceedings of the {{Eleventh ACM International Conference}} on {{Web Search}} and {{Data Mining}}  - {{WSDM}} '18},
  publisher = {{ACM Press}},
  urldate = {2019-03-30},
  date = {2018},
  pages = {3-3},
  author = {Pearl, Judea},
  file = {/Users/qualia/Documents/Papers/Pearl - 2018 - Theoretical Impediments to Machine Learning With S.pdf}
}

@inproceedings{Pathak2017,
  langid = {english},
  location = {{Honolulu, HI, USA}},
  title = {Curiosity-{{Driven Exploration}} by {{Self}}-{{Supervised Prediction}}},
  isbn = {978-1-5386-0733-6},
  url = {http://ieeexplore.ieee.org/document/8014804/},
  doi = {10.1109/CVPRW.2017.70},
  abstract = {In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent's ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  publisher = {{IEEE}},
  urldate = {2019-03-30},
  date = {2017-07},
  pages = {488-489},
  author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
  file = {/Users/qualia/Documents/Papers/Pathak et al. - 2017 - Curiosity-Driven Exploration by Self-Supervised Pr.pdf}
}

@article{Papadopoulos2017,
  langid = {english},
  title = {Development of Structural Correlations and Synchronization from Adaptive Rewiring in Networks of {{Kuramoto}} Oscillators},
  volume = {27},
  issn = {1054-1500, 1089-7682},
  url = {http://aip.scitation.org/doi/10.1063/1.4994819},
  doi = {10.1063/1.4994819},
  number = {7},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  urldate = {2019-03-30},
  date = {2017-07},
  pages = {073115},
  author = {Papadopoulos, Lia and Kim, Jason Z. and Kurths, J\"urgen and Bassett, Danielle S.},
  file = {/Users/qualia/Documents/Papers/Papadopoulos et al. - 2017 - Development of structural correlations and synchro.pdf}
}

@article{Ottino-Loffler,
  langid = {english},
  title = {Evolutionary Dynamics of Incubation Periods},
  pages = {28},
  author = {Ottino-Loffler, Bertrand and Scott, Jacob G and Strogatz, Steven H},
  file = {/Users/qualia/Documents/Papers/Ottino-Loffler et al. - Evolutionary dynamics of incubation periods.pdf}
}

@article{Ocker2017,
  langid = {english},
  title = {Linking Structure and Activity in Nonlinear Spiking Networks},
  url = {http://biorxiv.org/lookup/doi/10.1101/080705},
  doi = {10.1101/080705},
  abstract = {Recent experimental advances are producing an avalanche of data on both neural connectivity and neural activity. To take full advantage of these two emerging datasets we need a framework that links them, revealing how collective neural activity arises from the structure of neural connectivity and intrinsic neural dynamics. This problem of structure-driven activity has drawn major interest in computational neuroscience. Existing methods for relating activity and architecture in spiking networks rely on linearizing activity around a central operating point and thus fail to capture the nonlinear responses of individual neurons that are the hallmark of neural information processing. Here, we overcome this limitation and present a new relationship between connectivity and activity in networks of nonlinear spiking neurons by developing a diagrammatic fluctuation expansion based on statistical field theory. We explicitly show how recurrent network structure produces pairwise and higher-order correlated activity, and how nonlinearities impact the networks' spiking activity. Our findings open new avenues to investigating how single-neuron nonlinearities\textemdash{}including those of different cell types\textemdash{}combine with connectivity to shape population activity and function.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-03-10},
  author = {Ocker, Gabriel Koch and Josi\'c, Kre{\v s}imir and Shea-Brown, Eric and Buice, Michael A.},
  file = {/Users/qualia/Documents/Papers/Ocker et al. - 2017 - Linking structure and activity in nonlinear spikin 2.pdf;/Users/qualia/Documents/Papers/Ocker et al. - 2017 - Linking structure and activity in nonlinear spikin.pdf}
}

@article{OKeeffe2017,
  langid = {english},
  title = {Oscillators That Sync and Swarm},
  volume = {8},
  issn = {2041-1723},
  url = {http://www.nature.com/articles/s41467-017-01190-3},
  doi = {10.1038/s41467-017-01190-3},
  number = {1},
  journaltitle = {Nature Communications},
  urldate = {2019-03-30},
  date = {2017-12},
  author = {O'Keeffe, Kevin P. and Hong, Hyunsuk and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/O’Keeffe et al. - 2017 - Oscillators that sync and swarm.pdf}
}

@article{Mosqueiro2017,
  langid = {english},
  title = {Task Allocation and Site Fidelity Jointly Influence Foraging Regulation in Honeybee Colonies},
  volume = {4},
  issn = {2054-5703},
  url = {http://rsos.royalsocietypublishing.org/lookup/doi/10.1098/rsos.170344},
  doi = {10.1098/rsos.170344},
  abstract = {Variation in behavior among group members often impacts collective outcomes. Individuals may vary both in the task that they perform and in the persistence with which they perform each task. Although both the distribution of individuals among tasks and differences among individuals in behavioral persistence can each impact collective behavior, we do not know if and how they jointly affect collective outcomes. Here we use a detailed computational model to examine the joint impact of colony-level distribution among tasks and behavioral persistence of individuals, specifically their fidelity to particular resource sites, on the collective tradeoff between exploring for new resources and exploiting familiar ones. We developed an agent-based model of foraging honey bees, parameterized by data from 5 colonies, in which we simulated scouts, who search the environment for new resources, and individuals who are recruited by the scouts to the newly found resources, i.e., recruits. We varied the persistence to return to a particular food source of both scouts and recruits and found that for each value of persistence there is a different optimal ratio of scouts to recruits that maximizes resource collection by the colony. Furthermore, changes to the persistence of scouts induced opposite effects from changes to the persistence of recruits on the collective foraging of the colony. The proportion of scouts that resulted in the most resources collected by the colony decreased as the persistence of recruits increased. However, this optimal proportion of scouts increased as the persistence of scouts increased. Thus, behavioral persistence and task participation can interact to impact a colony's collective behavior in orthogonal directions. Our work provides new insights and generates new hypotheses into how variation in behavior at both the individual and colony levels jointly impact the trade-off between exploring for new resources and exploiting familiar ones.},
  number = {8},
  journaltitle = {Royal Society Open Science},
  urldate = {2019-03-30},
  date = {2017-08},
  pages = {170344},
  author = {Mosqueiro, Thiago and Cook, Chelsea and Huerta, Ramon and Gadau, J\"urgen and Smith, Brian and Pinter-Wollman, Noa},
  file = {/Users/qualia/Documents/Papers/Mosqueiro et al. - 2017 - Task allocation and site fidelity jointly influenc.pdf}
}

@article{Morishita2017,
  langid = {english},
  title = {Postoperative Lead Migration in Deep Brain Stimulation Surgery: {{Incidence}}, Risk Factors, and Clinical Impact},
  volume = {12},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0183711},
  doi = {10.1371/journal.pone.0183711},
  shorttitle = {Postoperative Lead Migration in Deep Brain Stimulation Surgery},
  number = {9},
  journaltitle = {PLOS ONE},
  urldate = {2019-03-30},
  date = {2017-09-13},
  pages = {e0183711},
  author = {Morishita, Takashi and Hilliard, Justin D. and Okun, Michael S. and Neal, Dan and Nestor, Kelsey A. and Peace, David and Hozouri, Alden A. and Davidson, Mark R. and Bova, Francis J. and Sporrer, Justin M. and Oyama, Genko and Foote, Kelly D.},
  editor = {Toft, Mathias},
  file = {/Users/qualia/Documents/Papers/Morishita et al. - 2017 - Postoperative lead migration in deep brain stimula.pdf}
}

@article{Reimann2017,
  langid = {english},
  title = {Cliques of {{Neurons Bound}} into {{Cavities Provide}} a {{Missing Link}} between {{Structure}} and {{Function}}},
  volume = {11},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2017.00048/full},
  doi = {10.3389/fncom.2017.00048},
  abstract = {The lack of a formal link between neural network structure and its emergent function has hampered our understanding of how the brain processes information. We have now come closer to describing such a link by taking the direction of synaptic transmission into account, constructing graphs of a network that reflect the direction of information flow, and analyzing these directed graphs using algebraic topology. Applying this approach to a local network of neurons in the neocortex revealed a remarkably intricate and previously unseen topology of synaptic connectivity. The synaptic network contains an abundance of cliques of neurons bound into cavities that guide the emergence of correlated activity. In response to stimuli, correlated activity binds synaptically connected neurons into functional cliques and cavities that evolve in a stereotypical sequence toward peak complexity. We propose that the brain processes stimuli by forming increasingly complex functional cliques and cavities.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2017-06-12},
  author = {Reimann, Michael W. and Nolte, Max and Scolamiero, Martina and Turner, Katharine and Perin, Rodrigo and Chindemi, Giuseppe and D\l{}otko, Pawe\l{} and Levi, Ran and Hess, Kathryn and Markram, Henry},
  file = {/Users/qualia/Documents/Papers/Reimann et al. - 2017 - Cliques of Neurons Bound into Cavities Provide a M 2.pdf;/Users/qualia/Documents/Papers/Reimann et al. - 2017 - Cliques of Neurons Bound into Cavities Provide a M.pdf}
}

@article{Mensch2018,
  langid = {english},
  title = {Stochastic {{Subsampling}} for {{Factorizing Huge Matrices}}},
  volume = {66},
  issn = {1053-587X, 1941-0476},
  url = {http://ieeexplore.ieee.org/document/8038072/},
  doi = {10.1109/TSP.2017.2752697},
  abstract = {We present a matrix-factorization algorithm that scales to input matrices with both huge number of rows and columns. Learned factors may be sparse or dense and/or non-negative, which makes our algorithm suitable for dictionary learning, sparse component analysis, and non-negative matrix factorization. Our algorithm streams matrix columns while subsampling them to iteratively learn the matrix factors. At each iteration, the row dimension of a new sample is reduced by subsampling, resulting in lower time complexity compared to a simple streaming algorithm. Our method comes with convergence guarantees to reach a stationary point of the matrix-factorization problem. We demonstrate its efficiency on massive functional Magnetic Resonance Imaging data (2 TB), and on patches extracted from hyperspectral images (103 GB). For both problems, which involve different penalties on rows and columns, we obtain significant speed-ups compared to state-of-the-art algorithms.},
  number = {1},
  journaltitle = {IEEE Transactions on Signal Processing},
  urldate = {2019-03-30},
  date = {2018-01-01},
  pages = {113-128},
  author = {Mensch, Arthur and Mairal, Julien and Thirion, Bertrand and Varoquaux, Gael},
  file = {/Users/qualia/Documents/Papers/Mensch et al. - 2018 - Stochastic Subsampling for Factorizing Huge Matric.pdf}
}

@article{Mensch,
  langid = {english},
  title = {Learning {{Neural Representations}} of {{Human Cognition}} across {{Many fMRI Studies}}},
  abstract = {Cognitive neuroscience is enjoying rapid increase in extensive public brain-imaging datasets. It opens the door to large-scale statistical models. Finding a unified perspective for all available data calls for scalable and automated solutions to an old challenge: how to aggregate heterogeneous information on brain function into a universal cognitive system that relates mental operations/cognitive processes/psychological tasks to brain networks? We cast this challenge in a machine-learning approach to predict conditions from statistical brain maps across different studies. For this, we leverage multi-task learning and multi-scale dimension reduction to learn low-dimensional representations of brain images that carry cognitive information and can be robustly associated with psychological stimuli. Our multi-dataset classification model achieves the best prediction performance on several large reference datasets, compared to models without cognitive-aware low-dimension representations; it brings a substantial performance boost to the analysis of small datasets, and can be introspected to identify universal template cognitive concepts.},
  pages = {14},
  author = {Mensch, Arthur and Mairal, Julien and Bzdok, Danilo and Thirion, Bertrand and Varoquaux, Ga\"el},
  file = {/Users/qualia/Documents/Papers/Mensch et al. - Learning Neural Representations of Human Cognition.pdf}
}

@article{Mathewson2017,
  langid = {english},
  title = {High and Dry? {{Comparing}} Active Dry {{EEG}} Electrodes to Active and Passive Wet Electrodes: {{Active}} Dry vs. Active \& Passive Wet {{EEG}} Electrodes},
  volume = {54},
  issn = {00485772},
  url = {http://doi.wiley.com/10.1111/psyp.12536},
  doi = {10.1111/psyp.12536},
  shorttitle = {High and Dry?},
  abstract = {Dry electrodes are becoming popular for both lab-based and consumer-level electrophysiological-recording technologies because they better afford the ability to move traditional lab-based research into the real world. It is unclear, however, how dry electrodes compare in data quality to traditional electrodes. The current study compared three EEG electrode types: (a) passive-wet electrodes with no onboard amplification, (b) actively amplified, wet electrodes with moderate impedance levels, and low impedance levels, and (c) active-dry electrodes with very high impedance. Participants completed a classic P3 auditory oddball task to elicit characteristic EEG signatures and eventrelated potentials (ERPs). Across the three electrode types, we compared single-trial noise, average ERPs, scalp topographies, ERP noise, and ERP statistical power as a function of number of trials. We extended past work showing active electrodes' insensitivity to moderate levels of interelectrode impedance when compared to passive electrodes in the same amplifier. Importantly, the new dry electrode system could reliably measure EEG spectra and ERP components comparable to traditional electrode types. As expected, however, dry active electrodes with very high interelectrode impedance exhibited marked increases in single-trial and average noise levels, which decreased statistical power, requiring more trials to detect significant effects. This power decrease must be considered as a tradeoff with the ease of application and long-term use. The current results help set constraints on experimental design with novel dry electrodes, and provide important evidence needed to measure brain activity in novel settings and situations.},
  number = {1},
  journaltitle = {Psychophysiology},
  urldate = {2019-03-30},
  date = {2017-01},
  pages = {74-82},
  author = {Mathewson, Kyle E. and Harrison, Tyler J. L. and Kizuk, Sayeed A. D.},
  file = {/Users/qualia/Documents/Papers/Mathewson et al. - 2017 - High and dry Comparing active dry EEG electrodes .pdf}
}

@article{Mastro2017,
  langid = {english},
  title = {Cell-Specific Pallidal Intervention Induces Long-Lasting Motor Recovery in Dopamine-Depleted Mice},
  volume = {20},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4559},
  doi = {10.1038/nn.4559},
  number = {6},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2017-06},
  pages = {815-823},
  author = {Mastro, Kevin J and Zitelli, Kevin T and Willard, Amanda M and Leblanc, Kimberly H and Kravitz, Alexxai V and Gittis, Aryn H},
  file = {/Users/qualia/Documents/Papers/Mastro et al. - 2017 - Cell-specific pallidal intervention induces long-l.pdf}
}

@article{Marti2018,
  langid = {english},
  title = {Correlations between Synapses in Pairs of Neurons Slow down Dynamics in Randomly Connected Neural Networks},
  volume = {97},
  issn = {2470-0045, 2470-0053},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.97.062314},
  doi = {10.1103/PhysRevE.97.062314},
  number = {6},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2018-06-26},
  author = {Mart\'i, Daniel and Brunel, Nicolas and Ostojic, Srdjan},
  file = {/Users/qualia/Documents/Papers/Martí et al. - 2018 - Correlations between synapses in pairs of neurons .pdf}
}

@article{Liu,
  langid = {english},
  title = {{{HIERARCHICAL REPRESENTATIONS FOR EFFICIENT ARCHITECTURE SEARCH}}},
  abstract = {We explore efficient neural architecture search methods and present a simple yet powerful evolutionary algorithm that can discover new architectures achieving state of the art results. Our approach combines a novel hierarchical genetic representation scheme that imitates the modularized design pattern commonly adopted by human experts, and an expressive search space that supports complex topologies. Our algorithm efficiently discovers architectures that outperform a large number of manually designed models for image classification, obtaining top-1 error of 3.6\% on CIFAR-10 and 20.3\% when transferred to ImageNet, which is competitive with the best existing neural architecture search approaches and represents the new state of the art for evolutionary strategies on this task. We also present results using random search, achieving 0.3\% less top-1 accuracy on CIFAR-10 and 0.1\% less on ImageNet whilst reducing the architecture search time from 36 hours down to 1 hour.},
  pages = {13},
  author = {Liu, Hanxiao and Simonyan, Karen and Vinyals, Oriol and Fernando, Chrisantha and Kavukcuoglu, Koray},
  file = {/Users/qualia/Documents/Papers/Liu et al. - HIERARCHICAL REPRESENTATIONS FOR EFFICIENT ARCHITE.pdf}
}

@article{Liao,
  langid = {english},
  title = {Theory of {{Deep Learning II}}: {{Landscape}} of the {{Empirical Risk}} in {{Deep Learning}}},
  abstract = {Previous theoretical work on deep learning and neural network optimization tend to focus on avoiding saddle points and local minima. However, the practical observation is that, at least in the case of the most successful Deep Convolutional Neural Networks (DCNNs), practitioners can always increase the network size to fit the training data (an extreme example would be [1]). The most successful DCNNs such as VGG and ResNets are best used with a degree of ``overparametrization''. In this work, we characterize with a mix of theory and experiments, the landscape of the empirical risk of overparametrized DCNNs. We first prove in the regression framework the existence of a large number of degenerate global minimizers with zero empirical error (modulo inconsistent equations). The argument that relies on the use of Bezout theorem is rigorous when the RELUs are replaced by a polynomial nonlinearity (which empirically works as well). As described in our Theory III [2] paper, the same minimizers are degenerate and thus very likely to be found by SGD that will furthermore select with higher probability the most robust zero-minimizer. We further experimentally explored and visualized the landscape of empirical risk of a DCNN on CIFAR-10 during the entire training process and especially the global minima. Finally, based on our theoretical and experimental results, we propose an intuitive model of the landscape of DCNN's empirical loss surface, which might not be as complicated as people commonly believe.},
  pages = {45},
  author = {Liao, Qianli and Poggio, Tomaso},
  file = {/Users/qualia/Documents/Papers/Liao and Poggio - Theory of Deep Learning II Landscape of the Empir.pdf}
}

@article{Lienard2017,
  langid = {english},
  title = {Beta-{{Band Oscillations}} without {{Pathways}}: The Opposing {{Roles}} of {{D2}} and {{D5 Receptors}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/161661},
  doi = {10.1101/161661},
  shorttitle = {Beta-{{Band Oscillations}} without {{Pathways}}},
  abstract = {Parkinson's disease is characterized by the death of dopaminergic neurons and the emergence of strong {$\beta$}-band oscillations throughout the basal ganglia nuclei. According to the mainstream theory, this synchrony is mediated by a dopamine deficit within the striatum creating a functional imbalance between the D1-expressing medium spiny neurons, which project to the internal segment of the globus pallidus, and D2-expressing one, which target its external segment, and ultimately leads to oscillatory activity. However, anatomical evidence gathered in rodents and primates has shown that striatal neurons are for the most part not organized into independent populations differentially targeting the two segments of the globus pallidus, nor alternatively expressing D1 or D2 receptors, thus calling for an alternative mechanism through which the lack of dopamine may cause oscillations. Here we adopt a computational approach in which we investigate a model whose parameters are fit to an extensive set of anatomical and physiological constraints from non-human primates, including axonal transmission delays gathered from eight experimental studies. Investigating the lack of dopamine in this model revealed that in the absence of segregated pathways, {$\beta$}-band oscillations emerge as a consequence of the extra-striate dopaminergic receptors reduced activity. These oscillations are caused by synchronous activity within the external globus pallidus-subthalamic nucleus loop, and their frequency are modulated by the transmission delays between these nuclei. Our model delivers a parsimonious explanation of oscillations that does not require any external driving influence from cortex, nor specific medium spiny neuron properties.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-07-17},
  author = {Lienard, Jean F. and Cos, Ignasi and Girard, Benoit},
  file = {/Users/qualia/Documents/Papers/Lienard et al. - 2017 - Beta-Band Oscillations without Pathways the oppos 2.pdf;/Users/qualia/Documents/Papers/Lienard et al. - 2017 - Beta-Band Oscillations without Pathways the oppos.pdf}
}

@article{Li2017a,
  langid = {english},
  title = {Single-Impulse Panoramic Photoacoustic Computed Tomography of Small-Animal Whole-Body Dynamics at High Spatiotemporal Resolution},
  volume = {1},
  issn = {2157-846X},
  url = {http://www.nature.com/articles/s41551-017-0071},
  doi = {10.1038/s41551-017-0071},
  number = {5},
  journaltitle = {Nature Biomedical Engineering},
  urldate = {2019-03-30},
  date = {2017-05},
  author = {Li, Lei and Zhu, Liren and Ma, Cheng and Lin, Li and Yao, Junjie and Wang, Lidai and Maslov, Konstantin and Zhang, Ruiying and Chen, Wanyi and Shi, Junhui and Wang, Lihong V.},
  file = {/Users/qualia/Documents/Papers/Li et al. - 2017 - Single-impulse panoramic photoacoustic computed to.pdf}
}

@article{Li2017,
  langid = {english},
  title = {Lifting the Veil on the Dynamics of Neuronal Activities Evoked by Transcranial Magnetic Stimulation},
  volume = {6},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/30552},
  doi = {10.7554/eLife.30552},
  abstract = {Transcranial magnetic stimulation (TMS) is a widely used non-invasive tool to study and modulate human brain functions. However, TMS-evoked activity of individual neurons has remained largely inaccessible due to the large TMS-induced electromagnetic fields. Here, we present a general method providing direct in vivo electrophysiological access to TMS-evoked neuronal activity 0.8\textendash{}1 ms after TMS onset. We translated human single-pulse TMS to rodents and unveiled time-grained evoked activities of motor cortex layer V neurons that show high-frequency spiking within the first 6 ms depending on TMS-induced current orientation and a multiphasic spike-rhythm alternating between excitation and inhibition in the 6\textendash{}300 ms epoch, all of which can be linked to various human TMS responses recorded at the level of spinal cord and muscles. The advance here facilitates a new level of insight into the TMS-brain interaction that is vital for developing this noninvasive tool to purposefully explore and effectively treat the human brain.},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2017-11-22},
  author = {Li, Bingshuo and Virtanen, Juha P and Oeltermann, Axel and Schwarz, Cornelius and Giese, Martin A and Ziemann, Ulf and Benali, Alia},
  file = {/Users/qualia/Documents/Papers/Li et al. - 2017 - Lifting the veil on the dynamics of neuronal activ.pdf}
}

@inproceedings{Lehman2018,
  langid = {english},
  location = {{Kyoto, Japan}},
  title = {Safe Mutations for Deep and Recurrent Neural Networks through Output Gradients},
  isbn = {978-1-4503-5618-3},
  url = {http://dl.acm.org/citation.cfm?doid=3205455.3205473},
  doi = {10.1145/3205455.3205473},
  abstract = {While neuroevolution (evolving neural networks) has a successful track record across a variety of domains from reinforcement learning to artificial life, it is rarely applied to large, deep neural networks. A central reason is that while random mutation generally works in low dimensions, a random perturbation of thousands or millions of weights is likely to break existing functionality, providing no learning signal even if some individual weight changes were beneficial. This paper proposes a solution by introducing a family of safe mutation (SM) operators that aim within the mutation operator itself to find a degree of change that does not alter network behavior too much, but still facilitates exploration. Importantly, these SM operators do not require any additional interactions with the environment. The most effective SM variant capitalizes on the intriguing opportunity to scale the degree of mutation of each individual weight according to the sensitivity of the network's outputs to that weight, which requires computing the gradient of outputs with respect to the weights (instead of the gradient of error, as in conventional deep learning). This safe mutation through gradients (SM-G) operator dramatically increases the ability of a simple genetic algorithm-based neuroevolution method to find solutions in high-dimensional domains that require deep and/or recurrent neural networks (which tend to be particularly brittle to mutation), including domains that require processing raw pixels. By improving our ability to evolve deep neural networks, this new safer approach to mutation expands the scope of domains amenable to neuroevolution.},
  eventtitle = {The {{Genetic}} and {{Evolutionary Computation Conference}}},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference}} on   - {{GECCO}} '18},
  publisher = {{ACM Press}},
  urldate = {2019-03-30},
  date = {2018},
  pages = {117-124},
  author = {Lehman, Joel and Chen, Jay and Clune, Jeff and Stanley, Kenneth O.},
  file = {/Users/qualia/Documents/Papers/Lehman et al. - 2018 - Safe mutations for deep and recurrent neural netwo.pdf}
}

@article{Kushnir2017,
  langid = {english},
  title = {Neural Classifiers with Limited Connectivity and Recurrent Readouts},
  url = {http://biorxiv.org/lookup/doi/10.1101/157289},
  doi = {10.1101/157289},
  abstract = {For many neural network models that are based on perceptrons, the number of activity patterns that can be classified is limited by the number of plastic connections that each neuron receives, even when the total number of neurons is much larger. This poses the problem of how the biological brain can take advantage of its huge number of neurons given that the connectivity is extremely sparse, especially when long range connections are considered. One possible way to overcome this limitation in the case of feed-forward networks is to combine multiple perceptrons together, as in committee machines. The number of classifiable random patterns would then grow linearly with the number of perceptrons, even when each perceptron has limited connectivity. However, the problem is moved to the downstream readout neurons, which would need a number of connections that is as large as the number of perceptrons. Here we propose a different approach in which the readout is implemented by connecting multiple perceptrons in a recurrent attractor neural network. We show with analytical calculations that the number of random classifiable patterns can grow unboundedly with the number of perceptrons, even when the connectivity of each perceptron remains finite. Most importantly both the recurrent connectivity and the connectivity of a downstream readout are also finite. Our study shows that feed-forward neural classifiers with numerous long range connections connecting different layers can be replaced by networks with sparse long range connectivity and local recurrent connectivity without sacrificing the classification performance. Our strategy could be used in the future to design more general scalable network architectures with limited connectivity, which resemble more closely brain neural circuits dominated by recurrent connectivity.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-12-14},
  author = {Kushnir, Lyudmila and Fusi, Stefano},
  file = {/Users/qualia/Documents/Papers/Kushnir and Fusi - 2017 - Neural classifiers with limited connectivity and r.pdf}
}

@article{Joseph2017,
  langid = {english},
  title = {All for {{One But Not One}} for {{All}}: {{Excitatory Synaptic Scaling}} and {{Intrinsic Excitability Are Coregulated}} by {{CaMKIV}}, {{Whereas Inhibitory Synaptic Scaling Is Under Independent Control}}},
  volume = {37},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0618-17.2017},
  doi = {10.1523/JNEUROSCI.0618-17.2017},
  shorttitle = {All for {{One But Not One}} for {{All}}},
  number = {28},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2017-07-12},
  pages = {6778-6785},
  author = {Joseph, Annelise and Turrigiano, Gina G.},
  file = {/Users/qualia/Documents/Papers/Joseph and Turrigiano - 2017 - All for One But Not One for All Excitatory Synapt.pdf}
}

@article{Tran2017,
  langid = {english},
  title = {Ionic {{Current Correlations Are Ubiquitous Across Phyla}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/137133},
  doi = {10.1101/137133},
  abstract = {Ionic currents, whether measured as conductance amplitude or as ion channel transcript levels, can vary many-fold within a population of identified neurons. This variability has been observed in multiple invertebrate neuronal types, but they do so in a coordinated manner such that their magnitudes are correlated. These conductance correlations are thought to reflect a tight homeostasis of cellular excitability that enhances the robustness and stability of neuronal activity over long stretches of time. Notably, although such ionic current correlations are well documented in invertebrates, they have not been reported in vertebrates. Here we demonstrate with two examples, identified mouse hippocampal granule cells and cholinergic basal forebrain neurons, that ionic current correlations is a ubiquitous phenomenon expressed by a number of species across phyla.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-05-12},
  author = {Tran, Trinh and Unal, Cagri T. and Zaborszky, Laszlo and Rotstein, Horacio G. and Kirkwood, Alfredo and Golowasch, Jorge P.},
  file = {/Users/qualia/Documents/Papers/Tran et al. - 2017 - Ionic Current Correlations Are Ubiquitous Across P 2.pdf;/Users/qualia/Documents/Papers/Tran et al. - 2017 - Ionic Current Correlations Are Ubiquitous Across P.pdf}
}

@article{Jones2016,
  langid = {english},
  title = {When Brain Rhythms Aren't `Rhythmic': Implication for Their Mechanisms and Meaning},
  volume = {40},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438816300769},
  doi = {10.1016/j.conb.2016.06.010},
  shorttitle = {When Brain Rhythms Aren't `Rhythmic'},
  abstract = {Rhythms are a prominent signature of brain activity. Their expression is correlated with numerous examples of healthy information processing and their fluctuations are a marker of disease states. Yet, their causal or epiphenomenal role in brain function is still highly debated. We review recent studies showing brain rhythms are not always ``rhythmic'', by which we mean representative of repeated cycles of activity. Rather, high power and continuous rhythms in averaged signals can represent brief transient events on single trials whose density accumulates in the average. We also review evidence showing time-domain signals with vastly different waveforms can exhibit identical spectral-domain frequency and power. Further, non-oscillatory waveform feature can create spurious high spectral power. Knowledge of these possibilities is essential when interpreting rhythms and is easily missed without considering pre-processed data. Lastly, we discuss how these finding suggest new directions to pursue in our quest to discover the mechanism and meaning of brain rhythms.},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2016-10},
  pages = {72-80},
  author = {Jones, Stephanie R},
  file = {/Users/qualia/Documents/Papers/Jones - 2016 - When brain rhythms aren't ‘rhythmic’ implication  2.pdf;/Users/qualia/Documents/Papers/Jones - 2016 - When brain rhythms aren't ‘rhythmic’ implication .pdf}
}

@article{Jang2017,
  langid = {english},
  title = {Task-Specific Feature Extraction and Classification of {{fMRI}} Volumes Using a Deep Neural Network Initialized with a Deep Belief Network: {{Evaluation}} Using Sensorimotor Tasks},
  volume = {145},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811916300362},
  doi = {10.1016/j.neuroimage.2016.04.003},
  shorttitle = {Task-Specific Feature Extraction and Classification of {{fMRI}} Volumes Using a Deep Neural Network Initialized with a Deep Belief Network},
  abstract = {Feedforward deep neural networks (DNN), artificial neural networks with multiple hidden layers, have recently demonstrated a record-breaking performance in multiple areas of applications in computer vision and speech processing. Following the success, DNNs have been applied to neuroimaging modalities including functional/structural magnetic resonance imaging (MRI) and positron-emission tomography data. However, no study has explicitly applied DNNs to 3D wholebrain fMRI volumes and thereby extracted hidden volumetric representations of fMRI that are discriminative for a task performed as the fMRI volume was acquired. Our study applied fully connected feedforward DNN to fMRI volumes collected in four sensorimotor tasks (i.e., left-hand clenching, right-hand clenching, auditory attention, and visual stimulus) undertaken by 12 healthy participants. Using a leave-one-subject-out cross-validation scheme, a restricted Boltzmann machinebased deep belief network was pretrained and used to initialize weights of the DNN. The pretrained DNN was fine-tuned while systematically controlling weight-sparsity levels across hidden layers. Optimal weight-sparsity levels were determined from a minimum validation error rate of fMRI volume classification. Minimum error rates (mean  standard deviation; \%) of 6.9 ( 3.8) were obtained from the three-layer DNN with the sparsest condition of weights across the three hidden layers. These error rates were even lower than the error rates from the single-layer network (9.4 {$\pm$} 4.6) and the two-layer network (7.4 {$\pm$} 4.1). The estimated DNN weights showed spatial patterns that are remarkably task-specific, particularly in the higher layers. The output values of the third hidden layer represented distinct patterns/codes of the 3D whole-brain fMRI volume and encoded the information of the tasks as evaluated from representational similarity analysis. Our reported findings show the ability of the DNN to classify a single fMRI volume based on the extraction of hidden representations of fMRI volumes associated with tasks across multiple hidden layers. Our study may be beneficial to the automatic classification/diagnosis of neuropsychiatric and neurological diseases and prediction of disease severity and recovery in (pre-) clinical settings using fMRI volumes without requiring an estimation of activation patterns or ad hoc statistical evaluation.},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2017-01},
  pages = {314-328},
  author = {Jang, Hojin and Plis, Sergey M. and Calhoun, Vince D. and Lee, Jong-Hwan},
  file = {/Users/qualia/Documents/Papers/Jang et al. - 2017 - Task-specific feature extraction and classificatio.pdf}
}

@article{Inagaki2017,
  langid = {english},
  title = {Discrete Attractor Dynamics Underlying Selective Persistent Activity in Frontal Cortex},
  url = {http://biorxiv.org/lookup/doi/10.1101/203448},
  doi = {10.1101/203448},
  abstract = {Short-term memories link events separated in time, such as past sensation and future actions. Short-term memories are correlated with selective persistent activity, which can be maintained over seconds. In a delayed response task that requires short-term memory, neurons in mouse anterior lateral motor cortex (ALM) show persistent activity that instructs future actions. To elucidate the mechanisms underlying this persistent activity we combined intracellular and extracellular electrophysiology with optogenetic perturbations and network modeling. During the delay epoch, both membrane potential and population activity of ALM neurons funneled towards discrete endpoints related to specific movement directions. These endpoints were robust to transient shifts in ALM activity caused by optogenetic perturbations. Perturbations occasionally switched the population dynamics to the other endpoint, followed by incorrect actions. Our results are consistent with discrete attractor dynamics underlying short-term memory related to motor planning.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-10-16},
  author = {Inagaki, Hidehiko K. and Fontolan, Lorenzo and Romani, Sandro and Svoboda, Karel},
  file = {/Users/qualia/Documents/Papers/Inagaki et al. - 2017 - Discrete attractor dynamics underlying selective p.pdf}
}

@article{Iemi2017,
  langid = {english},
  title = {Spontaneous {{Neural Oscillations Bias Perception}} by {{Modulating Baseline Excitability}}},
  volume = {37},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1432-16.2017},
  doi = {10.1523/JNEUROSCI.1432-16.2017},
  number = {4},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2017-01-25},
  pages = {807-819},
  author = {Iemi, Luca and Chaumon, Maximilien and Crouzet, S\'ebastien M. and Busch, Niko A.},
  file = {/Users/qualia/Documents/Papers/Iemi et al. - 2017 - Spontaneous Neural Oscillations Bias Perception by.pdf}
}

@article{Honey2017,
  langid = {english},
  title = {Switching between Internal and External Modes: {{A}} Multiscale Learning Principle},
  volume = {1},
  issn = {2472-1751},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/NETN_a_00024},
  doi = {10.1162/NETN_a_00024},
  shorttitle = {Switching between Internal and External Modes},
  number = {4},
  journaltitle = {Network Neuroscience},
  urldate = {2019-03-30},
  date = {2017-12},
  pages = {339-356},
  author = {Honey, Christopher J. and Newman, Ehren L. and Schapiro, Anna C.},
  file = {/Users/qualia/Documents/Papers/Honey et al. - 2017 - Switching between internal and external modes A m.pdf}
}

@article{Histed2017,
  langid = {english},
  title = {Feedforward Inhibition Allows Input Summation to Vary in Recurrent Cortical Networks},
  url = {http://biorxiv.org/lookup/doi/10.1101/109736},
  doi = {10.1101/109736},
  abstract = {Brain computations depend on how neurons transform inputs to spike outputs. Here, to understand input-output transformations in cortical networks, we recorded spiking responses from visual cortex (V1) of awake mice of either sex while pairing sensory stimuli with optogenetic perturbation of excitatory and parvalbumin-positive inhibitory neurons.  We found V1 neurons' average responses were primarily additive (linear). We used a recurrent cortical network model to determine if these data, as well as past observations of nonlinearity, could be described by a common circuit architecture.  The model showed cortical input-output transformations can be changed from linear to sublinear with moderate (\textasciitilde{}20\%) strengthening of connections between inhibitory neurons, but this change depends on the presence of feedforward inhibition.  Thus, feedforward inhibition, a common feature of cortical circuitry, enables networks to flexibly change their spiking responses via changes in recurrent connectivity.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-06-28},
  author = {Histed, Mark H},
  file = {/Users/qualia/Documents/Papers/Histed - 2017 - Feedforward inhibition allows input summation to v.pdf}
}

@article{Hessel,
  langid = {english},
  title = {Rainbow: {{Combining Improvements}} in {{Deep Reinforcement Learning}}},
  abstract = {The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance.},
  pages = {14},
  author = {Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Hessel et al. - Rainbow Combining Improvements in Deep Reinforcem.pdf}
}

@article{Heeger2017,
  langid = {english},
  title = {Theory of Cortical Function},
  volume = {114},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1619788114},
  doi = {10.1073/pnas.1619788114},
  number = {8},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2017-02-21},
  pages = {1773-1782},
  author = {Heeger, David J.},
  file = {/Users/qualia/Documents/Papers/Heeger - 2017 - Theory of cortical function.pdf}
}

@article{Hassabis2017,
  langid = {english},
  title = {Neuroscience-{{Inspired Artificial Intelligence}}},
  volume = {95},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627317305093},
  doi = {10.1016/j.neuron.2017.06.011},
  number = {2},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2017-07},
  pages = {245-258},
  author = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
  file = {/Users/qualia/Documents/Papers/Hassabis et al. - 2017 - Neuroscience-Inspired Artificial Intelligence.pdf}
}

@article{OHare2017,
  langid = {english},
  title = {Striatal Fast-Spiking Interneurons Selectively Modulate Circuit Output and Are Required for Habitual Behavior},
  volume = {6},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/26231},
  doi = {10.7554/eLife.26231},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2017-09-05},
  author = {O'Hare, Justin K and Li, Haofang and Kim, Namsoo and Gaidis, Erin and Ade, Kristen and Beck, Jeff and Yin, Henry and Calakos, Nicole},
  file = {/Users/qualia/Documents/Papers/O'Hare et al. - 2017 - Striatal fast-spiking interneurons selectively mod.pdf}
}

@article{Haarnoja,
  langid = {english},
  title = {Reinforcement {{Learning}} with {{Deep Energy}}-{{Based Policies}}},
  abstract = {We propose a method for learning expressive energy-based policies for continuous states and actions, which has been feasible only in tabular domains before. We apply our method to learning maximum entropy policies, resulting into a new algorithm, called soft Q-learning, that expresses the optimal policy via a Boltzmann distribution. We use the recently proposed amortized Stein variational gradient descent to learn a stochastic sampling network that approximates samples from this distribution. The benefits of the proposed algorithm include improved exploration and compositionality that allows transferring skills between tasks, which we confirm in simulated experiments with swimming and walking robots. We also draw a connection to actorcritic methods, which can be viewed performing approximate inference on the corresponding energy-based model.},
  pages = {16},
  author = {Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  file = {/Users/qualia/Documents/Papers/Haarnoja et al. - Reinforcement Learning with Deep Energy-Based Poli.pdf}
}

@article{Grewe2017,
  langid = {english},
  title = {Synchronous Spikes Are Necessary but Not Sufficient for a Synchrony Code in Populations of Spiking Neurons},
  volume = {114},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1615561114},
  doi = {10.1073/pnas.1615561114},
  number = {10},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2017-03-07},
  pages = {E1977-E1985},
  author = {Grewe, Jan and Kruscha, Alexandra and Lindner, Benjamin and Benda, Jan},
  file = {/Users/qualia/Documents/Papers/Grewe et al. - 2017 - Synchronous spikes are necessary but not sufficien.pdf}
}

@article{Gips2017,
  langid = {english},
  title = {Discovering Recurring Patterns in Electrophysiological Recordings},
  volume = {275},
  issn = {01650270},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027016302606},
  doi = {10.1016/j.jneumeth.2016.11.001},
  abstract = {Background: Fourier-based techniques are used abundantly in the analysis of electrophysiological data. However, these techniques are of limited value when the signal of interest is non-sinusoidal or nonperiodic. New method: We present sliding window matching (SWM): a new data-driven method for discovering recurring temporal patterns in electrophysiological data. SWM is effective in detecting recurring but unknown patterns even when they appear non-periodically.
Results: To demonstrate this, we used SWM on oscillations in local field potential (LFP) recordings from the rat hippocampus and monkey V1. The application of SWM yielded two interesting findings. We could show that rat hippocampal theta and monkey V1 gamma oscillations were both skewed (i.e. asymmetric in time), rather than being sinusoidal. Furthermore, gamma oscillations in monkey V1 were skewed differently in the superficial compared to the deeper cortical layers. Second, we used SWM to analyze responses evoked by stimuli or microsaccades even when the onset timing of stimulus or microsaccades was unknown.
Comparison with existing methods: We first validated the method on simulated datasets, and we checked that for recordings with a sufficiently low noise level the SWM results were consistent with results from the widely used phase alignment (PA) method.
Conclusions: We conclude that the proposed method has wide applicability in the exploration of noisy time series data where the onset times of particular events are unknown by the experimenter such as in resting state and sleep recordings.},
  journaltitle = {Journal of Neuroscience Methods},
  urldate = {2019-03-30},
  date = {2017-01},
  pages = {66-79},
  author = {Gips, Bart and Bahramisharif, Ali and Lowet, Eric and Roberts, Mark J. and de Weerd, Peter and Jensen, Ole and van der Eerden, Jan},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Gips et al. - 2017 - Discovering recurring patterns in electrophysiolog.pdf}
}

@article{Geirhos,
  langid = {english},
  title = {Comparing Deep Neural Networks against Humans: Object Recognition When the Signal Gets Weaker},
  abstract = {Human visual object recognition is typically rapid and seemingly effortless, as well as largely independent of viewpoint and object orientation. Until very recently, animate visual systems were the only ones capable of this remarkable computational feat. This has changed with the rise of a class of computer vision algorithms called deep neural networks (DNNs) that achieve human-level classification performance on object recognition tasks. Furthermore, a growing number of studies report similarities in the way DNNs and the human visual system process objects, suggesting that current DNNs may be good models of human visual object recognition. Yet there clearly exist important architectural and processing differences between stateof-the-art DNNs and the primate visual system. The potential behavioural consequences of these differences are not well understood. We aim to address this issue by comparing human and DNN generalisation abilities towards image degradations. We find the human visual system to be more robust to image manipulations like contrast reduction, additive noise or novel eidolon-distortions. In addition, we find progressively diverging classification error-patterns between man and DNNs when the signal gets weaker, indicating that there may still be marked differences in the way humans and current DNNs perform visual object recognition. We envision that our findings as well as our carefully measured and freely available behavioural datasets1 provide a new useful benchmark for the computer vision community to improve the robustness of DNNs and a motivation for neuroscientists to search for mechanisms in the brain that could facilitate this robustness.},
  pages = {31},
  author = {Geirhos, Robert and Janssen, David H J and Schutt, Heiko H and Rauber, Jonas and Bethge, Matthias and Wichmann, Felix A},
  file = {/Users/qualia/Documents/Papers/Geirhos et al. - Comparing deep neural networks against humans obj.pdf}
}

@article{Gabalda-Sagarra2017,
  langid = {english},
  title = {Recurrence-{{Based Information Processing}} in {{Gene Regulatory Networks}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/010124},
  doi = {10.1101/010124},
  abstract = {Cellular information processing is generally attributed to the complex networks of genes and proteins that regulate cell behavior. It is still unclear, however, what are the main features of those networks that allow a cell to encode and interpret its ever changing environment. Here we address this question by studying the computational capabilities of the transcriptional regulatory networks of five evolutionary distant organisms. We identify in all cases a cyclic recurrent structure, formed by a small core of genes, that is essential for dynamical encoding and information integration. The recent history of the cell is encoded by the transient dynamics of this recurrent reservoir of nodes, while the rest of the network forms a readout layer devoted to decode and interpret the highdimensional dynamical state of the recurrent core. This separation of roles allows for the integration of temporal information, while facilitating the learning of new environmental conditions and preventing catastrophic interference between those new inputs and the previously stored information. This resembles the reservoir-computing paradigm recently proposed in computational neuroscience and machine learning. Our results reveal that gene regulatory networks act as echo-state networks that perform optimally in standard memory-demanding tasks, and confirms that most of their memory resides in the recurrent reservoir. We also show that the readout layer can learn to decode the information stored in the reservoir via standard evolutionary strategies. Our work thus suggests that recurrent dynamics is a key element for the processing of complex time-dependent information by cells.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-09-05},
  author = {Gabalda-Sagarra, Marcal and Carey, Lucas and Garcia-Ojalvo, Jordi},
  file = {/Users/qualia/Documents/Papers/Gabalda-Sagarra et al. - 2017 - Recurrence-Based Information Processing in Gene Re.pdf}
}

@article{Fregnac2017,
  langid = {english},
  title = {Big Data and the Industrialization of Neuroscience: {{A}} Safe Roadmap for Understanding the Brain?},
  volume = {358},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aan8866},
  doi = {10.1126/science.aan8866},
  shorttitle = {Big Data and the Industrialization of Neuroscience},
  number = {6362},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2017-10-27},
  pages = {470-477},
  author = {Fr\'egnac, Yves},
  file = {/Users/qualia/Documents/Papers/Frégnac - 2017 - Big data and the industrialization of neuroscience.pdf}
}

@inproceedings{Favaretto2017,
  langid = {english},
  location = {{Seattle, WA, USA}},
  title = {Bode Meets {{Kuramoto}}: {{Synchronized}} Clusters in Oscillatory Networks},
  isbn = {978-1-5090-5992-8},
  url = {http://ieeexplore.ieee.org/document/7963375/},
  doi = {10.23919/ACC.2017.7963375},
  shorttitle = {Bode Meets {{Kuramoto}}},
  abstract = {In this paper we study cluster synchronization in a network of Kuramoto oscillators, where groups of oscillators evolve cohesively and at different frequencies from the neighboring oscillators. Synchronization is critical in a variety of systems, where it enables complex functionalities and behaviors. Synchronization over networks depends on the oscillators' dynamics, the interaction topology, and coupling strengths, and the relationship between these different factors can be quite intricate. In this work we formally show that three network properties enable the emergence of cluster synchronization. Specifically, weak inter-cluster connections, strong intra-cluster connections, and sufficiently diverse natural frequencies among oscillators belonging to different groups. Our approach relies on system-theoretic tools, and is validated with numerical studies.},
  eventtitle = {2017 {{American Control Conference}} ({{ACC}})},
  booktitle = {2017 {{American Control Conference}} ({{ACC}})},
  publisher = {{IEEE}},
  urldate = {2019-03-30},
  date = {2017-05},
  pages = {2799-2804},
  author = {Favaretto, Chiara and Bassett, Danielle S. and Cenedese, Angelo and Pasqualetti, Fabio},
  file = {/Users/qualia/Documents/Papers/Favaretto et al. - 2017 - Bode meets Kuramoto Synchronized clusters in osci.pdf}
}

@article{Erev1998a,
  langid = {english},
  title = {Signal Detection by Human Observers: {{A}} Cutoff Reinforcement Learning Model of Categorization Decisions under Uncertainty.},
  volume = {105},
  issn = {0033-295X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.105.2.280},
  doi = {10.1037//0033-295X.105.2.280},
  shorttitle = {Signal Detection by Human Observers},
  number = {2},
  journaltitle = {Psychological Review},
  urldate = {2019-03-30},
  date = {1998},
  pages = {280-298},
  author = {Erev, Ido},
  file = {/Users/qualia/Documents/Papers/Erev - 1998 - Signal detection by human observers A cutoff rein.pdf}
}

@article{Eichler2017,
  langid = {english},
  title = {The Complete Connectome of a Learning and Memory Centre in an Insect Brain},
  volume = {548},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature23455},
  doi = {10.1038/nature23455},
  number = {7666},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2017-08},
  pages = {175-182},
  author = {Eichler, Katharina and Li, Feng and Litwin-Kumar, Ashok and Park, Youngser and Andrade, Ingrid and Schneider-Mizell, Casey M. and Saumweber, Timo and Huser, Annina and Eschbach, Claire and Gerber, Bertram and Fetter, Richard D. and Truman, James W. and Priebe, Carey E. and Abbott, L. F. and Thum, Andreas S. and Zlatic, Marta and Cardona, Albert},
  file = {/Users/qualia/Documents/Papers/Eichler et al. - 2017 - The complete connectome of a learning and memory c.pdf}
}

@article{Duarte2017,
  langid = {english},
  title = {Synaptic Patterning and the Timescales of Cortical Dynamics},
  volume = {43},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438817300545},
  doi = {10.1016/j.conb.2017.02.007},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2017-04},
  pages = {156-165},
  author = {Duarte, Renato and Seeholzer, Alexander and Zilles, Karl and Morrison, Abigail},
  file = {/Users/qualia/Documents/Papers/Duarte et al. - 2017 - Synaptic patterning and the timescales of cortical.pdf}
}

@article{CogliatiDezza2017,
  langid = {english},
  title = {Learning the Value of Information and Reward over Time When Solving Exploration-Exploitation Problems},
  volume = {7},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/s41598-017-17237-w},
  doi = {10.1038/s41598-017-17237-w},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2017-12},
  author = {Cogliati Dezza, Irene and Yu, Angela J. and Cleeremans, Axel and Alexander, William},
  file = {/Users/qualia/Documents/Papers/Cogliati Dezza et al. - 2017 - Learning the value of information and reward over .pdf}
}

@article{DePasquale2018,
  langid = {english},
  title = {Full-{{FORCE}}: {{A}} Target-Based Method for Training Recurrent Networks},
  volume = {13},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0191527},
  doi = {10.1371/journal.pone.0191527},
  shorttitle = {Full-{{FORCE}}},
  abstract = {Trained recurrent networks are powerful tools for modeling dynamic neural computations. We present a target-based method for modifying the full connectivity matrix of a recurrent network to train it to perform tasks involving temporally complex input/output transformations. The method introduces a second network during training to provide suitable ``target'' dynamics useful for performing the task. Because it exploits the full recurrent connectivity, the method produces networks that perform tasks with fewer neurons and greater noise robustness than traditional least-squares (FORCE) approaches. In addition, we show how introducing additional input signals into the target-generating network, which act as task hints, greatly extends the range of tasks that can be learned and provides control over the complexity and nature of the dynamics of the trained, task-performing network.},
  number = {2},
  journaltitle = {PLOS ONE},
  urldate = {2019-03-30},
  date = {2018-02-07},
  pages = {e0191527},
  author = {DePasquale, Brian and Cueva, Christopher J. and Rajan, Kanaka and Escola, G. Sean and Abbott, L. F.},
  editor = {Chacron, Maurice J.},
  file = {/Users/qualia/Documents/Papers/DePasquale et al. - 2018 - full-FORCE A target-based method for training rec.pdf}
}

@article{Csaba,
  langid = {english},
  title = {Perspectives of {{Using Oscillators}} for {{Computing}} and {{Signal Processing}}},
  abstract = {It is an intriguing concept to use oscillators as fundamental building blocks of electronic computers. The idea is not new, but is currently subject to intense research as a part of the quest for 'beyond Moore' electronic devices. In this paper we give an engineering-minded survey of oscillator-based computing architectures, with the goal of understanding their promise and limitations for next-generation computing. We will mostly discuss non-Boolean, neurally-inspired computing concepts and put the emphasis on hardware and on circuits where the oscillators are realized from emerging, nanoscale building blocks. Despite all the promise that oscillatory computing holds, existing literature gives very few clear-cut arguments about the possible benefits of using oscillators in place of other analog nonlinear circuit elements. In this survey we will argue for finding the rationale of using oscillatory building blocks and call for benchmarking studies that compare oscillatory computing circuits to level-based (analog) implementations.},
  pages = {12},
  author = {Csaba, Gyorgy and Porod, Wolfgang},
  file = {/Users/qualia/Documents/Papers/Csaba and Porod - Perspectives of Using Oscillators for Computing an.pdf}
}

@article{Creswell2018,
  langid = {english},
  title = {Generative {{Adversarial Networks}}: {{An Overview}}},
  volume = {35},
  issn = {1053-5888},
  url = {http://ieeexplore.ieee.org/document/8253599/},
  doi = {10.1109/MSP.2017.2765202},
  shorttitle = {Generative {{Adversarial Networks}}},
  abstract = {Generative adversarial networks (GANs) provide a way to learn deep representations without extensively annotated training data. They achieve this through deriving backpropagation signals through a competitive process involving a pair of networks. The representations that can be learned by GANs may be used in a variety of applications, including image synthesis, semantic image editing, style transfer, image super-resolution and classification. The aim of this review paper is to provide an overview of GANs for the signal processing community, drawing on familiar analogies and concepts where possible. In addition to identifying different methods for training and constructing GANs, we also point to remaining challenges in their theory and application.},
  number = {1},
  journaltitle = {IEEE Signal Processing Magazine},
  urldate = {2019-03-30},
  date = {2018-01},
  pages = {53-65},
  author = {Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
  file = {/Users/qualia/Documents/Papers/Creswell et al. - 2018 - Generative Adversarial Networks An Overview.pdf}
}

@article{Conaway2017,
  langid = {english},
  title = {Solving {{Nonlinearly Separable Classifications}} in a {{Single}}-{{Layer Neural Network}}},
  volume = {29},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00931},
  doi = {10.1162/NECO_a_00931},
  number = {3},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2017-03},
  pages = {861-866},
  author = {Conaway, Nolan and Kurtz, Kenneth J.},
  file = {/Users/qualia/Documents/Papers/Conaway and Kurtz - 2017 - Solving Nonlinearly Separable Classifications in a.pdf}
}

@article{Cole2017,
  langid = {english},
  title = {Brain {{Oscillations}} and the {{Importance}} of {{Waveform Shape}}},
  volume = {21},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661316302182},
  doi = {10.1016/j.tics.2016.12.008},
  number = {2},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2017-02},
  pages = {137-149},
  author = {Cole, Scott R. and Voytek, Bradley},
  file = {/Users/qualia/Documents/Papers/Cole and Voytek - 2017 - Brain Oscillations and the Importance of Waveform  2.pdf;/Users/qualia/Documents/Papers/Cole and Voytek - 2017 - Brain Oscillations and the Importance of Waveform .pdf}
}

@article{Cole2017a,
  langid = {english},
  title = {Nonsinusoidal {{Beta Oscillations Reflect Cortical Pathophysiology}} in {{Parkinson}}'s {{Disease}}},
  volume = {37},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.2208-16.2017},
  doi = {10.1523/JNEUROSCI.2208-16.2017},
  number = {18},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2017-05-03},
  pages = {4830-4840},
  author = {Cole, Scott R. and van der Meij, Roemer and Peterson, Erik J. and de Hemptinne, Coralie and Starr, Philip A. and Voytek, Bradley},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Cole et al. - 2017 - Nonsinusoidal Beta Oscillations Reflect Cortical P.pdf}
}

@article{Cohen2017,
  langid = {english},
  title = {Computational Approaches to {{fMRI}} Analysis},
  volume = {20},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4499},
  doi = {10.1038/nn.4499},
  number = {3},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2017-03},
  pages = {304-313},
  author = {Cohen, Jonathan D and Daw, Nathaniel and Engelhardt, Barbara and Hasson, Uri and Li, Kai and Niv, Yael and Norman, Kenneth A and Pillow, Jonathan and Ramadge, Peter J and Turk-Browne, Nicholas B and Willke, Theodore L},
  file = {/Users/qualia/Documents/Papers/Cohen et al. - 2017 - Computational approaches to fMRI analysis.pdf}
}

@article{Chang2017,
  langid = {english},
  title = {The {{Code}} for {{Facial Identity}} in the {{Primate Brain}}},
  volume = {169},
  issn = {00928674},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S009286741730538X},
  doi = {10.1016/j.cell.2017.05.011},
  abstract = {Primates recognize complex objects such as faces with remarkable speed and reliability. Here, we reveal the brain's code for facial identity. Experiments in macaques demonstrate an extraordinarily simple transformation between faces and responses of cells in face patches. By formatting faces as points in a high-dimensional linear space, we discovered that each face cell's firing rate is proportional to the projection of an incoming face stimulus onto a single axis in this space, allowing a face cell ensemble to encode the location of any face in the space. Using this code, we could precisely decode faces from neural population responses and predict neural firing rates to faces. Furthermore, this code disavows the long-standing assumption that face cells encode specific facial identities, confirmed by engineering faces with drastically different appearance that elicited identical responses in single face cells. Our work suggests that other objects could be encoded by analogous metric coordinate systems.},
  number = {6},
  journaltitle = {Cell},
  urldate = {2019-03-30},
  date = {2017-06},
  pages = {1013-1028.e14},
  author = {Chang, Le and Tsao, Doris Y.},
  file = {/Users/qualia/Documents/Papers/Chang and Tsao - 2017 - The Code for Facial Identity in the Primate Brain.pdf}
}

@article{Cannon2017,
  langid = {english},
  title = {Stable {{Control}} of {{Firing Rate Mean}} and {{Variance}} by {{Dual Homeostatic Mechanisms}}},
  volume = {7},
  issn = {2190-8567},
  url = {http://mathematical-neuroscience.springeropen.com/articles/10.1186/s13408-017-0043-7},
  doi = {10.1186/s13408-017-0043-7},
  abstract = {Homeostatic processes that provide negative feedback to regulate neuronal firing rates are essential for normal brain function. Indeed, multiple parameters of individual neurons, including the scale of afferent synapse strengths and the densities of specific ion channels, have been observed to change on homeostatic time scales to oppose the effects of chronic changes in synaptic input. This raises the question of whether these processes are controlled by a single slow feedback variable or multiple slow variables. A single homeostatic process providing negative feedback to a neuron's firing rate naturally maintains a stable homeostatic equilibrium with a characteristic mean firing rate; but the conditions under which multiple slow feedbacks produce a stable homeostatic equilibrium have not yet been explored. Here we study a highly general model of homeostatic firing rate control in which two slow variables provide negative feedback to drive a firing rate toward two different target rates. Using dynamical systems techniques, we show that such a control system can be used to stably maintain a neuron's characteristic firing rate mean and variance in the face of perturbations, and we derive conditions under which this happens. We also derive expressions that clarify the relationship between the homeostatic firing rate targets and the resulting stable firing rate mean and variance. We provide specific examples of neuronal systems that can be effectively regulated by dual homeostasis. One of these examples is a recurrent excitatory network, which a dual feedback system can robustly tune to serve as an integrator.},
  number = {1},
  journaltitle = {The Journal of Mathematical Neuroscience},
  urldate = {2019-03-30},
  date = {2017-12},
  author = {Cannon, Jonathan and Miller, Paul},
  file = {/Users/qualia/Documents/Papers/Cannon and Miller - 2017 - Stable Control of Firing Rate Mean and Variance by.pdf}
}

@article{Caceres,
  langid = {english},
  title = {Towards a Realistic {{NNLIF}} Model: {{Analysis}} and Numerical Solver for Excitatory-Inhibitory Networks with Delay and Refractory Periods},
  abstract = {The Network of Noisy Leaky Integrate and Fire (NNLIF) model describes the behavior of a neural network at mesoscopic level. It is one of the simplest self-contained mean-field models considered for that purpose. Even so, to study the mathematical properties of the model some simplifications were necessary [4, 5, 6], which disregard crucial phenomena. In this work we deal with the general NNLIF model without simplifications. It involves a network with two populations (excitatory and inhibitory), with transmission delays between the neurons and where the neurons remain in a refractory state for a certain time. We have studied the number of steady states in terms of the model parameters, the long time behaviour via the entropy method and Poincar\textasciiacute{}e's inequality, blow-up phenomena, and the importance of transmission delays between excitatory neurons to prevent blow-up and to give rise to synchronous solutions. Besides analytical results, we have presented a numerical resolutor for this model, based on high order flux-splitting WENO schemes and an explicit third order TVD Runge-Kutta method, in order to describe the wide range of phenomena exhibited by the network: blow-up, asynchronous/synchronous solutions and instability/stability of the steady states; the solver also allows us to observe the time evolution of the firing rates, refractory states and the probability distributions of the excitatory and inhibitory populations.},
  pages = {28},
  author = {Caceres, Mar\i{}a J and Schneider, Ricarda},
  file = {/Users/qualia/Documents/Papers/Caceres and Schneider - Towards a realistic NNLIF model Analysis and nume.pdf}
}

@article{Beyeler2017,
  langid = {english},
  title = {Sparse Coding and Dimensionality Reduction in Cortex},
  url = {http://biorxiv.org/lookup/doi/10.1101/149880},
  doi = {10.1101/149880},
  abstract = {Supported by recent computational studies, sparse coding and dimensionality reduction are emerging as a ubiquitous coding strategy across brain regions and modalities, allowing neurons to achieve nonnegative sparse coding (NSC) by efficiently encoding highdimensional stimulus spaces using a sparse and parts-based population code. Reducing the dimensionality of complex, multimodal sensory streams is critically important for metabolically constrained brain areas to represent the world. In this article, we provide an overview of NSC, summarize evidence for its role in neural computation in disparate regions of the brain, ranging from visual processing to spatial navigation, and speculate that specific forms of synaptic plasticity and homeostatic modulation may underlie its implementation. We suggest that NSC may be an organizing principle in the nervous system.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-06-14},
  author = {Beyeler, Michael and Rounds, Emily and Carlson, Kristofor and Dutt, Nikil and Krichmar, Jeffrey L.},
  file = {/Users/qualia/Documents/Papers/Beyeler et al. - 2017 - Sparse coding and dimensionality reduction in cort.pdf}
}

@article{Bansal2018,
  langid = {english},
  title = {{{EMERGENT COMPLEXITY VIA MULTI}}-{{AGENT COMPETITION}}},
  abstract = {Reinforcement learning algorithms can train agents that solve problems in complex, interesting environments. Normally, the complexity of the trained agent is closely related to the complexity of the environment. This suggests that a highly capable agent requires a complex environment for training. In this paper, we point out that a competitive multi-agent environment trained with self-play can produce behaviors that are far more complex than the environment itself. We also point out that such environments come with a natural curriculum, because for any skill level, an environment full of agents of this level will have the right level of difficulty.},
  date = {2018},
  pages = {12},
  author = {Bansal, Trapit and Pachocki, Jakub and Sidor, Szymon and Sutskever, Ilya and Mordatch, Igor},
  file = {/Users/qualia/Documents/Papers/Bansal et al. - 2018 - EMERGENT COMPLEXITY VIA MULTI-AGENT COMPETITION.pdf}
}

@article{Arpit,
  langid = {english},
  title = {A {{Closer Look}} at {{Memorization}} in {{Deep Networks}}},
  abstract = {We examine the role of memorization in deep learning, drawing connections to capacity, generalization, and adversarial robustness. While deep networks are capable of memorizing noise data, our results suggest that they tend to prioritize learning simple patterns first. In our experiments, we expose qualitative differences in gradient-based optimization of deep neural networks (DNNs) on noise vs. real data. We also demonstrate that for appropriately tuned explicit regularization (e.g., dropout) we can degrade DNN training performance on noise datasets without compromising generalization on real data. Our analysis suggests that the notions of effective capacity which are dataset independent are unlikely to explain the generalization performance of deep networks when trained with gradient based methods because training data itself plays an important role in determining the degree of memorization.},
  pages = {10},
  author = {Arpit, Devansh and Jastrzebski, Stanis\l{}aw and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and Lacoste-Julien, Simon},
  file = {/Users/qualia/Documents/Papers/Arpit et al. - A Closer Look at Memorization in Deep Networks.pdf}
}

@article{Arakaki2017,
  langid = {english},
  title = {Capturing the Diversity of Biological Tuning Curves Using Generative Adversarial Networks},
  url = {http://biorxiv.org/lookup/doi/10.1101/167916},
  doi = {10.1101/167916},
  abstract = {Tuning curves characterizing the response selectivities of biological neurons often exhibit large degrees of irregularity and diversity across neurons. Theoretical network models that feature heterogeneous cell populations or random connectivity also give rise to diverse tuning curves. However, a general framework for fitting such models to experimentally measured tuning curves is lacking. We address this problem by proposing to view mechanistic network models as generative models whose parameters can be optimized to fit the distribution of experimentally measured tuning curves. A major obstacle for fitting such models is that their likelihood function is not explicitly available or is highly intractable to compute. Recent advances in machine learning provide ways for fitting generative models without the need to evaluate the likelihood and its gradient. Generative Adversarial Networks (GAN) provide one such framework which has been successful in traditional machine learning tasks. We apply this approach in two separate experiments, showing how GANs can be used to fit commonly used mechanistic models in theoretical neuroscience to datasets of measured tuning curves. This fitting procedure avoids the computationally expensive step of inferring latent variables, e.g., the biophysical parameters of individual cells or the particular realization of the full synaptic connectivity matrix, and directly learns model parameters which characterize the statistics of connectivity or of single-cell properties. Another strength of this approach is that it fits the entire, joint distribution of experimental tuning curves, instead of matching a few summary statistics picked a priori by the user. More generally, this framework opens the door to fitting theoretically motivated dynamical network models directly to simultaneously or non-simultaneously recorded neural responses.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-07-24},
  author = {Arakaki, Takafumi and Barello, Gregory and Ahmadian, Yashar},
  file = {/Users/qualia/Documents/Papers/Arakaki et al. - 2017 - Capturing the diversity of biological tuning curve.pdf}
}

@article{Andrychowicz,
  langid = {english},
  title = {Hindsight {{Experience Replay}}},
  abstract = {Dealing with sparse rewards is one of the biggest challenges in Reinforcement Learning (RL). We present a novel technique called Hindsight Experience Replay which allows sample-efficient learning from rewards which are sparse and binary and therefore avoid the need for complicated reward engineering. It can be combined with an arbitrary off-policy RL algorithm and may be seen as a form of implicit curriculum. We demonstrate our approach on the task of manipulating objects with a robotic arm. In particular, we run experiments on three different tasks: pushing, sliding, and pick-and-place, in each case using only binary rewards indicating whether or not the task is completed. Our ablation studies show that Hindsight Experience Replay is a crucial ingredient which makes training possible in these challenging environments. We show that our policies trained on a physics simulation can be deployed on a physical robot and successfully complete the task. The video presenting our experiments is available at https://goo.gl/SMrQnI.},
  pages = {15},
  author = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  file = {/Users/qualia/Documents/Papers/Andrychowicz et al. - Hindsight Experience Replay.pdf}
}

@article{Albers2018,
  langid = {english},
  title = {Decoupling of {{BOLD}} Amplitude and Pattern Classification of Orientation-Selective Activity in Human Visual Cortex},
  volume = {180},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917307942},
  doi = {10.1016/j.neuroimage.2017.09.046},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2018-10},
  pages = {31-40},
  author = {Albers, Anke Marit and Meindertsma, Thomas and Toni, Ivan and de Lange, Floris P.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Albers et al. - 2018 - Decoupling of BOLD amplitude and pattern classific.pdf}
}

@article{Zhao2017,
  langid = {english},
  title = {Variational {{Latent Gaussian Process}} for {{Recovering Single}}-{{Trial Dynamics}} from {{Population Spike Trains}}},
  volume = {29},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00953},
  doi = {10.1162/NECO_a_00953},
  abstract = {A small number of common factors often explain most of the interdependence among simultaneously recorded neurons, a signature of underlying low-dimensional dynamics. We posit that simple neural coding and computation manifest as low-dimensional nonlinear dynamics implemented redundantly within a large population of neurons. Recovering the latent dynamics from observations can offer a deeper understanding of neural computation. We improve upon previously-proposed methods for recovering latent dynamics, which assume either an inappropriate observation model or linear dynamics. We propose a practical and efficient inference method for a generative model with explicit point process observations and an assumption of smooth nonlinear dynamics. We validate our method on both simulated data and population recording from primary visual cortex.},
  number = {5},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2017-05},
  pages = {1293-1316},
  author = {Zhao, Yuan and Park, Il Memming},
  file = {/Users/qualia/Documents/Papers/Zhao and Park - 2017 - Variational Latent Gaussian Process for Recovering.pdf}
}

@article{Zhangb,
  langid = {english},
  title = {Understanding Deep Learning Requires Rethinking Generalization},
  abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training.},
  pages = {15},
  author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  file = {/Users/qualia/Documents/Papers/Zhang et al. - Understanding deep learning requires rethinking ge.pdf}
}

@article{Yuan2016,
  langid = {english},
  title = {Theoretical {{Analysis}} of {{Transcranial Magneto}}-{{Acoustical Stimulation}} with {{Hodgkin}}-{{Huxley Neuron Model}}},
  volume = {10},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/Article/10.3389/fncom.2016.00035/abstract},
  doi = {10.3389/fncom.2016.00035},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2016-04-19},
  author = {Yuan, Yi and Chen, Yudong and Li, Xiaoli},
  file = {/Users/qualia/Documents/Papers/Yuan et al. - 2016 - Theoretical Analysis of Transcranial Magneto-Acous 2.pdf;/Users/qualia/Documents/Papers/Yuan et al. - 2016 - Theoretical Analysis of Transcranial Magneto-Acous.pdf}
}

@article{Yavuz2016,
  langid = {english},
  title = {{{GeNN}}: A Code Generation Framework for Accelerated Brain Simulations},
  volume = {6},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/srep18854},
  doi = {10.1038/srep18854},
  shorttitle = {{{GeNN}}},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2016-05},
  author = {Yavuz, Esin and Turner, James and Nowotny, Thomas},
  file = {/Users/qualia/Documents/Papers/Yavuz et al. - 2016 - GeNN a code generation framework for accelerated .pdf}
}

@article{Wimmer2016,
  langid = {english},
  title = {Transitions between {{Multiband Oscillatory Patterns Characterize Memory}}-{{Guided Perceptual Decisions}} in {{Prefrontal Circuits}}},
  volume = {36},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3678-15.2016},
  doi = {10.1523/JNEUROSCI.3678-15.2016},
  number = {2},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2016-01-13},
  pages = {489-505},
  author = {Wimmer, K. and Ramon, M. and Pasternak, T. and Compte, A.},
  file = {/Users/qualia/Documents/Papers/Wimmer et al. - 2016 - Transitions between Multiband Oscillatory Patterns.pdf}
}

@article{Wen2016,
  langid = {english},
  title = {Separating {{Fractal}} and {{Oscillatory Components}} in the {{Power Spectrum}} of {{Neurophysiological Signal}}},
  volume = {29},
  issn = {0896-0267, 1573-6792},
  url = {http://link.springer.com/10.1007/s10548-015-0448-0},
  doi = {10.1007/s10548-015-0448-0},
  number = {1},
  journaltitle = {Brain Topography},
  urldate = {2019-03-30},
  date = {2016-01},
  pages = {13-26},
  author = {Wen, Haiguang and Liu, Zhongming},
  file = {/Users/qualia/Documents/Papers/Wen and Liu - 2016 - Separating Fractal and Oscillatory Components in t 2.pdf;/Users/qualia/Documents/Papers/Wen and Liu - 2016 - Separating Fractal and Oscillatory Components in t.pdf}
}

@article{Wang2016,
  langid = {english},
  title = {Brain Structure and Dynamics across Scales: In Search of Rules},
  volume = {37},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438815001889},
  doi = {10.1016/j.conb.2015.12.010},
  shorttitle = {Brain Structure and Dynamics across Scales},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2016-04},
  pages = {92-98},
  author = {Wang, Xiao-Jing and Kennedy, Henry},
  file = {/Users/qualia/Documents/Papers/Wang and Kennedy - 2016 - Brain structure and dynamics across scales in sea.pdf}
}

@article{Tran2016,
  langid = {english},
  title = {Alpha Phase Dynamics Predict Age-Related Visual Working Memory Decline},
  volume = {143},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S105381191630444X},
  doi = {10.1016/j.neuroimage.2016.08.052},
  abstract = {Alpha oscillations (7-14 Hz) are modulated in response to visual temporal and spatial cues. However, the neural response to alerting cues is less explored, as is how this response is affected by healthy aging. Using scalp EEG, we examined how visual cortical alpha activity relates to working memory performance. Younger (20-30 years) and older (60-70 years) participants were presented with a visual alerting cue uninformative of the position or size of a lateralized working memory array. Older adults showed longer response times overall and reduced accuracy when memory load was high. Older adults had less consistent cue-evoked alpha phase resetting than younger adults, which predicted worse performance. Alpha phase prior to memory array presentation predicted response time, but the relationship between phase and response time was weaker in older adults. These results suggest that changes in alpha phase dynamics, especially prior to presentation of task-relevant stimuli, potentially contribute to age-related cognitive decline.},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2016-12},
  pages = {196-203},
  author = {Tran, Tam T. and Hoffner, Nicole C. and LaHue, Sara C. and Tseng, Lisa and Voytek, Bradley},
  file = {/Users/qualia/Documents/Papers/Tran et al. - 2016 - Alpha phase dynamics predict age-related visual wo.pdf}
}

@article{Tripp2016,
  langid = {english},
  title = {Function Approximation in Inhibitory Networks},
  volume = {77},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608016000113},
  doi = {10.1016/j.neunet.2016.01.010},
  abstract = {In performance-optimized artificial neural networks, such as convolutional networks, each neuron makes excitatory connections with some of its targets and inhibitory connections with others. In contrast, physiological neurons are typically either excitatory or inhibitory, not both. This is a puzzle, because it seems to constrain computation, and because there are several counter-examples that suggest that it may not be a physiological necessity. Parisien et al. (2008) showed that any mixture of excitatory and inhibitory functional connections could be realized by a purely excitatory projection in parallel with a two-synapse projection through an inhibitory population. They showed that this works well with ratios of excitatory and inhibitory neurons that are realistic for the neocortex, suggesting that perhaps the cortex efficiently works around this apparent computational constraint. Extending this work, we show here that mixed excitatory and inhibitory functional connections can also be realized in networks that are dominated by inhibition, such as those of the basal ganglia. Further, we show that the function-approximation capacity of such connections is comparable to that of idealized mixed-weight connections. We also study whether such connections are viable in recurrent networks, and find that such recurrent networks can flexibly exhibit a wide range of dynamics. These results offer a new perspective on computation in the basal ganglia, and also perhaps on inhibitory networks within the cortex.},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2016-05},
  pages = {95-106},
  author = {Tripp, Bryan and Eliasmith, Chris},
  file = {/Users/qualia/Documents/Papers/Tripp and Eliasmith - 2016 - Function approximation in inhibitory networks.pdf}
}

@article{Tan2016,
  langid = {english},
  title = {Decoding Gripping Force Based on Local Field Potentials Recorded from Subthalamic Nucleus in Humans},
  volume = {5},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/19089},
  doi = {10.7554/eLife.19089},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2016-11-18},
  author = {Tan, Huiling and Pogosyan, Alek and Ashkan, Keyoumars and Green, Alexander L and Aziz, Tipu and Foltynie, Thomas and Limousin, Patricia and Zrinzo, Ludvic and Hariz, Marwan and Brown, Peter},
  file = {/Users/qualia/Documents/Papers/Tan et al. - 2016 - Decoding gripping force based on local field poten.pdf}
}

@article{Strouse2017,
  langid = {english},
  title = {The {{Deterministic Information Bottleneck}}},
  volume = {29},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00961},
  doi = {10.1162/NECO_a_00961},
  abstract = {Lossy compression and clustering fundamentally involve a decision about what features are relevant and which are not. The information bottleneck method (IB) by Tishby, Pereira, and Bialek formalized this notion as an information-theoretic optimization problem and proposed an optimal tradeoff between throwing away as many bits as possible, and selectively keeping those that are most important. In the IB, compression is measure my mutual information. Here, we introduce an alternative formulation that replaces mutual information with entropy, which we call the deterministic information bottleneck (DIB), that we argue better captures this notion of compression. As suggested by its name, the solution to the DIB problem turns out to be a deterministic encoder, or hard clustering, as opposed to the stochastic encoder, or soft clustering, that is optimal under the IB. We compare the IB and DIB on synthetic data, showing that the IB and DIB perform similarly in terms of the IB cost function, but that the DIB significantly outperforms the IB in terms of the DIB cost function. We also empirically find that the DIB offers a considerable gain in computational efficiency over the IB, over a range of convergence parameters. Our derivation of the DIB also suggests a method for continuously interpolating between the soft clustering of the IB and the hard clustering of the DIB.},
  number = {6},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2017-06},
  pages = {1611-1630},
  author = {Strouse, Dj and Schwab, David J.},
  file = {/Users/qualia/Documents/Papers/Strouse and Schwab - 2017 - The Deterministic Information Bottleneck 2.pdf;/Users/qualia/Documents/Papers/Strouse and Schwab - 2017 - The Deterministic Information Bottleneck.pdf}
}

@article{Delevich2016,
  langid = {english},
  title = {Parvalbumin Interneuron Dysfunction in a Thalamus - Prefrontal Cortex Circuit in {{Disc1}} Deficiency Mice},
  url = {http://biorxiv.org/lookup/doi/10.1101/054759},
  doi = {10.1101/054759},
  abstract = {Two of the most consistent findings across disrupted-in-schizophrenia-1 (DISC1) mouse models are impaired working memory and reduced number or function of parvalbumin interneurons within the prefrontal cortex. While these findings suggest parvalbumin interneuron dysfunction in DISC1-related pathophysiology, to date, cortical inhibitory circuit function has not been investigated in depth in DISC1 deficiency mouse models. Here we assessed the function of a feedforward circuit between the mediodorsal thalamus (MD) and the medial prefrontal cortex (mPFC) in mice harboring a deletion in one allele of the Disc1 gene. We found that the inhibitory drive onto layer 3 pyramidal neurons in the mPFC was significantly reduced in the Disc1 deficient mice. This reduced inhibition was accompanied by decreased GABA release from local parvalbumin, but not somatostatin, inhibitory interneurons, and by impaired feedforward inhibition in the MD-mPFC circuit. Our results reveal a cellular mechanism by which deficiency in DISC1 causes neural circuit dysfunction frequently implicated in psychiatric disorders.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-05-21},
  author = {Delevich, Kristen and Jaaro-Peled, Hanna and Penzo, Mario and Sawa, Akira and Li, Bo},
  file = {/Users/qualia/Documents/Papers/Delevich et al. - 2016 - Parvalbumin interneuron dysfunction in a thalamus .pdf}
}

@article{Walker2001,
  langid = {english},
  title = {Minimax {{Play}} at {{Wimbledon}}},
  volume = {91},
  issn = {0002-8282},
  url = {http://pubs.aeaweb.org/doi/10.1257/aer.91.5.1521},
  doi = {10.1257/aer.91.5.1521},
  abstract = {We use data from classic professional tennis matches to provide an empirical test of the theory of mixed strategy equilibrium. We \TH{}nd that the serve-andreturn play of John McEnroe, Bjorn Borg, Boris Becker, Pete Sampras and others is consistent with equilibrium play. The same statistical tests soundly reject the assumption of equilibrium play in experimental data, including the data from Barry O'Neill's celebrated experiment.},
  number = {5},
  journaltitle = {American Economic Review},
  urldate = {2019-03-30},
  date = {2001-12},
  pages = {1521-1538},
  author = {Walker, Mark and Wooders, John},
  file = {/Users/qualia/Documents/Papers/Walker and Wooders - 2001 - Minimax Play at Wimbledon.pdf}
}

@article{Song2016,
  langid = {english},
  title = {Training {{Excitatory}}-{{Inhibitory Recurrent Neural Networks}} for {{Cognitive Tasks}}: {{A Simple}} and {{Flexible Framework}}},
  volume = {12},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004792},
  doi = {10.1371/journal.pcbi.1004792},
  shorttitle = {Training {{Excitatory}}-{{Inhibitory Recurrent Neural Networks}} for {{Cognitive Tasks}}},
  number = {2},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2016-02-29},
  pages = {e1004792},
  author = {Song, H. Francis and Yang, Guangyu R. and Wang, Xiao-Jing},
  editor = {Sporns, Olaf},
  file = {/Users/qualia/Documents/Papers/Song et al. - 2016 - Training Excitatory-Inhibitory Recurrent Neural Ne.pdf}
}

@article{Song,
  langid = {english},
  title = {Reward-Based Training of Recurrent Neural Networks for Cognitive and Value-Based Tasks},
  abstract = {Trained neural network models, which exhibit many features observed in neural recordings from behaving animals and whose activity and connectivity can be fully analyzed, may provide insights into neural mechanisms. In contrast to commonly used methods for supervised learning from graded error signals, however, animals learn from reward feedback on definite actions through reinforcement learning. Reward maximization is particularly relevant when the optimal behavior depends on an animal's internal judgment of confidence or subjective preferences. Here, we describe reward-based training of recurrent neural networks in which a value network guides learning by using the selected actions and activity of the policy network to predict future reward. We show that such models capture both behavioral and electrophysiological findings from well-known experimental paradigms. Our results provide a unified framework for investigating diverse cognitive and value-based computations, including a role for value representation that is essential for learning, but not executing, a task.},
  pages = {59},
  author = {Song, H Francis and Yang, Guangyu R and Wang, Xiao-Jing},
  file = {/Users/qualia/Documents/Papers/Song et al. - Reward-based training of recurrent neural networks.pdf}
}

@article{Sohal2016,
  langid = {english},
  title = {How {{Close Are We}} to {{Understanding What}} (If {{Anything}}) {{Oscillations Do}} in {{Cortical Circuits}}?},
  volume = {36},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0990-16.2016},
  doi = {10.1523/JNEUROSCI.0990-16.2016},
  number = {41},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2016-10-12},
  pages = {10489-10495},
  author = {Sohal, V. S.},
  file = {/Users/qualia/Documents/Papers/Sohal - 2016 - How Close Are We to Understanding What (if Anythin.pdf}
}

@article{Sims2016,
  langid = {english},
  title = {Rate\textendash{}Distortion Theory and Human Perception},
  volume = {152},
  issn = {00100277},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027716300750},
  doi = {10.1016/j.cognition.2016.03.020},
  abstract = {The fundamental goal of perception is to aid in the achievement of behavioral objectives. This requires extracting and communicating useful information from noisy and uncertain sensory signals. At the same time, given the complexity of sensory information and the limitations of biological information processing, it is necessary that some information must be lost or discarded in the act of perception. Under these circumstances, what constitutes an `optimal' perceptual system? This paper describes the mathematical framework of rate\textendash{}distortion theory as the optimal solution to the problem of minimizing the costs of perceptual error subject to strong constraints on the ability to communicate or transmit information. Rate\textendash{}distortion theory offers a general and principled theoretical framework for developing computational-level models of human perception (Marr, 1982). Models developed in this framework are capable of producing quantitatively precise explanations for human perceptual performance, while yielding new insights regarding the nature and goals of perception. This paper demonstrates the application of rate\textendash{}distortion theory to two benchmark domains where capacity limits are especially salient in human perception: discrete categorization of stimuli (also known as absolute identification) and visual working memory. A software package written for the R statistical programming language is described that aids in the development of models based on rate\textendash{}distortion theory.},
  journaltitle = {Cognition},
  urldate = {2019-03-30},
  date = {2016-07},
  pages = {181-198},
  author = {Sims, Chris R.},
  file = {/Users/qualia/Documents/Papers/Sims - 2016 - Rate–distortion theory and human perception.pdf}
}

@article{Silver2016,
  langid = {english},
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  volume = {529},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature16961},
  doi = {10.1038/nature16961},
  number = {7587},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2016-01},
  pages = {484-489},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Silver et al. - 2016 - Mastering the game of Go with deep neural networks.pdf}
}

@article{Sherman2016,
  langid = {english},
  title = {Neural Mechanisms of Transient Neocortical Beta Rhythms: {{Converging}} Evidence from Humans, Computational Modeling, Monkeys, and Mice},
  volume = {113},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1604135113},
  doi = {10.1073/pnas.1604135113},
  shorttitle = {Neural Mechanisms of Transient Neocortical Beta Rhythms},
  number = {33},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2016-08-16},
  pages = {E4885-E4894},
  author = {Sherman, Maxwell A. and Lee, Shane and Law, Robert and Haegens, Saskia and Thorn, Catherine A. and H\"am\"al\"ainen, Matti S. and Moore, Christopher I. and Jones, Stephanie R.},
  file = {/Users/qualia/Documents/Papers/Sherman et al. - 2016 - Neural mechanisms of transient neocortical beta rh.pdf}
}

@article{Sheremet2016,
  langid = {english},
  title = {Movement {{Enhances}} the {{Nonlinearity}} of {{Hippocampal Theta}}},
  volume = {36},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3564-15.2016},
  doi = {10.1523/JNEUROSCI.3564-15.2016},
  number = {15},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2016-04-13},
  pages = {4218-4230},
  author = {Sheremet, A. and Burke, S. N. and Maurer, A. P.},
  file = {/Users/qualia/Documents/Papers/Sheremet et al. - 2016 - Movement Enhances the Nonlinearity of Hippocampal .pdf}
}

@article{Schoenick2017,
  langid = {english},
  title = {Moving beyond the {{Turing Test}} with the {{Allen AI Science Challenge}}},
  volume = {60},
  issn = {00010782},
  url = {http://dl.acm.org/citation.cfm?doid=3134526.3122814},
  doi = {10.1145/3122814},
  number = {9},
  journaltitle = {Communications of the ACM},
  urldate = {2019-03-30},
  date = {2017-08-23},
  pages = {60-64},
  author = {Schoenick, Carissa and Clark, Peter and Tafjord, Oyvind and Turney, Peter and Etzioni, Oren},
  file = {/Users/qualia/Documents/Papers/Schoenick et al. - 2017 - Moving beyond the Turing Test with the Allen AI Sc.pdf}
}

@article{Schoenholz2017,
  langid = {english},
  title = {{{DEEP INFORMATION PROPAGATION}}},
  abstract = {We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.},
  date = {2017},
  pages = {18},
  author = {Schoenholz, Samuel S and Gilmer, Justin and Ganguli, Surya and Sohl-Dickstein, Jascha},
  file = {/Users/qualia/Documents/Papers/Schoenholz et al. - 2017 - DEEP INFORMATION PROPAGATION.pdf}
}

@article{Sanborn2016,
  langid = {english},
  title = {Bayesian {{Brains}} without {{Probabilities}}},
  volume = {20},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661316301565},
  doi = {10.1016/j.tics.2016.10.003},
  number = {12},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2016-12},
  pages = {883-893},
  author = {Sanborn, Adam N. and Chater, Nick},
  file = {/Users/qualia/Documents/Papers/Sanborn and Chater - 2016 - Bayesian Brains without Probabilities.pdf}
}

@article{Samaha2016,
  langid = {english},
  title = {Decoding and {{Reconstructing}} the {{Focus}} of {{Spatial Attention}} from the {{Topography}} of {{Alpha}}-Band {{Oscillations}}},
  volume = {28},
  issn = {0898-929X, 1530-8898},
  url = {http://www.mitpressjournals.org/doi/10.1162/jocn_a_00955},
  doi = {10.1162/jocn_a_00955},
  number = {8},
  journaltitle = {Journal of Cognitive Neuroscience},
  urldate = {2019-03-30},
  date = {2016-08},
  pages = {1090-1097},
  author = {Samaha, Jason and Sprague, Thomas C. and Postle, Bradley R.},
  file = {/Users/qualia/Documents/Papers/Samaha et al. - 2016 - Decoding and Reconstructing the Focus of Spatial A.pdf}
}

@article{Saleem2016,
  langid = {english},
  title = {Subcortical Source and Modulation of the Narrowband Gamma Oscillation in Mouse Visual Cortex},
  url = {http://biorxiv.org/lookup/doi/10.1101/050245},
  doi = {10.1101/050245},
  abstract = {Visual cortex (V1) exhibits two types of gamma oscillation: a well-characterized broadband (30-90Hz) rhythm, and a narrowband oscillation occurring at frequencies close to 60 Hz in mice. We investigated the source of narrowband gamma, the factors modulating its strength, and its relationship to broadband gamma. Narrowband and broadband gamma power were uncorrelated. Increasing visual contrast had opposite effects on the two kinds of gamma activity: it increased broadband power, but suppressed the narrowband oscillation. Narrowband power was strongest in layer 4, and was mediated primarily by excitatory currents entrained by rhythmically firing neuronal ensembles in the lateral geniculate nucleus (LGN). Silencing the cortex optogenetically did not affect narrowband rhythmicity in either LGN spike trains or cortical EPSCs, suggesting that this oscillation reflects unidirectional flow of information from LGN to V1.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-10-04},
  author = {Saleem, Aman B and Lien, Anthony D and Krumin, Michael and Haider, Bilal and Roman Roson, Miroslav and Ayaz, Asli and Reinhold, Kimberley and Busse, Laura and Carandini, Matteo and Harris, Kenneth D},
  file = {/Users/qualia/Documents/Papers/Saleem et al. - 2016 - Subcortical source and modulation of the narrowban.pdf}
}

@article{Ruder,
  langid = {english},
  title = {An Overview of Gradient Descent Optimization Algorithms},
  abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
  pages = {14},
  author = {Ruder, Sebastian},
  file = {/Users/qualia/Documents/Papers/Ruder - An overview of gradient descent optimization algor.pdf}
}

@article{Rubin2017,
  langid = {english},
  title = {Decoding Brain Activity Using a Large-Scale Probabilistic Functional-Anatomical Atlas of Human Cognition},
  volume = {13},
  issn = {1553-7358},
  url = {http://dx.plos.org/10.1371/journal.pcbi.1005649},
  doi = {10.1371/journal.pcbi.1005649},
  abstract = {A central goal of cognitive neuroscience is to decode human brain activity\textemdash{}that is, to infer mental processes from observed patterns of whole-brain activation. Previous decoding efforts have focused on classifying brain activity into a small set of discrete cognitive states. To attain maximal utility, a decoding framework must be open-ended, systematic, and context-sensitive\textemdash{}that is, capable of interpreting numerous brain states, presented in arbitrary combinations, in light of prior information. Here we take steps towards this objective by introducing a probabilistic decoding framework based on a novel topic model\textemdash{}Generalized Correspondence Latent Dirichlet Allocation\textemdash{}that learns latent topics from a database of over 11,000 published fMRI studies. The model produces highly interpretable, spatially-circumscribed topics that enable flexible decoding of whole-brain images. Importantly, the Bayesian nature of the model allows one to ``seed'' decoder priors with arbitrary images and text\textemdash{}enabling researchers, for the first time, to generate quantitative, context-sensitive interpretations of whole-brain patterns of brain activity.},
  number = {10},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2017-10-23},
  pages = {e1005649},
  author = {Rubin, Timothy N. and Koyejo, Oluwasanmi and Gorgolewski, Krzysztof J. and Jones, Michael N. and Poldrack, Russell A. and Yarkoni, Tal},
  editor = {Gershman, Samuel J.},
  file = {/Users/qualia/Documents/Papers/Rubin et al. - 2017 - Decoding brain activity using a large-scale probab.pdf}
}

@article{Rossert,
  langid = {english},
  title = {Automated Point-Neuron Simplification of Data-Driven Microcircuit Models},
  abstract = {A method is presented for the reduction of morphologically detailed microcircuit models to a point-neuron representation without human intervention. The simplification occurs in a modular workflow, in the neighborhood of a user specified network activity state for the reference model, the ``operating point''. First, synapses are moved to the soma, correcting for dendritic filtering by low-pass filtering the delivered synaptic current. Filter parameters are computed numerically and independently for inhibitory and excitatory input on the basal and apical dendrites, respectively, in a distance dependent and post-synaptic m-type specific manner. Next, point-neuron models for each neuron in the microcircuit are fit to their respective morphologically detailed counterparts. Here, generalized integrate-and-fire point neuron models are used, leveraging a recently published fitting toolbox. The fits are constrained by currents and voltages computed in the morphologically detailed partner neurons with soma corrected synapses at three depolarizations about the user specified operating point. The result is a simplified circuit which is well constrained by the reference circuit, and can be continuously updated as the latter iteratively integrates new data. The modularity of the approach makes it applicable also for other point-neuron and synapse models.},
  pages = {26},
  author = {Rossert, Christian and Pozzorini, Christian and Chindemi, Giuseppe and Eroe, Csaba and King, James and Newton, Taylor H and Nolte, Max and Reimann, Michael W and Gewaltig, Marc-Oliver and Gerstner, Wulfram and Markram, Henry and Segev, Idan and Muller, Eilif},
  file = {/Users/qualia/Documents/Papers/Rossert et al. - Automated point-neuron simpliﬁcation of data-drive.pdf}
}

@inproceedings{Ribeiro2016,
  langid = {english},
  location = {{San Francisco, California, USA}},
  title = {"{{Why Should I Trust You}}?": {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  isbn = {978-1-4503-4232-2},
  url = {http://dl.acm.org/citation.cfm?doid=2939672.2939778},
  doi = {10.1145/2939672.2939778},
  shorttitle = {"{{Why Should I Trust You}}?},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  eventtitle = {The 22nd {{ACM SIGKDD International Conference}}},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}} - {{KDD}} '16},
  publisher = {{ACM Press}},
  urldate = {2019-03-30},
  date = {2016},
  pages = {1135-1144},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  file = {/Users/qualia/Documents/Papers/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf}
}

@article{Rajan2016,
  langid = {english},
  title = {Recurrent {{Network Models}} of {{Sequence Generation}} and {{Memory}}},
  volume = {90},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627316001021},
  doi = {10.1016/j.neuron.2016.02.009},
  abstract = {Sequential activation of neurons is a common feature of network activity during a variety of behaviors, including working memory and decision making. Previous network models for sequences and memory emphasized specialized architectures in which a principled mechanism is pre-wired into their connectivity. Here we demonstrate that, starting from random connectivity and modifying a small fraction of connections, a largely disordered recurrent network can produce sequences and implement working memory efficiently. We use this process, called Partial In-Network Training (PINning), to model and match cellular resolution imaging data from the posterior parietal cortex during a virtual memoryguided two-alternative forced-choice task. Analysis of the connectivity reveals that sequences propagate by the cooperation between recurrent synaptic interactions and external inputs, rather than through feedforward or asymmetric connections. Together our results suggest that neural sequences may emerge through learning from largely unstructured network architectures.},
  number = {1},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2016-04},
  pages = {128-142},
  author = {Rajan, Kanaka and Harvey, Christopher D. and Tank, David W.},
  file = {/Users/qualia/Documents/Papers/Rajan et al. - 2016 - Recurrent Network Models of Sequence Generation an.pdf}
}

@article{Poggio2017,
  langid = {english},
  title = {Why and When Can Deep-but Not Shallow-Networks Avoid the Curse of Dimensionality: {{A}} Review},
  volume = {14},
  issn = {1476-8186, 1751-8520},
  url = {http://link.springer.com/10.1007/s11633-017-1054-2},
  doi = {10.1007/s11633-017-1054-2},
  shorttitle = {Why and When Can Deep-but Not Shallow-Networks Avoid the Curse of Dimensionality},
  abstract = {The paper characterizes classes of functions for which deep learning can be exponentially better than shallow learning. Deep convolutional networks are a special case of these conditions, though weight sharing is not the main reason for their exponential advantage.},
  number = {5},
  journaltitle = {International Journal of Automation and Computing},
  urldate = {2019-03-30},
  date = {2017-10},
  pages = {503-519},
  author = {Poggio, Tomaso and Mhaskar, Hrushikesh and Rosasco, Lorenzo and Miranda, Brando and Liao, Qianli},
  file = {/Users/qualia/Documents/Papers/Poggio et al. - 2017 - Why and when can deep-but not shallow-networks avo.pdf}
}

@article{Pearl,
  langid = {english},
  title = {Theoretical {{Impediments}} to {{Machine Learning}}},
  abstract = {Current machine learning systems operate, almost exclusively, in a purely statistical mode, which puts severe theoretical limits on their performance. We consider the feasibility of leveraging counterfactual reasoning in machine learning tasks, and to identify areas where such reasoning could lead to major breakthroughs in machine learning applications.},
  pages = {5},
  author = {Pearl, Judea},
  file = {/Users/qualia/Documents/Papers/Pearl - Theoretical Impediments to Machine Learning.pdf}
}

@article{Papernot2017,
  langid = {english},
  title = {{{SEMI}}-{{SUPERVISED KNOWLEDGE TRANSFER FOR DEEP LEARNING FROM PRIVATE TRAINING DATA}}},
  abstract = {Some machine learning applications involve training data that is sensitive, such as the medical histories of patients in a clinical trial. A model may inadvertently and implicitly store some of its training data; careful analysis of the model may therefore reveal sensitive information.},
  date = {2017},
  pages = {14},
  author = {Papernot, Nicolas and Abadi, Mart\i{}n},
  file = {/Users/qualia/Documents/Papers/Papernot and Abadi - 2017 - SEMI-SUPERVISED KNOWLEDGE TRANSFER FOR DEEP LEARNI.pdf}
}

@article{Papadopoulos,
  langid = {english},
  title = {Embedding of Biological Distribution Networks with Differing Environmental Constraints},
  pages = {20},
  author = {Papadopoulos, Lia and Blinder, Pablo and Ronellenfitsch, Henrik and Katifori, Eleni and Kleinfeld, David and Bassett, Danielle S},
  file = {/Users/qualia/Documents/Papers/Papadopoulos et al. - Embedding of biological distribution networks with.pdf}
}

@article{Stringer2016,
  langid = {english},
  title = {Inhibitory Control of Shared Variability in Cortical Networks},
  url = {http://biorxiv.org/lookup/doi/10.1101/041103},
  doi = {10.1101/041103},
  abstract = {Cortical networks exhibit intrinsic dynamics that drive coordinated, large-scale fluctuations across neuronal populations and create noise correlations that impact sensory coding. To investigate the network-level mechanisms that underlie these dynamics, we developed novel computational techniques to fit a deterministic spiking network model directly to multi-neuron recordings from different species, sensory modalities, and behavioral states. The model accurately reproduced the wide variety of activity patterns in our recordings, and analysis of its parameters suggested that differences in noise correlations across recordings were due primarily to differences in the strength of feedback inhibition. Further analysis of our recordings confirmed that putative inhibitory interneurons were indeed more active during desynchronized cortical states with weak noise correlations. Our results demonstrate the power of fitting spiking network models directly to multi-neuron recordings and suggest that inhibition modulates the interactions between intrinsic dynamics and sensory inputs by controlling network stability.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-07-16},
  author = {Stringer, Carsen and Pachitariu, Marius and Okun, Michael and Bartho, Peter and Harris, Kenneth and Latham, Peter and Sahani, Maneesh and Lesica, Nicholas},
  file = {/Users/qualia/Documents/Papers/Stringer et al. - 2016 - Inhibitory control of shared variability in cortic 2.pdf;/Users/qualia/Documents/Papers/Stringer et al. - 2016 - Inhibitory control of shared variability in cortic.pdf}
}

@article{Ottino-Loffler2016b,
  langid = {english},
  title = {Kuramoto Model with Uniformly Spaced Frequencies: {{Finite}}- {{N}} Asymptotics of the Locking Threshold},
  volume = {93},
  issn = {2470-0045, 2470-0053},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.93.062220},
  doi = {10.1103/PhysRevE.93.062220},
  shorttitle = {Kuramoto Model with Uniformly Spaced Frequencies},
  number = {6},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2016-06-22},
  author = {Ottino-L\"offler, Bertrand and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/Ottino-Löffler and Strogatz - 2016 - Kuramoto model with uniformly spaced frequencies .pdf}
}

@article{Ottino-Loffler2016,
  langid = {english},
  title = {Comparing the Locking Threshold for Rings and Chains of Oscillators},
  volume = {94},
  issn = {2470-0045, 2470-0053},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.94.062203},
  doi = {10.1103/PhysRevE.94.062203},
  number = {6},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2016-12-02},
  author = {Ottino-L\"offler, Bertrand and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/Ottino-Löffler and Strogatz - 2016 - Comparing the locking threshold for rings and chai.pdf}
}

@article{Ottino-Loffler2016a,
  langid = {english},
  title = {Frequency Spirals},
  volume = {26},
  issn = {1054-1500, 1089-7682},
  url = {http://aip.scitation.org/doi/10.1063/1.4954038},
  doi = {10.1063/1.4954038},
  number = {9},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  urldate = {2019-03-30},
  date = {2016-09},
  pages = {094804},
  author = {Ottino-L\"offler, Bertrand and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/Ottino-Löffler and Strogatz - 2016 - Frequency spirals.pdf}
}

@article{Ogunmolu,
  langid = {english},
  title = {Nonlinear {{Systems Identification Using Deep Dynamic Neural Networks}}},
  abstract = {Neural networks are known to be effective function approximators. Recently, deep neural networks have proven to be very effective in pattern recognition, classification tasks and human-level control to model highly nonlinear realworld systems. This paper investigates the effectiveness of deep neural networks in the modeling of dynamical systems with complex behavior. Three deep neural network structures are trained on sequential data, and we investigate the effectiveness of these networks in modeling associated characteristics of the underlying dynamical systems. We carry out similar evaluations on select publicly available system identification datasets. We demonstrate that deep neural networks are effective model estimators from input-output data.},
  pages = {8},
  author = {Ogunmolu, Olalekan and Gu, Xuejun and Jiang, Steve and Gans, Nicholas},
  file = {/Users/qualia/Documents/Papers/Ogunmolu et al. - Nonlinear Systems Identiﬁcation Using Deep Dynamic.pdf}
}

@article{OKeeffe2016,
  langid = {english},
  title = {Dynamics of a Population of Oscillatory and Excitable Elements},
  volume = {93},
  issn = {2470-0045, 2470-0053},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.93.062203},
  doi = {10.1103/PhysRevE.93.062203},
  number = {6},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2016-06-07},
  author = {O'Keeffe, Kevin P. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/O'Keeffe and Strogatz - 2016 - Dynamics of a population of oscillatory and excita.pdf}
}

@article{Nunes2016,
  langid = {english},
  title = {Multi-Alternative Decision-Making with Non-Stationary Inputs},
  volume = {3},
  issn = {2054-5703},
  url = {http://rsos.royalsocietypublishing.org/lookup/doi/10.1098/rsos.160376},
  doi = {10.1098/rsos.160376},
  number = {8},
  journaltitle = {Royal Society Open Science},
  urldate = {2019-03-30},
  date = {2016-08},
  pages = {160376},
  author = {Nunes, Luana F. and Gurney, Kevin},
  file = {/Users/qualia/Documents/Papers/Nunes and Gurney - 2016 - Multi-alternative decision-making with non-station.pdf}
}

@article{Noonan2016,
  langid = {english},
  title = {Distinct {{Mechanisms}} for {{Distractor Suppression}} and {{Target Facilitation}}},
  volume = {36},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2133-15.2016},
  doi = {10.1523/JNEUROSCI.2133-15.2016},
  number = {6},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2016-02-10},
  pages = {1797-1807},
  author = {Noonan, M. P. and Adamian, N. and Pike, A. and Printzlau, F. and Crittenden, B. M. and Stokes, M. G.},
  file = {/Users/qualia/Documents/Papers/Noonan et al. - 2016 - Distinct Mechanisms for Distractor Suppression and.pdf}
}

@article{Nogaret2016,
  langid = {english},
  title = {Automatic {{Construction}} of {{Predictive Neuron Models}} through {{Large Scale Assimilation}} of {{Electrophysiological Data}}},
  volume = {6},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/srep32749},
  doi = {10.1038/srep32749},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2016-12},
  author = {Nogaret, Alain and Meliza, C. Daniel and Margoliash, Daniel and Abarbanel, Henry D. I.},
  file = {/Users/qualia/Documents/Papers/Nogaret et al. - 2016 - Automatic Construction of Predictive Neuron Models 2.pdf;/Users/qualia/Documents/Papers/Nogaret et al. - 2016 - Automatic Construction of Predictive Neuron Models 3.pdf;/Users/qualia/Documents/Papers/Nogaret et al. - 2016 - Automatic Construction of Predictive Neuron Models.pdf}
}

@article{Muscinelli2017,
  langid = {english},
  title = {Exponentially {{Long Orbits}} in {{Hopfield Neural Networks}}},
  volume = {29},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00919},
  doi = {10.1162/NECO_a_00919},
  number = {2},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2017-02},
  pages = {458-484},
  author = {Muscinelli, Samuel P. and Gerstner, Wulfram and Brea, Johanni},
  file = {/Users/qualia/Documents/Papers/Muscinelli et al. - 2017 - Exponentially Long Orbits in Hopfield Neural Netwo.pdf}
}

@article{Morrison,
  langid = {english},
  title = {Diversity of Emergent Dynamics in Competitive Threshold-Linear Networks: A Preliminary Report},
  pages = {12},
  author = {Morrison, Katherine and Degeratu, Anda and Itskov, Vladimir and Curto, Carina},
  file = {/Users/qualia/Documents/Papers/Morrison et al. - Diversity of emergent dynamics in competitive thre.pdf}
}

@article{Moore2017,
  langid = {english},
  title = {Dynamics of Cortical Dendritic Membrane Potential and Spikes in Freely Behaving Rats},
  volume = {355},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aaj1497},
  doi = {10.1126/science.aaj1497},
  number = {6331},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2017-03-24},
  pages = {eaaj1497},
  author = {Moore, Jason J. and Ravassard, Pascal M. and Ho, David and Acharya, Lavanya and Kees, Ashley L. and Vuong, Cliff and Mehta, Mayank R.},
  file = {/Users/qualia/Documents/Papers/Moore et al. - 2017 - Dynamics of cortical dendritic membrane potential .pdf}
}

@article{Mochizuki2016,
  langid = {english},
  title = {Similarity in {{Neuronal Firing Regimes}} across {{Mammalian Species}}},
  volume = {36},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0230-16.2016},
  doi = {10.1523/JNEUROSCI.0230-16.2016},
  number = {21},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2016-05-25},
  pages = {5736-5747},
  author = {Mochizuki, Y. and Onaga, T. and Shimazaki, H. and Shimokawa, T. and Tsubo, Y. and Kimura, R. and Saiki, A. and Sakai, Y. and Isomura, Y. and Fujisawa, S. and Shibata, K.-i. and Hirai, D. and Furuta, T. and Kaneko, T. and Takahashi, S. and Nakazono, T. and Ishino, S. and Sakurai, Y. and Kitsukawa, T. and Lee, J. W. and Lee, H. and Jung, M. W. and Babul, C. and Maldonado, P. E. and Takahashi, K. and Arce-McShane, F. I. and Ross, C. F. and Sessle, B. J. and Hatsopoulos, N. G. and Brochier, T. and Riehle, A. and Chorley, P. and Grun, S. and Nishijo, H. and Ichihara-Takeda, S. and Funahashi, S. and Shima, K. and Mushiake, H. and Yamane, Y. and Tamura, H. and Fujita, I. and Inaba, N. and Kawano, K. and Kurkin, S. and Fukushima, K. and Kurata, K. and Taira, M. and Tsutsui, K.-I. and Ogawa, T. and Komatsu, H. and Koida, K. and Toyama, K. and Richmond, B. J. and Shinomoto, S.},
  file = {/Users/qualia/Documents/Papers/Mochizuki et al. - 2016 - Similarity in Neuronal Firing Regimes across Mamma.pdf}
}

@article{Mnih,
  langid = {english},
  title = {Asynchronous {{Methods}} for {{Deep Reinforcement Learning}}},
  abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
  pages = {19},
  author = {Mnih, Volodymyr and Badia, Adri\`a Puigdom\`enech and Mirza, Mehdi and Graves, Alex and Harley, Tim and Lillicrap, Timothy P and Silver, David and Kavukcuoglu, Koray},
  file = {/Users/qualia/Documents/Papers/Mnih et al. - Asynchronous Methods for Deep Reinforcement Learni.pdf}
}

@article{Miconi2017,
  langid = {english},
  title = {Biologically Plausible Learning in Recurrent Neural Networks Reproduces Neural Dynamics Observed during Cognitive Tasks},
  url = {http://biorxiv.org/lookup/doi/10.1101/057729},
  doi = {10.1101/057729},
  abstract = {Neural activity during cognitive tasks exhibits complex dynamics that flexibly encode task\-relevant variables. Recurrent neural networks operating in the near\-chaotic regime, which spontaneously generate rich dynamics, have been proposed as a model of cortical computation during cognitive tasks. However, existing methods for training these networks are either biologically implausible, and/or require a continuous, real\-time error signal to guide the learning process. The lack of a biological learning method currently restricts the plausibility of recurrent networks as models of cortical computation. Here we show that a biologically plausible learning rule can train such recurrent networks, guided solely by delayed, phasic rewards at the end of each trial, for nontrivial tasks. We use this method to learn various tasks from the experimental literature, showing that this learning rule can successfully implement flexible associations, memory maintenance, nonlinear mixed selectivities, and coordination among multiple outputs. We show that the resulting networks exhibit complex dynamics previously observed in animal cortex, such as dynamic encoding and maintenance of task features, switching from stimulus\-specific to response\-specific representations, and selective integration of relevant input streams. We conclude that recurrent neural networks offer a plausible model of cortical dynamics during both learning and performance of flexible behavior.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-02-22},
  author = {Miconi, Thomas},
  file = {/Users/qualia/Documents/Papers/Miconi - 2017 - Biologically plausible learning in recurrent neura.pdf}
}

@article{Mhaskar,
  langid = {english},
  title = {Learning {{Functions}}: {{When Is Deep Better Than Shallow}}},
  pages = {12},
  author = {Mhaskar, Hrushikesh and Liao, Qianli and Poggio, Tomaso},
  file = {/Users/qualia/Documents/Papers/Mhaskar et al. - Learning Functions When Is Deep Better Than Shall.pdf}
}

@article{Merker2016,
  langid = {english},
  title = {Cortical {{Gamma Oscillations}}: {{Details}} of {{Their Genesis Preclude}} a {{Role}} in {{Cognition}}},
  volume = {10},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/Article/10.3389/fncom.2016.00078/abstract},
  doi = {10.3389/fncom.2016.00078},
  shorttitle = {Cortical {{Gamma Oscillations}}},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2016-07-27},
  author = {Merker, Bjorn H.},
  file = {/Users/qualia/Documents/Papers/Merker - 2016 - Cortical Gamma Oscillations Details of Their Gene.pdf}
}

@article{Mejias,
  langid = {english},
  title = {Feedforward and Feedback Frequency-Dependent Interactions in a Large-Scale Laminar Network of the Primate Cortex},
  abstract = {Interactions between top-down and bottom-up processes in the cerebral cortex hold the key to understanding predictive coding, executive control and a gamut of other brain functions. The underlying circuit mechanism, however, remains poorly understood and represents a major challenge in neuroscience. In the present work we tackled this problem using a large-scale computational model of the primate cortex constrained by new directed and weighted connectivity data. In our model, the interplay between feedforward and feedback signaling depends on the cortical laminar structure and involves complex dynamics across multiple (intra-laminar, inter-laminar, inter-areal and whole cortex) scales. The model was tested by reproducing, and shedding insights into, a wide range of neurophysiological findings about frequency-dependent interactions between visual cortical areas: feedforward pathways are associated with enhanced gamma (30-70 Hz) oscillations, whereas feedback projections selectively modulate alpha/low beta (8-15 Hz) oscillations. We found that in order for the model to account for the experimental observations, the feedback projection needs to predominantly target infragranular layers in a target area, which leads to a proposed circuit substrate for predictive coding. The model reproduces a functional hierarchy based on frequency-dependent Granger causality analysis of inter-areal signaling, as reported in recent monkey and human experiments. Taken together, this work highlights the importance of multi-scale approaches and provides a modeling platform for studies of large-scale brain circuit dynamics and functions.},
  pages = {26},
  author = {Mejias, Jorge F and Murray, John D and Kennedy, Henry and Wang, Xiao-Jing},
  file = {/Users/qualia/Documents/Papers/Mejias et al. - Feedforward and feedback frequency-dependent inter.pdf}
}

@article{Marzen2016,
  langid = {english},
  title = {Weak Universality in Sensory Tradeoffs},
  volume = {94},
  issn = {2470-0045, 2470-0053},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.94.060101},
  doi = {10.1103/PhysRevE.94.060101},
  number = {6},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2016-12-07},
  author = {Marzen, Sarah and DeDeo, Simon},
  file = {/Users/qualia/Documents/Papers/Marzen and DeDeo - 2016 - Weak universality in sensory tradeoffs.pdf}
}

@article{Marblestone2016,
  langid = {english},
  title = {Towards an Integration of Deep Learning and Neuroscience},
  url = {http://biorxiv.org/lookup/doi/10.1101/058545},
  doi = {10.1101/058545},
  abstract = {Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) these cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-08-22},
  author = {Marblestone, Adam Henry and Wayne, Greg and Kording, Konrad P},
  file = {/Users/qualia/Documents/Papers/Marblestone et al. - 2016 - Towards an integration of deep learning and neuros.pdf}
}

@article{Cohen-KashiMalina2016,
  langid = {english},
  title = {Local and Thalamic Origins of Ongoing and Sensory Evoked Cortical Correlations},
  url = {http://biorxiv.org/lookup/doi/10.1101/058727},
  doi = {10.1101/058727},
  abstract = {Thalamic inputs of layer 4 (L4) cells in sensory cortices are outnumbered by local connections. Thus, it was suggested that robust sensory response in L4 emerges due to synchronized thalamic activity. In order to investigate the role of both inputs in generation of cortical synchronization, we isolated the thalamic excitatory inputs of cortical cells by optogenetically silencing cortical firing. In anesthetized mice, we measured the correlation between isolated thalamic synaptic inputs of simultaneously patched nearby L4 cells of the barrel cortex. In contrast to correlated activity of excitatory synaptic inputs in the intact cortex, isolated thalamic inputs exhibit lower variability and asynchronous spontaneous and sensory evoked inputs. These results were further supported in awake mice when we recorded the excitatory inputs of individual cortical cells simultaneously with the local field potential (LFP) in a nearby site. Our results therefore indicate that cortical synchronization emerges by intracortical coupling.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-06-13},
  author = {Cohen-Kashi Malina, Katayun and Mohar, Boaz and Rappaport, Akiva N and Lampl, Ilan},
  file = {/Users/qualia/Documents/Papers/Cohen-Kashi Malina et al. - 2016 - Local and thalamic origins of ongoing and sensory .pdf}
}

@article{Lynch,
  langid = {english},
  title = {Computational {{Tradeoffs}} in {{Biological Neural Networks}}: {{Self}}-{{Stabilizing Winner}}-{{Take}}-{{All Networks}}},
  abstract = {We initiate a line of investigation into biological neural networks from an algorithmic perspective. We develop a simplified but biologically plausible model for distributed computation in stochastic spiking neural networks and study tradeoffs between computation time and network complexity in this model. Our aim is to abstract real neural networks in a way that, while not capturing all interesting features, preserves high-level behavior and allows us to make biologically relevant conclusions.},
  pages = {43},
  author = {Lynch, Nancy and Musco, Cameron and Parter, Merav},
  file = {/Users/qualia/Documents/Papers/Lynch et al. - Computational Tradeoﬀs in Biological Neural Networ.pdf}
}

@article{Lundqvist2016,
  langid = {english},
  title = {Gamma and {{Beta Bursts Underlie Working Memory}}},
  volume = {90},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627316001458},
  doi = {10.1016/j.neuron.2016.02.028},
  abstract = {Working memory is thought to result from sustained neuron spiking. However, computational models suggest complex dynamics with discrete oscillatory bursts. We analyzed local field potential (LFP) and spiking from the prefrontal cortex (PFC) of monkeys performing a working memory task. There were brief bursts of narrow-band gamma oscillations (45\textendash{}100 Hz), varied in time and frequency, accompanying encoding and re-activation of sensory information. They appeared at a minority of recording sites associated with spiking reflecting the to-beremembered items. Beta oscillations (20\textendash{}35 Hz) also occurred in brief, variable bursts but reflected a default state interrupted by encoding and decoding. Only activity of neurons reflecting encoding/ decoding correlated with changes in gamma burst rate. Thus, gamma bursts could gate access to, and prevent sensory interference with, working memory. This supports the hypothesis that working memory is manifested by discrete oscillatory dynamics and spiking, not sustained activity.},
  number = {1},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2016-04},
  pages = {152-164},
  author = {Lundqvist, Mikael and Rose, Jonas and Herman, Pawel and Brincat, Scott L. and Buschman, Timothy J. and Miller, Earl K.},
  file = {/Users/qualia/Documents/Papers/Lundqvist et al. - 2016 - Gamma and Beta Bursts Underlie Working Memory.pdf}
}

@article{Lowet2016,
  langid = {english},
  title = {Neuronal Gamma-Band Synchronization Regulated by Instantaneous Modulations of the Oscillation Frequency},
  url = {http://biorxiv.org/lookup/doi/10.1101/070672},
  doi = {10.1101/070672},
  abstract = {Neuronal gamma-band synchronization shapes information flow during sensory and cognitive processing. A common view is that a stable and shared frequency over time is required for robust and functional synchronization. To the contrary, we found that non-stationary instantaneous frequency modulations were essential for synchronization. First, we recorded gamma rhythms in monkey visual area V1, and found that they synchronized by continuously modulating their frequency difference in a phase-dependent manner. The frequency modulation properties regulated both the phase-locking and the preferred phase-relation between gamma rhythms. Second, our experimental observations were in agreement with a biophysical model of gamma rhythms and were accurately predicted by the theory of weakly coupled oscillators revealing the underlying theoretical principles that govern gamma synchronization. Thus, synchronization through instantaneous frequency modulations represents a fundamental principle of gamma-band neural coordination that is likely generalizable to other brain rhythms.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-09-25},
  author = {Lowet, Eric and Roberts, Mark and Peter, Alina and Gips, Bart and De Weerd, Peter},
  file = {/Users/qualia/Documents/Papers/Lowet et al. - 2016 - Neuronal gamma-band synchronization regulated by i.pdf}
}

@incollection{Loreto2016,
  langid = {english},
  location = {{Cham}},
  title = {Dynamics on {{Expanding Spaces}}: {{Modeling}} the {{Emergence}} of {{Novelties}}},
  isbn = {978-3-319-24401-3 978-3-319-24403-7},
  url = {http://link.springer.com/10.1007/978-3-319-24403-7_5},
  shorttitle = {Dynamics on {{Expanding Spaces}}},
  abstract = {Novelties are part of our daily lives. We constantly adopt new technologies, conceive new ideas, meet new people, and experiment with new situations. Occasionally, we as individual, in a complicated cognitive and sometimes fortuitous process, come up with something that is not only new to us, but to our entire society so that what is a personal novelty can turn into an innovation at a global level. Innovations occur throughout social, biological, and technological systems and, though we perceive them as a very natural ingredient of our human experience, little is known about the processes determining their emergence. Still the statistical occurrence of innovations shows striking regularities that represent a starting point to get a deeper insight in the whole phenomenology. This paper represents a small step in that direction, focusing on reviewing the scientific attempts to effectively model the emergence of the new and its regularities, with an emphasis on more recent contributions: from the plain Simon's model tracing back to the 1950s, to the newest model of Polya's urn with triggering of one novelty by another. What seems to be key in the successful modeling schemes proposed so far is the idea of looking at evolution as a path in a complex space, physical, conceptual, biological, and technological, whose structure and topology get continuously reshaped and expanded by the occurrence of the new. Mathematically, it is very interesting to look at the consequences of the interplay between the ``actual'' and the ``possible'' and this is the aim of this short review.},
  booktitle = {Creativity and {{Universality}} in {{Language}}},
  publisher = {{Springer International Publishing}},
  urldate = {2019-03-30},
  date = {2016},
  pages = {59-83},
  author = {Loreto, Vittorio and Servedio, Vito D. P. and Strogatz, Steven H. and Tria, Francesca},
  editor = {Degli Esposti, Mirko and Altmann, Eduardo G. and Pachet, Fran{\c c}ois},
  file = {/Users/qualia/Documents/Papers/Loreto et al. - 2016 - Dynamics on Expanding Spaces Modeling the Emergen.pdf},
  doi = {10.1007/978-3-319-24403-7_5}
}

@article{Lipton,
  langid = {english},
  title = {Combating {{Reinforcement Learning}}'s {{Sisyphean Curse}} with {{Intrinsic Fear}}},
  abstract = {Many practical environments contain catastrophic states that an optimal agent would visit infrequently or never. Even on toy problems, Deep Reinforcement Learning (DRL) agents tend to periodically revisit these states upon forgetting their existence under a new policy. We introduce intrinsic fear (IF), a learned reward shaping that guards DRL agents against periodic catastrophes. IF agents possess a fear model trained to predict the probability of imminent catastrophe. This score is then used to penalize the Qlearning objective. Our theoretical analysis bounds the reduction in average return due to learning on the perturbed objective. We also prove robustness to classi cation errors. As a bonus, IF models tend to learn faster, owing to reward shaping. Experiments demonstrate that intrinsic-fear DQNs solve otherwise pathological environments and improve on several Atari games.},
  pages = {14},
  author = {Lipton, Zachary C and Azizzadenesheli, Kamyar and Kumar, Abhishek and Li, Lihong and Gao, Jianfeng and Deng, Li},
  file = {/Users/qualia/Documents/Papers/Lipton et al. - Combating Reinforcement Learning’s Sisyphean Curse.pdf}
}

@article{Lindahl2016,
  langid = {english},
  title = {Untangling {{Basal Ganglia Network Dynamics}} and {{Function}}: {{Role}} of {{Dopamine Depletion}} and {{Inhibition Investigated}} in a {{Spiking Network Model}}},
  volume = {3},
  issn = {2373-2822},
  url = {http://eneuro.org/cgi/doi/10.1523/ENEURO.0156-16.2016},
  doi = {10.1523/ENEURO.0156-16.2016},
  shorttitle = {Untangling {{Basal Ganglia Network Dynamics}} and {{Function}}},
  number = {6},
  journaltitle = {eneuro},
  urldate = {2019-03-30},
  date = {2016},
  pages = {ENEURO.0156-16.2016},
  author = {Lindahl, Mikael and Hellgren Kotaleski, Jeanette},
  file = {/Users/qualia/Documents/Papers/Lindahl and Hellgren Kotaleski - 2016 - Untangling Basal Ganglia Network Dynamics and Func.pdf}
}

@article{Li2016,
  langid = {english},
  title = {Robust Neuronal Dynamics in Premotor Cortex during Motor Planning},
  volume = {532},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/doifinder/10.1038/nature17643},
  doi = {10.1038/nature17643},
  number = {7600},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2016-04-13},
  pages = {459-464},
  author = {Li, Nuo and Daie, Kayvon and Svoboda, Karel and Druckmann, Shaul},
  file = {/Users/qualia/Documents/Papers/Li et al. - 2016 - Robust neuronal dynamics in premotor cortex during.pdf}
}

@article{Lahiri,
  langid = {english},
  title = {A Universal Tradeoff between Power, Precision and Speed in Physical Communication},
  pages = {6},
  author = {Lahiri, Subhaneil and Sohl-Dickstein, Jascha and Ganguli, Surya},
  file = {/Users/qualia/Documents/Papers/Lahiri et al. - A universal tradeoﬀ between power, precision and s.pdf}
}

@article{Kulkarni,
  langid = {english},
  title = {Deep {{Successor Reinforcement Learning}}},
  pages = {10},
  author = {Kulkarni, Tejas D and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  file = {/Users/qualia/Documents/Papers/Kulkarni et al. - Deep Successor Reinforcement Learning.pdf}
}

@article{Kuczala2016,
  langid = {english},
  title = {Eigenvalue Spectra of Large Correlated Random Matrices},
  volume = {94},
  issn = {2470-0045, 2470-0053},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.94.050101},
  doi = {10.1103/PhysRevE.94.050101},
  number = {5},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2016-11-17},
  author = {Kuczala, Alexander and Sharpee, Tatyana O.},
  file = {/Users/qualia/Documents/Papers/Kuczala and Sharpee - 2016 - Eigenvalue spectra of large correlated random matr.pdf}
}

@article{Kuchibhotla2017,
  langid = {english},
  title = {Parallel Processing by Cortical Inhibition Enables Context-Dependent Behavior},
  volume = {20},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4436},
  doi = {10.1038/nn.4436},
  number = {1},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2017-01},
  pages = {62-71},
  author = {Kuchibhotla, Kishore V and Gill, Jonathan V and Lindsay, Grace W and Papadoyannis, Eleni S and Field, Rachel E and Sten, Tom A Hindmarsh and Miller, Kenneth D and Froemke, Robert C},
  file = {/Users/qualia/Documents/Papers/Kuchibhotla et al. - 2017 - Parallel processing by cortical inhibition enables.pdf}
}

@article{ChandranKS2016,
  langid = {english},
  title = {Comparison of {{Matching Pursuit Algorithm}} with {{Other Signal Processing Techniques}} for {{Computation}} of the {{Time}}-{{Frequency Power Spectrum}} of {{Brain Signals}}},
  volume = {36},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3633-15.2016},
  doi = {10.1523/JNEUROSCI.3633-15.2016},
  number = {12},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2016-03-23},
  pages = {3399-3408},
  author = {Chandran KS, S. and Mishra, A. and Shirhatti, V. and Ray, S.},
  file = {/Users/qualia/Documents/Papers/Chandran KS et al. - 2016 - Comparison of Matching Pursuit Algorithm with Othe.pdf}
}

@article{Kim2016,
  langid = {english},
  title = {Low-Dielectric-Constant Polyimide Aerogel Composite Films with Low Water Uptake},
  volume = {48},
  issn = {0032-3896, 1349-0540},
  url = {http://www.nature.com/articles/pj201637},
  doi = {10.1038/pj.2016.37},
  number = {7},
  journaltitle = {Polymer Journal},
  urldate = {2019-03-30},
  date = {2016-07},
  pages = {829-834},
  author = {Kim, Jinyoung and Kwon, Jinuk and Kim, Myeongsoo and Do, Jeonguk and Lee, Daero and Han, Haksoo},
  file = {/Users/qualia/Documents/Papers/Kim et al. - 2016 - Low-dielectric-constant polyimide aerogel composit.pdf}
}

@article{Kriegeskorte2016,
  langid = {english},
  title = {Inferring Brain-Computational Mechanisms with Models of Activity Measurements},
  volume = {371},
  issn = {0962-8436, 1471-2970},
  url = {http://rstb.royalsocietypublishing.org/lookup/doi/10.1098/rstb.2016.0278},
  doi = {10.1098/rstb.2016.0278},
  number = {1705},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  urldate = {2019-03-30},
  date = {2016-10-05},
  pages = {20160278},
  author = {Kriegeskorte, Nikolaus and Diedrichsen, J\"orn},
  file = {/Users/qualia/Documents/Papers/Kriegeskorte and Diedrichsen - 2016 - Inferring brain-computational mechanisms with mode.pdf}
}

@article{Kirkpatrick2017,
  langid = {english},
  title = {Overcoming Catastrophic Forgetting in Neural Networks},
  volume = {114},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1611835114},
  doi = {10.1073/pnas.1611835114},
  number = {13},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2017-03-28},
  pages = {3521-3526},
  author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
  file = {/Users/qualia/Documents/Papers/Kirkpatrick et al. - 2017 - Overcoming catastrophic forgetting in neural netwo.pdf}
}

@article{Kheradpisheh2018,
  langid = {english},
  title = {{{STDP}}-Based Spiking Deep Convolutional Neural Networks for Object Recognition},
  volume = {99},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608017302903},
  doi = {10.1016/j.neunet.2017.12.005},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2018-03},
  pages = {56-67},
  author = {Kheradpisheh, Saeed Reza and Ganjtabesh, Mohammad and Thorpe, Simon J. and Masquelier, Timoth\'ee},
  file = {/Users/qualia/Documents/Papers/Kheradpisheh et al. - 2018 - STDP-based spiking deep convolutional neural netwo.pdf}
}

@article{Kharkwal2016,
  langid = {english},
  title = {Parkinsonism {{Driven}} by {{Antipsychotics Originates}} from {{Dopaminergic Control}} of {{Striatal Cholinergic Interneurons}}},
  volume = {91},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627316302677},
  doi = {10.1016/j.neuron.2016.06.014},
  abstract = {Typical antipsychotics can cause disabling side effects. Specifically, antagonism of D2R signaling by the typical antipsychotic haloperidol induces parkinsonism in humans and catalepsy in rodents. Striatal dopamine D2 receptors (D2R) are major regulators of motor activity through their signaling on striatal projection neurons and interneurons. We show that D2R signaling on cholinergic interneurons contributes to an in vitro pause in firing of these otherwise tonically active neurons and to the striatal dopamine/acetylcholine balance. The selective ablation of D2R from cholinergic neurons allows discrimination between the motor-reducing and cataleptic effects of antipsychotics. The cataleptic effect of antipsychotics is triggered by blockade of D2R on cholinergic interneurons and the consequent increase of acetylcholine signaling on striatal projection neurons. These studies illuminate the critical role of D2R-mediated signaling in regulating the activity of striatal cholinergic interneurons and the mechanisms of typical antipsychotic side effects.},
  number = {1},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2016-07},
  pages = {67-78},
  author = {Kharkwal, Geetika and Brami-Cherrier, Karen and Lizardi-Ortiz, Jos\'e E. and Nelson, Alexandra B. and Ramos, Maria and Del Barrio, Daniel and Sulzer, David and Kreitzer, Anatol C. and Borrelli, Emiliana},
  file = {/Users/qualia/Documents/Papers/Kharkwal et al. - 2016 - Parkinsonism Driven by Antipsychotics Originates f.pdf}
}

@article{Jonas2016,
  langid = {english},
  title = {Could a Neuroscientist Understand a Microprocessor?},
  url = {http://biorxiv.org/lookup/doi/10.1101/055624},
  doi = {10.1101/055624},
  abstract = {There is a popular belief in neuroscience that we are primarily data limited, that producing large, multimodal, and complex datasets will, enabled by data analysis algorithms, lead to fundamental insights into the way the brain processes information. Microprocessors are among those artificial information processing systems that are both complex and that we understand at all levels, from the overall logical flow, via logical gates, to the dynamics of transistors. Here we take a simulated classical microprocessor as a model organism, and use our ability to perform arbitrary experiments on it to see if popular data analysis methods from neuroscience can elucidate the way it processes information. We show that the approaches reveal interesting structure in the data but do not meaningfully describe the hierarchy of information processing in the processor. This suggests that current approaches in neuroscience may fall short of producing meaningful models of the brain.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-11-14},
  author = {Jonas, Eric and Kording, Konrad},
  file = {/Users/qualia/Documents/Papers/Jonas and Kording - 2016 - Could a neuroscientist understand a microprocessor.pdf}
}

@article{Jensen2016,
  langid = {english},
  title = {Discriminating {{Valid}} from {{Spurious Indices}} of {{Phase}}-{{Amplitude Coupling}}},
  volume = {3},
  issn = {2373-2822},
  url = {http://eneuro.org/cgi/doi/10.1523/ENEURO.0334-16.2016},
  doi = {10.1523/ENEURO.0334-16.2016},
  abstract = {Recently there has been a strong interest in cross-frequency coupling, the interaction between neuronal oscillations in different frequency bands. In particular, measures quantifying the coupling between the phase of slow oscillations and the amplitude of fast oscillations have been applied to a wide range of data recorded from animals and humans. Some of the measures applied to detect phase-amplitude coupling have been criticized for being sensitive to nonsinusoidal properties of the oscillations and thus spuriously indicate the presence of coupling. While such instances of spurious identification of coupling have been observed, in this commentary we give concrete examples illustrating cases when the identification of cross-frequency coupling can be trusted. These examples are based on control analyses and empirical observations rather than signal-processing tools. Finally, we provide concrete advice on how to determine when measures of phase-amplitude coupling can be considered trustworthy.},
  number = {6},
  journaltitle = {eneuro},
  urldate = {2019-03-30},
  date = {2016},
  pages = {ENEURO.0334-16.2016},
  author = {Jensen, Ole and Spaak, Eelke and Park, Hyojin},
  file = {/Users/qualia/Documents/Papers/Jensen et al. - 2016 - Discriminating Valid from Spurious Indices of Phas.pdf}
}

@article{Jaderberg,
  langid = {english},
  title = {Decoupled {{Neural Interfaces}} Using {{Synthetic Gradients}}},
  abstract = {Training directed neural networks typically requires forward-propagating data through a computation graph, followed by backpropagating error signal, to produce weight updates. All layers, or more generally, modules, of the network are therefore locked, in the sense that they must wait for the remainder of the network to execute forwards and propagate error backwards before they can be updated. In this work we break this constraint by decoupling modules by introducing a model of the future computation of the network graph. These models predict what the result of the modelled subgraph will produce using only local information. In particular we focus on modelling error gradients: by using the modelled synthetic gradient in place of true backpropagated error gradients we decouple subgraphs, and can update them independently and asynchronously i.e. we realise decoupled neural interfaces. We show results for feed-forward models, where every layer is trained asynchronously, recurrent neural networks (RNNs) where predicting one's future gradient extends the time over which the RNN can effectively model, and also a hierarchical RNN system with ticking at different timescales. Finally, we demonstrate that in addition to predicting gradients, the same framework can be used to predict inputs, resulting in models which are decoupled in both the forward and backwards pass \textendash{} amounting to independent networks which co-learn such that they can be composed into a single functioning corporation.},
  pages = {16},
  author = {Jaderberg, Max and Czarnecki, Wojciech Marian and Osindero, Simon and Vinyals, Oriol and Graves, Alex and Kavukcuoglu, Koray},
  file = {/Users/qualia/Documents/Papers/Jaderberg et al. - Decoupled Neural Interfaces using Synthetic Gradie.pdf}
}

@article{Huth2016,
  langid = {english},
  title = {Natural Speech Reveals the Semantic Maps That Tile Human Cerebral Cortex},
  volume = {532},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/doifinder/10.1038/nature17637},
  doi = {10.1038/nature17637},
  number = {7600},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2016-04-27},
  pages = {453-458},
  author = {Huth, Alexander G. and de Heer, Wendy A. and Griffiths, Thomas L. and Theunissen, Fr\'ed\'eric E. and Gallant, Jack L.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Huth et al. - 2016 - Natural speech reveals the semantic maps that tile.pdf}
}

@inproceedings{Huang2017,
  langid = {english},
  location = {{Honolulu, HI}},
  title = {Densely {{Connected Convolutional Networks}}},
  isbn = {978-1-5386-0457-1},
  url = {http://ieeexplore.ieee.org/document/8099726/},
  doi = {10.1109/CVPR.2017.243},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  publisher = {{IEEE}},
  urldate = {2019-03-30},
  date = {2017-07},
  pages = {2261-2269},
  author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
  file = {/Users/qualia/Documents/Papers/Huang et al. - 2017 - Densely Connected Convolutional Networks.pdf}
}

@article{Hu2016,
  langid = {english},
  title = {Painful {{Issues}} in {{Pain Prediction}}},
  volume = {39},
  issn = {01662236},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223616000163},
  doi = {10.1016/j.tins.2016.01.004},
  number = {4},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {2016-04},
  pages = {212-220},
  author = {Hu, Li and Iannetti, Gian Domenico},
  file = {/Users/qualia/Documents/Papers/Hu and Iannetti - 2016 - Painful Issues in Pain Prediction.pdf}
}

@article{Hong2016,
  langid = {english},
  title = {Phase Coherence Induced by Correlated Disorder},
  volume = {93},
  issn = {2470-0045, 2470-0053},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.93.022219},
  doi = {10.1103/PhysRevE.93.022219},
  number = {2},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2016-02-26},
  author = {Hong, Hyunsuk and O'Keeffe, Kevin P. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/Hong et al. - 2016 - Phase coherence induced by correlated disorder.pdf}
}

@article{Holt2016,
  langid = {english},
  title = {Phasic {{Burst Stimulation}}: {{A Closed}}-{{Loop Approach}} to {{Tuning Deep Brain Stimulation Parameters}} for {{Parkinson}}'s {{Disease}}},
  volume = {12},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1005011},
  doi = {10.1371/journal.pcbi.1005011},
  shorttitle = {Phasic {{Burst Stimulation}}},
  number = {7},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2016-07-14},
  pages = {e1005011},
  author = {Holt, Abbey B. and Wilson, Dan and Shinn, Max and Moehlis, Jeff and Netoff, Theoden I.},
  editor = {Sporns, Olaf},
  file = {/Users/qualia/Documents/Papers/Holt et al. - 2016 - Phasic Burst Stimulation A Closed-Loop Approach t.pdf}
}

@article{Hennequin,
  langid = {english},
  title = {Characterizing Variability in Nonlinear, Recurrent Neuronal Networks},
  abstract = {In this note, we develop semi-analytical techniques to obtain the full correlational structure of a stochastic network of nonlinear neurons described by rate variables. Under the assumption that pairs of membrane potentials are jointly Gaussian \textendash{} which they tend to be in large networks \textendash{} we obtain deterministic equations for the temporal evolution of the mean firing rates and the noise covariance matrix that can be solved straightforwardly given the network connectivity. We also obtain spike count statistics such as Fano factors and pairwise correlations, assuming doubly-stochastic action potential firing. Importantly, our theory does not require fluctuations to be small, and works for several biologically motivated, convex single-neuron nonlinearities.},
  pages = {17},
  author = {Hennequin, Guillaume and Lengyel, Mate},
  file = {/Users/qualia/Documents/Papers/Hennequin and Lengyel - Characterizing variability in nonlinear, recurrent.pdf}
}

@article{Hagen2016,
  langid = {english},
  title = {Hybrid {{Scheme}} for {{Modeling Local Field Potentials}} from {{Point}}-{{Neuron Networks}}},
  volume = {26},
  issn = {1047-3211, 1460-2199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhw237},
  doi = {10.1093/cercor/bhw237},
  abstract = {With rapidly advancing multi-electrode recording technology, the local field potential (LFP) has again become a popular measure of neuronal activity in both research and clinical applications. Proper understanding of the LFP requires detailed mathematical modeling incorporating the anatomical and electrophysiological features of neurons near the recording electrode, as well as synaptic inputs from the entire network. Here we propose a hybrid modeling scheme combining efficient point-neuron network models with biophysical principles underlying LFP generation by real neurons. The LFP predictions rely on populations of network-equivalent multicompartment neuron models with layer-specific synaptic connectivity, can be used with an arbitrary number of point-neuron network populations, and allows for a full separation of simulated network dynamics and LFPs. We apply the scheme to a full-scale cortical network model for a {$\sim$}1 mm2 patch of primary visual cortex, predict laminar LFPs for different network states, assess the relative LFP contribution from different laminar populations, and investigate effects of input correlations and neuron density on the LFP. The generic nature of the hybrid scheme and its public implementation in hybridLFPy form the basis for LFP predictions from other and larger pointneuron network models, as well as extensions of the current application with additional biological detail.},
  number = {12},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2016-12},
  pages = {4461-4496},
  author = {Hagen, Espen and Dahmen, David and Stavrinou, Maria L. and Lind\'en, Henrik and Tetzlaff, Tom and van Albada, Sacha J. and Gr\"un, Sonja and Diesmann, Markus and Einevoll, Gaute T.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Hagen et al. - 2016 - Hybrid Scheme for Modeling Local Field Potentials .pdf}
}

@article{Gutig2016,
  langid = {english},
  title = {Spiking Neurons Can Discover Predictive Features by Aggregate-Label Learning},
  volume = {351},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aab4113},
  doi = {10.1126/science.aab4113},
  number = {6277},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2016-03-04},
  pages = {aab4113-aab4113},
  author = {Gutig, R.},
  file = {/Users/qualia/Documents/Papers/Gutig - 2016 - Spiking neurons can discover predictive features b.pdf}
}

@article{Guntupalli2016,
  langid = {english},
  title = {A {{Model}} of {{Representational Spaces}} in {{Human Cortex}}},
  volume = {26},
  issn = {1047-3211, 1460-2199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhw068},
  doi = {10.1093/cercor/bhw068},
  abstract = {Current models of the functional architecture of human cortex emphasize areas that capture coarse-scale features of cortical topography but provide no account for population responses that encode information in fine-scale patterns of activity. Here, we present a linear model of shared representational spaces in human cortex that captures fine-scale distinctions among population responses with response-tuning basis functions that are common across brains and models cortical patterns of neural responses with individual-specific topographic basis functions. We derive a common model space for the whole cortex using a new algorithm, searchlight hyperalignment, and complex, dynamic stimuli that provide a broad sampling of visual, auditory, and social percepts. The model aligns representations across brains in occipital, temporal, parietal, and prefrontal cortices, as shown by between-subject multivariate pattern classification and intersubject correlation of representational geometry, indicating that structural principles for shared neural representations apply across widely divergent domains of information. The model provides a rigorous account for individual variability of well-known coarse-scale topographies, such as retinotopy and category selectivity, and goes further to account for fine-scale patterns that are multiplexed with coarse-scale topographies and carry finer distinctions.},
  number = {6},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2016-06},
  pages = {2919-2934},
  author = {Guntupalli, J. Swaroop and Hanke, Michael and Halchenko, Yaroslav O. and Connolly, Andrew C. and Ramadge, Peter J. and Haxby, James V.},
  file = {/Users/qualia/Documents/Papers/Guntupalli et al. - 2016 - A Model of Representational Spaces in Human Cortex.pdf}
}

@article{Guest2016,
  langid = {english},
  title = {What the {{Success}} of {{Brain Imaging Implies}} about the {{Neural Code}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/071076},
  doi = {10.1101/071076},
  abstract = {The success of fMRI places constraints on the nature of the neural code. The fact that researchers can infer similarities between neural representations, despite limitations in what fMRI measures, implies that certain neural coding schemes are more likely than others. For fMRI to be successful given its low temporal and spatial resolution, the neural code must smooth at the subvoxel and functional level such that similar stimuli engender similar internal representations. Through proof and simulation, we evaluate a number of reasonable coding schemes and demonstrate that only a subset are plausible given both fMRI's successes and its limitations in measuring neural activity. Deep neural network approaches, which have been forwarded as computational accounts of the ventral stream, are consistent with the success of fMRI, though functional smoothness breaks down in the later network layers. These results have implications for the nature of neural code and ventral stream, as well as what can be successfully investigated with fMRI.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-09-09},
  author = {Guest, Olivia and Love, Bradley C},
  file = {/Users/qualia/Documents/Papers/Guest and Love - 2016 - What the Success of Brain Imaging Implies about th.pdf}
}

@article{Guerguiev2017,
  langid = {english},
  title = {Towards Deep Learning with Segregated Dendrites},
  volume = {6},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/22901},
  doi = {10.7554/eLife.22901},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2017-12-05},
  author = {Guerguiev, Jordan and Lillicrap, Timothy P and Richards, Blake A},
  file = {/Users/qualia/Documents/Papers/Guerguiev et al. - 2017 - Towards deep learning with segregated dendrites 2.pdf;/Users/qualia/Documents/Papers/Guerguiev et al. - 2017 - Towards deep learning with segregated dendrites.pdf}
}

@article{Guergiuev,
  langid = {english},
  title = {Deep Learning with Segregated Dendrites},
  abstract = {Deep learning has led to significant advances in artificial intelligence, in part, by adopting strategies motivated by neurophysiology. However, it is unclear whether deep learning could occur in the real brain. Here, we show that deep learning can be achieved by moving away from point neuron models and towards multi-compartment neurons. Like neocortical pyramidal neurons, neurons in our model receive feedforward sensory information and higher-order feedback in electrotonically segregated compartments. Thanks to this segregation, the network can calculate local synaptic weight updates that allow it to categorize images from the MNIST data-set with good accuracy. We show that our learning algorithm can take advantage of multilayer architectures to identify abstract categories\textemdash{}the hallmark of deep learning. This work demonstrates that deep learning can be achieved using segregated dendritic compartments for feedforward and feedback information, which may help to explain the dendritic morphology of neocortical pyramidal neurons.},
  pages = {29},
  author = {Guergiuev, Jordan and Lillicrap, Timothy P and Richards, Blake A},
  file = {/Users/qualia/Documents/Papers/Guergiuev et al. - Deep learning with segregated dendrites.pdf}
}

@article{Guclu2017,
  langid = {english},
  title = {Modeling the {{Dynamics}} of {{Human Brain Activity}} with {{Recurrent Neural Networks}}},
  volume = {11},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2017.00007/full},
  doi = {10.3389/fncom.2017.00007},
  abstract = {Encoding models are used for predicting brain activity in response to sensory stimuli with the objective of elucidating how sensory information is represented in the brain. Encoding models typically comprise a nonlinear transformation of stimuli to features (feature model) and a linear transformation of features to responses (response model). While there has been extensive work on developing better feature models, the work on developing better response models has been rather limited. Here, we investigate the extent to which recurrent neural network models can use their internal memories for nonlinear processing of arbitrary feature sequences to predict feature-evoked response sequences as measured by functional magnetic resonance imaging. We show that the proposed recurrent neural network models can significantly outperform established response models by accurately estimating long-term dependencies that drive hemodynamic responses. The results open a new window into modeling the dynamics of brain activity in response to sensory stimuli.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2017-02-09},
  author = {G\"u{\c c}l\"u, Umut and van Gerven, Marcel A. J.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Güçlü and van Gerven - 2017 - Modeling the Dynamics of Human Brain Activity with.pdf}
}

@article{Grillner2016,
  langid = {english},
  title = {The {{Basal Ganglia Over}} 500 {{Million Years}}},
  volume = {26},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982216306807},
  doi = {10.1016/j.cub.2016.06.041},
  number = {20},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2016-10},
  pages = {R1088-R1100},
  author = {Grillner, Sten and Robertson, Brita},
  file = {/Users/qualia/Documents/Papers/Grillner and Robertson - 2016 - The Basal Ganglia Over 500 Million Years.pdf}
}

@article{UniversidadTecnologicadePereira2016,
  langid = {english},
  title = {Estimation of the Neuromodulation Parameters from the Planned Volume of Tissue Activated in Deep Brain Stimulation},
  issn = {01206230},
  url = {http://aprendeenlinea.udea.edu.co/revistas/index.php/ingenieria/article/view/22921},
  doi = {10.17533/udea.redin.n79a02},
  abstract = {Deep brain stimulation (DBS) is a therapy with promissory results for the treatment of movement disorders. It delivers electric stimulation via an electrode to a specific target brain region. The spatial extent of neural response to this stimulation is known as volume of tissue activated (VTA). Changes in stimulation parameters that control VTA, such as amplitude, pulse width and electrode configuration can affect the effectiveness of the DBS therapy. In this study, we develop a novel methodology for estimating suitable DBS neuromodulation parameters, from planned VTA, that attempts to maximize the therapeutic effects, and to minimize the adverse effects of DBS. For estimating the continuous outputs (amplitude and pulse width), we use multi-output support vector regression, taking the geometry of the VTA as input space. For estimating the electrode polarity configuration, we perform several classification problems, also using support vector machines from the same input space. Our methodology attains promising results for both the regression setting, and for predicting electrode active contacts and their polarity. Combining biological neural modeling techniques together with machine learning, we introduce a novel area of research where parameters of neuromodulation in DBS can be tuned by manually specifying a desired geometric volume.},
  number = {79},
  journaltitle = {Revista Facultad de Ingenier\'ia Universidad de Antioquia},
  urldate = {2019-03-30},
  date = {2016-06},
  author = {{Universidad Tecnol\'ogica de Pereira} and G\'omez-Orozco, Viviana and \'Alvarez-L\'opez, Mauricio Alexander and {Universidad Tecnol\'ogica de Pereira} and Henao-Gallo, \'Oscar Alberto and {Universidad Tecnol\'ogica de Pereira} and Daza-Santacoloma, Genaro and {Instituto de Epilepsia y Parkinson del Eje Cafetero - Neurocentro} and Orozco-Guti\'errez, \'Alvaro \'Angel and {Universidad Tecnol\'ogica de Pereira}},
  file = {/Users/qualia/Documents/Papers/Universidad Tecnológica de Pereira et al. - 2016 - Estimation of the neuromodulation parameters from .pdf}
}

@article{Goense2016,
  langid = {english},
  title = {{{fMRI}} at {{High Spatial Resolution}}: {{Implications}} for {{BOLD}}-{{Models}}},
  volume = {10},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/Article/10.3389/fncom.2016.00066/abstract},
  doi = {10.3389/fncom.2016.00066},
  shorttitle = {{{fMRI}} at {{High Spatial Resolution}}},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2016-06-28},
  author = {Goense, Jozien and Bohraus, Yvette and Logothetis, Nikos K.},
  file = {/Users/qualia/Documents/Papers/Goense et al. - 2016 - fMRI at High Spatial Resolution Implications for .pdf}
}

@article{Glasser2016,
  langid = {english},
  title = {The {{Human Connectome Project}}'s Neuroimaging Approach},
  volume = {19},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4361},
  doi = {10.1038/nn.4361},
  number = {9},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2016-09},
  pages = {1175-1187},
  author = {Glasser, Matthew F and Smith, Stephen M and Marcus, Daniel S and Andersson, Jesper L R and Auerbach, Edward J and Behrens, Timothy E J and Coalson, Timothy S and Harms, Michael P and Jenkinson, Mark and Moeller, Steen and Robinson, Emma C and Sotiropoulos, Stamatios N and Xu, Junqian and Yacoub, Essa and Ugurbil, Kamil and Van Essen, David C},
  file = {/Users/qualia/Documents/Papers/Glasser et al. - 2016 - The Human Connectome Project's neuroimaging approa.pdf}
}

@article{Gillary2016,
  langid = {english},
  title = {The {{Edge}} of {{Stability}}: {{Response Times}} and {{Delta Oscillations}} in {{Balanced Networks}}},
  volume = {12},
  issn = {1553-7358},
  url = {http://dx.plos.org/10.1371/journal.pcbi.1005121},
  doi = {10.1371/journal.pcbi.1005121},
  shorttitle = {The {{Edge}} of {{Stability}}},
  number = {9},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2016-09-30},
  pages = {e1005121},
  author = {Gillary, Grant and Niebur, Ernst},
  editor = {Battaglia, Francesco P.},
  file = {/Users/qualia/Documents/Papers/Gillary and Niebur - 2016 - The Edge of Stability Response Times and Delta Os.pdf}
}

@article{Gao2016,
  langid = {english},
  title = {Inferring {{Synaptic Excitation}}/{{Inhibition Balance}} from {{Field Potentials}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/081125},
  doi = {10.1101/081125},
  abstract = {Neural circuits sit in a dynamic balance between excitation (E) and inhibition (I). Fluctuations in this E:I balance have been shown to influence neural computation, working memory, and information processing. While more drastic shifts and aberrant E:I patterns are implicated in numerous neurological and psychiatric disorders, current methods for measuring E:I dynamics require invasive procedures that are difficult to perform in behaving animals, and nearly impossible in humans. This has limited the ability to examine the full impact that E:I shifts have in neural computation and disease. In this study, we develop a computational model to show that E:I ratio can be estimated from the power law exponent (slope) of the electrophysiological power spectrum, and validate this relationship using previously published datasets from two species (rat local field potential and macaque electrocorticography). This simple method--one that can be applied retrospectively to existing data--removes a major hurdle in understanding a currently difficult to measure, yet fundamental, aspect of neural computation.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-10-16},
  author = {Gao, Richard D and Peterson, Erik J and Voytek, Bradley},
  file = {/Users/qualia/Documents/Papers/Gao et al. - 2016 - Inferring Synaptic ExcitationInhibition Balance f.pdf}
}

@article{Fyodorov2016,
  langid = {english},
  title = {Nonlinear Analogue of the {{May}}-{{Wigner}} Instability Transition},
  volume = {113},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1601136113},
  doi = {10.1073/pnas.1601136113},
  number = {25},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2016-06-21},
  pages = {6827-6832},
  author = {Fyodorov, Yan V. and Khoruzhenko, Boris A.},
  file = {/Users/qualia/Documents/Papers/Fyodorov and Khoruzhenko - 2016 - Nonlinear analogue of the May−Wigner instability t.pdf}
}

@article{Fusi2016,
  langid = {english},
  title = {Why Neurons Mix: High Dimensionality for Higher Cognition},
  volume = {37},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438816000118},
  doi = {10.1016/j.conb.2016.01.010},
  shorttitle = {Why Neurons Mix},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2016-04},
  pages = {66-74},
  author = {Fusi, Stefano and Miller, Earl K and Rigotti, Mattia},
  file = {/Users/qualia/Documents/Papers/Fusi et al. - 2016 - Why neurons mix high dimensionality for higher co.pdf}
}

@article{Friston2016,
  langid = {english},
  title = {Active Inference and Learning},
  volume = {68},
  issn = {01497634},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763416301336},
  doi = {10.1016/j.neubiorev.2016.06.022},
  abstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},
  journaltitle = {Neuroscience \& Biobehavioral Reviews},
  urldate = {2019-03-30},
  date = {2016-09},
  pages = {862-879},
  author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O⿿Doherty, John and Pezzulo, Giovanni},
  file = {/Users/qualia/Documents/Papers/Friston et al. - 2016 - Active inference and learning.pdf}
}

@article{Enel2016,
  langid = {english},
  title = {Reservoir {{Computing Properties}} of {{Neural Dynamics}} in {{Prefrontal Cortex}}},
  volume = {12},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004967},
  doi = {10.1371/journal.pcbi.1004967},
  number = {6},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2016-06-10},
  pages = {e1004967},
  author = {Enel, Pierre and Procyk, Emmanuel and Quilodran, Ren\'e and Dominey, Peter Ford},
  editor = {O'Reilly, Jill X},
  file = {/Users/qualia/Documents/Papers/Enel et al. - 2016 - Reservoir Computing Properties of Neural Dynamics .pdf}
}

@article{Eklund2016,
  langid = {english},
  title = {Cluster Failure: {{Why fMRI}} Inferences for Spatial Extent Have Inflated False-Positive Rates},
  volume = {113},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1602413113},
  doi = {10.1073/pnas.1602413113},
  shorttitle = {Cluster Failure},
  number = {28},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2016-07-12},
  pages = {7900-7905},
  author = {Eklund, Anders and Nichols, Thomas E. and Knutsson, Hans},
  file = {/Users/qualia/Documents/Papers/Eklund et al. - 2016 - Cluster failure Why fMRI inferences for spatial e 2.pdf;/Users/qualia/Documents/Papers/Eklund et al. - 2016 - Cluster failure Why fMRI inferences for spatial e.pdf}
}

@article{DePasquale,
  langid = {english},
  title = {Using {{Firing}}-{{Rate Dynamics}} to {{Train Recurrent Networks}} of {{Spiking Model Neurons}}},
  abstract = {Recurrent neural networks are powerful tools for understanding and modeling computation and representation by populations of neurons. Continuous-variable or ``rate'' model networks have been analyzed and applied extensively for these purposes. However, neurons fire action potentials, and the discrete nature of spiking is an important feature of neural circuit dynamics. Despite significant advances, training recurrently connected spiking neural networks remains a challenge. We present a procedure for training recurrently connected spiking networks to generate dynamical patterns autonomously, to produce complex temporal outputs based on integrating network input, and to model physiological data. Our procedure makes use of a continuous-variable network to identify targets for training the inputs to the spiking model neurons. Surprisingly, we are able to construct spiking networks that duplicate tasks performed by continuous-variable networks with only a relatively minor expansion in the number of neurons. Our approach provides a novel view of the significance and appropriate use of ``firing rate'' models, and it is a useful approach for building model spiking networks that can be used to address important questions about representation and computation in neural systems.},
  pages = {17},
  author = {DePasquale, Brian and Churchland, Mark M and Abbott, L F},
  file = {/Users/qualia/Documents/Papers/DePasquale et al. - Using Firing-Rate Dynamics to Train Recurrent Netw.pdf}
}

@article{Deneve2016,
  langid = {english},
  title = {Efficient Codes and Balanced Networks},
  volume = {19},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4243},
  doi = {10.1038/nn.4243},
  number = {3},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2016-03},
  pages = {375-382},
  author = {Den\`eve, Sophie and Machens, Christian K},
  file = {/Users/qualia/Documents/Papers/Denève and Machens - 2016 - Efficient codes and balanced networks.pdf}
}

@article{Dehghani2016,
  langid = {english},
  title = {Dynamic {{Balance}} of {{Excitation}} and {{Inhibition}} in {{Human}} and {{Monkey Neocortex}}},
  volume = {6},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/srep23176},
  doi = {10.1038/srep23176},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2016-09},
  author = {Dehghani, Nima and Peyrache, Adrien and Telenczuk, Bartosz and Le Van Quyen, Michel and Halgren, Eric and Cash, Sydney S. and Hatsopoulos, Nicholas G. and Destexhe, Alain},
  file = {/Users/qualia/Documents/Papers/2014 - Dehghani et al. - Multiscale Balance of Excitation and Inhibition in Single-Unit ensemble Recordings in Human and Monkey Neocorte.pdf;/Users/qualia/Documents/Papers/Dehghani et al. - 2016 - Dynamic Balance of Excitation and Inhibition in Hu 2.pdf;/Users/qualia/Documents/Papers/Dehghani et al. - 2016 - Dynamic Balance of Excitation and Inhibition in Hu.pdf}
}

@article{Cui2017,
  langid = {english},
  title = {The {{HTM Spatial Pooler}}: A Neocortical Algorithm for Online Sparse Distributed Coding},
  url = {http://biorxiv.org/lookup/doi/10.1101/085035},
  doi = {10.1101/085035},
  shorttitle = {The {{HTM Spatial Pooler}}},
  abstract = {Each region in the cortex receives input through millions of axons from sensory organs and from other cortical regions. It remains a mystery how cortical neurons learn to form specific connections from this large number of unlabeled inputs in order to support further computations. Hierarchical temporal memory (HTM) provides a theoretical framework for understanding the computational principles in the neocortex. In this paper we describe an important component of HTM, the HTM spatial pooler that models how neurons learn feedforward connections. The spatial pooler converts arbitrary binary input patterns into sparse distributed representations (SDRs) using competitive Hebbian learning rules and homeostasis excitability control mechanisms. Through a series of simulations, we demonstrate the key computational properties of HTM spatial pooler, including preserving semantic similarity among inputs, fast adaptation to changing statistics of the inputs, improved noise robustness over learning, efficient use of all cells and flexibility in the event of cell death or loss of input afferents. To quantify these properties, we developed a set of metrics that can be directly measured from the spatial pooler outputs. These metrics can be used as complementary performance indicators for any sparse coding algorithm. We discuss the relationship with neuroscience and previous studies of sparse coding and competitive learning. The HTM spatial pooler represents a neurally inspired algorithm for learning SDRs from noisy data streams online.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-02-16},
  author = {Cui, Yuwei and Ahmad, Subutai and Hawkins, Jeff},
  file = {/Users/qualia/Documents/Papers/Cui et al. - 2017 - The HTM Spatial Pooler a neocortical algorithm fo.pdf}
}

@article{Crossley2016,
  langid = {english},
  title = {A Two-Neuron System for Adaptive Goal-Directed Decision-Making in {{Lymnaea}}},
  volume = {7},
  issn = {2041-1723},
  url = {http://www.nature.com/articles/ncomms11793},
  doi = {10.1038/ncomms11793},
  number = {1},
  journaltitle = {Nature Communications},
  urldate = {2019-03-30},
  date = {2016-12},
  author = {Crossley, Michael and Staras, Kevin and Kemenes, Gy\"orgy},
  file = {/Users/qualia/Documents/Papers/Crossley et al. - 2016 - A two-neuron system for adaptive goal-directed dec.pdf}
}

@article{Cox2016,
  langid = {english},
  title = {Variability and Stability of Large-Scale Cortical Oscillation Patterns},
  url = {http://biorxiv.org/lookup/doi/10.1101/093005},
  doi = {10.1101/093005},
  abstract = {Individual differences in brain organization exist at many spatial and temporal scales, contributing to the substantial heterogeneity underlying human thought and behavior. Oscillatory neural activity is crucial for these behaviors, but how such rhythms are expressed across the cortex within and across individuals has not been thoroughly characterized. Combining electroencephalography (EEG) with representational similarity and multivariate classification techniques, we provide a systematic characterization of brain-wide activity across frequency bands and oscillatory features during rest and task performance. Results indicate that oscillatory profiles exhibit sizable group-level correspondences, indicating the presence of common templates of oscillatory organization. At the same time, we observed well-defined subject-specific network profiles that were discernible above and beyond the structure shared across individuals. These individualized patterns were sufficiently stable over time to allow successful classification of individuals several months later. Finally, our findings indicate that the network structure of rhythmic activity varies considerably across distinct oscillatory frequencies and features, suggesting the existence of multiple, parallel information processing streams embedded in distributed electrophysiological activity. Together, these findings affirm the richness of spatiotemporal EEG signals and emphasize the utility of multivariate network analyses for understanding the role of brain oscillations in physiology and behavior.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-12-09},
  author = {Cox, Roy and Schapiro, Anna and Stickgold, Robert},
  file = {/Users/qualia/Documents/Papers/Cox et al. - 2016 - Variability and stability of large-scale cortical .pdf}
}

@article{Corbit2016,
  langid = {english},
  title = {Pallidostriatal {{Projections Promote Oscillations}} in a {{Dopamine}}-{{Depleted Biophysical Network Model}}},
  volume = {36},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0339-16.2016},
  doi = {10.1523/JNEUROSCI.0339-16.2016},
  number = {20},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2016-05-18},
  pages = {5556-5571},
  author = {Corbit, V. L. and Whalen, T. C. and Zitelli, K. T. and Crilly, S. Y. and Rubin, J. E. and Gittis, A. H.},
  file = {/Users/qualia/Documents/Papers/Corbit et al. - 2016 - Pallidostriatal Projections Promote Oscillations i.pdf}
}

@article{Coon2016,
  langid = {english},
  title = {Oscillatory Phase Modulates the Timing of Neuronal Activations and Resulting Behavior},
  volume = {133},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811916002135},
  doi = {10.1016/j.neuroimage.2016.02.080},
  abstract = {Human behavioral response timing is highly variable from trial to trial. While it is generally understood that behavioral variability must be due to trial-by-trial variations in brain function, it is still largely unknown which physiological mechanisms govern the timing of neural activity as it travels through networks of neuronal populations, and how variations in the timing of neural activity relate to variations in the timing of behavior. In our study, we submitted recordings from the cortical surface to novel analytic techniques to chart the trajectory of neuronal population activity across the human cortex in single trials, and found joint modulation of the timing of this activity and of consequent behavior by neuronal oscillations in the alpha band (8\textendash{}12 Hz). Specifically, we established that the onset of population activity tends to occur during the trough of oscillatory activity, and that deviations from this preferred relationship are related to changes in the timing of population activity and the speed of the resulting behavioral response. These results indicate that neuronal activity incurs variable delays as it propagates across neuronal populations, and that the duration of each delay is a function of the instantaneous phase of oscillatory activity. We conclude that the results presented in this paper are supportive of a general model for variability in the effective speed of information transmission in the human brain and for variability in the timing of human behavior.},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2016-06},
  pages = {294-301},
  author = {Coon, W.G. and Gunduz, A. and Brunner, P. and Ritaccio, A.L. and Pesaran, B. and Schalk, G.},
  file = {/Users/qualia/Documents/Papers/Coon et al. - 2016 - Oscillatory phase modulates the timing of neuronal 2.pdf;/Users/qualia/Documents/Papers/Coon et al. - 2016 - Oscillatory phase modulates the timing of neuronal.pdf}
}

@article{Collins2017,
  langid = {english},
  title = {{{CAPACITY AND TRAINABILITY IN RECURRENT NEURAL NETWORKS}}},
  abstract = {Two potential bottlenecks on the expressiveness of recurrent neural networks (RNNs) are their ability to store information about the task in their parameters, and to store information about the input history in their units. We show experimentally that all common RNN architectures achieve nearly the same per-task and per-unit capacity bounds with careful training, for a variety of tasks and stacking depths. They can store an amount of task information which is linear in the number of parameters, and is approximately 5 bits per parameter. They can additionally store approximately one real number from their input history per hidden unit. We further find that for several tasks it is the per-task parameter capacity bound that determines performance. These results suggest that many previous results comparing RNN architectures are driven primarily by differences in training effectiveness, rather than differences in capacity. Supporting this observation, we compare training difficulty for several architectures, and show that vanilla RNNs are far more difficult to train, yet have higher capacity. Finally, we propose two novel RNN architectures, one of which is easier to train than the LSTM or GRU.},
  date = {2017},
  pages = {16},
  author = {Collins, Jasmine and Sohl-Dickstein, Jascha and Sussillo, David},
  file = {/Users/qualia/Documents/Papers/Collins et al. - 2017 - CAPACITY AND TRAINABILITY IN RECURRENT NEURAL NETW.pdf}
}

@article{Colgin2016,
  langid = {english},
  title = {Rhythms of the Hippocampal Network},
  volume = {17},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn.2016.21},
  doi = {10.1038/nrn.2016.21},
  abstract = {The hippocampal local field potential (LFP) shows three major types of rhythms: theta, sharp wave\textendash{}ripples and gamma. These rhythms are defined by their frequencies, they have behavioural correlates in several species including rats and humans, and they have been proposed to carry out distinct functions in hippocampal memory processing. However, recent findings have challenged traditional views on these behavioural functions. In this Review, I discuss our current understanding of the origins and the mnemonic functions of hippocampal theta, sharp wave\textendash{}ripples and gamma rhythms on the basis of findings from rodent studies. In addition, I present an updated synthesis of their roles and interactions within the hippocampal network.},
  number = {4},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2016-04},
  pages = {239-249},
  author = {Colgin, Laura Lee},
  file = {/Users/qualia/Documents/Papers/Colgin - 2016 - Rhythms of the hippocampal network.pdf}
}

@article{Cocchi2016,
  langid = {english},
  title = {A Hierarchy of Timescales Explains Distinct Effects of Local Inhibition of Primary Visual Cortex and Frontal Eye Fields},
  volume = {5},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/15252},
  doi = {10.7554/eLife.15252},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2016-09-06},
  author = {Cocchi, Luca and Sale, Martin V and L Gollo, Leonardo and Bell, Peter T and Nguyen, Vinh T and Zalesky, Andrew and Breakspear, Michael and Mattingley, Jason B},
  file = {/Users/qualia/Documents/Papers/Cocchi et al. - 2016 - A hierarchy of timescales explains distinct effect.pdf}
}

@article{Chehelcheraghi2016,
  langid = {english},
  title = {A Neural Mass Model of Phase\textendash{}Amplitude Coupling},
  volume = {110},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-016-0687-5},
  doi = {10.1007/s00422-016-0687-5},
  abstract = {Brain activity shows phase\textendash{}amplitude coupling between its slow and fast oscillatory components. We study phase\textendash{}amplitude coupling as recorded at individual sites, using a modified version of the well-known Wendling neural mass model. To the population of fast inhibitory interneurons of this model, we added external modulatory input and dynamic self-feedback. These two modifications together are sufficient to let the inhibitory population serve as a limit-cycle oscillator, with frequency characteristics comparable to the beta and gamma bands. The frequency and power of these oscillations can be tuned through the time constant of the dynamic and modulatory input. Alpha band activity is generated, as is usual in such models, as a result of interactions of pyramidal neurons and a population of slow inhibitory interneurons. The slow inhibitory population activity directly influences the fast oscillations via the synaptic gain between slow and fast inhibitory populations. As a result, the amplitude envelope of the fast oscillation is coupled to the phase of the slow activity; this result is consistent with the notion that phase\textendash{}amplitude coupling is effectuated by interactions between inhibitory interneurons.},
  number = {2-3},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2016-06},
  pages = {171-192},
  author = {Chehelcheraghi, Mojtaba and Nakatani, Chie and Steur, Erik and van Leeuwen, Cees},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Chehelcheraghi et al. - 2016 - A neural mass model of phase–amplitude coupling.pdf}
}

@article{Chaudhuri2016,
  langid = {english},
  title = {Random Recurrent Networks near Criticality Capture the Broadband Power Distribution of Human {{ECoG}} Dynamics},
  url = {http://biorxiv.org/lookup/doi/10.1101/036228},
  doi = {10.1101/036228},
  abstract = {The power spectrum of brain electric field potential recordings is dominated by an arrhythmic broadband signal but a mechanistic account of its underlying neural network dynamics is lacking. Here we show how the broadband power spectrum of field potential recordings can be explained by a simple random network of nodes near criticality. Such a recurrent network produces activity with a combination of a fast and a slow autocorrelation time constant, with the fast mode corresponding to local dynamics and the slow mode resulting from recurrent excitatory connections across the network. These modes are combined to produce a power spectrum similar to that observed in human intracranial EEG (i.e., electrocorticography, ECoG) recordings. Moreover, such a network naturally converts input correlations across nodes into temporal autocorrelation of the network activity. Consequently, increased independence between nodes results in a reduction in low-frequency power, which offers a possible explanation for observed changes in ECoG power spectra during task performance. Lastly, changes in network coupling produce changes in network activity power spectra reminiscent of those seen in human ECoG recordings across different arousal states. This model thus links macroscopic features of the empirical ECoG power spectrum to a parsimonious underlying network structure and proposes potential mechanisms for changes in ECoG power spectra observed across behavioral and arousal states. This provides a computational framework within which to generate and test hypotheses about the cellular and network mechanisms underlying whole brain electrical dynamics, their variations across behavioral states as well as abnormalities associated with brain diseases.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-01-08},
  author = {Chaudhuri, Rishidev and He, Biyu and Wang, Xiao-Jing},
  file = {/Users/qualia/Documents/Papers/Chaudhuri et al. - 2016 - Random recurrent networks near criticality capture.pdf}
}

@article{Caze,
  langid = {english},
  title = {Dendrites Enable a Robust Mechanism for Neuronal Stimulus Selectivity},
  abstract = {Hearing, vision, touch \textendash{} underlying all of these senses is stimulus selectivity, a robust information processing operation in which cortical neurons respond more to some stimuli than to others. Previous models assume that these neurons receive the highest weighted input from an ensemble encoding the preferred stimulus, but dendrites enable other possibilities. Non-linear dendritic processing can produce stimulus selectivity based on the spatial distribution of synapses, even if the total preferred stimulus weight does not exceed that of non-preferred stimuli. Using a multi-subunit non-linear model, we demonstrate that selectivity can arise from the spatial distribution of synapses.},
  pages = {16},
  author = {Caze, Romain D and Jarvis, Sarah and Foust, Amanda J and Schultz, Simon R},
  file = {/Users/qualia/Documents/Papers/Caze et al. - Dendrites enable a robust mechanism for neuronal s.pdf}
}

@article{Cardin2016,
  langid = {english},
  title = {Snapshots of the {{Brain}} in {{Action}}: {{Local Circuit Operations}} through the {{Lens}} of {{Oscillations}}},
  volume = {36},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1021-16.2016},
  doi = {10.1523/JNEUROSCI.1021-16.2016},
  shorttitle = {Snapshots of the {{Brain}} in {{Action}}},
  number = {41},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2016-10-12},
  pages = {10496-10504},
  author = {Cardin, J. A.},
  file = {/Users/qualia/Documents/Papers/Cardin - 2016 - Snapshots of the Brain in Action Local Circuit Op.pdf}
}

@article{Cannon2016,
  langid = {english},
  title = {Synaptic and Intrinsic Homeostasis Cooperate to Optimize Single Neuron Response Properties and Tune Integrator Circuits},
  volume = {116},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00253.2016},
  doi = {10.1152/jn.00253.2016},
  number = {5},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2016-11},
  pages = {2004-2022},
  author = {Cannon, Jonathan and Miller, Paul},
  file = {/Users/qualia/Documents/Papers/Cannon and Miller - 2016 - Synaptic and intrinsic homeostasis cooperate to op.pdf}
}

@article{Bird2016,
  langid = {english},
  title = {Optimal {{Current Transfer}} in {{Dendrites}}},
  volume = {12},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004897},
  doi = {10.1371/journal.pcbi.1004897},
  number = {5},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2016-05-04},
  pages = {e1004897},
  author = {Bird, Alex D. and Cuntz, Hermann},
  editor = {van Rossum, Mark C. W.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Bird and Cuntz - 2016 - Optimal Current Transfer in Dendrites.pdf}
}

@article{Barreto,
  langid = {english},
  title = {Successor {{Features}} for {{Transfer}} in {{Reinforcement Learning}}},
  abstract = {Transfer in reinforcement learning refers to the notion that generalization should occur not only within a task but also across tasks. We propose a transfer framework for the scenario where the reward function changes between tasks but the environment's dynamics remain the same. Our approach rests on two key ideas: successor features, a value function representation that decouples the dynamics of the environment from the rewards, and generalized policy improvement, a generalization of dynamic programming's policy improvement operation that considers a set of policies rather than a single one. Put together, the two ideas lead to an approach that integrates seamlessly within the reinforcement learning framework and allows the free exchange of information across tasks. The proposed method also provides performance guarantees for the transferred policy even before any learning has taken place. We derive two theorems that set our approach in firm theoretical ground and present experiments that show that it successfully promotes transfer in practice, significantly outperforming alternative methods in a sequence of navigation tasks and in the control of a simulated robotic arm.},
  pages = {11},
  author = {Barreto, Andre and Dabney, Will and Munos, Remi and Hunt, Jonathan J and Schaul, Tom},
  file = {/Users/qualia/Documents/Papers/Barreto et al. - Successor Features for Transfer in Reinforcement L.pdf}
}

@article{Arandia-Romero2016,
  langid = {english},
  title = {Multiplicative and {{Additive Modulation}} of {{Neuronal Tuning}} with {{Population Activity Affects Encoded Information}}},
  volume = {89},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S089662731600091X},
  doi = {10.1016/j.neuron.2016.01.044},
  abstract = {Numerous studies have shown that neuronal responses are modulated by stimulus properties and also by the state of the local network. However, little is known about how activity fluctuations of neuronal populations modulate the sensory tuning of cells and affect their encoded information. We found that fluctuations in ongoing and stimulus-evoked population activity in primate visual cortex modulate the tuning of neurons in a multiplicative and additive manner. While distributed on a continuum, neurons with stronger multiplicative effects tended to have less additive modulation and vice versa. The information encoded by multiplicatively modulated neurons increased with greater population activity, while that of additively modulated neurons decreased. These effects offset each other so that population activity had little effect on total information. Our results thus suggest that intrinsic activity fluctuations may act as a ``traffic light'' that determines which subset of neurons is most informative.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2016-03},
  pages = {1305-1316},
  author = {Arandia-Romero, I\~nigo and Tanabe, Seiji and Drugowitsch, Jan and Kohn, Adam and Moreno-Bote, Rub\'en},
  file = {/Users/qualia/Documents/Papers/Arandia-Romero et al. - 2016 - Multiplicative and Additive Modulation of Neuronal.pdf}
}

@article{Alekseichuk2016,
  langid = {english},
  title = {Spatial {{Working Memory}} in {{Humans Depends}} on {{Theta}} and {{High Gamma Synchronization}} in the {{Prefrontal Cortex}}},
  volume = {26},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S096098221630358X},
  doi = {10.1016/j.cub.2016.04.035},
  abstract = {Previous, albeit correlative, findings have shown that the neural mechanisms underlying working memory critically require cross-structural and cross-frequency coupling mechanisms between theta and gamma neural oscillations. However, the direct causality between cross-frequency coupling and working memory performance remains to be demonstrated. Here we externally modulated the interaction of theta and gamma rhythms in the prefrontal cortex using novel cross-frequency protocols of transcranial alternating current stimulation to affect spatial working memory performance in humans. Enhancement of working memory performance and increase of global neocortical connectivity were observed when bursts of high gamma oscillations (80\textendash{}100 Hz) coincided with the peaks of the theta waves, whereas superimposition on the trough of the theta wave and low gamma frequency protocols were ineffective. Thus, our results demonstrate the sensitivity of working memory performance and global neocortical connectivity to the phase and rhythm of the externally driven thetagamma cross-frequency synchronization.},
  number = {12},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2016-06},
  pages = {1513-1521},
  author = {Alekseichuk, Ivan and Turi, Zsolt and Amador de Lara, Gabriel and Antal, Andrea and Paulus, Walter},
  file = {/Users/qualia/Documents/Papers/Alekseichuk et al. - 2016 - Spatial Working Memory in Humans Depends on Theta .pdf}
}

@article{Aitchison2016,
  langid = {english},
  title = {The {{Hamiltonian Brain}}: {{Efficient Probabilistic Inference}} with {{Excitatory}}-{{Inhibitory Neural Circuit Dynamics}}},
  volume = {12},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1005186},
  doi = {10.1371/journal.pcbi.1005186},
  shorttitle = {The {{Hamiltonian Brain}}},
  number = {12},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2016-12-27},
  pages = {e1005186},
  author = {Aitchison, Laurence and Lengyel, M\'at\'e},
  editor = {Kording, Konrad P.},
  file = {/Users/qualia/Documents/Papers/Aitchison and Lengyel - 2016 - The Hamiltonian Brain Efficient Probabilistic Inf.pdf}
}

@article{Advani,
  langid = {english},
  title = {Statistical Mechanics of High-Dimensional Inference},
  pages = {12},
  author = {Advani, Madhu and Ganguli, Surya},
  file = {/Users/qualia/Documents/Papers/Advani and Ganguli - Statistical mechanics of high-dimensional inferenc.pdf}
}

@article{Abbott2016,
  langid = {english},
  title = {Building Functional Networks of Spiking Model Neurons},
  volume = {19},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4241},
  doi = {10.1038/nn.4241},
  number = {3},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2016-03},
  pages = {350-355},
  author = {Abbott, L F and DePasquale, Brian and Memmesheimer, Raoul-Martin},
  file = {/Users/qualia/Documents/Papers/Abbott et al. - 2016 - Building functional networks of spiking model neur.pdf}
}

@inproceedings{Abadi2016,
  langid = {english},
  location = {{Vienna, Austria}},
  title = {Deep {{Learning}} with {{Differential Privacy}}},
  isbn = {978-1-4503-4139-4},
  url = {http://dl.acm.org/citation.cfm?doid=2976749.2978318},
  doi = {10.1145/2976749.2978318},
  abstract = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
  eventtitle = {The 2016 {{ACM SIGSAC Conference}}},
  booktitle = {Proceedings of the 2016 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}} - {{CCS}}'16},
  publisher = {{ACM Press}},
  urldate = {2019-03-30},
  date = {2016},
  pages = {308-318},
  author = {Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  file = {/Users/qualia/Documents/Papers/Abadi et al. - 2016 - Deep Learning with Differential Privacy.pdf}
}

@article{Zhou2015,
  langid = {english},
  title = {Establishing a {{Statistical Link}} between {{Network Oscillations}} and {{Neural Synchrony}}},
  volume = {11},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004549},
  doi = {10.1371/journal.pcbi.1004549},
  abstract = {Pairs of active neurons frequently fire action potentials or ``spikes'' nearly synchronously (i.e., within 5 ms of each other). This spike synchrony may occur by chance, based solely on the neurons' fluctuating firing patterns, or it may occur too frequently to be explicable by chance alone. When spike synchrony above chances levels is present, it may subserve computation for a specific cognitive process, or it could be an irrelevant byproduct of such computation. Either way, spike synchrony is a feature of neural data that should be explained. A point process regression framework has been developed previously for this purpose, using generalized linear models (GLMs). In this framework, the observed number of synchronous spikes is compared to the number predicted by chance under varying assumptions about the factors that affect each of the individual neuron's firing-rate functions. An important possible source of spike synchrony is network-wide oscillations, which may provide an essential mechanism of network information flow. To establish the statistical link between spike synchrony and network-wide oscillations, we have integrated oscillatory field potentials into our point process regression framework. We first extended a previouslypublished model of spike-field association and showed that we could recover phase relationships between oscillatory field potentials and firing rates. We then used this new framework to demonstrate the statistical relationship between oscillatory field potentials and spike synchrony in: 1) simulated neurons, 2) in vitro recordings of hippocampal CA1 pyramidal cells, and 3) in vivo recordings of neocortical V4 neurons. Our results provide a rigorous method for establishing a statistical link between network oscillations and neural synchrony.},
  number = {10},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-10-14},
  pages = {e1004549},
  author = {Zhou, Pengcheng and Burton, Shawn D. and Snyder, Adam C. and Smith, Matthew A. and Urban, Nathaniel N. and Kass, Robert E.},
  editor = {Sporns, Olaf},
  file = {/Users/qualia/Documents/Papers/Zhou et al. - 2015 - Establishing a Statistical Link between Network Os.pdf}
}

@article{Wiltschko2015,
  langid = {english},
  title = {Mapping {{Sub}}-{{Second Structure}} in {{Mouse Behavior}}},
  volume = {88},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315010375},
  doi = {10.1016/j.neuron.2015.11.031},
  abstract = {Complex animal behaviors are likely built from simpler modules, but their systematic identification in mammals remains a significant challenge. Here we use depth imaging to show that 3D mouse pose dynamics are structured at the sub-second timescale. Computational modeling of these fast dynamics effectively describes mouse behavior as a series of reused and stereotyped modules with defined transition probabilities. We demonstrate this combined 3D imaging and machine learning method can be used to unmask potential strategies employed by the brain to adapt to the environment, to capture both predicted and previously hidden phenotypes caused by genetic or neural manipulations, and to systematically expose the global structure of behavior within an experiment. This work reveals that mouse body language is built from identifiable components and is organized in a predictable fashion; deciphering this language establishes an objective framework for characterizing the influence of environmental cues, genes and neural activity on behavior.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-12},
  pages = {1121-1135},
  author = {Wiltschko, Alexander B. and Johnson, Matthew J. and Iurilli, Giuliano and Peterson, Ralph E. and Katon, Jesse M. and Pashkovski, Stan L. and Abraira, Victoria E. and Adams, Ryan P. and Datta, Sandeep Robert},
  file = {/Users/qualia/Documents/Papers/Wiltschko et al. - 2015 - Mapping Sub-Second Structure in Mouse Behavior.pdf}
}

@article{Wilson2015,
  langid = {english},
  title = {Clustered {{Desynchronization}} from {{High}}-{{Frequency Deep Brain Stimulation}}},
  volume = {11},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004673},
  doi = {10.1371/journal.pcbi.1004673},
  number = {12},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-12-29},
  pages = {e1004673},
  author = {Wilson, Dan and Moehlis, Jeff},
  editor = {Diedrichsen, J\"orn},
  file = {/Users/qualia/Documents/Papers/Wilson and Moehlis - 2015 - Clustered Desynchronization from High-Frequency De.pdf}
}

@article{Weichwald2015,
  langid = {english},
  title = {Causal Interpretation Rules for Encoding and Decoding Models in Neuroimaging},
  volume = {110},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S105381191500052X},
  doi = {10.1016/j.neuroimage.2015.01.036},
  abstract = {Causal terminology is often introduced in the interpretation of encoding and decoding models trained on neuroimaging data. In this article, we investigate which causal statements are warranted and which ones are not supported by empirical evidence. We argue that the distinction between encoding and decoding models is not sufficient for this purpose: relevant features in encoding and decoding models carry a different meaning in stimulus- and in response-based experimental paradigms.We show that only encoding models in the stimulus-based setting support unambiguous causal interpretations. By combining encoding and decoding models trained on the same data, however, we obtain insights into causal relations beyond those that are implied by each individual model type. We illustrate the empirical relevance of our theoretical findings on EEG data recorded during a visuo-motor learning task.},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {48-59},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Quantitative Biology - Neurons and Cognition,Statistics - Applications},
  author = {Weichwald, Sebastian and Meyer, Timm and \"Ozdenizci, Ozan and Sch\"olkopf, Bernhard and Ball, Tonio and Grosse-Wentrup, Moritz},
  file = {/Users/qualia/Documents/Papers/Weichwald et al. - 2015 - Causal interpretation rules for encoding and decod 2.pdf;/Users/qualia/Documents/Papers/Weichwald et al. - 2015 - Causal interpretation rules for encoding and decod.pdf}
}

@article{Voytek2015,
  langid = {english},
  title = {Dynamic {{Network Communication}} as a {{Unifying Neural Basis}} for {{Cognition}}, {{Development}}, {{Aging}}, and {{Disease}}},
  volume = {77},
  issn = {00063223},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0006322315003546},
  doi = {10.1016/j.biopsych.2015.04.016},
  number = {12},
  journaltitle = {Biological Psychiatry},
  urldate = {2019-03-30},
  date = {2015-06},
  pages = {1089-1097},
  author = {Voytek, Bradley and Knight, Robert T.},
  file = {/Users/qualia/Documents/Papers/Voytek and Knight - 2015 - Dynamic Network Communication as a Unifying Neural 2.pdf;/Users/qualia/Documents/Papers/Voytek and Knight - 2015 - Dynamic Network Communication as a Unifying Neural.pdf}
}

@article{Voytek2015a,
  langid = {english},
  title = {Oscillatory Dynamics Coordinating Human Frontal Networks in Support of Goal Maintenance},
  volume = {18},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4071},
  doi = {10.1038/nn.4071},
  number = {9},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2015-09},
  pages = {1318-1324},
  author = {Voytek, Bradley and Kayser, Andrew S and Badre, David and Fegen, David and Chang, Edward F and Crone, Nathan E and Parvizi, Josef and Knight, Robert T and D'Esposito, Mark},
  file = {/Users/qualia/Documents/Papers/Voytek et al. - 2015 - Oscillatory dynamics coordinating human frontal ne.pdf}
}

@article{Urban2015,
  langid = {english},
  title = {Real-Time Imaging of Brain Activity in Freely Moving Rats Using Functional Ultrasound},
  volume = {12},
  issn = {1548-7091, 1548-7105},
  url = {http://www.nature.com/articles/nmeth.3482},
  doi = {10.1038/nmeth.3482},
  number = {9},
  journaltitle = {Nature Methods},
  urldate = {2019-03-30},
  date = {2015-09},
  pages = {873-878},
  author = {Urban, Alan and Dussaux, Clara and Martel, Guillaume and Brunner, Cl\'ement and Mace, Emilie and Montaldo, Gabriel},
  file = {/Users/qualia/Documents/Papers/Urban et al. - 2015 - Real-time imaging of brain activity in freely movi.pdf}
}

@article{Sigeti1987,
  langid = {english},
  title = {High-Frequency Power Spectra for Systems Subject to Noise},
  volume = {35},
  issn = {0556-2791},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.35.2276},
  doi = {10.1103/PhysRevA.35.2276},
  number = {5},
  journaltitle = {Physical Review A},
  urldate = {2019-03-30},
  date = {1987-03-01},
  pages = {2276-2282},
  author = {Sigeti, D. and Horsthemke, W.},
  file = {/Users/qualia/Documents/Papers/1987 - Sigeti, Horsthemke - High-frequency power spectra for systems subject to noise.pdf}
}

@article{Bak1988,
  langid = {english},
  title = {Self-Organized Criticality},
  volume = {38},
  issn = {0556-2791},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.38.364},
  doi = {10.1103/PhysRevA.38.364},
  number = {1},
  journaltitle = {Physical Review A},
  urldate = {2019-03-30},
  date = {1988-07-01},
  pages = {364-374},
  author = {Bak, Per and Tang, Chao and Wiesenfeld, Kurt},
  file = {/Users/qualia/Documents/Papers/1988 - Bak, Tang, Wiensenfeld - Self-organized criticality.pdf}
}

@article{Thalmeier2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1505.07866},
  langid = {english},
  title = {Learning Universal Computations with Spikes},
  volume = {12},
  issn = {1553-7358},
  url = {http://arxiv.org/abs/1505.07866},
  doi = {10.1371/journal.pcbi.1004895},
  abstract = {Providing the neurobiological basis of information processing in higher animals, spiking neural networks must be able to learn a variety of complicated computations, including the generation of appropriate, possibly delayed reactions to inputs and the self-sustained generation of complex activity patterns, e.g. for locomotion. Many such computations require previous building of intrinsic world models. Here we show how spiking neural networks may solve these different tasks. Firstly, we derive constraints under which classes of spiking neural networks lend themselves to substrates of powerful general purpose computing. The networks contain dendritic or synaptic nonlinearities and have a constrained connectivity. We then combine such networks with learning rules for outputs or recurrent connections. We show that this allows to learn even difficult benchmark tasks such as the self-sustained generation of desired low-dimensional chaotic dynamics or memory-dependent computations. Furthermore, we show how spiking networks can build models of external world systems and use the acquired knowledge to control them.},
  number = {6},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2016-06-16},
  pages = {e1004895},
  keywords = {Quantitative Biology - Neurons and Cognition},
  author = {Thalmeier, Dominik and Uhlmann, Marvin and Kappen, Hilbert J. and Memmesheimer, Raoul-Martin},
  file = {/Users/qualia/Documents/Papers/2015 - Thalmeier et al. - Learning universal computations with spikes.pdf;/Users/qualia/Documents/Papers/Thalmeier et al. - 2016 - Learning universal computations with spikes.pdf}
}

@article{Sussillo2015,
  langid = {english},
  title = {A Neural Network That Finds a Naturalistic Solution for the Production of Muscle Activity},
  volume = {18},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4042},
  doi = {10.1038/nn.4042},
  number = {7},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2015-07},
  pages = {1025-1033},
  author = {Sussillo, David and Churchland, Mark M and Kaufman, Matthew T and Shenoy, Krishna V},
  file = {/Users/qualia/Documents/Papers/2015 - Sussillo et al. - A neural network that finds a naturalistic solution for the production of muscle activity.pdf;/Users/qualia/Documents/Papers/Sussillo et al. - 2015 - A neural network that finds a naturalistic solutio.pdf}
}

@article{Stokes2015,
  langid = {english},
  title = {`{{Activity}}-Silent' Working Memory in Prefrontal Cortex: A Dynamic Coding Framework},
  volume = {19},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661315001023},
  doi = {10.1016/j.tics.2015.05.004},
  shorttitle = {`{{Activity}}-Silent' Working Memory in Prefrontal Cortex},
  number = {7},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2015-07},
  pages = {394-405},
  author = {Stokes, Mark G.},
  file = {/Users/qualia/Documents/Papers/2015 - Stokes - ‘Activity-silent’ working memory in prefrontal cortex a dynamic coding framework.pdf;/Users/qualia/Documents/Papers/Stokes - 2015 - ‘Activity-silent’ working memory in prefrontal cor.pdf}
}

@article{Sotero2016,
  langid = {english},
  title = {Topology, Cross-Frequency, and Same-Frequency Band Interactions Shape the Generation of Phase-Amplitude Coupling in a Neural Mass Model of a Cortical Column},
  url = {http://biorxiv.org/lookup/doi/10.1101/023291},
  doi = {10.1101/023291},
  abstract = {Phase-amplitude coupling (PAC), the phenomenon where the phase of a low-frequency rhythm modulates the amplitude of a higher frequency, is becoming an important neurophysiological indicator of short- and long-range information transmission in the brain. Although recent evidence suggests that PAC might play a functional role during sensorimotor, and cognitive events, the neurobiological mechanisms underlying its generation remain imprecise. Thus, a realistic but simple enough computational model of the phenomenon is needed. Here we propose a neural mass model of a cortical column, comprising fourteen neuronal populations distributed across four layers (L2/3, L4, L5 and L6). While experimental studies often focus in only one or two PAC combinations (e.g., theta-gamma or alpha-gamma) our simulations show that the cortical column can generate almost all possible couplings of phases and amplitudes, which are influenced by connectivity parameters, time constants, and external inputs. Furthermore, our simulations suggest that the effective connectivity between neuronal populations can result in the emergence of PAC combinations with frequencies different from the natural frequencies of the oscillators involved. For instance, simulations of oscillators with natural frequencies in the theta, alpha and gamma bands, were able to produce significant PAC combinations involving delta and beta bands.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-02-23},
  author = {Sotero, Roberto},
  file = {/Users/qualia/Documents/Papers/2015 - Sotero - Generation of phase-amplitude coupling of neurophysiological signals in a neural mass model of a cortical column(2).pdf}
}

@article{Sutton,
  langid = {english},
  title = {{{IntegraBteadseAd rocnhiAtepctpurroexsimfoartiLnegaDrnyinnga}},{{mPiclaPnrnoingrga}}, {{manmdinRgeacting}}},
  abstract = {This paper extends previous work with Dyna, a class of architectures for intelligent systems based on approximating dynamic programming methods. Dyna architectures integrate trial-and-error (reinforcement) learning and execution-time planning into a single process operating alternately on the world and on a learned model of the world. In this paper, I present and show results for two Dyna architectures. The Dyna-PI architecture is based on dynamic programming's policy iteration method and can be related to existing AI ideas such as evaluation functions and universal plans (reactive systems). Using a navigation task, results are shown for a simple Dyna-PI system that simultaneously learns by trial and error, learns a world model, and plans optimal routes using the evolving world model. The Dyna-Q architecture is based on Watkins's Q-learning, a new kind of reinforcement learning. Dyna-Q uses a less familiar set of data structures than does Dyna-PI, but is arguably simpler to implement and use. We show that Dyna-Q architectures are easy to adapt for use in changing environments.},
  pages = {9},
  author = {Sutton, Richard S},
  file = {/Users/qualia/Documents/Papers/1990 - Sutton - Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming.pdf}
}

@article{Rahnev2011,
  langid = {english},
  title = {Prior {{Expectation Modulates}} the {{Interaction}} between {{Sensory}} and {{Prefrontal Regions}} in the {{Human Brain}}},
  volume = {31},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1478-11.2011},
  doi = {10.1523/JNEUROSCI.1478-11.2011},
  number = {29},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2011-07-20},
  pages = {10741-10748},
  author = {Rahnev, D. and Lau, H. and de Lange, F. P.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2011 - Rahnev, Lau, de Lange - Prior expectation modulates the interaction between sensory and prefrontal regions in the human brain.pdf}
}

@article{Rasmussen2011,
  langid = {english},
  title = {Visualization of Nonlinear Kernel Models in Neuroimaging by Sensitivity Maps},
  volume = {55},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910016198},
  doi = {10.1016/j.neuroimage.2010.12.035},
  abstract = {There is significant current interest in decoding mental states from neuroimages. In this context kernel methods, e.g., support vector machines (SVM) are frequently adopted to learn statistical relations between patterns of brain activation and experimental conditions. In this paper we focus on visualization of such nonlinear kernel models. Specifically, we investigate the sensitivity map as a technique for generation of global summary maps of kernel classification models. We illustrate the performance of the sensitivity map on functional magnetic resonance (fMRI) data based on visual stimuli. We show that the performance of linear models is reduced for certain scan labelings/categorizations in this data set, while the nonlinear models provide more flexibility. We show that the sensitivity map can be used to visualize nonlinear versions of kernel logistic regression, the kernel Fisher discriminant, and the SVM, and conclude that the sensitivity map is a versatile and computationally efficient tool for visualization of nonlinear kernel models in neuroimaging. \textcopyright{} 2010 Elsevier Inc. All rights reserved.},
  number = {3},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-04},
  pages = {1120-1131},
  author = {Rasmussen, Peter Mondrup and Madsen, Kristoffer Hougaard and Lund, Torben Ellegaard and Hansen, Lars Kai},
  file = {/Users/qualia/Documents/Papers/2011 - Rasmussen et al. - Visualization of nonlinear kernel models in neuroimaging by sensitivity maps.pdf}
}

@article{Rogalsky2011,
  langid = {english},
  title = {Functional {{Anatomy}} of {{Language}} and {{Music Perception}}: {{Temporal}} and {{Structural Factors Investigated Using Functional Magnetic Resonance Imaging}}},
  volume = {31},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4515-10.2011},
  doi = {10.1523/JNEUROSCI.4515-10.2011},
  shorttitle = {Functional {{Anatomy}} of {{Language}} and {{Music Perception}}},
  number = {10},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2011-03-09},
  pages = {3843-3852},
  author = {Rogalsky, C. and Rong, F. and Saberi, K. and Hickok, G.},
  file = {/Users/qualia/Documents/Papers/2011 - Rogalsky et al. - Functional anatomy of language and music perception temporal and structural factors investigated using function.pdf}
}

@article{Ross,
  langid = {english},
  title = {A {{Bayesian Approach}} for {{Learning}} and {{Planning}} in {{Partially Observable Markov Decision Processes}}},
  abstract = {Bayesian learning methods have recently been shown to provide an elegant solution to the exploration-exploitation trade-off in reinforcement learning. However most investigations of Bayesian reinforcement learning to date focus on the standard Markov Decision Processes (MDPs). The primary focus of this paper is to extend these ideas to the case of partially observable domains, by introducing the Bayes-Adaptive Partially Observable Markov Decision Processes. This new framework can be used to simultaneously (1) learn a model of the POMDP domain through interaction with the environment, (2) track the state of the system under partial observability, and (3) plan (near-)optimal sequences of actions. An important contribution of this paper is to provide theoretical results showing how the model can be finitely approximated while preserving good learning performance. We present approximate algorithms for belief tracking and planning in this model, as well as empirical results that illustrate how the model estimate and agent's return improve as a function of experience.},
  pages = {45},
  author = {Ross, Stephane and Pineau, Joelle and Chaib-draa, Brahim and Kreitmann, Pierre},
  file = {/Users/qualia/Documents/Papers/2011 - Ross, Pineau - A Bayesian approach for learning and planning in partially observable Markov decision processes.pdf}
}

@article{Serences2011,
  langid = {english},
  title = {Mechanisms of {{Selective Attention}}: {{Response Enhancement}}, {{Noise Reduction}}, and {{Efficient Pooling}} of {{Sensory Responses}}},
  volume = {72},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S089662731101004X},
  doi = {10.1016/j.neuron.2011.11.005},
  shorttitle = {Mechanisms of {{Selective Attention}}},
  number = {5},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2011-12},
  pages = {685-687},
  author = {Serences, John T.},
  file = {/Users/qualia/Documents/Papers/2011 - Serences - Mechanisms of selective attention Response enhancement, noise reduction, and efficient pooling of sensory responses.pdf}
}

@article{Shafto2011,
  langid = {english},
  title = {A Probabilistic Model of Cross-Categorization},
  volume = {120},
  issn = {00100277},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027711000709},
  doi = {10.1016/j.cognition.2011.02.010},
  abstract = {Most natural domains can be represented in multiple ways: we can categorize foods in terms of their nutritional content or social role, animals in terms of their taxonomic groupings or their ecological niches, and musical instruments in terms of their taxonomic categories or social uses. Previous approaches to modeling human categorization have largely ignored the problem of cross-categorization, focusing on learning just a single system of categories that explains all of the features. Cross-categorization presents a difficult problem: how can we infer categories without first knowing which features the categories are meant to explain? We present a novel model that suggests that human cross-categorization is a result of joint inference about multiple systems of categories and the features that they explain. We also formalize two commonly proposed alternative explanations for cross-categorization behavior: a features-first and an objects-first approach. The features-first approach suggests that cross-categorization is a consequence of attentional processes, where features are selected by an attentional mechanism first and categories are derived second. The objects-first approach suggests that cross-categorization is a consequence of repeated, sequential attempts to explain features, where categories are derived first, then features that are poorly explained are recategorized. We present two sets of simulations and experiments testing the models' predictions about human categorization. We find that an approach based on joint inference provides the best fit to human categorization behavior, and we suggest that a full account of human category learning will need to incorporate something akin to these capabilities.},
  number = {1},
  journaltitle = {Cognition},
  urldate = {2019-03-30},
  date = {2011-07},
  pages = {1-25},
  author = {Shafto, Patrick and Kemp, Charles and Mansinghka, Vikash and Tenenbaum, Joshua B.},
  file = {/Users/qualia/Documents/Papers/2011 - Shafto et al. - A probabilistic model of cross-categorization.pdf}
}

@article{Smith2011,
  langid = {english},
  title = {The Confounding Effect of Response Amplitude on {{MVPA}} Performance Measures},
  volume = {56},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910008311},
  doi = {10.1016/j.neuroimage.2010.05.079},
  abstract = {Multi-voxel pattern analysis (MVPA) is proving very powerful in the analysis of fMRI timeseries data, yielding surprising sensitivity, in many different contexts, to the response characteristics of neurons in a given brain region. However, MVPA yields a metric (classification performance) that does not readily lend itself to quantitative comparisons across experimental conditions, brain regions or people. This is because performance is influenced by a number of factors other than the sensitivity of neurons to the experimental manipulation. One such factor that varies widely but has been largely ignored in MVPA studies is the amplitude of the response being decoded. In a noisy system, it is expected that measured classification performance will decline with declining response amplitude, even if the underlying neuronal specificity is constant. We document the relationship between response amplitude and classification performance in the context of orientation decoding in the visual cortex. Flickering sine gratings were presented at each of two orthogonal orientations in a block design (multivariate experiment) or an event-related design (univariate experiment). Response amplitude was manipulated by varying stimulus contrast. Orientation classification performance in retinotopically defined occipital area V1 increased approximately linearly with the logarithm of stimulus contrast. As expected, univariate response amplitude also increased with contrast. Similar results were obtained in V2, V3 and V3A. Plotting classification performance against response amplitude gave a function with a compressive non-linearity that was well fit by a power function. Knowledge of this function potentially allows adjustment of classification performance to take account of the effect of response size, making comparisons across brain areas, categories or people more meaningful.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-05},
  pages = {525-530},
  author = {Smith, A.T. and Kosillo, P. and Williams, A.L.},
  file = {/Users/qualia/Documents/Papers/2011 - Smith, Kosillo, Williams - The confounding effect of response amplitude on MVPA performance measures.pdf}
}

@article{Solari2011,
  langid = {english},
  title = {Cognitive Consilience: {{Primate}} Non-Primary Neuroanatomical Circuits Underlying Cognition},
  issn = {16625129},
  url = {http://journal.frontiersin.org/article/10.3389/fnana.2011.00065/abstract},
  doi = {10.3389/fnana.2011.00065},
  shorttitle = {Cognitive Consilience},
  abstract = {Interactions between the cerebral cortex, thalamus, and basal ganglia form the basis of cognitive information processing in the mammalian brain. Understanding the principles of neuroanatomical organization in these structures is critical to understanding the functions they perform and ultimately how the human brain works. We have manually distilled and synthesized hundreds of primate neuroanatomy facts into a single interactive visualization. The resulting picture represents the fundamental neuroanatomical blueprint upon which cognitive functions must be implemented. Within this framework we hypothesize and detail 7 functional circuits corresponding to psychological perspectives on the brain: consolidated long-term declarative memory, short-term declarative memory, working memory/information processing, behavioral memory selection, behavioral memory output, cognitive control, and cortical information flow regulation. Each circuit is described in terms of distinguishable neuronal groups including the cerebral isocortex (9 pyramidal neuronal groups), parahippocampal gyrus and hippocampus, thalamus (4 neuronal groups), basal ganglia (7 neuronal groups), metencephalon, basal forebrain, and other subcortical nuclei. We focus on neuroanatomy related to primate nonprimary cortical systems to elucidate the basis underlying the distinct homotypical cognitive architecture. To display the breadth of this review, we introduce a novel method of integrating and presenting data in multiple independent visualizations: an interactive website (http://www.frontiersin.org/files/cognitiveconsilience/index.html) and standalone iPhone and iPad applications. With these tools we present a unique, annotated view of neuroanatomical consilience (integration of knowledge).},
  journaltitle = {Frontiers in Neuroanatomy},
  urldate = {2019-03-30},
  date = {2011},
  author = {{Solari}},
  file = {/Users/qualia/Documents/Papers/2011 - Solari, Stoner - Cognitive consilience primate non-primary neuroanatomical circuits underlying cognition.pdf}
}

@book{Spiegler2012,
  langid = {english},
  location = {{Ilmenau}},
  title = {Dynamics of Biologically Informed Neurals Mass Models of the Brain},
  isbn = {978-3-86360-024-2},
  abstract = {Die vorliegende Arbeit stellt einen Beitrag zur Entwicklung und Analyse von Computermodellen zum Verst\"andnis von Hirnfunktionen dar. Es wird die mittlere Aktivit\"at eines Hirnareals analytisch einfach und dabei biologisch plausibel modelliert. Auf Grundlage eines Neuronalen Massenmodells (NMM) werden die Wechsel zwischen Oszillationsregimen (z.B. durch pharmakologisch, epilepsie-, schlaf- oder kontextbedingte Zustands\"anderungen) als geordnete Folge beschrieben und Resonanzph\"anomene in einem Photic-Driving-Experiment erkl\"art. Dieses NMM kann sehr komplexe Dynamiken (z.B. Chaos) innerhalb biologisch plausibler Parameterbereiche hervorbringen. Um das Verhalten abzusch\"atzen, wird das NMM als Funktion konstanter Eingangsgr\"o\ss{}en und charakteristischer Zeitenkonstanten vollst\"andig auf Bifurkationen untersucht und klassifiziert. Dies erm\"oglicht die Beschreibung wechselnder Regime als geordnete Folge durch spezifische Eingangstrajektorien. Es wird ein Prinzip vorgestellt, um komplexe Ph\"anomene durch Prozesse verschiedener Zeitskalen darzustellen. Da aufgrund rhythmischer Stimuli und der intrinsischen Rhythmen von Neuronenverb\"anden die Eingangsgr\"o\ss{}en h\"aufig periodisch sind, wird das Verhalten des NMM als Funktion der Intensit\"at und Frequenz einer periodischen Stimulation mittels der zugeh\"origen Lyapunov-Spektren und der Zeitreihen charakterisiert. Auf der Basis der gr\"o\ss{}ten Lyapunov-Exponenten wird das NMM mit dem Photic-Driving-Experiment \"uberein gebracht. Dieses Experiment findet routinem\"a\ss{}ige Anwendung in der Diagnostik verschiedener Erkrankungen wie Epilepsie, Migr\"ane, Schizophrenie und Depression. Durch die Anwendung des vorgestellten NMM wird der f\"ur die Diagnostik entscheidende Mitnahmeeffekt reproduziert und es werden Vorhersagen f\"ur eine Verbesserung der Indikation getroffen},
  pagetotal = {193},
  publisher = {{Univ.-Verl. Ilmenau}},
  date = {2012},
  author = {Spiegler, Andreas and Haueisen, Jens and Kn\"osche, Thomas R. and Jirsa, Viktor K.},
  file = {/Users/qualia/Documents/Papers/2011 - Spiegler - Dynamics of biologically informed neural mass models of the brain.pdf},
  note = {OCLC: 855873253}
}

@article{Sun2011,
  langid = {english},
  title = {Gamma Oscillations in Schizophrenia: {{Mechanisms}} and Clinical Significance},
  volume = {1413},
  issn = {00068993},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0006899311012364},
  doi = {10.1016/j.brainres.2011.06.065},
  shorttitle = {Gamma Oscillations in Schizophrenia},
  abstract = {Brain oscillations are increasingly used for understanding complex psychiatric disorders. Gamma (30\textendash{}50 Hz) oscillations have warranted special attention due to their omnipresence in cognitive tasks. For patients with schizophrenia (SCZ), a disease associated with poor cognition, abnormal gamma oscillations have been reported in many experimental paradigms. The goal of this paper is to review the literature on gamma oscillations in SCZ. The review is structured into four sections. First, the functional role, neurobiology, and analysis of brain oscillations, especially gamma oscillations will be outlined. Second, the neurobiological abnormalities of SCZ in relation to gamma oscillations will be reviewed. Third, selected paradigms for investigating irregular gamma oscillations in SCZ will be discussed in detail. Finally, a discussion on the limitations of current findings and potential future research directions will be provided. The reviewed evidence suggests that gamma oscillations are disrupted in SCZ and could account for cognitive disturbances in this disorder. With additional analysis and experimentation, these indices may ultimately serve as endophenotypes that facilitate the development of etiologically based diagnostic methods, foster early identification and treatment, and advance our understanding of the complex genetic mechanisms involved in this disorder.},
  journaltitle = {Brain Research},
  urldate = {2019-03-30},
  date = {2011-09},
  pages = {98-114},
  author = {Sun, Yinming and Farzan, Faranak and Barr, Mera S. and Kirihara, Kenji and Fitzgerald, Paul B. and Light, Gregory A. and Daskalakis, Zafiris J.},
  file = {/Users/qualia/Documents/Papers/2011 - Sun et al. - Gamma oscillations in schizophrenia Mechanisms and clinical significance.pdf}
}

@article{Tachibana2011,
  langid = {english},
  title = {Subthalamo-Pallidal Interactions Underlying Parkinsonian Neuronal Oscillations in the Primate Basal Ganglia: {{BG}} Oscillations in {{Parkinson}}'s Disease},
  volume = {34},
  issn = {0953816X},
  url = {http://doi.wiley.com/10.1111/j.1460-9568.2011.07865.x},
  doi = {10.1111/j.1460-9568.2011.07865.x},
  shorttitle = {Subthalamo-Pallidal Interactions Underlying Parkinsonian Neuronal Oscillations in the Primate Basal Ganglia},
  abstract = {Parkinson's disease is characterized by degeneration of nigral dopaminergic neurons, leading to a wide variety of psychomotor dysfunctions. Accumulated evidence suggests that abnormally synchronized oscillations in the basal ganglia contribute to the expression of parkinsonian motor symptoms. However, the mechanism that generates abnormal oscillations in a dopamine-depleted state remains poorly understood. We addressed this question by examining basal ganglia neuronal activity in two 1-methyl-4-phenyl1,2,3,6-tetrahydropyridine-treated parkinsonian monkeys. We found that systemic administration of l-3,4-dihydroxyphenylalanine (l-DOPA; dopamine precursor) decreased abnormal neuronal oscillations (8\textendash{}15 Hz) in the internal segment of the globus pallidus (GPi) and the subthalamic nucleus (STN) during the ON state when parkinsonian signs were alleviated and during l-DOPA-induced dyskinesia. GPi oscillations and parkinsonian signs were suppressed by silencing of the STN with infusion of muscimol (GABAA receptor agonist). Intrapallidal microinjection of a mixture of 3-(2-carboxypiperazin-4-yl)-propyl-1-phosphonic acid (CPP; N-methyl-daspartate receptor antagonist) and 1,2,3,4-tetrahydro-6-nitro-2,3-dioxo-benzo[f]quinoxaline-7-sulfonamide (NBQX; AMPA {$\fracslash$} kainate receptor antagonist) also decreased the oscillations in the GPi and the external segment of the globus pallidus (GPe). Neuronal oscillations in the STN were suppressed after intrasubthalamic microinjection of CPP {$\fracslash$} NBQX to block glutamatergic afferents of the STN. The STN oscillations were further reduced by muscimol inactivation of the GPe to block GABAergic inputs from the GPe. These results suggest that, in the dopamine-depleted state, glutamatergic inputs to the STN and reciprocal GPe\textendash{}STN interconnections are both important for the generation and amplification of the oscillatory activity of STN neurons, which is subsequently transmitted to the GPi, thus contributing to the symptomatic expression of Parkinson's disease.},
  number = {9},
  journaltitle = {European Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2011-11},
  pages = {1470-1484},
  author = {Tachibana, Yoshihisa and Iwamuro, Hirokazu and Kita, Hitoshi and Takada, Masahiko and Nambu, Atsushi},
  file = {/Users/qualia/Documents/Papers/2011 - Tachibana et al. - Subthalamo-pallidal interactions underlying parkinsonian neuronal oscillations in the primate basal ganglia.pdf}
}

@article{Toth2011,
  langid = {english},
  title = {Dynamical Estimation of Neuron and Network Properties {{I}}: Variational Methods},
  volume = {105},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-011-0459-1},
  doi = {10.1007/s00422-011-0459-1},
  shorttitle = {Dynamical Estimation of Neuron and Network Properties {{I}}},
  number = {3-4},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2011-10},
  pages = {217-237},
  author = {Toth, Bryan A. and Kostuk, Mark and Meliza, C. Daniel and Margoliash, Daniel and Abarbanel, Henry D. I.},
  file = {/Users/qualia/Documents/Papers/2011 - Toth et al. - Dynamical estimation of neuron and network properties I Variational methods.pdf}
}

@article{Touboul2011,
  langid = {english},
  title = {Finite-Size and Correlation-Induced Effects in Mean-Field Dynamics},
  volume = {31},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-011-0320-5},
  doi = {10.1007/s10827-011-0320-5},
  number = {3},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2011-11},
  pages = {453-484},
  author = {Touboul, Jonathan D. and Ermentrout, G. Bard},
  file = {/Users/qualia/Documents/Papers/2011 - Touboul, Ermentrout - Finite-size and correlation-induced effects in mean-field dynamics(2).pdf}
}

@article{Toyoizumi2011,
  langid = {english},
  title = {Beyond the Edge of Chaos: {{Amplification}} and Temporal Integration by Recurrent Networks in the Chaotic Regime},
  volume = {84},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.84.051908},
  doi = {10.1103/PhysRevE.84.051908},
  shorttitle = {Beyond the Edge of Chaos},
  number = {5},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2011-11-14},
  author = {Toyoizumi, T. and Abbott, L. F.},
  file = {/Users/qualia/Documents/Papers/2011 - Toyoizumi, Abbott - Beyond the edge of chaos Amplification and temporal integration by recurrent networks in the chaotic regime.pdf}
}

@article{Watanabe2011,
  langid = {english},
  title = {Prediction of Subsequent Recognition Performance Using Brain Activity in the Medial Temporal Lobe},
  volume = {54},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910013595},
  doi = {10.1016/j.neuroimage.2010.10.066},
  abstract = {Application of multivoxel pattern analysis (MVPA) to functional magnetic resonance imaging (fMRI) data enables reconstruction and classification of cognitive status from brain activity. However, previous studies using MVPA have extracted information about cognitive status that is experienced simultaneously with fMRI scanning, but not one that will be observed after the scanning. In this study, by focusing on activity in the medial temporal lobe (MTL), we demonstrate that MVPA on fMRI data is capable of predicting subsequent recognition performance. In this experiment, six runs of fMRI signals were acquired during encoding of phonogram stimuli. In the analysis, using data acquired in runs 1\textendash{}3, we first conducted MVPA-based voxelwise search for the clusters in the MTL whose signals contained the most information about subsequent recognition performance. Next, using the fMRI signals acquired in runs 1\textendash{}3 from the selected clusters, we trained a classifier function in MVPA. Finally, the trained classifier function was applied to fMRI signals acquired in runs 4\textendash{}6. Consequently, we succeeded in predicting the subsequent recognition performance for stimuli studied in runs 4\textendash{}6 with significant accuracy. This accurate prediction suggests that MVPA can extract information that is associated not only with concurrent cognitive status, but also with behavior in the near future.},
  number = {4},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-02},
  pages = {3085-3092},
  author = {Watanabe, Takamitsu and Hirose, Satoshi and Wada, Hiroyuki and Katsura, Masaki and Chikazoe, Junichi and Jimura, Koji and Imai, Yoshio and Machida, Toru and Shirouzu, Ichiro and Miyashita, Yasushi and Konishi, Seiki},
  file = {/Users/qualia/Documents/Papers/2011 - Watanabe et al. - Prediction of subsequent recognition performance using brain activity in the medial temporal lobe.pdf}
}

@article{Whitten2011,
  langid = {english},
  title = {A Better Oscillation Detection Method Robustly Extracts {{EEG}} Rhythms across Brain State Changes: {{The}} Human Alpha Rhythm as a Test Case},
  volume = {54},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910011614},
  doi = {10.1016/j.neuroimage.2010.08.064},
  shorttitle = {A Better Oscillation Detection Method Robustly Extracts {{EEG}} Rhythms across Brain State Changes},
  abstract = {Oscillatory activity is a principal mode of operation in the brain. Despite an intense resurgence of interest in the mechanisms and functions of brain rhythms, methods for the detection and analysis of oscillatory activity in neurophysiological recordings are still highly variable across studies. We recently proposed a method for detecting oscillatory activity from time series data, which we call the BOSC (Better OSCillation detection) method. This method produces systematic, objective, and consistent results across frequencies, brain regions and tasks. It does so by modeling the functional form of the background spectrum by fitting the empirically observed spectrum at the recording site. This minimizes bias in oscillation detection across frequency, region and task. Here we show that the method is also robust to dramatic changes in state that are known to influence the shape of the power spectrum, namely, the presence versus absence of the alpha rhythm, and can be applied to independent components, which are thought to reflect underlying sources, in addition to individual raw signals. This suggests that the BOSC method is an effective tool for measuring changes in rhythmic activity in the more common research scenario wherein state is unknown.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-01},
  pages = {860-874},
  author = {Whitten, Tara A. and Hughes, Adam M. and Dickson, Clayton T. and Caplan, Jeremy B.},
  file = {/Users/qualia/Documents/Papers/2011 - Whitten et al. - A better oscillation detection method robustly extracts EEG rhythms across brain state changes The human alpha r.pdf}
}

@article{Wongsarnpigoon2010a,
  langid = {english},
  title = {Energy-Efficient Waveform Shapes for Neural Stimulation Revealed with a Genetic Algorithm},
  volume = {7},
  issn = {1741-2560, 1741-2552},
  url = {http://stacks.iop.org/1741-2552/7/i=4/a=046009?key=crossref.b2a503428f3820e6d26994c496acc3d4},
  doi = {10.1088/1741-2560/7/4/046009},
  abstract = {The energy efficiency of stimulation is an important consideration for battery-powered implantable stimulators. We used a genetic algorithm (GA) to determine the energy-optimal waveform shape for neural stimulation. The GA was coupled to a computational model of extracellular stimulation of a mammalian myelinated axon. As the GA progressed, waveforms became increasingly energy-efficient and converged upon an energy-optimal shape. The results of the GA were consistent across several trials, and resulting waveforms resembled truncated Gaussian curves. When constrained to monophasic cathodic waveforms, the GA produced waveforms that were symmetric about the peak, which occurred approximately during the middle of the pulse. However, when the cathodic waveforms were coupled to rectangular chargebalancing anodic pulses, the location and sharpness of the peak varied with the duration and timing (i.e., before or after cathodic phase) of the anodic phase. In a model of a population of mammalian axons and in vivo experiments on cat sciatic nerve, the GA-optimized waveforms were more energy-efficient and charge-efficient than several conventional waveform shapes used in neural stimulation. If used in implantable neural stimulators, GA-optimized waveforms could prolong battery life, thereby reducing the frequency of recharge intervals, the volume of implanted pulse generators, and the costs and risks of battery-replacement surgeries.},
  number = {4},
  journaltitle = {Journal of Neural Engineering},
  urldate = {2019-03-30},
  date = {2010-08-01},
  pages = {046009},
  author = {Wongsarnpigoon, Amorn and Grill, Warren M},
  file = {/Users/qualia/Documents/Papers/2011 - Wongsarnpigoon, Grill - Energy-efficient waveform shapes for neural stimulation revealed with genetic algorithm.pdf}
}

@article{Ayaz2009,
  langid = {english},
  title = {Gain {{Modulation}} of {{Neuronal Responses}} by {{Subtractive}} and {{Divisive Mechanisms}} of {{Inhibition}}},
  volume = {101},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.90547.2008},
  doi = {10.1152/jn.90547.2008},
  number = {2},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2009-02},
  pages = {958-968},
  author = {Ayaz, Asli and Chance, Frances S.},
  file = {/Users/qualia/Documents/Papers/2012 - Ayaz, Chance - Gain Modulation of Neuronal Responses by Subtractive and Divisive Mechanisms of Inhibition Gain Modulation of Neur.pdf}
}

@article{Badre2012,
  langid = {english},
  title = {Mechanisms of {{Hierarchical Reinforcement Learning}} in {{Cortico}}-{{Striatal Circuits}} 2: {{Evidence}} from {{fMRI}}},
  volume = {22},
  issn = {1047-3211, 1460-2199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhr117},
  doi = {10.1093/cercor/bhr117},
  shorttitle = {Mechanisms of {{Hierarchical Reinforcement Learning}} in {{Cortico}}-{{Striatal Circuits}} 2},
  abstract = {The frontal lobes may be organized hierarchically such that more rostral frontal regions modulate cognitive control operations in caudal regions. In our companion paper (Frank MJ, Badre D. 2011. Mechanisms of hierarchical reinforcement learning in corticostriatal circuits I: computational analysis. 22:509--526), we provide novel neural circuit and algorithmic models of hierarchical cognitive control in cortico--striatal circuits. Here, we test key model predictions using functional magnetic resonance imaging (fMRI). Our neural circuit model proposes that contextual representations in rostral frontal cortex influence the striatal gating of contextual representations in caudal frontal cortex. Reinforcement learning operates at each level, such that the system adaptively learns to gate higher order contextual information into rostral regions. Our algorithmic Bayesian ``mixture of experts'' model captures the key computations of this neural model and provides trial-by-trial estimates of the learner's latent hypothesis states. In the present paper, we used these quantitative estimates to reanalyze fMRI data from a hierarchical reinforcement learning task reported in Badre D, Kayser AS, D'Esposito M. 2010. Frontal cortex and the discovery of abstract action rules. Neuron. 66:315\textendash{}326. Results validate key predictions of the models and provide evidence for an individual cortico--striatal circuit for reinforcement learning of hierarchical structure at a specific level of policy abstraction. These findings are initially consistent with the proposal that hierarchical control in frontal cortex may emerge from interactions among nested cortico--striatal circuits at different levels of abstraction.},
  number = {3},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2012-03-01},
  pages = {527-536},
  author = {Badre, D. and Frank, M. J.},
  file = {/Users/qualia/Documents/Papers/2012 - Badre, Frank - Mechanisms of hierarchical reinforcement learning in cortico-striatal circuits 2 Evidence from fMRI.pdf}
}

@article{Bakhtin2012,
  langid = {english},
  title = {A Neural Computation Model for Decision-Making Times},
  volume = {56},
  issn = {00222496},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S002224961200051X},
  doi = {10.1016/j.jmp.2012.05.005},
  abstract = {We introduce two new models for decision-making times for a two-choice decision task with no a priori bias. One of the models is the mean-field Curie\textendash{}Weiss model of neural computation, and the other is based on dynamics near an unstable equilibrium under a small noise perturbation. As in the existing literature, we interpret exit times as reaction times and show that our models lead to a specific shape of the exit time distributions in the vanishing noise limit. We test the distribution shape against experimental data and show that for almost 90\% of the participants, reaction times are described well by the model. Among the features of our model are: the dependence of the exit distribution only on two parameters, the elegance of rigorous mathematical analysis, and the microscopic nature of the noise.},
  number = {5},
  journaltitle = {Journal of Mathematical Psychology},
  urldate = {2019-03-30},
  date = {2012-10},
  pages = {333-340},
  author = {Bakhtin, Yuri and Correll, Joshua},
  file = {/Users/qualia/Documents/Papers/2012 - Bakhtin, Correll - A neural computation model for decision-making times.pdf}
}

@article{Baladron2012,
  langid = {english},
  title = {Mean-Field Description and Propagation of Chaos in Networks of {{Hodgkin}}-{{Huxley}} and {{FitzHugh}}-{{Nagumo}} Neurons},
  volume = {2},
  issn = {2190-8567},
  url = {http://mathematical-neuroscience.springeropen.com/articles/10.1186/2190-8567-2-10},
  doi = {10.1186/2190-8567-2-10},
  number = {1},
  journaltitle = {The Journal of Mathematical Neuroscience},
  urldate = {2019-03-30},
  date = {2012},
  pages = {10},
  author = {Baladron, Javier and Fasoli, Diego and Faugeras, Olivier and Touboul, Jonathan},
  file = {/Users/qualia/Documents/Papers/2012 - Baladron et al. - Mean-field description and propagation of chaos in networks of Hodgkin-Huxley and FitzHugh-Nagumo neurons.pdf}
}

@article{Barth2012,
  langid = {english},
  title = {Experimental Evidence for Sparse Firing in the Neocortex},
  volume = {35},
  issn = {01662236},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223612000513},
  doi = {10.1016/j.tins.2012.03.008},
  number = {6},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {2012-06},
  pages = {345-355},
  author = {Barth, Alison L. and Poulet, James F.A.},
  file = {/Users/qualia/Documents/Papers/2012 - Barth, Poulet - Experimental evidence for sparse firing in the neocortex.pdf}
}

@article{Ben-Yakov2012,
  langid = {english},
  title = {Loss of Reliable Temporal Structure in Event-Related Averaging of Naturalistic Stimuli},
  volume = {63},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811912007185},
  doi = {10.1016/j.neuroimage.2012.07.008},
  abstract = {To separate neural signals from noise, brain responses measured in neuroimaging are routinely averaged across space and time. However, such procedures may obscure some properties of neural activity. Recently, multi-voxel pattern analysis methods have demonstrated that patterns of activity across voxels contain valuable information that is concealed by spatial averaging. Here we show that temporal patterns of neural activity contain information that can discriminate different stimuli, even within brain regions that show no net activation to that stimulus class. Furthermore, we find that in many brain regions, responses to natural stimuli are highly context dependent. In such cases, prototypical event-related responses do not even exist for individual stimuli, so that averaging responses to the same stimulus within different contexts may worsen the effective signal-to-noise. As a result, analysis of the temporal structures of single events can reveal aspects of neural dynamics which cannot be detected using standard event-related averaging methods.},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2012-10},
  pages = {501-506},
  author = {Ben-Yakov, Aya and Honey, Christopher J. and Lerner, Yulia and Hasson, Uri},
  file = {/Users/qualia/Documents/Papers/2012 - Ben-Yakov et al. - Loss of reliable temporal structure in event-related averaging of naturalistic stimuli.pdf}
}

@article{Bonnefond2012,
  langid = {english},
  title = {Alpha {{Oscillations Serve}} to {{Protect Working Memory Maintenance}} against {{Anticipated Distracters}}},
  volume = {22},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982212009943},
  doi = {10.1016/j.cub.2012.08.029},
  abstract = {When operating in a complex world, it is essential to have mechanisms that can suppress distracting information [1, 2]. Such mechanisms might be related to neuronal oscillations, which are known to be involved in gating of incoming information [3]. We here apply a working memory (WM) task to investigate how neuronal oscillations are involved in the suppression of distracting information that can be predicted in time. We used a modified Sternberg WM task in which distracters were presented in the retention interval, while we recorded the ongoing brain activity using magnetoencephalography. The data revealed a robust adjustment of the phase of alpha oscillations in anticipation of the distracter. In trials with strong phase adjustment, response times to the memory probe were reduced. Further, the power of alpha oscillations increased prior to the distracter and predicted performance. Our findings demonstrate that the doors of perception close when a distracter is expected. The phase adjustment of the alpha rhythm adds to the computational versatility of brain oscillations, because such a mechanism allows for modulating neuronal processing on a fine temporal scale.},
  number = {20},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2012-10},
  pages = {1969-1974},
  author = {Bonnefond, Mathilde and Jensen, Ole},
  file = {/Users/qualia/Documents/Papers/2012 - Bonnefond, Jensen - Alpha oscillations serve to protect working memory maintenance against anticipated distracters.pdf}
}

@article{Buzsaki2012,
  langid = {english},
  title = {The Origin of Extracellular Fields and Currents \textemdash{} {{EEG}}, {{ECoG}}, {{LFP}} and Spikes},
  volume = {13},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn3241},
  doi = {10.1038/nrn3241},
  abstract = {Neuronal activity in the brain gives rise to transmembrane currents that can be measured in the extracellular medium. Although the major contributor of the extracellular signal is the synaptic transmembrane current, other sources \textemdash{} including Na+ and Ca2+ spikes, ionic fluxes through voltage- and ligand-gated channels, and intrinsic membrane oscillations \textemdash{} can substantially shape the extracellular field. High-density recordings of field activity in animals and subdural grid recordings in humans, combined with recently developed data processing tools and computational modelling, can provide insight into the cooperative behaviour of neurons, their average synaptic input and their spiking output, and can increase our understanding of how these processes contribute to the extracellular signal.},
  number = {6},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2012-06},
  pages = {407-420},
  author = {Buzs\'aki, Gy\"orgy and Anastassiou, Costas A. and Koch, Christof},
  file = {/Users/qualia/Documents/Papers/2012 - Buzsáki, Anastassiou, Koch - The origin of extracellular fields and currents--EEG, ECoG, LFP and spikes.pdf}
}

@article{Chambers2012,
  langid = {english},
  title = {Parametric Computation Predicts a Multiplicative Interaction between Synaptic Strength Parameters That Control Gamma Oscillations},
  volume = {6},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2012.00053/abstract},
  doi = {10.3389/fncom.2012.00053},
  abstract = {Gamma oscillations are thought to be critical for a number of behavioral functions, they occur in many regions of the brain and through a variety of mechanisms. Fast repetitive bursting (FRB) neurons in layer 2 of the cortex are able to drive gamma oscillations over long periods of time. Even though the oscillation is driven by FRB neurons, strong feedback within the rest of the cortex must modulate properties of the oscillation such as frequency and power. We used a highly detailed model of the cortex to determine how a cohort of 33 parameters controlling synaptic drive might modulate gamma oscillation properties. We were interested in determining not just the effects of parameters individually, but we also wanted to reveal interactions between parameters beyond additive effects. To prevent a combinatorial explosion in parameter combinations that might need to be simulated, we used a fractional factorial design (FFD) that estimated the effects of individual parameters and two parameter interactions. This experiment required only 4096 model runs. We found that the largest effects on both gamma power and frequency came from a complex interaction between efficacy of synaptic connections from layer 2 inhibitory neurons to layer 2 excitatory neurons and the parameter for the reciprocal connection. As well as the effect of the individual parameters determining synaptic efficacy, there was an interaction between these parameters beyond the additive effects of the parameters alone. The magnitude of this effect was similar to that of the individual parameters, predicting that it is physiologically important in setting gamma oscillation properties.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2012},
  author = {Chambers, Jordan D. and Bethwaite, Blair and Diamond, Neil T. and Peachey, Tom and Abramson, David and Petrou, Steve and Thomas, Evan A.},
  file = {/Users/qualia/Documents/Papers/2012 - Chambers et al. - Parametric computation predicts a multiplicative interaction between synaptic strength parameters that control.pdf}
}

@article{Chaturvedi2012,
  langid = {english},
  title = {Current Steering to Activate Targeted Neural Pathways during Deep Brain Stimulation of the Subthalamic Region},
  volume = {5},
  issn = {1935861X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1935861X11000672},
  doi = {10.1016/j.brs.2011.05.002},
  number = {3},
  journaltitle = {Brain Stimulation},
  urldate = {2019-03-30},
  date = {2012-07},
  pages = {369-377},
  author = {Chaturvedi, Ashutosh and Foutz, Thomas J. and McIntyre, Cameron C.},
  file = {/Users/qualia/Documents/Papers/2012 - Chaturvedi, Foutz, McIntyre - Current steering to activate targeted neural pathways during deep brain stimulation of the subthala.pdf}
}

@article{Churchland2012,
  langid = {english},
  title = {Neural Population Dynamics during Reaching},
  volume = {487},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature11129},
  doi = {10.1038/nature11129},
  number = {7405},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2012-07},
  pages = {51-56},
  author = {Churchland, Mark M. and Cunningham, John P. and Kaufman, Matthew T. and Foster, Justin D. and Nuyujukian, Paul and Ryu, Stephen I. and Shenoy, Krishna V.},
  file = {/Users/qualia/Documents/Papers/2012 - Churchland et al. - Neural population dynamics during reaching.pdf}
}

@article{Churchland2012a,
  langid = {english},
  title = {Two Layers of Neural Variability},
  volume = {15},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3247},
  doi = {10.1038/nn.3247},
  number = {11},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2012-11},
  pages = {1472-1474},
  author = {Churchland, Mark M and Abbott, L F},
  file = {/Users/qualia/Documents/Papers/2012 - Churchland, Abbott - Two layers of neural variability(2).pdf}
}

@article{Connolly2012,
  langid = {english},
  title = {The {{Representation}} of {{Biological Classes}} in the {{Human Brain}}},
  volume = {32},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5547-11.2012},
  doi = {10.1523/JNEUROSCI.5547-11.2012},
  number = {8},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2012-02-22},
  pages = {2608-2618},
  author = {Connolly, A. C. and Guntupalli, J. S. and Gors, J. and Hanke, M. and Halchenko, Y. O. and Wu, Y.-C. and Abdi, H. and Haxby, J. V.},
  file = {/Users/qualia/Documents/Papers/2012 - Connolly et al. - The representation of biological classes in the human brain.pdf}
}

@article{Degris2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1205.4839},
  primaryClass = {cs},
  langid = {english},
  title = {Off-{{Policy Actor}}-{{Critic}}},
  url = {http://arxiv.org/abs/1205.4839},
  abstract = {This paper presents the first actor-critic algorithm for off-policy reinforcement learning. Our algorithm is online and incremental, and its per-time-step complexity scales linearly with the number of learned weights. Previous work on actor-critic algorithms is limited to the on-policy setting and does not take advantage of the recent advances in offpolicy gradient temporal-difference learning. Off-policy techniques, such as Greedy-GQ, enable a target policy to be learned while following and obtaining data from another (behavior) policy. For many problems, however, actor-critic methods are more practical than action value methods (like Greedy-GQ) because they explicitly represent the policy; consequently, the policy can be stochastic and utilize a large action space. In this paper, we illustrate how to practically combine the generality and learning potential of off-policy learning with the flexibility in action selection given by actor-critic methods. We derive an incremental, linear time and space complexity algorithm that includes eligibility traces, prove convergence under assumptions similar to previous off-policy algorithms1, and empirically show better or comparable performance to existing algorithms on standard reinforcement-learning benchmark problems.},
  urldate = {2019-03-30},
  date = {2012-05-22},
  keywords = {Computer Science - Machine Learning},
  author = {Degris, Thomas and White, Martha and Sutton, Richard S.},
  file = {/Users/qualia/Documents/Papers/2012 - Degris, White, Sutton - Off-Policy Actor-Critic.pdf}
}

@article{Druckmann2012,
  langid = {english},
  title = {Neuronal {{Circuits Underlying Persistent Representations Despite Time Varying Activity}}},
  volume = {22},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982212010810},
  doi = {10.1016/j.cub.2012.08.058},
  abstract = {Background: Our brains are capable of remarkably stable stimulus representations despite time-varying neural activity. For instance, during delay periods in working memory tasks, while stimuli are represented in working memory, neurons in the prefrontal cortex, thought to support the memory representation, exhibit time-varying neuronal activity. Since neuronal activity encodes the stimulus, its time-varying dynamics appears to be paradoxical and incompatible with stable network stimulus representations. Indeed, this finding raises a fundamental question: can stable representations only be encoded with stable neural activity, or, its corollary, is every change in activity a sign of change in stimulus representation?
Results: Here we explain how different time-varying representations offered by individual neurons can be woven together to form a coherent, time-invariant, representation. Motivated by two ubiquitous features of the neocortex\textemdash{}redundancy of neural representation and sparse intracortical connections\textemdash{}we derive a network architecture that resolves the apparent contradiction between representation stability and changing neural activity. Unexpectedly, this network architecture exhibits many structural properties that have been measured in cortical sensory areas. In particular, we can account for few-neuron motifs, synapse weight distribution, and the relations between neuronal functional properties and connection probability.
Conclusions: We show that the intuition regarding network stimulus representation, typically derived from considering single neurons, may be misleading and that time-varying activity of distributed representation in cortical circuits does not necessarily imply that the network explicitly encodes time-varying properties.},
  number = {22},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2012-11},
  pages = {2095-2103},
  author = {Druckmann, Shaul and Chklovskii, Dmitri B.},
  file = {/Users/qualia/Documents/Papers/2012 - Druckmann, Chklovskii - Neuronal circuits underlying persistent representations despite time varying activity.pdf;/Users/qualia/Documents/Papers/2012 - Druckmann, Chklovskii - Neuronal circuits underlying persistent representations despite time varying activity(2).pdf}
}

@article{Giraud2012,
  langid = {english},
  title = {Cortical Oscillations and Speech Processing: Emerging Computational Principles and Operations},
  volume = {15},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3063},
  doi = {10.1038/nn.3063},
  shorttitle = {Cortical Oscillations and Speech Processing},
  number = {4},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2012-04},
  pages = {511-517},
  author = {Giraud, Anne-Lise and Poeppel, David},
  file = {/Users/qualia/Documents/Papers/2012 - Giraud, Poeppel - Cortical oscillations and speech processing emerging computational principles and operations.pdf}
}

@article{Gluth2012,
  langid = {english},
  title = {Deciding {{When}} to {{Decide}}: {{Time}}-{{Variant Sequential Sampling Models Explain}} the {{Emergence}} of {{Value}}-{{Based Decisions}} in the {{Human Brain}}},
  volume = {32},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0727-12.2012},
  doi = {10.1523/JNEUROSCI.0727-12.2012},
  shorttitle = {Deciding {{When}} to {{Decide}}},
  number = {31},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2012-08-01},
  pages = {10686-10698},
  author = {Gluth, S. and Rieskamp, J. and Buchel, C.},
  file = {/Users/qualia/Documents/Papers/2012 - Gluth, Rieskamp, Büchel - Deciding when to decide time-variant sequential sampling models explain the emergence of value-based d.pdf}
}

@article{Hertag2012,
  langid = {english},
  title = {An {{Approximation}} to the {{Adaptive Exponential Integrate}}-and-{{Fire Neuron Model Allows Fast}} and {{Predictive Fitting}} to {{Physiological Data}}},
  volume = {6},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2012.00062/abstract},
  doi = {10.3389/fncom.2012.00062},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2012},
  author = {Hert\"ag, Loreen and Hass, Joachim and Golovko, Tatiana and Durstewitz, Daniel},
  file = {/Users/qualia/Documents/Papers/2012 - Hertäg et al. - An Approximation to the Adaptive Exponential Integrate-and-Fire Neuron Model Allows Fast and Predictive Fitting.pdf}
}

@article{Hong2012,
  langid = {english},
  title = {Mean-Field Behavior in Coupled Oscillators with Attractive and Repulsive Interactions},
  volume = {85},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.85.056210},
  doi = {10.1103/PhysRevE.85.056210},
  number = {5},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2012-05-23},
  author = {Hong, Hyunsuk and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/2012 - Hong, Strogatz - Mean-field behavior in coupled oscillators with attractive and repulsive interactions.pdf}
}

@article{Humphries2012,
  langid = {english},
  title = {Network Effects of Subthalamic Deep Brain Stimulation Drive a Unique Mixture of Responses in Basal Ganglia Output: {{STN DBS}} Causes Mix of Output Responses},
  volume = {36},
  issn = {0953816X},
  url = {http://doi.wiley.com/10.1111/j.1460-9568.2012.08085.x},
  doi = {10.1111/j.1460-9568.2012.08085.x},
  shorttitle = {Network Effects of Subthalamic Deep Brain Stimulation Drive a Unique Mixture of Responses in Basal Ganglia Output},
  abstract = {Deep brain stimulation (DBS) is a remarkably successful treatment for the motor symptoms of Parkinson's disease. High-frequency stimulation of the subthalamic nucleus (STN) within the basal ganglia is a main clinical target, but the physiological mechanisms of therapeutic STN DBS at the cellular and network level are unclear. We set out to begin to address the hypothesis that a mixture of responses in the basal ganglia output nuclei, combining regularized firing and inhibition, is a key contributor to the effectiveness of STN DBS. We used our computational model of the complete basal ganglia circuit to show how such a mixture of responses in basal ganglia output naturally arises from the network effects of STN DBS. We replicated the diversification of responses recorded in a primate STN DBS study to show that the model's predicted mixture of responses is consistent with therapeutic STN DBS. We then showed how this `mixture of response' perspective suggests new ideas for DBS mechanisms: first, that the therapeutic frequency of STN DBS is above 100 Hz because the diversification of responses exhibits a step change above this frequency; and second, that optogenetic models of direct STN stimulation during DBS have proven therapeutically ineffective because they do not replicate the mixture of basal ganglia output responses evoked by electrical DBS.},
  number = {2},
  journaltitle = {European Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2012-07},
  pages = {2240-2251},
  author = {Humphries, Mark D. and Gurney, Kevin},
  file = {/Users/qualia/Documents/Papers/2012 - Humphries, Gurney - Network effects of subthalamic deep brain stimulation drive a unique mixture of responses in basal ganglia ou.pdf}
}

@article{Huth2012,
  langid = {english},
  title = {A {{Continuous Semantic Space Describes}} the {{Representation}} of {{Thousands}} of {{Object}} and {{Action Categories}} across the {{Human Brain}}},
  volume = {76},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627312009348},
  doi = {10.1016/j.neuron.2012.10.014},
  abstract = {Humans can see and name thousands of distinct object and action categories, so it is unlikely that each category is represented in a distinct brain area. A more efficient scheme would be to represent categories as locations in a continuous semantic space mapped smoothly across the cortical surface. To search for such a space, we used functional magnetic resonance imaging (fMRI) to measure human brain activity evoked by natural movies. We then used voxel-wise models to examine the cortical representation of 1705 object and action categories. The first few dimensions of the underlying semantic space were recovered from the fit models by principal components analysis. Projection of the recovered semantic space onto cortical flat maps shows that semantic selectivity is organized into smooth gradients that cover much of visual and nonvisual cortex. Furthermore, both the recovered semantic space and the cortical organization of the space are shared across different individuals.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2012-12},
  pages = {1210-1224},
  author = {Huth, Alexander G. and Nishimoto, Shinji and Vu, An T. and Gallant, Jack L.},
  file = {/Users/qualia/Documents/Papers/2012 - Huth et al. - A continuous semantic space describes the representation of thousands of object and action categories across the hu.pdf}
}

@article{Jadi2012,
  langid = {english},
  title = {Location-{{Dependent Effects}} of {{Inhibition}} on {{Local Spiking}} in {{Pyramidal Neuron Dendrites}}},
  volume = {8},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1002550},
  doi = {10.1371/journal.pcbi.1002550},
  abstract = {Cortical computations are critically dependent on interactions between pyramidal neurons (PNs) and a menagerie of inhibitory interneuron types. A key feature distinguishing interneuron types is the spatial distribution of their synaptic contacts onto PNs, but the location-dependent effects of inhibition are mostly unknown, especially under conditions involving active dendritic responses. We studied the effect of somatic vs. dendritic inhibition on local spike generation in basal dendrites of layer 5 PNs both in neocortical slices and in simple and detailed compartmental models, with equivalent results: somatic inhibition divisively suppressed the amplitude of dendritic spikes recorded at the soma while minimally affecting dendritic spike thresholds. In contrast, distal dendritic inhibition raised dendritic spike thresholds while minimally affecting their amplitudes. On-the-path dendritic inhibition modulated both the gain and threshold of dendritic spikes depending on its distance from the spike initiation zone. Our findings suggest that cortical circuits could assign different mixtures of gain vs. threshold inhibition to different neural pathways, and thus tailor their local computations, by managing their relative activation of soma- vs. dendrite-targeting interneurons.},
  number = {6},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2012-06-14},
  pages = {e1002550},
  author = {Jadi, Monika and Polsky, Alon and Schiller, Jackie and Mel, Bartlett W.},
  editor = {Gutkin, Boris S.},
  file = {/Users/qualia/Documents/Papers/2012 - Jadi et al. - Location-dependent effects of inhibition on local spiking in pyramidal neuron dendrites.pdf}
}

@article{Jimura2012,
  langid = {english},
  title = {Analyses of Regional-Average Activation and Multivoxel Pattern Information Tell Complementary Stories},
  volume = {50},
  issn = {00283932},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0028393211005070},
  doi = {10.1016/j.neuropsychologia.2011.11.007},
  abstract = {Multivariate pattern analysis (MVPA) has recently received increasing attention in functional neuroimaging due to its ability to decode mental states from fMRI signals. However, questions remain regarding both the empirical and conceptual relationships between results from MVPA and standard univariate analyses. In the current study, whole-brain univariate and searchlight MVPAs of parametric manipulations of monetary gain and loss in a decision making task (Tom et al., 2007) were compared to identify the differences in the results across these methods and the implications for understanding the underlying mental processes. The MVPA and univariate results did identify some overlapping regions in whole brain analyses. However, an analysis of consistency revealed that in many regions the effect size estimates obtained from MVPA and univariate analysis were uncorrelated. Moreover, comparison of sensitivity showed a general trend towards greater sensitivity to task manipulations by MVPA compared to univariate analysis. These results demonstrate that MVPA methods may provide a different view of the functional organization of mental processing compared to univariate analysis, wherein MVPA is more sensitive to distributed coding of information whereas univariate analysis is more sensitive to global engagement in ongoing tasks. The results also highlight the need for better ways to integrate these methods.},
  number = {4},
  journaltitle = {Neuropsychologia},
  urldate = {2019-03-30},
  date = {2012-03},
  pages = {544-552},
  author = {Jimura, Koji and Poldrack, Russell A.},
  file = {/Users/qualia/Documents/Papers/2012 - Jimura, Poldrack - Analyses of regional-average activation and multivoxel pattern information tell complementary stories.pdf}
}

@article{Kelly2012,
  langid = {english},
  title = {A {{Framework}} for {{Evaluating Pairwise}} and {{Multiway Synchrony Among Stimulus}}-{{Driven Neurons}}},
  volume = {24},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00307},
  doi = {10.1162/NECO_a_00307},
  number = {8},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2012-08},
  pages = {2007-2032},
  author = {Kelly, Ryan C. and Kass, Robert E.},
  file = {/Users/qualia/Documents/Papers/2012 - Kelly, Kass - A Framework for Evaluating Pairwise and Multiway Synchrony Among Stimulus-Driven Neurons.pdf}
}

@article{Klimesch2012,
  langid = {english},
  title = {Alpha-Band Oscillations, Attention, and Controlled Access to Stored Information},
  volume = {16},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661312002434},
  doi = {10.1016/j.tics.2012.10.007},
  number = {12},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2012-12},
  pages = {606-617},
  author = {Klimesch, Wolfgang},
  file = {/Users/qualia/Documents/Papers/2012 - Klimesch - Alpha-band oscillations, attention, and controlled access to stored information.pdf}
}

@article{Kostuk2012,
  langid = {english},
  title = {Dynamical Estimation of Neuron and Network Properties {{II}}: Path Integral {{Monte Carlo}} Methods},
  volume = {106},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-012-0487-5},
  doi = {10.1007/s00422-012-0487-5},
  shorttitle = {Dynamical Estimation of Neuron and Network Properties {{II}}},
  number = {3},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2012-03},
  pages = {155-167},
  author = {Kostuk, Mark and Toth, Bryan A. and Meliza, C. Daniel and Margoliash, Daniel and Abarbanel, Henry D. I.},
  file = {/Users/qualia/Documents/Papers/2012 - Kostuk et al. - Dynamical estimation of neuron and network properties II Path integral Monte Carlo methods.pdf}
}

@article{Lambert2012,
  langid = {english},
  title = {Confirmation of Functional Zones within the Human Subthalamic Nucleus: {{Patterns}} of Connectivity and Sub-Parcellation Using Diffusion Weighted Imaging},
  volume = {60},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811911013644},
  doi = {10.1016/j.neuroimage.2011.11.082},
  shorttitle = {Confirmation of Functional Zones within the Human Subthalamic Nucleus},
  abstract = {The subthalamic nucleus (STN) is a small, glutamatergic nucleus situated in the diencephalon. A critical component of normal motor function, it has become a key target for deep brain stimulation in the treatment of Parkinson's disease. Animal studies have demonstrated the existence of three functional sub-zones but these have never been shown conclusively in humans. In this work, a data driven method with diffusion weighted imaging demonstrated that three distinct clusters exist within the human STN based on brain connectivity profiles. The STN was successfully sub-parcellated into these regions, demonstrating good correspondence with that described in the animal literature. The local connectivity of each sub-region supported the hypothesis of bilateral limbic, associative and motor regions occupying the anterior, mid and posterior portions of the nucleus respectively. This study is the first to achieve in-vivo, non-invasive anatomical parcellation of the human STN into three anatomical zones within normal diagnostic scan times, which has important future implications for deep brain stimulation surgery.},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2012-03},
  pages = {83-94},
  author = {Lambert, Christian and Zrinzo, Ludvic and Nagy, Zoltan and Lutti, Antoine and Hariz, Marwan and Foltynie, Thomas and Draganski, Bogdan and Ashburner, John and Frackowiak, Richard},
  file = {/Users/qualia/Documents/Papers/2012 - Lambert et al. - Confirmation of functional zones within the human subthalamic nucleus Patterns of connectivity and sub-parcellat.pdf}
}

@article{Li2013,
  langid = {english},
  title = {Using a Million Cell Simulation of the Cerebellum: {{Network}} Scaling and Task Generality},
  volume = {47},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608012002821},
  doi = {10.1016/j.neunet.2012.11.005},
  shorttitle = {Using a Million Cell Simulation of the Cerebellum},
  abstract = {Several factors combine to make it feasible to build computer simulations of the cerebellum and to test them in biologically realistic ways. These simulations can be used to help understand the computational contributions of various cerebellar components, including the relevance of the enormous number of neurons in the granule cell layer. In previous work we have used a simulation containing 12000 granule cells to develop new predictions and to account for various aspects of eyelid conditioning, a form of motor learning mediated by the cerebellum. Here we demonstrate the feasibility of scaling up this simulation to over one million granule cells using parallel graphics processing unit (GPU) technology. We observe that this increase in number of granule cells requires only twice the execution time of the smaller simulation on the GPU. We demonstrate that this simulation, like its smaller predecessor, can emulate certain basic features of conditioned eyelid responses, with a slight improvement in performance in one measure. We also use this simulation to examine the generality of the computation properties that we have derived from studying eyelid conditioning. We demonstrate that this scaled up simulation can learn a high level of performance in a classic machine learning task, the cart\textendash{}pole balancing task. These results suggest that this parallel GPU technology can be used to build very large-scale simulations whose connectivity ratios match those of the real cerebellum and that these simulations can be used guide future studies on cerebellar mediated tasks and on machine learning problems.},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2013-11},
  pages = {95-102},
  author = {Li, Wen-Ke and Hausknecht, Matthew J. and Stone, Peter and Mauk, Michael D.},
  file = {/Users/qualia/Documents/Papers/2012 - Li et al. - Using a million cell simulation of the cerebellum Network scaling and task generality.pdf}
}

@article{Lintas2012,
  langid = {english},
  title = {Dopamine Deficiency Increases Synchronized Activity in the Rat Subthalamic Nucleus},
  volume = {1434},
  issn = {00068993},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0006899311016623},
  doi = {10.1016/j.brainres.2011.09.005},
  abstract = {Abnormal neuronal activity in the subthalamic nucleus (STN) plays a crucial role in the pathophysiology of Parkinson's disease (PD). In this study we investigated changes in rat STN neuronal activity after 28 days following the injection of 6-OHDA in the substantia nigra pars compacta (SNc). This drug provoked a lesion of SNc that induced a dopamine (DA) depletion assessed by changes in rotating capacity in response to apomorphine injection and by histological analysis. By means of extracellular recordings and waveshape spike sorting it was possible to analyze simultaneous spike trains and compute the crosscorrelations. Based on the analysis of the autocorrelograms we classified four types of firing patterns: regular (Poissonian-like), oscillatory (in the range 4\textendash{}12 Hz), bursty and cells characterized by a long refractoriness. The distribution of unit types in the control (n = 61) and lesioned (n = 83) groups was similar, as well as the firing rate. In 6-OHDA treated rats we observed a significant increase (from 26\% to 48\%) in the number of pairs with synchronous firing. These data suggest that the synchronous activity of STN cells, provoked by loss of DA cells in SNc, is likely to be among the most significant dysfunctions in the basal ganglia of Parkinsonian patients. We raise the hypothesis that in normal conditions, DA maintains a balance between funneling information via the hyperdirect cortico-subthalamic pathway and parallel processing through the parallel cortico-basal ganglia-subthalamic pathways, both of which are necessary for selected motor behaviors.},
  journaltitle = {Brain Research},
  urldate = {2019-03-30},
  date = {2012-01},
  pages = {142-151},
  author = {Lintas, Alessandra and Silkis, Isabella G. and Alb\'eri, Lavinia and Villa, Alessandro E.P.},
  file = {/Users/qualia/Documents/Papers/2012 - Lintas et al. - Dopamine deficiency increases synchronized activity in the rat subthalamic nucleus.pdf}
}

@article{Mallet2012,
  langid = {english},
  title = {Dichotomous {{Organization}} of the {{External Globus Pallidus}}},
  volume = {74},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627312004242},
  doi = {10.1016/j.neuron.2012.04.027},
  abstract = {Different striatal projection neurons are the origin of a dual organization essential for basal ganglia function. We have defined an analogous division of labor in the external globus pallidus (GPe) of Parkinsonian rats, showing that the distinct temporal activities of two populations of GPe neuron in vivo are underpinned by distinct molecular profiles and axonal connectivities. A first population of prototypic GABAergic GPe neurons fire antiphase to subthalamic nucleus (STN) neurons, often express parvalbumin, and target downstream basal ganglia nuclei, including STN. In contrast, a second population (arkypallidal neurons) fire in-phase with STN neurons, express preproenkephalin, and only innervate the striatum. This novel cell type provides the largest extrinsic GABAergic innervation of striatum, targeting both projection neurons and interneurons. We conclude that GPe exhibits several core components of a dichotomous organization as fundamental as that in striatum. Thus, two populations of GPe neuron together orchestrate activities across all basal ganglia nuclei in a cell-type-specific manner.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2012-06},
  pages = {1075-1086},
  author = {Mallet, Nicolas and Micklem, Benjamin R. and Henny, Pablo and Brown, Matthew T. and Williams, Claire and Bolam, J. Paul and Nakamura, Kouichi C. and Magill, Peter J.},
  file = {/Users/qualia/Documents/Papers/2012 - Mallet et al. - Dichotomous Organization of the External Globus Pallidus.pdf}
}

@article{Burns2010,
  langid = {english},
  title = {Comparisons of the {{Dynamics}} of {{Local Field Potential}} and {{Multiunit Activity Signals}} in {{Macaque Visual Cortex}}},
  volume = {30},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0743-10.2010},
  doi = {10.1523/JNEUROSCI.0743-10.2010},
  abstract = {The local field potential (LFP) and multi-unit activity (MUA) are extracellularly recorded signals that describe local neuronal network dynamics. In our experiments, the LFP and MUA, recorded from the same electrode in macaque V1 in response to drifting grating visual stimuli, were evaluated on coarse time-scales (\textasciitilde{}1-5s) and fine time-scales ({$<$} 0.1s) . On coarse time-scales, MUA and the LFP both produced sustained visual responses to optimal and nonoptimal oriented visual stimuli. The sustainedness of the two signals across the population of recording sites was correlated (correlation coefficient \textasciitilde{}0.4). At most recording sites the MUA was at least as sustained as the LFP and significantly more sustained for optimal orientations. In previous literature the BOLD (blood oxygen level dependent) signal of fMRI (functional magnetic resonance imaging) studies was found to be more strongly correlated with the LFP than with the MUA due to the lack of sustained response in the MUA signal. Since we found that MUA was as sustained as the LFP, MUA may also be correlated with BOLD. On fine time-scales, we computed the coherence between the LFP and MUA over the frequency range 10-150Hz. The LFP and MUA were weakly but significantly coherent (\textasciitilde{} 0.14) in the gamma-band (20-90Hz). The amount of gamma-band coherence was correlated with the power in the gamma-band of the LFP. The data were consistent with the proposal that the LFP and MUA are generated in a noisy, resonant cortical network.},
  number = {41},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2010-10-13},
  pages = {13739-13749},
  author = {Burns, S. P. and Xing, D. and Shapley, R. M.},
  file = {/Users/qualia/Documents/Papers/2012 - Manuscript - NIH Public Access.pdf}
}

@article{Hansel1992,
  langid = {english},
  title = {Synchronization and Computation in a Chaotic Neural Network},
  volume = {68},
  issn = {0031-9007},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.68.718},
  doi = {10.1103/PhysRevLett.68.718},
  number = {5},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {1992-02-03},
  pages = {718-721},
  author = {Hansel, D. and Sompolinsky, H.},
  file = {/Users/qualia/Documents/Papers/1992 - Hansel, Sompolinsky - Synchronization and computation in a chaotic neural network.pdf}
}

@article{Heeger1992,
  langid = {english},
  title = {Half-Squaring in Responses of Cat Striate Cells},
  volume = {9},
  issn = {0952-5238, 1469-8714},
  url = {http://www.journals.cambridge.org/abstract_S095252380001124X},
  doi = {10.1017/S095252380001124X},
  abstract = {Simple cells in striate cortex have been depicted as rectified linear operators, and complex cells have been depicted as energy mechanisms (constructed from the squared sums of linear operator outputs). This paper discusses two essential hypotheses of the linear/energy model: (1) that a cell's selectivity is due to an underlying (spatiotemporal and binocular) linear stage; and (2) that a cell's firing rate depends on the squared output of the underlying linear stage. This paper reviews physiological measurements of cat striate cell responses, and concludes that both of these hypotheses are supported by the data.},
  number = {05},
  journaltitle = {Visual Neuroscience},
  urldate = {2019-03-30},
  date = {1992-11},
  pages = {427-443},
  author = {Heeger, David J.},
  file = {/Users/qualia/Documents/Papers/1992 - Heeger - Half-squaring in responses of cat striate cells.pdf}
}

@article{Jefferys1992,
  eprinttype = {jstor},
  eprint = {29774559},
  langid = {english},
  title = {Ockham's {{Razor}} and {{Bayesian Analysis}}},
  volume = {80},
  number = {1},
  journaltitle = {American Scientist},
  date = {1992},
  pages = {64-72},
  author = {Jefferys, William H. and {work(s):}, James O. Berger Reviewed},
  file = {/Users/qualia/Documents/Papers/1992 - Jefferys, Berger - Ockham's Razor and Bayesian Analysis.pdf}
}

@article{Lin,
  langid = {english},
  title = {Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching},
  abstract = {To date, reinforcement learning has mostly been studied solving simple learning tasks. Reinforcement learning methods that have been studied so far typically converge slowly. The purpose of this work is thus twofold: 1) to investigate the utility of reinforcement learning in solving much more complicated learning tasks than previously studied, and 2) to investigate methods that will speed up reinforcement learning.},
  pages = {29},
  author = {Lin, Long-Ji},
  file = {/Users/qualia/Documents/Papers/1992 - Lin - Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching.pdf}
}

@article{Molgedey1992,
  langid = {english},
  title = {Suppressing Chaos in Neural Networks by Noise},
  volume = {69},
  issn = {0031-9007},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.69.3717},
  doi = {10.1103/PhysRevLett.69.3717},
  number = {26},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {1992-12-28},
  pages = {3717-3719},
  author = {Molgedey, L. and Schuchhardt, J. and Schuster, H. G.},
  file = {/Users/qualia/Documents/Papers/1992 - Molgedey, Schuchhardt, Schuster - Suppressing chaos in neural networks by noise.pdf}
}

@article{Abbott1993,
  langid = {english},
  title = {Analysis of {{Neuron Models}} with {{Dynamically Regulated Conductances}}},
  volume = {5},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.1993.5.6.823},
  doi = {10.1162/neco.1993.5.6.823},
  number = {6},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {1993-11},
  pages = {823-842},
  author = {Abbott, L. F. and LeMasson, Gwendal},
  file = {/Users/qualia/Documents/Papers/1993 - Abbott, LeMasson - Analysis of Neuron Models with Dynamically Regulated Conductances.pdf}
}

@article{Dayan,
  langid = {english},
  title = {Improving {{Generalisation}} for {{Temporal Difference Learning}}: {{The Successor Representation}}},
  abstract = {Estimation of returns over time, the focus of temporal difference (TD) algorithms, imposes particular constraints on good function approximators or representations. Appropriate generalisation between states is determined by how similar their successors are, and representations should follow suit. This paper shows how TD machinery can be used to learn such representations, and illustrates, using a navigation task, the appropriately distributed nature of the result.},
  pages = {14},
  author = {Dayan, Peter},
  file = {/Users/qualia/Documents/Papers/1993 - Dayan - Improving Generalization for Temporal Difference Learning The Successor Representation.pdf}
}

@article{LeMasson1993,
  langid = {english},
  title = {Activity-Dependent Regulation of Conductances in Model Neurons},
  volume = {259},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.8456317},
  doi = {10.1126/science.8456317},
  number = {5103},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {1993-03-26},
  pages = {1915-1917},
  author = {LeMasson, G and Marder, E and Abbott, L.},
  file = {/Users/qualia/Documents/Papers/1993 - LeMasson, Marder, Abbott - Activity-dependent regulation of conductances in model neurons.pdf}
}

@article{Hewitt1994,
  langid = {english},
  title = {A Computer Model of Amplitude-modulation Sensitivity of Single Units in the Inferior Colliculus},
  volume = {95},
  issn = {0001-4966},
  url = {http://asa.scitation.org/doi/10.1121/1.408676},
  doi = {10.1121/1.408676},
  number = {4},
  journaltitle = {The Journal of the Acoustical Society of America},
  urldate = {2019-03-30},
  date = {1994-04},
  pages = {2145-2159},
  author = {Hewitt, Michael J. and Meddis, Ray},
  file = {/Users/qualia/Documents/Papers/1994 - Hewitt, Meddis - A computer model of amplitude‐modulation sensitivity of single units in the inferior colliculus.pdf}
}

@incollection{Maass1994,
  langid = {english},
  location = {{Boston, MA}},
  title = {A {{Comparison}} of the {{Computational Power}} of {{Sigmoid}} and {{Boolean Threshold Circuits}}},
  isbn = {978-1-4613-6160-2 978-1-4615-2696-4},
  url = {http://link.springer.com/10.1007/978-1-4615-2696-4_4},
  abstract = {We examine the power of constant depth circuits with sigmoid (i.e. smooth) threshold gates for computing boolean functions. It is shown that, for depth 2, constant size circuits of this type are strictly more powerful than constant size boolean threshold circuits (i.e. circuits with linear threshold gates). On the other hand it turns out that, for any constant depth d, polynomial size sigmoid threshold circuits with polynomially bounded weights compute exactly the same boolean functions as the corresponding circuits with linear threshold gates.},
  booktitle = {Theoretical {{Advances}} in {{Neural Computation}} and {{Learning}}},
  publisher = {{Springer US}},
  urldate = {2019-03-30},
  date = {1994},
  pages = {127-151},
  author = {Maass, W. and Schnitger, G. and Sontag, E. D.},
  editor = {Roychowdhury, Vwani and Siu, Kai-Yeung and Orlitsky, Alon},
  file = {/Users/qualia/Documents/Papers/1994 - Maass, Schnitger, Sontag - A comparison of the computational power of sigmoid and Boolean threshold circuits.pdf},
  doi = {10.1007/978-1-4615-2696-4_4}
}

@article{Rasmussen,
  langid = {english},
  title = {A Neural Reinforcement Learning Model for Tasks with Unknown Time Delays},
  abstract = {We present a biologically based neural model capable of performing reinforcement learning in complex tasks. The model is unique in its ability to solve tasks that require the agent to make a sequence of unrewarded actions in order to reach the goal, in an environment where there are unknown and variable time delays between actions, state transitions, and rewards. Specifically, this is the first neural model of reinforcement learning able to function within a Semi-Markov Decision Process (SMDP) framework. We believe that this extension of current modelling efforts lays the groundwork for increasingly sophisticated models of human decision making.},
  pages = {6},
  author = {Rasmussen, Daniel and Eliasmith, Chris},
  file = {/Users/qualia/Documents/Papers/1994 - Rasmussen, Eliasmith - A neural reinforcement learning model for tasks with unknown time delays.pdf;/Users/qualia/Documents/Papers/1994 - Rasmussen, Eliasmith - A neural reinforcement learning model for tasks with unknown time delays(2).pdf}
}

@article{Siegel1994,
  langid = {english},
  title = {Activity-Dependent Current Distributions in Model Neurons.},
  volume = {91},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.91.24.11308},
  doi = {10.1073/pnas.91.24.11308},
  abstract = {The electrical activity of a neuron can affect its intrinsic physiological characteristics through a wide range of processes. We study a computer-simulated multicompartment model neuron In which channel density depends on local Ca2+ concentrations. This has three interesting consequences for the spatial distribution of conductances and the physiological behavior ofthe neuron: (i) the model neuron spontaneously develops a realistic, nonuniform distribution of conductances that is linked both to the morphology of the neuron and to the pattern of synaptic input that it receives, (i) the response to synaptic Input reveals a form of intrinsic localized plasticity that balances the synaptic contribution from dendritic regions receiving unequal stimulation, and (i) intrinsic plasticity establishes a biophysical gain control that restores the neuron to its optimal firing range after synapses are strengthened by "Hebbian" long-term potentiation.},
  number = {24},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {1994-11-22},
  pages = {11308-11312},
  author = {Siegel, M. and Marder, E. and Abbott, L. F.},
  file = {/Users/qualia/Documents/Papers/1994 - Siegel, Marder, Abbottt - Activity-dependent current distributions in model neurons.pdf}
}

@article{Buonomano1995,
  langid = {english},
  title = {Temporal Information Transformed into a Spatial Code by a Neural Network with Realistic Properties},
  volume = {267},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.7863330},
  doi = {10.1126/science.7863330},
  number = {5200},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {1995-02-17},
  pages = {1028-1030},
  author = {Buonomano, D. and Merzenich, M.},
  file = {/Users/qualia/Documents/Papers/1995 - Buonomano, Mauk - Temporal information transformed into a spatial code by a neural network with realistic properties.pdf}
}

@article{Dayan1995,
  langid = {english},
  title = {The {{Helmholtz Machine}}},
  volume = {7},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.1995.7.5.889},
  doi = {10.1162/neco.1995.7.5.889},
  number = {5},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {1995-09},
  pages = {889-904},
  author = {Dayan, Peter and Hinton, Geoffrey E. and Neal, Radford M. and Zemel, Richard S.},
  file = {/Users/qualia/Documents/Papers/1995 - Dayan et al. - The helmholtz machine.pdf}
}

@article{Gray1995,
  langid = {english},
  title = {A {{Perceptron Reveals}} the {{Face}} of {{Sex}}},
  volume = {7},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.1995.7.6.1160},
  doi = {10.1162/neco.1995.7.6.1160},
  number = {6},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {1995-11},
  pages = {1160-1164},
  author = {Gray, Michael S. and Lawrence, David T. and Golomb, Beatrice A. and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/1995 - Gray et al. - A perception reveals the face of sex.pdf}
}

@article{Grill1995,
  langid = {english},
  title = {Stimulus Waveforms for Selective Neural Stimulation},
  volume = {14},
  issn = {07395175},
  url = {http://ieeexplore.ieee.org/document/395310/},
  doi = {10.1109/51.395310},
  number = {4},
  journaltitle = {IEEE Engineering in Medicine and Biology Magazine},
  urldate = {2019-03-30},
  year = {July-Aug./1995},
  pages = {375-385},
  author = {Grill, W.M. and Mortimer, J.T.},
  file = {/Users/qualia/Documents/Papers/1995 - Grill, Mortimer - Stimulus Waveforms for Selective Neural Stimulation.pdf}
}

@article{Katz1995,
  eprinttype = {jstor},
  eprint = {10.2307/2691411?origin=crossref},
  langid = {english},
  title = {Ideas of {{Calculus}} in {{Islam}} and {{India}}},
  volume = {68},
  issn = {0025570X},
  doi = {10.2307/2691411},
  number = {3},
  journaltitle = {Mathematics Magazine},
  date = {1995-06-01},
  pages = {163},
  author = {Katz, Victor J.},
  file = {/Users/qualia/Documents/Papers/1995 - Katz - Ideas of Calculus in Islam and India.pdf}
}

@article{Grill1996,
  langid = {english},
  title = {The Effect of Stimulus Pulse Duration on Selectivity of Neural Stimulation},
  volume = {43},
  issn = {00189294},
  url = {http://ieeexplore.ieee.org/document/481985/},
  doi = {10.1109/10.481985},
  number = {2},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  urldate = {2019-03-30},
  year = {Feb./1996},
  pages = {161-166},
  author = {Grill, W.M. and Mortimer, J.T.},
  file = {/Users/qualia/Documents/Papers/1996 - Grill, Mortimer - The Effect of Stimulus Pulse Duration on Selectivity of Neural Stimulation.pdf}
}

@article{Holt1996,
  langid = {english},
  title = {Comparison of Discharge Variability in Vitro and in Vivo in Cat Visual Cortex Neurons},
  volume = {75},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.1996.75.5.1806},
  doi = {10.1152/jn.1996.75.5.1806},
  number = {5},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {1996-05},
  pages = {1806-1814},
  author = {Holt, G. R. and Softky, W. R. and Koch, C. and Douglas, R. J.},
  file = {/Users/qualia/Documents/Papers/1996 - Holt et al. - Comparison of discharge variability in vitro and in vivo in cat visual cortex neurons.pdf}
}

@article{Mainen1996,
  langid = {english},
  title = {Influence of Dendritic Structure on Firing Pattern in Model Neocortical Neurons},
  volume = {382},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/382363a0},
  doi = {10.1038/382363a0},
  number = {6589},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {1996-07},
  pages = {363-366},
  author = {Mainen, Zachary F. and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/1996 - Mainen, Sejnowski - Influence of dendritic structure on firing pattern in model neocortical neurons(2).pdf}
}

@article{Pfurtscheller1996,
  langid = {english},
  title = {Event-Related Synchronization ({{ERS}}) in the Alpha Band \textemdash{} an Electrophysiological Correlate of Cortical Idling: {{A}} Review},
  volume = {24},
  issn = {01678760},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167876096000669},
  doi = {10.1016/S0167-8760(96)00066-9},
  shorttitle = {Event-Related Synchronization ({{ERS}}) in the Alpha Band \textemdash{} an Electrophysiological Correlate of Cortical Idling},
  abstract = {EEG desynchronization is a reliable correlate of excited neural structures or activated cortical areas. EEG synchronization within the alpha band may be an electrophysiological correlate of deactivated cortical areas. Such areas are not processing sensory information or motor output and can be considered to be in an idling state. One example of such an idling cortical area is the enhancement of mu rhythms in the primary hand area during visual processing or during foot movement. In both circumstances, the neurons in the hand area are not needed for visual processing or preparation for foot movement. As a result of this, an enhanced hand area mu rhythm can be observed.},
  number = {1-2},
  journaltitle = {International Journal of Psychophysiology},
  urldate = {2019-03-30},
  date = {1996-11},
  pages = {39-46},
  author = {Pfurtscheller, G. and Stanc\'ak, A. and Neuper, Ch.},
  file = {/Users/qualia/Documents/Papers/1996 - Pfurtscheller, Stancák, Neuper - Event-related synchronization (ERS) in the alpha band - An electrophysiological correlate of co.pdf}
}

@article{Vreeswijk1996,
  langid = {english},
  title = {Chaos in {{Neuronal Networks}} with {{Balanced Excitatory}} and {{Inhibitory Activity}}},
  volume = {274},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.274.5293.1724},
  doi = {10.1126/science.274.5293.1724},
  number = {5293},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {1996-12-06},
  pages = {1724-1726},
  author = {v. Vreeswijk, C. and Sompolinsky, H.},
  file = {/Users/qualia/Documents/Papers/1996 - van Vreeswijk, Sompolinsky - Chaos in neuronal networks with balanced excitatory and inhibitory activity.pdf}
}

@inproceedings{Bylander1997,
  langid = {english},
  location = {{Houston, TX, USA}},
  title = {A Perceptron-like Online Algorithm for Tracking the Median},
  volume = {4},
  isbn = {978-0-7803-4122-7},
  url = {http://ieeexplore.ieee.org/document/614292/},
  doi = {10.1109/ICNN.1997.614292},
  abstract = {We present an online algorithm for tracking the median of a series of values. The algorithm updates its current estimate of the median by incrementing or decrementing a fixed value, which is analogous to perceptron updating. The median value of a sequence minimizes the absolute loss, i.e., the sum of absolute deviations. Our analysis shows that the worst-case absolute loss of our algorithm is comparable to the absolute loss of any sequence of target medians, given restrictions on how much the target can change per trial.},
  eventtitle = {International {{Conference}} on {{Neural Networks}} ({{ICNN}}'97)},
  booktitle = {Proceedings of {{International Conference}} on {{Neural Networks}} ({{ICNN}}'97)},
  publisher = {{IEEE}},
  urldate = {2019-03-30},
  date = {1997},
  pages = {2219-2224},
  author = {Bylander, T. and Rosen, B.},
  file = {/Users/qualia/Documents/Papers/1997 - Bylander, Rosen - A perceptron-like online algorithm for tracking the median.pdf}
}

@article{Dale1997,
  langid = {english},
  title = {Selective Averaging of Rapidly Presented Individual Trials Using {{fMRI}}},
  volume = {5},
  issn = {10659471},
  url = {http://doi.wiley.com/10.1002/%28SICI%291097-0193%281997%295%3A5%3C329%3A%3AAID-HBM1%3E3.0.CO%3B2-5},
  doi = {10.1002/(SICI)1097-0193(1997)5:5<329::AID-HBM1>3.0.CO;2-5},
  abstract = {A major limitation in conducting functional neuroimaging studies, particularly for cognitive experiments, has been the use of blocked task paradigms. Here we explored whether selective averaging techniques similar to those applied in event-related potential (ERP) experiments could be used to demonstrate functional magnetic resonance imaging (fMRI) responses to rapidly intermixed trials. In the first two experiments, we observed that for 1-sec trials of full-field visual checkerboard stimulation, the fMRI blood oxygenation level-dependent (BOLD) signal summated in a roughly linear fashion across successive trials even at very short (2 sec and 5 sec) intertrial intervals, although subtle departures from linearity were observed. In experiments 3 and 4, we observed that it is possible to obtain robust activation maps for rapidly presented randomly mixed trial types (left- and right-hemifield visual checkerboard stimulation) spaced as little as 2 sec apart. Taken collectively, these results suggest that selective averaging may enable fMRI experimental designs identical to those used in typical behavioral and ERP studies. The ability to analyze closely spaced single-trial, or event-related, signals provides for a class of experiments which cannot be conducted using blocked designs. Trial types can be randomly intermixed, and selective averaging based upon trial type and/or subject performance is possible. Hum. Brain Mapping 5:329\textendash{}340, 1997.},
  number = {5},
  journaltitle = {Human Brain Mapping},
  urldate = {2019-03-30},
  date = {1997},
  pages = {329-340},
  author = {Dale, Anders M. and Buckner, Randy L.},
  file = {/Users/qualia/Documents/Papers/1997 - Dale, Buckner - Selective averaging of rapidly presented individual trials using fMRI.pdf}
}

@article{Ferre1997,
  langid = {english},
  title = {Adenosine\textendash{}Dopamine Receptor\textendash{}Receptor Interactions as an Integrative Mechanism in the Basal Ganglia},
  volume = {20},
  issn = {01662236},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0166223697010965},
  doi = {10.1016/S0166-2236(97)01096-5},
  number = {10},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {1997-10},
  pages = {482-487},
  author = {Ferr\'e, Sergi and Fuxe, Kjell and B. Fredholm, Bertil and Morelli, Micaela and Popoli, Patrizia},
  file = {/Users/qualia/Documents/Papers/1997 - Ferré et al. - Adenosine-dopamine receptor-receptor interactions as an integrative mechanism in the basal ganglia.pdf}
}

@article{Holt1997,
  langid = {english},
  title = {Shunting {{Inhibition Does Not Have}} a {{Divisive Effect}} on {{Firing Rates}}},
  volume = {9},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.5.1001},
  doi = {10.1162/neco.1997.9.5.1001},
  number = {5},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {1997-07},
  pages = {1001-1013},
  author = {Holt, Gary R. and Koch, Christof},
  file = {/Users/qualia/Documents/Papers/1997 - Holt, Koch - Shunting inhibition does not have a divisive effect on firing rates.pdf}
}

@article{Kreiss1997,
  langid = {english},
  title = {The {{Response}} of {{Subthalamic Nucleus Neurons}} to {{Dopamine Receptor Stimulation}} in a {{Rodent Model}} of {{Parkinson}}'s {{Disease}}},
  volume = {17},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.17-17-06807.1997},
  doi = {10.1523/JNEUROSCI.17-17-06807.1997},
  number = {17},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {1997-09-01},
  pages = {6807-6819},
  author = {Kreiss, Deborah S. and Mastropietro, Christopher W. and Rawji, Saima S. and Walters, Judith R.},
  file = {/Users/qualia/Documents/Papers/1997 - Kreiss et al. - The response of subthalamic nucleus neurons to dopamine receptor stimulation in a rodent model of Parkinson's dis.pdf}
}

@article{Markram1997,
  langid = {english},
  title = {Regulation of {{Synaptic Efficacy}} by {{Coincidence}} of {{Postsynaptic APs}} and {{EPSPs}}},
  volume = {275},
  issn = {00368075, 10959203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.275.5297.213},
  doi = {10.1126/science.275.5297.213},
  number = {5297},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {1997-01-10},
  pages = {213-215},
  author = {Markram, H.},
  file = {/Users/qualia/Documents/Papers/1997 - Markram et al. - Regulation of synaptic efficacy by coincidence of postsynaptic APs and EPSPs.pdf}
}

@article{Weibull,
  langid = {english},
  title = {{{WHAT HAVE WE LEARNED FROM EVOLUTIONARY GAME THEORY SO FAR}}?},
  pages = {30},
  author = {Weibull, J\"orgen W},
  file = {/Users/qualia/Documents/Papers/1997 - Wiebull - What have we learned from Evolutionary Game Theory so far.pdf}
}

@article{Huang1998,
  langid = {english},
  title = {The Empirical Mode Decomposition and the {{Hilbert}} Spectrum for Nonlinear and Non-Stationary Time Series Analysis},
  volume = {454},
  issn = {1471-2946},
  url = {http://www.royalsocietypublishing.org/doi/10.1098/rspa.1998.0193},
  doi = {10.1098/rspa.1998.0193},
  number = {1971},
  journaltitle = {Proceedings of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences},
  urldate = {2019-03-30},
  date = {1998-03-08},
  pages = {903-995},
  author = {Huang, Norden E. and Shen, Zheng and Long, Steven R. and Wu, Manli C. and Shih, Hsing H. and Zheng, Quanan and Yen, Nai-Chyuan and Tung, Chi Chao and Liu, Henry H.},
  file = {/Users/qualia/Documents/Papers/1998 - Branch et al. - (1998) N. E. Huang, et.al. (1998) The Empirical Mode Decomposition and the Hilbert Spectrum for Nonlinear and Non.pdf}
}

@article{Buonomano1998,
  langid = {english},
  title = {Net {{Interaction Between Different Forms}} of {{Short}}-{{Term Synaptic Plasticity}} and {{Slow}}-{{IPSPs}} in the {{Hippocampus}} and {{Auditory Cortex}}},
  volume = {80},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.1998.80.4.1765},
  doi = {10.1152/jn.1998.80.4.1765},
  number = {4},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {1998-10},
  pages = {1765-1774},
  author = {Buonomano, Dean V. and Merzenich, Michael M.},
  file = {/Users/qualia/Documents/Papers/1998 - Buonomano, Merzenich - Net interaction between different forms of short-term synaptic plasticity and slow-IPSPs in the hippocampu.pdf}
}

@article{Camerer1998,
  langid = {english},
  title = {Experience-{{Weighted Attraction Learning}} in {{Coordination Games}}: {{Probability Rules}}, {{Heterogeneity}}, and {{Time}}-{{Variation}}},
  volume = {42},
  issn = {00222496},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0022249698912172},
  doi = {10.1006/jmps.1998.1217},
  shorttitle = {Experience-{{Weighted Attraction Learning}} in {{Coordination Games}}},
  number = {2-3},
  journaltitle = {Journal of Mathematical Psychology},
  urldate = {2019-03-30},
  date = {1998-06},
  pages = {305-326},
  author = {Camerer, Colin and Ho, Teck-Hua},
  file = {/Users/qualia/Documents/Papers/1998 - Camerer, Ho - Experience-Weighted Attraction Learning in Coordination Games Probability Rules, Heterogeneity, and Time-Variation.pdf}
}

@article{Claus,
  langid = {english},
  title = {The {{Dynamics}} of {{Reinforcement Learning}} in {{Cooperative Multiagent Systems}}},
  abstract = {Reinforcement learning can provide a robust and natural means for agents to learn how to coordinate their action choices in multiagent systems. We examine some of the factors that can influence the dynamics of the learning process in such a setting. We first distinguish reinforcement learners that are unaware of (or ignore) the presence of other agents from those that explicitly attempt to learn the value of joint actions and the strategies of their counterparts. We study (a simple form of) Q-learning in cooperative multiagent systems under these two perspectives, focusing on the influence of that game structure and exploration strategies on convergence to (optimal and suboptimal) Nash equilibria. We then propose alternative optimistic exploration strategies that increase the likelihood of convergence to an optimal equilibrium.},
  pages = {7},
  author = {Claus, Caroline and Boutilier, Craig},
  file = {/Users/qualia/Documents/Papers/1998 - Claus, Boutilier - The Dynamics of Reinforcement Learning in Cooperative Multiagent Systems.pdf}
}

@article{Destexhe,
  langid = {english},
  title = {Kinetic {{Models}} of {{Synaptic Transmission}}},
  pages = {26},
  author = {Destexhe, A and Mainen, Z F and Sejnowski, T J and Koch, C (EDITOR) and Segev, I (EDITOR)},
  file = {/Users/qualia/Documents/Papers/1998 - Destexhe et al. - Kinetic models of synaptic transmission.pdf}
}

@article{Erev1998,
  eprinttype = {jstor},
  eprint = {117009},
  langid = {english},
  title = {Predicting {{How People Play Games}}: {{Reinforcement Learning}} in {{Experimental Games}} with {{Unique}} , {{Mixed Strategy Equilibria}}},
  volume = {88},
  number = {4},
  journaltitle = {The American Economic Review},
  date = {1998},
  pages = {848-881},
  author = {Erev, Ido and Roth, Alvin E.},
  file = {/Users/qualia/Documents/Papers/1998 - Erev, Roth - Predicting how people play games Reinforcement learning in games with unique strategy equilibrium.pdf}
}

@article{Fellous,
  langid = {english},
  title = {Computational {{Models}} of {{Neuromodulation}}},
  pages = {35},
  author = {Fellous, Jean-Marc and Linster, Christiane},
  file = {/Users/qualia/Documents/Papers/1998 - Fellous, Linser - Computational Models of Neuromodulation.pdf}
}

@article{Gillies1998,
  langid = {english},
  title = {A Massively Connected Subthalamic Nucleus Leads to the Generation of Widespread Pulses},
  volume = {265},
  issn = {1471-2954},
  url = {http://www.royalsocietypublishing.org/doi/10.1098/rspb.1998.0546},
  doi = {10.1098/rspb.1998.0546},
  number = {1410},
  journaltitle = {Proceedings of the Royal Society of London. Series B: Biological Sciences},
  urldate = {2019-03-30},
  date = {1998-11-07},
  pages = {2101-2109},
  author = {Gillies, A. J. and Willshaw, D. J.},
  file = {/Users/qualia/Documents/Papers/1998 - Gillies, Willshaw - A massively connected subthalamic nucleus leads to the generation of widespread pulses.pdf}
}

@article{Houtekamer1998,
  langid = {english},
  title = {Data {{Assimilation Using}} an {{Ensemble Kalman Filter Technique}}},
  volume = {126},
  issn = {0027-0644, 1520-0493},
  url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281998%29126%3C0796%3ADAUAEK%3E2.0.CO%3B2},
  doi = {10.1175/1520-0493(1998)126<0796:DAUAEK>2.0.CO;2},
  abstract = {The possibility of performing data assimilation using the flow-dependent statistics calculated from an ensemble of short-range forecasts (a technique referred to as ensemble Kalman filtering) is examined in an idealized environment. Using a three-level, quasigeostrophic, T21 model and simulated observations, experiments are performed in a perfect-model context. By using forward interpolation operators from the model state to the observations, the ensemble Kalman filter is able to utilize nonconventional observations.},
  number = {3},
  journaltitle = {Monthly Weather Review},
  urldate = {2019-03-30},
  date = {1998-03},
  pages = {796-811},
  author = {Houtekamer, P. L. and Mitchell, Herschel L.},
  file = {/Users/qualia/Documents/Papers/1998 - Houtekamer et al. - Data Assimilation Using an Ensemble Kalman Filter Technique.pdf;/Users/qualia/Documents/Papers/1998 - Service - Data Assimilation Using an Ensemble Kalman Filter Technique.pdf}
}

@article{Jensen1998,
  langid = {english},
  title = {An {{Oscillatory Short}}-{{Term Memory Buffer Model Can Account}} for {{Data}} on the {{Sternberg Task}}},
  volume = {18},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.18-24-10688.1998},
  doi = {10.1523/JNEUROSCI.18-24-10688.1998},
  number = {24},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {1998-12-15},
  pages = {10688-10699},
  author = {Jensen, Ole and Lisman, John E.},
  file = {/Users/qualia/Documents/Papers/1998 - Jensen, Lisman - An oscillatory short-term memory buffer model can account for data on the Sternberg task.pdf}
}

@article{Kuznetsov,
  title = {Elements of {{Applied Bifurcation Theory}}, {{Second Edition}}},
  pages = {614},
  author = {Kuznetsov, Yuri A},
  file = {/Users/qualia/Documents/Papers/1998 - Kuznetsov - Elements of Applied Bifurcation Theory.pdf}
}

@article{Liu1998,
  langid = {english},
  title = {A {{Model Neuron}} with {{Activity}}-{{Dependent Conductances Regulated}} by {{Multiple Calcium Sensors}}},
  volume = {18},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.18-07-02309.1998},
  doi = {10.1523/JNEUROSCI.18-07-02309.1998},
  number = {7},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {1998-04-01},
  pages = {2309-2320},
  author = {Liu, Zheng and Golowasch, Jorge and Marder, Eve and Abbott, L. F.},
  file = {/Users/qualia/Documents/Papers/1998 - Liu et al. - A model neuron with activity-dependent conductances regulated by multiple calcium sensors.pdf}
}

@article{Sherman1998,
  langid = {english},
  title = {On the Actions That One Nerve Cell Can Have on Another: {{Distinguishing}} "Drivers" from "Modulators"},
  volume = {95},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.95.12.7121},
  doi = {10.1073/pnas.95.12.7121},
  shorttitle = {On the Actions That One Nerve Cell Can Have on Another},
  abstract = {When one nerve cell acts on another, its postsynaptic effect can vary greatly. In sensory systems, inputs from ``drivers'' can be differentiated from those of ``modulators.'' The driver can be identified as the transmitter of receptive field properties; the modulator can be identified as altering the probability of certain aspects of that transmission. Where receptive fields are not available, the distinction is more difficult and currently is undefined. We use the visual pathways, particularly the thalamic geniculate relay for which much relevant evidence is available, to explore ways in which drivers can be distinguished from modulators. The extent to which the distinction may apply first to other parts of the thalamus and then, possibly, to other parts of the brain is considered. We suggest the following distinctions: Crosscorrelograms from driver inputs have sharper peaks than those from modulators; there are likely to be few drivers but many modulators for any one cell; and drivers are likely to act only through ionotropic receptors having a fast postsynaptic effect whereas modulators also are likely to activate metabotropic receptors having a slow and prolonged postsynaptic effect.},
  number = {12},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {1998-06-09},
  pages = {7121-7126},
  author = {Sherman, S. M. and Guillery, R. W.},
  file = {/Users/qualia/Documents/Papers/1998 - Sherman, Guillery - On the actions that one nerve cell can have on another distinguishing drivers from modulators.pdf}
}

@article{Wang1998,
  langid = {english},
  title = {Calcium {{Coding}} and {{Adaptive Temporal Computation}} in {{Cortical Pyramidal Neurons}}},
  volume = {79},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.1998.79.3.1549},
  doi = {10.1152/jn.1998.79.3.1549},
  number = {3},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {1998-03},
  pages = {1549-1566},
  author = {Wang, Xiao-Jing},
  file = {/Users/qualia/Documents/Papers/1998 - Wang - Calcium coding and adaptive temporal computation in cortical pyramidal neurons.pdf}
}

@article{Watts1998,
  langid = {english},
  title = {Collective Dynamics of `Small-World' Networks},
  volume = {393},
  date = {1998},
  pages = {3},
  author = {Watts, Duncan J and Strogatz, Steven H},
  file = {/Users/qualia/Documents/Papers/1998 - Watts, Strogatz - Collective dynamics of ‘small-world’ networks.pdf}
}

@article{Beurrier1999,
  langid = {english},
  title = {Subthalamic {{Nucleus Neurons Switch}} from {{Single}}-{{Spike Activity}} to {{Burst}}-{{Firing Mode}}},
  volume = {19},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.19-02-00599.1999},
  doi = {10.1523/JNEUROSCI.19-02-00599.1999},
  number = {2},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {1999-01-15},
  pages = {599-609},
  author = {Beurrier, Corinne and Congar, Patrice and Bioulac, Bernard and Hammond, Constance},
  file = {/Users/qualia/Documents/Papers/1999 - Beurrier et al. - Subthalamic nucleus neurons switch from single-spike activity to burst-firing mode.pdf}
}

@article{Borst1999,
  langid = {english},
  title = {Information Theory and Neural Coding},
  volume = {2},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn1199_947},
  doi = {10.1038/14731},
  number = {11},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {1999-11},
  pages = {947-957},
  author = {Borst, Alexander and Theunissen, Fr\'ed\'eric E.},
  file = {/Users/qualia/Documents/Papers/1999 - Borst, Theunissen - Information theory and neural coding.pdf}
}

@article{Buonomano1999,
  langid = {english},
  title = {A {{Neural Network Model}} of {{Temporal Code Generation}} and {{Position}}-{{Invariant Pattern Recognition}}},
  volume = {11},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976699300016836},
  doi = {10.1162/089976699300016836},
  number = {1},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {1999-01},
  pages = {103-116},
  author = {Buonomano, Dean V. and Merzenich, Michael},
  file = {/Users/qualia/Documents/Papers/1999 - Buonomano, Merzenich - A neural network model of temporal code generation and position- invariant pattern recognition.pdf}
}

@article{Baumgartner1999,
  langid = {english},
  title = {Assessment of Cluster Homogeneity in {{fMRI}} Data Using {{Kendall}}'s Coefficient of Concordance},
  volume = {17},
  issn = {0730725X},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0730725X99001010},
  doi = {10.1016/S0730-725X(99)00101-0},
  number = {10},
  journaltitle = {Magnetic Resonance Imaging},
  urldate = {2019-03-30},
  date = {1999-12},
  pages = {1525-1532},
  author = {Baumgartner, R. and Somorjai, R. and Summers, R. and Richter, W.},
  file = {/Users/qualia/Documents/Papers/1999 - Concordance - q Technical Note ASSESSMENT OF CLUSTER HOMOGENEITY IN fMRI DATA USING KENDALL ’ S COEFFICIENT OF CONCORDANCE.pdf}
}

@article{Freund1999,
  langid = {english},
  title = {Adaptive {{Game Playing Using Multiplicative Weights}}},
  volume = {29},
  issn = {08998256},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0899825699907388},
  doi = {10.1006/game.1999.0738},
  abstract = {We present a simple algorithm for playing a repeated game. We show that a player using this algorithm suffers average loss that is guaranteed to come close to the minimum loss achievable by any fixed strategy. Our bounds are non-asymptotic and hold for any opponent. The algorithm, which uses the multiplicative-weight methods of Littlestone and Warmuth, is analyzed using the Kullback-Liebler divergence. This analysis yields a new, simple proof of the minmax theorem, as well as a provable method of approximately solving a game. A variant of our game-playing algorithm is proved to be optimal in a very strong sense.},
  number = {1-2},
  journaltitle = {Games and Economic Behavior},
  urldate = {2019-03-30},
  date = {1999-10},
  pages = {79-103},
  author = {Freund, Yoav and Schapire, Robert E.},
  file = {/Users/qualia/Documents/Papers/1999 - Freund, Schapire - Adaptive game playing using multiplicative weights.pdf}
}

@article{Goeree1999,
  langid = {english},
  title = {Stochastic Game Theory: {{For}} Playing Games, Not Just for Doing Theory},
  volume = {96},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.96.19.10564},
  doi = {10.1073/pnas.96.19.10564},
  shorttitle = {Stochastic Game Theory},
  number = {19},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {1999-09-14},
  pages = {10564-10567},
  author = {Goeree, J. K. and Holt, C. A.},
  file = {/Users/qualia/Documents/Papers/1999 - Goeree, Holt - Stochastic game theory For playing games, not just for doing theory.pdf}
}

@article{Golowasch1999,
  langid = {english},
  title = {Network {{Stability}} from {{Activity}}-{{Dependent Regulation}} of {{Neuronal Conductances}}},
  volume = {11},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976699300016359},
  doi = {10.1162/089976699300016359},
  number = {5},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {1999-07},
  pages = {1079-1096},
  author = {Golowasch, Jorge and Casey, Michael and Abbott, L. F. and Marder, Eve},
  file = {/Users/qualia/Documents/Papers/1999 - Golowasch et al. - Network Stability from Activity-Dependent Regulation of Neuronal Conductances.pdf}
}

@article{Manwani1999,
  langid = {english},
  title = {Detecting and {{Estimating Signals}} in {{Noisy Cable Structures}}, {{II}}: {{Information Theoretical Analysis}}},
  volume = {11},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976699300015981},
  doi = {10.1162/089976699300015981},
  shorttitle = {Detecting and {{Estimating Signals}} in {{Noisy Cable Structures}}, {{II}}},
  number = {8},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {1999-11},
  pages = {1831-1873},
  author = {Manwani, Amit and Koch, Christof},
  file = {/Users/qualia/Documents/Papers/1999 - Manwani, Koch - Detecting and estimating signals in noisy cable structures, II information theoretical analysis.pdf}
}

@incollection{Polani2001,
  location = {{Berlin, Heidelberg}},
  title = {An {{Information}}-{{Theoretic Approach}} for the {{Quantification}} of {{Relevance}}},
  volume = {2159},
  isbn = {978-3-540-42567-0 978-3-540-44811-2},
  url = {http://link.springer.com/10.1007/3-540-44811-X_82},
  booktitle = {Advances in {{Artificial Life}}},
  publisher = {{Springer Berlin Heidelberg}},
  urldate = {2019-03-30},
  date = {2001},
  pages = {704-713},
  author = {Polani, Daniel and Martinetz, Thomas and Kim, Jan},
  editor = {Kelemen, Jozef and Sos\'ik, Petr},
  editorb = {Goos, G. and Hartmanis, J. and van Leeuwen, J.},
  editorbtype = {redactor},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/1999 - Monmarche, Venturini - Advances in Artificial Life.pdf},
  doi = {10.1007/3-540-44811-X_82}
}

@article{Plenz1999,
  langid = {english},
  title = {A Basal Ganglia Pacemaker Formed by the Subthalamic Nucleus and External Globus Pallidus},
  volume = {400},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/23281},
  doi = {10.1038/23281},
  number = {6745},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {1999-08},
  pages = {677-682},
  author = {Plenz, Dietmar and Kital, Stephen T.},
  file = {/Users/qualia/Documents/Papers/1999 - Plenz, Kital - A basal ganglia pacemaker formed by the subthalamic nucleus and external globus pallidus.pdf}
}

@article{Sarin1999,
  langid = {english},
  title = {Payoff {{Assessments}} without {{Probabilities}}: {{A Simple Dynamic Model}} of {{Choice}}},
  volume = {28},
  issn = {08998256},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0899825698907023},
  doi = {10.1006/game.1998.0702},
  shorttitle = {Payoff {{Assessments}} without {{Probabilities}}},
  number = {2},
  journaltitle = {Games and Economic Behavior},
  urldate = {2019-03-30},
  date = {1999-08},
  pages = {294-309},
  author = {Sarin, Rajiv and Vahid, Farshid},
  file = {/Users/qualia/Documents/Papers/1999 - Sarin, Vahid - Payoff assessments without probabilities A simple dynamic model of choice.pdf}
}

@article{Sarin2001,
  langid = {english},
  title = {Predicting {{How People Play Games}}: {{A Simple Dynamic Model}} of {{Choice}}},
  volume = {34},
  issn = {08998256},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0899825699907832},
  doi = {10.1006/game.1999.0783},
  shorttitle = {Predicting {{How People Play Games}}},
  number = {1},
  journaltitle = {Games and Economic Behavior},
  urldate = {2019-03-30},
  date = {2001-01},
  pages = {104-122},
  author = {Sarin, Rajiv and Vahid, Farshid},
  file = {/Users/qualia/Documents/Papers/1999 - Sarin, Vahid - Predicting How People Play Games Suhglfwlqj Krz Shrsoh Sod Jdphv = D Vlpsoh.pdf}
}

@article{Yeung1999,
  langid = {english},
  title = {Time {{Delay}} in the {{Kuramoto Model}} of {{Coupled Oscillators}}},
  volume = {82},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.82.648},
  doi = {10.1103/PhysRevLett.82.648},
  number = {3},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {1999-01-18},
  pages = {648-651},
  author = {Yeung, M. K. Stephen and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/1999 - Yeung, Strogatz - Time Delay in the Kuramoto Model of Coupled Oscillators.pdf}
}

@article{Anderson2000,
  langid = {english},
  title = {The {{Contribution}} of {{Noise}} to {{Contrast Invariance}} of {{Orientation Tuning}} in {{Cat Visual Cortex}}},
  volume = {290},
  issn = {00368075, 10959203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.290.5498.1968},
  doi = {10.1126/science.290.5498.1968},
  number = {5498},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2000-12-08},
  pages = {1968-1972},
  author = {Anderson, J. S.},
  file = {/Users/qualia/Documents/Papers/2000 - Anderson et al. - The contribution of noise to contrast invariance of orientation tuning in cat visual cortex.pdf}
}

@article{Callaway2000,
  langid = {english},
  title = {Network {{Robustness}} and {{Fragility}}: {{Percolation}} on {{Random Graphs}}},
  volume = {85},
  number = {25},
  journaltitle = {PHYSICAL REVIEW LETTERS},
  date = {2000},
  pages = {4},
  author = {Callaway, Duncan S and Newman, M E J and Strogatz, Steven H and Watts, Duncan J},
  file = {/Users/qualia/Documents/Papers/2000 - Callaway et al. - Network robustness and fragility percolation on random graphs.pdf}
}

@article{Chance,
  langid = {english},
  title = {Divisive Inhibition in Recurrent Networks},
  abstract = {Models of visual cortex suggest that response selectivity can arise from recurrent networks operating at high gain. However, such networks have a number of problematic features: (i) they operate perilously close to a point of instability, (ii) small changes in synaptic strength can dramatically modify the degree of amplification, and (iii) they respond slowly to rapidly changing stimuli. Divisive inhibition, acting through interneurons that are themselves divisively inhibited, can solve these problems without degrading the selectivity of a recurrent network.},
  pages = {11},
  author = {Chance, Frances S and Abbott, L F},
  file = {/Users/qualia/Documents/Papers/2000 - Chance, Abbott - Divisive inhibition in recurrent networks.pdf}
}

@book{Pierce2002,
  langid = {english},
  location = {{Cambridge, Mass}},
  title = {Types and Programming Languages},
  isbn = {978-0-262-16209-8},
  pagetotal = {623},
  publisher = {{MIT Press}},
  date = {2002},
  keywords = {Programming languages (Electronic computers)},
  author = {Pierce, Benjamin C.},
  file = {/Users/qualia/Documents/Papers/2000 - Ferreira - IUuI for Programming Languages.pdf}
}

@article{Forster2000,
  langid = {english},
  title = {Key {{Concepts}} in {{Model Selection}}: {{Performance}} and {{Generalizability}}},
  volume = {44},
  issn = {00222496},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0022249699912841},
  doi = {10.1006/jmps.1999.1284},
  shorttitle = {Key {{Concepts}} in {{Model Selection}}},
  number = {1},
  journaltitle = {Journal of Mathematical Psychology},
  urldate = {2019-03-30},
  date = {2000-03},
  pages = {205-231},
  author = {Forster, Malcolm R},
  file = {/Users/qualia/Documents/Papers/2000 - Forster - Key Concepts in Model Selection Performance and Generalizability.pdf}
}

@article{Gabaix2000,
  eprinttype = {jstor},
  eprint = {117264},
  langid = {english},
  title = {A {{Boundedly Rational Decision Algorithm}}},
  volume = {90},
  issue = {2,},
  journaltitle = {The American Economic Review},
  date = {2000},
  pages = {433- 438},
  author = {Gabaix, Xavier and Laibson, David},
  file = {/Users/qualia/Documents/Papers/2000 - Gabaix, Laibson - A boundedly rational decision algorithm.pdf}
}

@article{Rasmussena,
  langid = {english},
  title = {The {{Infinite Gaussian Mixture Model}}},
  abstract = {In a Bayesian mixture model it is not necessary a priori to limit the number of components to be finite. In this paper an infinite Gaussian mixture model is presented which neatly sidesteps the difficult problem of finding the ``right'' number of mixture components. Inference in the model is done using an efficient parameter-free Markov Chain that relies entirely on Gibbs sampling.},
  pages = {7},
  author = {Rasmussen, Carl Edward},
  file = {/Users/qualia/Documents/Papers/2000 - Rasmussen - The Infinite Gaussian Mixture Model.pdf}
}

@article{Sato2000,
  langid = {english},
  title = {Axonal Branching Pattern of Neurons of the Subthalamic Nucleus in Primates},
  volume = {424},
  issn = {0021-9967, 1096-9861},
  url = {http://doi.wiley.com/10.1002/1096-9861%2820000814%29424%3A1%3C142%3A%3AAID-CNE10%3E3.0.CO%3B2-8},
  doi = {10.1002/1096-9861(20000814)424:1<142::AID-CNE10>3.0.CO;2-8},
  abstract = {Axonal projections arising from the subthalamic nucleus (STN) in cynomolgus monkeys (Macaca fascicularis) were traced after labeling small pools (5\textendash{}15 cells) of neurons with biotinylated dextran amine. Seventy-five single axons were reconstructed from serial sagittal sections with a camera lucida. Most of the STN labeled cells displayed five to eight long, sparsely spined dendrites that arborized mostly along the main axis of the nucleus. Based on their axonal targets, five distinct types of STN projection neurons have been identified: 1) neurons projecting to the substantia nigra pars reticulata (SNr), the internal (GPi) and external (GPe) segments of the globus pallidus (21.3\%); 2) neurons targeting SNr and GPe (2.7\%); 3) neurons projecting to GPi and GPe (48\%); 4) neurons targeting GPe only (10.7 \%); and 5) neurons with axons that coursed toward the sriatum, but whose terminal arborization could not be visualized in detail (17.3\%). Axons of the first two types bifurcated into rostral subthalamopallidal and caudal pallidonigral branches. However, the majority of STN axons had only a single branch that coursed rostrally toward the pallidum and striatum. These results reveal that, in contrast to current beliefs, the primate STN is not a monolithic entity. This nucleus harbors several subtypes of projection neurons, each endowed with a highly patterned set of collaterals. This organization allows STN neurons to exert a multifarious effect not only on the GPe, with which the STN is reciprocally connected, but also on the two major output structures of the basal ganglia, the SNr and the GPi. J. Comp. Neurol. 424: 142\textendash{}152, 2000. \textcopyright{} 2000 Wiley-Liss, Inc.},
  number = {1},
  journaltitle = {The Journal of Comparative Neurology},
  urldate = {2019-03-30},
  date = {2000-08-14},
  pages = {142-152},
  author = {Sato, Fumi and Parent, Martin and Levesque, Martin and Parent, Andre},
  file = {/Users/qualia/Documents/Papers/2000 - Sato et al. - Axonal branching pattern of neurons of the subthalamic nucleus in primates.pdf}
}

@article{Song2000,
  langid = {english},
  title = {Competitive {{Hebbian}} Learning through Spike-Timing-Dependent Synaptic Plasticity},
  volume = {3},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn0900_919},
  doi = {10.1038/78829},
  number = {9},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2000-09},
  pages = {919-926},
  author = {Song, Sen and Miller, Kenneth D. and Abbott, L. F.},
  file = {/Users/qualia/Documents/Papers/2000 - Song, Miller, Abbott - Competitive Hebbian Learning through Spike-Time Dependent Synaptic Plasticity.pdf;/Users/qualia/Documents/Papers/2000 - Song, Miller, Abbott - Competitive Hebbian learning through spike-timing-dependent synaptic plasticity.pdf}
}

@article{zotero-2129,
  langid = {english},
  title = {Continuity {{Debate}}},
  pages = {22},
  file = {/Users/qualia/Documents/Papers/2000 - Unknown - No Title.pdf}
}

@article{Albin1989,
  langid = {english},
  title = {The Functional Anatomy of Basal Ganglia Disorders},
  volume = {12},
  issn = {01662236},
  url = {https://linkinghub.elsevier.com/retrieve/pii/016622368990074X},
  doi = {10.1016/0166-2236(89)90074-X},
  number = {10},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {1989-01},
  pages = {366-375},
  author = {Albin, Roger L. and Young, Anne B. and Penney, John B.},
  file = {/Users/qualia/Documents/Papers/1983 - Albin, Penney, Young - The Functional Anatomy of Basal Ganglia Disorders.pdf}
}

@article{Buzsaki1983,
  langid = {english},
  title = {Cellular Bases of Hippocampal {{EEG}} in the Behaving Rat},
  volume = {6},
  issn = {01650173},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0165017383900371},
  doi = {10.1016/0165-0173(83)90037-1},
  number = {2},
  journaltitle = {Brain Research Reviews},
  urldate = {2019-03-30},
  date = {1983-10},
  pages = {139-171},
  author = {Buzs\'aki, Gy\"orgy and Lai-Wo S., Leung and Vanderwolf, Cornelius H.},
  file = {/Users/qualia/Documents/Papers/1983 - Buzsáki, Leung, Vanderwolf - Cellular Bases of Hippocampal EEG in the Behaving Rat.pdf}
}

@article{Afsharpour1985,
  langid = {english},
  title = {Light Microscopic Analysis of Golgi-Impregnated Rat Subthalamic Neurons},
  volume = {236},
  issn = {0021-9967, 1096-9861},
  url = {http://doi.wiley.com/10.1002/cne.902360102},
  doi = {10.1002/cne.902360102},
  number = {1},
  journaltitle = {The Journal of Comparative Neurology},
  urldate = {2019-03-30},
  date = {1985-06-01},
  pages = {1-13},
  author = {Afsharpour, Salman},
  file = {/Users/qualia/Documents/Papers/1985 - Afsharpour - Light microscopic analysis of golgi‐impregnated rat subthalamic neurons.pdf}
}

@article{Nosofsky1985,
  langid = {english},
  title = {Overall Similarity and the Identification of Separable-Dimension Stimuli: {{A}} Choice Model Analysis},
  volume = {38},
  issn = {0031-5117, 1532-5962},
  url = {http://www.springerlink.com/index/10.3758/BF03207172},
  doi = {10.3758/BF03207172},
  shorttitle = {Overall Similarity and the Identification of Separable-Dimension Stimuli},
  number = {5},
  journaltitle = {Perception \& Psychophysics},
  urldate = {2019-03-30},
  date = {1985-09},
  pages = {415-432},
  author = {Nosofsky, Robert},
  file = {/Users/qualia/Documents/Papers/1985 - Nosofsky - Overall similarity and the identification of separable-dimension stimuli a choice model analysis.pdf}
}

@article{SalthouseandWemaraLichty,
  langid = {english},
  title = {Testsof {{theNeuralNoiseHypothesiosf Age}}-{{RelatedCognitiveChange}}'},
  pages = {8},
  author = {SalthouseandWemaraLichty, TimothyA},
  file = {/Users/qualia/Documents/Papers/1985 - Salthouse, Lichty - of the Neural Noise Hypothesis Cognitive Change ' J T Jrj J '.pdf}
}

@article{Ennis1988,
  langid = {english},
  title = {A Multidimensional Stochastic Theory of Similarity},
  volume = {32},
  issn = {00222496},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0022249688900235},
  doi = {10.1016/0022-2496(88)90023-5},
  number = {4},
  journaltitle = {Journal of Mathematical Psychology},
  urldate = {2019-03-30},
  date = {1988-12},
  pages = {449-465},
  author = {Ennis, Daniel M. and Palen, Joseph J. and Mullen, Kenneth},
  file = {/Users/qualia/Documents/Papers/1988 - Ennis - Theory of Similarity.pdf}
}

@article{Mcculloch,
  langid = {english},
  title = {A {{LOGICAL CALCULUS OF THE IDEAS IMMANENT IN NERVOUS ACTIVITY}}},
  pages = {17},
  author = {Mcculloch, Warren S and Pitts, Walter},
  file = {/Users/qualia/Documents/Papers/1990 - Mcculloch, Pitts - A logical calculus nervous activity.pdf}
}

@article{Mandelbrot1968,
  eprinttype = {jstor},
  eprint = {2027184},
  langid = {english},
  title = {Fractional {{Brownian Motions}}, {{Fractional Noises}} and {{Applications}}},
  volume = {10},
  number = {4},
  journaltitle = {SIAM Review},
  date = {1968},
  pages = {422-437},
  author = {Mandelbrot, Benoit B. and Ness, John W. Van},
  file = {/Users/qualia/Documents/Papers/1968 - Mandelbrot, Van Ness - Fractional Brownian Motions, Fractional Noises and Applications.pdf}
}

@article{Krnjevic1971,
  langid = {english},
  title = {The Mechanism of Excitation by Acetylcholine in the Cerebral Cortex},
  volume = {215},
  issn = {00223751},
  url = {http://doi.wiley.com/10.1113/jphysiol.1971.sp009467},
  doi = {10.1113/jphysiol.1971.sp009467},
  number = {1},
  journaltitle = {The Journal of Physiology},
  urldate = {2019-03-30},
  date = {1971-05-01},
  pages = {247-268},
  author = {Krnjevi\'c, K. and Pumain, R. and Renaud, L.},
  file = {/Users/qualia/Documents/Papers/1971 - Krnjevj, Pumain, Renaudt - THE MECHANISM OF EXCITATION BY ACETYLCHOLINE IN THE CEREBRAL CORTEX BY.pdf}
}

@article{Luzzana,
  langid = {english},
  title = {The Regulation of Oxygen Affinity of Human Haemoglobin},
  pages = {2},
  author = {Luzzana, M},
  file = {/Users/qualia/Documents/Papers/1972 - Brindley, Cgraggs - The electrical activity in the motor cortex that accompanices volentary movement.pdf}
}

@article{Knight1972,
  langid = {english},
  title = {Dynamics of {{Encoding}} in a {{Population}} of {{Neurons}}},
  volume = {59},
  issn = {0022-1295, 1540-7748},
  url = {http://www.jgp.org/cgi/doi/10.1085/jgp.59.6.734},
  doi = {10.1085/jgp.59.6.734},
  abstract = {A simple encoder model, which is a reasonable idealization from known electrophysiological properties, yields a population in which the variation of the firing rate with time is a perfect replica of the shape of the input stimulus. A population of noise-free encoders which depart even slightly from the simple model yield a very much degraded copy of the input stimulus. The presence of noise improves the performance of such a population. The firing rate of a population of neurons is related to the firing rate of a single member in a subtle way.},
  number = {6},
  journaltitle = {The Journal of General Physiology},
  urldate = {2019-03-30},
  date = {1972-06-01},
  pages = {734-766},
  author = {Knight, B. W.},
  file = {/Users/qualia/Documents/Papers/1972 - Knight - Dynamics of Encoding in a Population of Neurons.pdf}
}

@article{Wilson1972,
  langid = {english},
  title = {Excitatory and {{Inhibitory Interactions}} in {{Localized Populations}} of {{Model Neurons}}},
  volume = {12},
  issn = {00063495},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0006349572860685},
  doi = {10.1016/S0006-3495(72)86068-5},
  number = {1},
  journaltitle = {Biophysical Journal},
  urldate = {2019-03-30},
  date = {1972-01},
  pages = {1-24},
  author = {Wilson, Hugh R. and Cowan, Jack D.},
  file = {/Users/qualia/Documents/Papers/1972 - Wilson, Cowan - Excitatory and inhibitory interactions in localized populations of model neurons.pdf}
}

@article{Wilson1973,
  langid = {english},
  title = {A Mathematical Theory of the Functional Dynamics of Cortical and Thalamic Nervous Tissue},
  volume = {13},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/BF00288786},
  doi = {10.1007/BF00288786},
  abstract = {It is proposed that distinct anatomical regions of cerebral cortex and of thalamic nuclei are functionally two-dimensional. On this view, the third (radial) dimension of cortical and thalamic structures is associated with a redundancy of circuits and functions so that reliable signal processing obtains in the presence of noisy or ambiguous stimuli.},
  number = {2},
  journaltitle = {Kybernetik},
  urldate = {2019-03-30},
  date = {1973-09},
  pages = {55-80},
  author = {Wilson, H. R. and Cowan, J. D.},
  file = {/Users/qualia/Documents/Papers/1973 - Wilson, Cowan - A mathematical theory of the functional dynamics of cortical and thalamic nervous tissue.pdf}
}

@article{Ahrens1974,
  langid = {english},
  title = {Computer Methods for Sampling from Gamma, Beta, Poisson and Bionomial Distributions},
  volume = {12},
  issn = {0010-485X, 1436-5057},
  url = {http://link.springer.com/10.1007/BF02293108},
  doi = {10.1007/BF02293108},
  abstract = {Zusammenfassung Computer Methods for Sampling from Gamma, Beta, Poisson and Binomial Distributions. Accurate computer methods are evaluated which transform uniformly distributed random numbers into quantities that follow gamma, beta, Poisson, binomial and negative-binomial distributions. All algorithms are designed for variable parameters. The known convenient methods are slow when the parameters are large. Therefore new procedures are introduced which can cope efficiently with parameters of all sizes. Some algorithms require sampling from the normal distribution as an intermediate step. In the reported computer experiments the normal deviates were obtained from a recent method which is also described.},
  number = {3},
  journaltitle = {Computing},
  urldate = {2019-03-30},
  date = {1974-09},
  pages = {223-246},
  author = {Ahrens, J. H. and Dieter, U.},
  file = {/Users/qualia/Documents/Papers/1974 - Ahrens, Dieter - Computer methods for sampling from gamma, beta, poisson and bionomial distributions.pdf}
}

@article{LopesdaSilva1974,
  langid = {english},
  title = {Model of Brain Rhythmic Activity: {{The}} Alpha-Rhythm of the Thalamus},
  volume = {15},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/BF00270757},
  doi = {10.1007/BF00270757},
  shorttitle = {Model of Brain Rhythmic Activity},
  abstract = {I. A model of a neuronal network has been set up in a digital computer based on histological and biophysical data experimentally obtained from the thalamus; the model includes two populations of neurons interconnected by means of negative feedback; in the model allowance is also made for other sort of interactions.},
  number = {1},
  journaltitle = {Kybernetik},
  urldate = {2019-03-30},
  date = {1974},
  pages = {27-37},
  author = {Lopes da Silva, F. H. and Hoeks, A. and Smits, H. and Zetterberg, L. H.},
  file = {/Users/qualia/Documents/Papers/1974 - Lopes da Silva, Smits, Health - The Alpha-Rhythm of the Thalamus.pdf}
}

@incollection{LopesdaSilva1976,
  langid = {english},
  title = {Models of {{Neuronal Populations}}: {{The Basic Mechanisms}} of {{Rhythmicity}}},
  volume = {45},
  isbn = {978-0-444-41457-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0079612308609954},
  shorttitle = {Models of {{Neuronal Populations}}},
  booktitle = {Progress in {{Brain Research}}},
  publisher = {{Elsevier}},
  urldate = {2019-03-30},
  date = {1976},
  pages = {281-308},
  author = {Lopes da Silva, F.H. and van Rotterdam, A. and Barts, P. and van Heusden, E. and Burr, W.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/1976 - Lopes da Silva et al. - Models of neuronal populations the basic mechanisms of rhythmicity.pdf},
  doi = {10.1016/S0079-6123(08)60995-4}
}

@article{Ratcliff,
  langid = {english},
  title = {Retrieval {{Processes}} in {{Recognition Memory}}},
  pages = {25},
  author = {Ratcliff, Roger and Murdock, Bennet B},
  file = {/Users/qualia/Documents/Papers/1976 - Ratcliff, Murdock - Retrieval processes in recognition memory.pdf}
}

@article{Connor1977,
  langid = {english},
  title = {Neural Repetitive Firing: Modifications of the {{Hodgkin}}-{{Huxley}} Axon Suggested by Experimental Results from Crustacean Axons},
  volume = {18},
  issn = {00063495},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0006349577855987},
  doi = {10.1016/S0006-3495(77)85598-7},
  shorttitle = {Neural Repetitive Firing},
  abstract = {The Hodgkin-Huxley equations for space-clamped squid axon (18'C) have been modified to approximate voltage clamp data from repetitive-firing crustacean walking leg axons and activity in response to constant current stimulation has been computed. The ino and h. parameters of the sodium conductance system were shifted along the voltage axis in opposite directions so that their relative overlap was increased approximately 7 mV. Time constants, Tm and Th, were moved in a similar manner. Voltage-dependent parameters of delayed potassium conductance, n,O and T, were shifted 4.3 mV in the positive direction and Tr was uniformly increased by a factor of 2. Leakage conductance and capacitance were unchanged. Repetitive activity of this modified circuit was qualitatively similar to that of the standard model. A fifth branch was added to the circuit representing a transient potassium conductance system present in the repetitive walking leg axons and in other repetitive neurons. This model, with various parameter choices, fired repetitively down to approximately 2 spikes/s and up to 350/s. The frequency vs. stimulus current plot could be fit well by a straight line over a decade of the low frequency range and the general appearance of the spike trains was similar to that of other repetitive neurons. Stimulus intensities were of the same order as those which produce repetitive activity in the standard Hodgkin-Huxley axon. The repetitive firing rate and first spike latency (utilization time) were found to be most strongly influenced by the inactivation time constant of the transient potassium conductance (TB), the delayed potassium conductance (Tn), and the value of leakage conductance (ga. The model presents a mechanism by which stable low frequency discharge can be generated by millisecondorder membrane conductance changes.},
  number = {1},
  journaltitle = {Biophysical Journal},
  urldate = {2019-03-30},
  date = {1977-04},
  pages = {81-102},
  author = {Connor, J.A. and Walter, D. and McKown, R.},
  file = {/Users/qualia/Documents/Papers/1977 - The - Modifications of the Hodgkin-Huxley Axon Suggested.pdf}
}

@article{Shannon,
  title = {A {{Mathematical Theory}} of {{Communication}}},
  author = {Shannon, Claude},
  file = {/Users/qualia/Documents/Papers/1948 - Shannon - A Mathematical Theory of Communication.pdf}
}

@misc{zotero-2170,
  title = {1929 - {{Hans}} - {{Uber}} Das Elektrenkephalogramm Des Menshen.Pdf},
  file = {/Users/qualia/Documents/Papers/1929 - Hans - Uber das elektrenkephalogramm des menshen.pdf}
}

@misc{zotero-2171,
  title = {1961 - {{Surwillo}} - {{Frequency}} of the `{{Alpha}}' {{Rhythm}}, {{Reaction Time}} and {{Age}}.Pdf},
  file = {/Users/qualia/Documents/Papers/1961 - Surwillo - Frequency of the ‘Alpha’ Rhythm, Reaction Time and Age.pdf}
}

@misc{zotero-2172,
  title = {1955 - {{Neyman}} - {{The}} Problem of Inductive Inference.Pdf},
  file = {/Users/qualia/Documents/Papers/1955 - Neyman - The problem of inductive inference.pdf}
}

@misc{zotero-2173,
  title = {1983 - {{Chan}}, {{Golub}}, {{LeVeque}} - {{Algorithms}} for {{Computing}} the {{Sample Variance Analysis}} and {{Recommendations}}.Pdf},
  file = {/Users/qualia/Documents/Papers/1983 - Chan, Golub, LeVeque - Algorithms for Computing the Sample Variance Analysis and Recommendations.pdf}
}

@misc{zotero-2174,
  title = {1984 - {{Hindmarsh}}, {{Rose}} - {{A Model}} of {{Neuronal Bursting Using Three Coupled First Order Differential Equations}}.Pdf},
  file = {/Users/qualia/Documents/Papers/1984 - Hindmarsh, Rose - A Model of Neuronal Bursting Using Three Coupled First Order Differential Equations.pdf}
}

@misc{zotero-2175,
  title = {1987 - {{Reiter}} - {{Nonmonotonic}} Reasoning.Pdf},
  file = {/Users/qualia/Documents/Papers/1987 - Reiter - Nonmonotonic reasoning.pdf}
}

@misc{zotero-2176,
  title = {1988 - {{Intended}}, {{Minsky}} - {{No Harm Intended}}.Pdf},
  file = {/Users/qualia/Documents/Papers/1988 - Intended, Minsky - No Harm Intended.pdf}
}

@article{Fang1991,
  langid = {english},
  title = {A Method to Effect Physiological Recruitment Order in Electrically Activated Muscle},
  volume = {38},
  issn = {00189294},
  url = {http://ieeexplore.ieee.org/document/76384/},
  doi = {10.1109/10.76384},
  abstract = {A new stimulation method has been utilized to achieve physiological recruitment order of small-to-large motor units in electrically activated muscles. The use of quasitrapezoidal-shaped pulses and a tripolar cuff electrode made selective activation of small motor axons possible, thus recruiting slow-twitch, fatigue-resistant muscle units before fast-twitch, fatigable units in a heterogeneous muscle. Isometric contraction force from the medial gastrocnemius muscle was measured in five cats. The physiological recruitment order was evidenced by larger twitch widths at lower force levels and smaller twitch widths at higher force levels in the muscles tested. In addition, force modulation process was more gradual and fused contractions were obtained at lower stimulation frequencies when the new stimulation method was employed. Furthermore, muscles activated by the new method were more fatigue-resistant under repetitive activation at low force levels. This stimulation method is simpler to implement and has fewer adverse effects on the neuromuscular system than previous blocking methods. Therefore, it may have applications in future functional neuromuscular stimulation systems.},
  number = {2},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  urldate = {2019-03-30},
  year = {Feb./1991},
  pages = {175-179},
  author = {Fang, Z.-P. and Mortimer, J.T.},
  file = {/Users/qualia/Documents/Papers/1991 - Fang, Mortimer - A Method to Effect Physiological Recruitment Order in Electrically Activated Muscle.pdf}
}

@article{Jefferys,
  langid = {english},
  title = {Sharpening {{Ockham}}'s {{Razor}} on a {{Bayesian Strop}} ({{Key}} Terms: {{Bayes}}' Theorem {{Ockham}}'s Razor)},
  pages = {14},
  author = {Jefferys, William H and Berger, James O},
  file = {/Users/qualia/Documents/Papers/1991 - Je, Berger - Sharpening Ockham ' s Razor on a Bayesian Strop ( Key terms Bayes ' theorem Ockham ' s razor ).pdf}
}

@article{Schmidhuber,
  langid = {english},
  title = {A {{Possibility}} for {{Implementing Curiosity}} and {{Boredom}} in {{Model}}-{{Building Neural Controllers}}},
  pages = {7},
  author = {Schmidhuber, Jurgen},
  file = {/Users/qualia/Documents/Papers/1991 - Urgen Schmidhuber - A Possibility for Implementing Curiosity and Boredom in Model-Building Neural Controllers.pdf}
}

@misc{zotero-2180,
  title = {1989 - {{LeCun}} et Al. - {{Backpropagation}} Applied to Handwritten Zip Code Recognition.Pdf},
  file = {/Users/qualia/Documents/Papers/1989 - LeCun et al. - Backpropagation applied to handwritten zip code recognition.pdf}
}

@article{Schmidhuber1991,
  title = {A Possibility for Implementing Curiosity and Boredom in Model-Building Neural Controllers},
  journaltitle = {Proc. of the international conference on simulation of adaptive behavior: From animals to animats},
  date = {1991},
  pages = {222-227},
  author = {Schmidhuber},
  file = {/Users/qualia/Documents/Papers/1991 - Schmidhuber - A possibility for implementing curiosity and boredom in model-building neural controllers.pdf}
}

@misc{zotero-2182,
  title = {1992 - {{Heeger}} - {{Normalization}} of Cell Responses in Cat Striate Cortex.Pdf},
  file = {/Users/qualia/Documents/Papers/1992 - Heeger - Normalization of cell responses in cat striate cortex.pdf}
}

@misc{zotero-2183,
  title = {1992 - {{Williams}} - {{Simple}} Statistical Gradient-Following Algorithmns for Connectionist Reinforcement Learning.Pdf},
  file = {/Users/qualia/Documents/Papers/1992 - Williams - Simple statistical gradient-following algorithmns for connectionist reinforcement learning.pdf}
}

@misc{zotero-2184,
  title = {1996 - {{Mainen}}, {{Sejnowski}} - {{Influence}} of Dendritic Structure on Firing Pattern in Model Neocortical Neurons.Pdf},
  file = {/Users/qualia/Documents/Papers/1996 - Mainen, Sejnowski - Influence of dendritic structure on firing pattern in model neocortical neurons.pdf}
}

@article{Schmidhuber2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.09249},
  primaryClass = {cs},
  langid = {english},
  title = {On {{Learning}} to {{Think}}: {{Algorithmic Information Theory}} for {{Novel Combinations}} of {{Reinforcement Learning Controllers}} and {{Recurrent Neural World Models}}},
  url = {http://arxiv.org/abs/1511.09249},
  shorttitle = {On {{Learning}} to {{Think}}},
  abstract = {This paper addresses the general problem of reinforcement learning (RL) in partially observable environments. In 2013, our large RL recurrent neural networks (RNNs) learned from scratch to drive simulated cars from high-dimensional video input. However, real brains are more powerful in many ways. In particular, they learn a predictive model of their initially unknown environment, and somehow use it for abstract (e.g., hierarchical) planning and reasoning. Guided by algorithmic information theory, we describe RNN-based AIs (RNNAIs) designed to do the same. Such an RNNAI can be trained on never-ending sequences of tasks, some of them provided by the user, others invented by the RNNAI itself in a curious, playful fashion, to improve its RNN-based world model. Unlike our previous model-building RNN-based RL machines dating back to 1990, the RNNAI learns to actively query its model for abstract reasoning and planning and decision making, essentially ``learning to think.'' The basic ideas of this report can be applied to many other cases where one RNN-like system exploits the algorithmic information content of another. They are taken from a grant proposal submitted in Fall 2014, and also explain concepts such as ``mirror neurons.'' Experimental results will be described in separate papers.},
  urldate = {2019-03-30},
  date = {2015-11-30},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Artificial Intelligence},
  author = {Schmidhuber, Juergen},
  file = {/Users/qualia/Documents/Papers/2015 - Schmidhuber - On Learning to Think Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers an.pdf}
}

@article{Worden,
  langid = {english},
  title = {Anticipatory {{Biasing}} of {{Visuospatial Attention Indexed}} by {{Retinotopically Specific}} \textvisiblespace{}-{{Band Electroencephalography Increases}} over {{Occipital Cortex}}},
  pages = {6},
  author = {Worden, Michael S and Foxe, John J and Wang, Norman and Simpson, Gregory V},
  file = {/Users/qualia/Documents/Papers/2000 - Worden et al. - Anticipatory biasing of visuospatial attention indexed by retinotopically specific alpha-band electroencephalogra.pdf}
}

@article{Barbour2001,
  langid = {english},
  title = {An {{Evaluation}} of {{Synapse Independence}}},
  volume = {21},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.21-20-07969.2001},
  doi = {10.1523/JNEUROSCI.21-20-07969.2001},
  number = {20},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2001-10-15},
  pages = {7969-7984},
  author = {Barbour, Boris},
  file = {/Users/qualia/Documents/Papers/2001 - Barbour - An Evaluation of Synapse Independence.pdf}
}

@article{Baumgartner2001,
  langid = {english},
  title = {Graphical Display of {{fMRI}} Data: Visualizing Multidimensional Space},
  volume = {19},
  issn = {0730725X},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0730725X0100296X},
  doi = {10.1016/S0730-725X(01)00296-X},
  shorttitle = {Graphical Display of {{fMRI}} Data},
  abstract = {Visualization of multidimensional data is an integral part of computational statistics and exploratory data analysis (EDA). We show how visualization of fMRI time-courses may be used to reveal the fMRI data structure. We consider fMRI time-courses (TCs) as points in multidimensional space. In simulated and in vivo data, we show that minimum spanning tree (MST)-based sequencing of multivariate time-courses, in combination with a homogeneity map visualization, allows for effective and useful graphical display of the groups of coactivated time-courses obtained by temporal clustering. This display may serve as a tool for investigation of brain connectivity. We also suggest a simple overall display of the entire fMRI data set. \textcopyright{} 2001 Elsevier Science Inc. All rights reserved.},
  number = {2},
  journaltitle = {Magnetic Resonance Imaging},
  urldate = {2019-03-30},
  date = {2001-02},
  pages = {283-286},
  author = {Baumgartner, R and Somorjai, R},
  file = {/Users/qualia/Documents/Papers/2001 - Baumgartner, Somorjai - Graphical display of fMRI data visualizing multidimensional space.pdf}
}

@article{Bendor2001,
  langid = {english},
  title = {{{ASPIRATION}}-{{BASED REINFORCEMENT LEARNING IN REPEATED INTERACTION GAMES}}: {{AN OVERVIEW}}},
  volume = {03},
  issn = {0219-1989, 1793-6675},
  url = {http://www.worldscientific.com/doi/abs/10.1142/S0219198901000348},
  doi = {10.1142/S0219198901000348},
  shorttitle = {{{ASPIRATION}}-{{BASED REINFORCEMENT LEARNING IN REPEATED INTERACTION GAMES}}},
  issue = {02n03},
  journaltitle = {International Game Theory Review},
  urldate = {2019-03-30},
  date = {2001-06},
  pages = {159-174},
  author = {Bendor, Jonathan and Mookherjee, Dilip and Ray, Debraj},
  file = {/Users/qualia/Documents/Papers/2001 - BENDOR, MOOKHERJEE, RAY - Aspiration-Based Reinforcement Learning in Repeated Interaction Games an Overview.pdf}
}

@article{Bowling,
  langid = {english},
  title = {Rational and {{Convergent Learning}} in {{Stochastic Games}}},
  abstract = {This paper investigates the problem of policy learning in multiagent environments using the stochastic game framework, which we briefly overview. We introduce two properties as desirable for a learning agent when in the presence of other learning agents, namely rationality and convergence. We examine existing reinforcement learning algorithms according to these two properties and notice that they fail to simultaneously meet both criteria. We then contribute a new learning algorithm, WoLF policy hillclimbing, that is based on a simple principle: ``learn quickly while losing, slowly while winning.'' The algorithm is proven to be rational and we present empirical results for a number of stochastic games showing the algorithm converges.},
  pages = {6},
  author = {Bowling, Michael and Veloso, Manuela},
  file = {/Users/qualia/Documents/Papers/2001 - Bowling, Veloso - Rational and convergent learning in stochastic games.pdf}
}

@article{Callaway2001,
  langid = {english},
  title = {Are Randomly Grown Graphs Really Random?},
  volume = {64},
  issn = {1063-651X, 1095-3787},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.64.041902},
  doi = {10.1103/PhysRevE.64.041902},
  number = {4},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2001-09-20},
  author = {Callaway, Duncan S. and Hopcroft, John E. and Kleinberg, Jon M. and Newman, M. E. J. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/2001 - Callaway et al. - Are randomly grown graphs really random.pdf}
}

@article{Caraballo2001,
  langid = {english},
  title = {Attractors for {{Differential Equations}} with {{Variable Delays}}},
  volume = {260},
  issn = {0022247X},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0022247X0097464X},
  doi = {10.1006/jmaa.2000.7464},
  number = {2},
  journaltitle = {Journal of Mathematical Analysis and Applications},
  urldate = {2019-03-30},
  date = {2001-08},
  pages = {421-438},
  author = {Caraballo, Tom\'as and Langa, Jos\'e A. and Robinson, James C.},
  file = {/Users/qualia/Documents/Papers/2001 - Caraballo, Langa, Robinson - Attractors for Differential Equations with Variable Delays.pdf}
}

@article{Crespo-Facorro2001,
  langid = {english},
  title = {Neural {{Mechanisms}} of {{Anhedonia}} in {{Schizophrenia}}: {{A PET Study}} of {{Response}} to {{Unpleasant}} and {{Pleasant Odors}}},
  volume = {286},
  issn = {0098-7484},
  url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.286.4.427},
  doi = {10.1001/jama.286.4.427},
  shorttitle = {Neural {{Mechanisms}} of {{Anhedonia}} in {{Schizophrenia}}},
  abstract = {Objective To study the neural basis of emotional processing in schizophrenia by exploring the pattern of brain responses to olfactory stimuli in patients and healthy volunteers. Design Positron emission tomographic study of patients with schizophrenia and healthy volunteers. Positron emission tomographic data were collected between July 21, 1995, and September 11, 1997, and data analyses were conducted in 1999-2001. Setting The Mental Health Clinical Research Center at the University of Iowa, Iowa City. Participants Sixteen healthy volunteers with a mean age of 29.5 years and 18 patients with schizophrenia and a mean age of 30.0 years. Main Outcome Measure Areas of relative increase or decrease in regional cerebral blood flow, measured using positron emission tomography and the [15O]water method while participants performed an emotion-induction olfactory task to determine response to pleasant (vanillin) and unpleasant (4-methylvaleric acid) odors, compared between patients and healthy volunteers.
Results Patients with schizophrenia subjectively experienced unpleasant odors in a manner similar to healthy volunteers but showed impairment in the experience of pleasant odors. The analysis of the regional cerebral blood flow revealed that patients failed to activate limbic/paralimbic regions (eg, insular cortex, nucleus accumbens, and parahippocampal gyrus) during the experience of unpleasant odors, recruiting a compensatory set of frontal cortical regions instead.
Conclusion Abnormalities in the complex functional interactions between mesolimbic and frontal regions may underlie emotional disturbances in schizophrenia. JAMA. 2001;286:427-435},
  number = {4},
  journaltitle = {JAMA},
  urldate = {2019-03-30},
  date = {2001-07-25},
  pages = {427},
  author = {Crespo-Facorro, Benedicto and Paradiso, Sergio and Andreasen, Nancy C. and O'Leary, Daniel S. and Watkins, G. Leonard and Ponto, Laura L. B. and Hichwa, Richard D.},
  file = {/Users/qualia/Documents/Papers/2001 - Crespo-Facorro et al. - Neural Mechanisms of Anhedonia in Schizophrenia A PET Study of Response to Unpleasant and Pleasant Odors.pdf}
}

@article{Doiron2001,
  langid = {english},
  title = {Subtractive and {{Divisive Inhibition}}: {{Effect}} of {{Voltage}}-{{Dependent Inhibitory Conductances}} and {{Noise}}},
  volume = {13},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976601300014691},
  doi = {10.1162/089976601300014691},
  shorttitle = {Subtractive and {{Divisive Inhibition}}},
  number = {1},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2001-01},
  pages = {227-248},
  author = {Doiron, Brent and Longtin, Andr\'e and Berman, Neil and Maler, Leonard},
  file = {/Users/qualia/Documents/Papers/2001 - Doiron et al. - Subtractive and divisive inhibition effect of voltage-dependent inhibitory conductances and noise.pdf}
}

@article{Fries2001,
  langid = {english},
  title = {Modulation of {{Oscillatory Neuronal Synchronization}} by {{Selective Visual Attention}}},
  volume = {291},
  issn = {00368075, 10959203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1055465},
  doi = {10.1126/science.1055465},
  number = {5508},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2001-02-23},
  pages = {1560-1563},
  author = {Fries, P.},
  file = {/Users/qualia/Documents/Papers/2001 - Fries - Modulation of Oscillatory Neuronal Synchronization by Selective Visual Attention.pdf}
}

@article{Goeree2001,
  langid = {english},
  title = {Ten {{Little Treasures}} of {{Game Theory}} and {{Ten Intuitive Contradictions}}},
  volume = {91},
  issn = {0002-8282},
  url = {http://pubs.aeaweb.org/doi/10.1257/aer.91.5.1402},
  doi = {10.1257/aer.91.5.1402},
  abstract = {This paper reports data for a series of two-person games that are played only once. These games span the standard categories: static and dynamic games with complete and incomplete information. For each game, the treasure is a treatment for which behavior conforms quite nicely to the predictions of the Nash equilibrium or relevant refinement. In each case we change a key payoff parameter in a manner that does not alter the equilibrium predictions, but this theoretically neutral payoff change has a major (often dramatic) effect on observed behavior. These contradictions are typically consistent with simple economic intuition and with some recent theoretical work that incorporates bounded rationality.},
  number = {5},
  journaltitle = {American Economic Review},
  urldate = {2019-03-30},
  date = {2001-12},
  pages = {1402-1422},
  author = {Goeree, Jacob K and Holt, Charles A},
  file = {/Users/qualia/Documents/Papers/2001 - Goeree, Holt - Ten little treasure of game theory and ten intuitive contradictions.pdf}
}

@article{Gurney2001,
  langid = {english},
  title = {A Computational Model of Action Selection in the Basal Ganglia. {{I}}. {{A}} New Functional Anatomy},
  volume = {84},
  issn = {0340-1200},
  url = {http://link.springer.com/10.1007/PL00007984},
  doi = {10.1007/PL00007984},
  abstract = {We present a biologically plausible model of processing intrinsic to the basal ganglia based on the computational premise that action selection is a primary role of these central brain structures. By encoding the propensity for selecting a given action in a scalar value (the salience), it is shown that action selection may be recast in terms of signal selection. The generic properties of signal selection are de\textregistered{}ned and neural networks for this type of computation examined. A comparison between these networks and basal ganglia anatomy leads to a novel functional decomposition of the basal ganglia architecture into `selection' and `control' pathways. The former pathway performs the selection per se via a feedforward o-centre on-surround network. The control pathway regulates the action of the selection pathway to ensure its eective operation, and synergistically complements its dopaminergic modulation. The model contrasts with the prevailing functional segregation of basal ganglia into `direct' and `indirect' pathways.},
  number = {6},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2001-05-11},
  pages = {401-410},
  author = {Gurney, K. and Prescott, T. J. and Redgrave, P.},
  file = {/Users/qualia/Documents/Papers/2001 - Gurney, Prescott, Redgrave - A computational model of action selection in the basal ganglia. I. A new functional anatomy.pdf}
}

@article{Gurney2001a,
  langid = {english},
  title = {A Computational Model of Action Selection in the Basal Ganglia. {{II}}. {{Analysis}} and Simulation of Behaviour},
  volume = {84},
  issn = {0340-1200},
  url = {http://link.springer.com/10.1007/PL00007985},
  doi = {10.1007/PL00007985},
  abstract = {In a companion paper a new functional architecture was proposed for the basal ganglia based on the premise that these brain structures play a central role in behavioural action selection. The current paper quantitatively describes the properties of the model using analysis and simulation. The decomposition of the basal ganglia into selection and control pathways is supported in several ways. First, several elegant features are exposed {$\pm$} capacity scaling, enhanced selectivity and synergistic dopamine modulation {$\pm$} which might be expected to exist in a well designed action selection mechanism. The discovery of these features also lends support to the computational premise of selection that underpins our model. Second, good matches between model globus pallidus external segment output and globus pallidus internal segment and substantia nigra reticulata area output, and neurophysiological data, have been found which are indicative of common architectural features in the model and biological basal ganglia. Third, the behaviour of the model as a signal selection mechanism has parallels with some kinds of action selection observed in animals under various levels of dopaminergic modulation.},
  number = {6},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2001-05-11},
  pages = {411-423},
  author = {Gurney, K. and Prescott, T. J. and Redgrave, P.},
  file = {/Users/qualia/Documents/Papers/2001 - Gurney, Prescott, Redgrave - A computational model of action selection in the basal ganglia. II. Analysis and simulation of behav.pdf}
}

@incollection{Hart2001,
  langid = {english},
  location = {{Berlin, Heidelberg}},
  title = {A {{Reinforcement Procedure Leading}} to {{Correlated Equilibrium}}},
  isbn = {978-3-642-07539-1 978-3-662-04623-4},
  url = {http://link.springer.com/10.1007/978-3-662-04623-4_12},
  abstract = {We consider repeated games where at any period each player knows only his set of actions and the stream of payoffs that he has received in the past. He knows neither his own payoff function, nor the characteristics of the other players (how many there are, their strategies and payoffs). In this context, we present an adaptive procedure for play \textemdash{} called ``modified-regret-matching'' \textemdash{} which is interpretable as a stimulus-response or reinforcement procedure, and which has the property that any limit point of the empirical distribution of play is a correlated equilibrium of the stage game.},
  booktitle = {Economics {{Essays}}},
  publisher = {{Springer Berlin Heidelberg}},
  urldate = {2019-03-30},
  date = {2001},
  pages = {181-200},
  author = {Hart, Sergiu and Mas-Colell, Andreu},
  editor = {Debreu, G\'erard and Neuefeind, Wilhelm and Trockel, Walter},
  file = {/Users/qualia/Documents/Papers/2001 - Hart, Mas-colell - Economics Essays.pdf},
  doi = {10.1007/978-3-662-04623-4_12}
}

@article{Haxby2001,
  langid = {english},
  title = {Distributed and {{Overlapping Representations}} of {{Faces}} and {{Objects}} in {{Ventral Temporal Cortex}}},
  volume = {293},
  issn = {00368075, 10959203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1063736},
  doi = {10.1126/science.1063736},
  number = {5539},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2001-09-28},
  pages = {2425-2430},
  author = {Haxby, J. V.},
  file = {/Users/qualia/Documents/Papers/2001 - Haxby et al. - Distributed and overlapping representations of faces and objects in ventral temporal cortex.pdf}
}

@article{Megias2001,
  langid = {english},
  title = {Total Number and Distribution of Inhibitory and Excitatory Synapses on Hippocampal {{CA1}} Pyramidal Cells},
  volume = {102},
  issn = {03064522},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0306452200004966},
  doi = {10.1016/S0306-4522(00)00496-6},
  abstract = {The integrative properties of neurons depend strongly on the number, proportions and distribution of excitatory and inhibitory synaptic inputs they receive. In this study the three-dimensional geometry of dendritic trees and the density of symmetrical and asymmetrical synapses on different cellular compartments of rat hippocampal CA I area pyramidal cells was measured to calculate the total number and distribution of excitatory and inhibitory inputs on a single cell.},
  number = {3},
  journaltitle = {Neuroscience},
  urldate = {2019-03-30},
  date = {2001-02},
  pages = {527-540},
  author = {Meg\i\'as, M and Emri, Zs and Freund, T.F and Guly\'as, A.I},
  file = {/Users/qualia/Documents/Papers/2001 - Megías et al. - Total number and distribution of inhibitory and excitatory synapses on hippocampal CA1 pyramidal cells.pdf}
}

@article{Miller2001,
  langid = {english},
  title = {Processing in Layer 4 of the Neocortical Circuit: New Insights from Visual and Somatosensory Cortex},
  volume = {11},
  issn = {09594388},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438800002397},
  doi = {10.1016/S0959-4388(00)00239-7},
  shorttitle = {Processing in Layer 4 of the Neocortical Circuit},
  number = {4},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2001-08-01},
  pages = {488-497},
  author = {Miller, K},
  file = {/Users/qualia/Documents/Papers/2001 - Miller, Pinto, Simons - Processing in layer 4 of the neocortical circuit New insights from visual and somatosensory cortex.pdf}
}

@article{Nutt2001,
  langid = {english},
  title = {Interactions between Deep Brain Stimulation and Levodopa in {{Parkinson}}'s Disease},
  volume = {57},
  issn = {0028-3878, 1526-632X},
  url = {http://www.neurology.org/cgi/doi/10.1212/WNL.57.10.1835},
  doi = {10.1212/WNL.57.10.1835},
  number = {10},
  journaltitle = {Neurology},
  urldate = {2019-03-30},
  date = {2001-11-27},
  pages = {1835-1842},
  author = {Nutt, J.G. and Rufener, S.L. and Carter, J.H. and Anderson, V.C. and Pahwa, R. and Hammerstad, J.P. and Burchiel, K.J.},
  file = {/Users/qualia/Documents/Papers/2001 - Nutt et al. - Interactions between deep brain stimulation and levodopa in Parkinson ’ s disease.pdf}
}

@article{Perlstein2001,
  langid = {english},
  title = {Relation of {{Prefrontal Cortex Dysfunction}} to {{Working Memory}} and {{Symptoms}} in {{Schizophrenia}}},
  volume = {158},
  issn = {0002-953X, 1535-7228},
  url = {http://psychiatryonline.org/doi/abs/10.1176/appi.ajp.158.7.1105},
  doi = {10.1176/appi.ajp.158.7.1105},
  number = {7},
  journaltitle = {American Journal of Psychiatry},
  urldate = {2019-03-30},
  date = {2001-07},
  pages = {1105-1113},
  author = {Perlstein, William M. and Carter, Cameron S. and Noll, Douglas C. and Cohen, Jonathan D.},
  file = {/Users/qualia/Documents/Papers/2001 - Perlstein et al. - Relation of Prefrontal Cortex Dysfunction to Working Memory and Symptoms in Schizophrenia.pdf}
}

@article{Sato2001,
  langid = {english},
  title = {Search {{Efficiency}} but {{Not Response Interference Affects Visual Selection}} in {{Frontal Eye Field}}},
  volume = {30},
  issn = {08966273},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S089662730100304X},
  doi = {10.1016/S0896-6273(01)00304-X},
  abstract = {Two manipulations of a visual search task were used to test the hypothesis that the discrimination of a target from distractors by visually responsive neurons in the frontal eye field (FEF) marks the outcome and conclusion of visual processing instead of saccade preparation. First, search efficiency was reduced by increasing the similarity of the distractors to the target. Second, response interference was introduced by infrequently changing the location of the target in the array. Both manipulations increased reaction time, but only the change in search efficiency affected the time needed to select the target by visually responsive neurons. This result indicates that visually responsive neurons in FEF form an explicit representation of the location of the target in the image.},
  number = {2},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2001-05},
  pages = {583-591},
  author = {Sato, Takashi and Murthy, Aditya and Thompson, Kirk G. and Schall, Jeffrey D.},
  file = {/Users/qualia/Documents/Papers/2001 - Sato et al. - Search efficiency but not response interference affects visual selection in frontal eye field.pdf}
}

@article{Attwell2002,
  langid = {english},
  title = {The Neural Basis of Functional Brain Imaging Signals},
  volume = {25},
  issn = {01662236},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0166223602022646},
  doi = {10.1016/S0166-2236(02)02264-6},
  number = {12},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {2002-12},
  pages = {621-625},
  author = {Attwell, David and Iadecola, Costantino},
  file = {/Users/qualia/Documents/Papers/2002 - Attwell, Iadecola - The neural basis of functional brain imaging signals.pdf}
}

@article{Bandt2002,
  langid = {english},
  title = {Permutation {{Entropy}}: {{A Natural Complexity Measure}} for {{Time Series}}},
  volume = {88},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.88.174102},
  doi = {10.1103/PhysRevLett.88.174102},
  shorttitle = {Permutation {{Entropy}}},
  number = {17},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2002-04-11},
  author = {Bandt, Christoph and Pompe, Bernd},
  file = {/Users/qualia/Documents/Papers/2002 - Bandt, Pompe - Permutation entropy a natural complexity measure for time series.pdf}
}

@article{Bowling2002,
  langid = {english},
  title = {Multiagent Learning Using a Variable Learning Rate},
  volume = {136},
  issn = {00043702},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370202001212},
  doi = {10.1016/S0004-3702(02)00121-2},
  abstract = {Learning to act in a multiagent environment is a difficult problem since the normal definition of an optimal policy no longer applies. The optimal policy at any moment depends on the policies of the other agents. This creates a situation of learning a moving target. Previous learning algorithms have one of two shortcomings depending on their approach. They either converge to a policy that may not be optimal against the specific opponents' policies, or they may not converge at all. In this article we examine this learning problem in the framework of stochastic games. We look at a number of previous learning algorithms showing how they fail at one of the above criteria. We then contribute a new reinforcement learning technique using a variable learning rate to overcome these shortcomings. Specifically, we introduce the WoLF principle, ``Win or Learn Fast,'' for varying the learning rate. We examine this technique theoretically, proving convergence in self-play on a restricted class of iterated matrix games. We also present empirical results on a variety of more general stochastic games, in situations of self-play and otherwise, demonstrating the wide applicability of this method.},
  number = {2},
  journaltitle = {Artificial Intelligence},
  urldate = {2019-03-30},
  date = {2002-04},
  pages = {215-250},
  author = {Bowling, Michael and Veloso, Manuela},
  file = {/Users/qualia/Documents/Papers/2002 - Bowling, Veloso - Multiagent learning using a variable learning rate.pdf}
}

@article{Camerer2002,
  langid = {english},
  title = {Sophisticated {{Experience}}-{{Weighted Attraction Learning}} and {{Strategic Teaching}} in {{Repeated Games}}},
  volume = {104},
  issn = {00220531},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0022053102929273},
  doi = {10.1006/jeth.2002.2927},
  number = {1},
  journaltitle = {Journal of Economic Theory},
  urldate = {2019-03-30},
  date = {2002-05},
  pages = {137-188},
  author = {Camerer, Colin F. and Ho, Teck-Hua and Chong, Juin-Kuan},
  file = {/Users/qualia/Documents/Papers/2002 - Camerer, Ho, Chong - Sophisticated experience-weighted attraction learning and strategic teaching in repeated games.pdf}
}

@article{Daw2002,
  langid = {english},
  title = {Opponent Interactions between Serotonin and Dopamine},
  volume = {15},
  issn = {08936080},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608002000527},
  doi = {10.1016/S0893-6080(02)00052-7},
  abstract = {Anatomical and pharmacological evidence suggests that the dorsal raphe serotonin system and the ventral tegmental and substantia nigra dopamine system may act as mutual opponents. In the light of the temporal difference model of the involvement of the dopamine system in reward learning, we consider three aspects of motivational opponency involving dopamine and serotonin. We suggest that a tonic serotonergic signal reports the long-run average reward rate as part of an average-case reinforcement learning model; that a tonic dopaminergic signal reports the long-run average punishment rate in a similar context; and finally speculate that a phasic serotonin signal might report an ongoing prediction error for future punishment. q 2002 Elsevier Science Ltd. All rights reserved.},
  number = {4-6},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2002-06},
  pages = {603-616},
  author = {Daw, Nathaniel D and Kakade, Sham and Dayan, Peter},
  file = {/Users/qualia/Documents/Papers/2002 - Daw, Kakade, Dayan - Opponent interactions between serotonin and dopamine.pdf}
}

@article{Deb2002,
  langid = {english},
  title = {A Fast and Elitist Multiobjective Genetic Algorithm: {{NSGA}}-{{II}}},
  volume = {6},
  issn = {1089778X},
  url = {http://ieeexplore.ieee.org/document/996017/},
  doi = {10.1109/4235.996017},
  shorttitle = {A Fast and Elitist Multiobjective Genetic Algorithm},
  number = {2},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  urldate = {2019-03-30},
  date = {2002-04},
  pages = {182-197},
  author = {Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
  file = {/Users/qualia/Documents/Papers/2002 - Deb et al. - A fast and elitist multiobjective genetic algorithm NSGA-II.pdf}
}

@article{Duann2002,
  langid = {english},
  title = {Single-{{Trial Variability}} in {{Event}}-{{Related BOLD Signals}}},
  volume = {15},
  issn = {10538119},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811901910493},
  doi = {10.1006/nimg.2001.1049},
  number = {4},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2002-04},
  pages = {823-835},
  author = {Duann, Jeng-Ren and Jung, Tzyy-Ping and Kuo, Wen-Jui and Yeh, Tzu-Chen and Makeig, Scott and Hsieh, Jen-Chuen and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/2002 - Duann et al. - Single-trial variability in event-related BOLD signals.pdf}
}

@article{Feltovich,
  langid = {english},
  title = {John {{Du}} Y {{Department}} of {{Economics University}} of {{Pittsburgh Pittsburgh}}, {{PA}} 15260, {{USA}} Jdu Y+@pitt.Edu},
  abstract = {How do individuals achieve good outcomes" in one shot strategic situations? One much explored possibility is that they engage in some kind of preplay communication|cheap talk|in which they endeavor to convince one another of the actions they intend to play. However, there may be no incentive for such communication to be truthful, or even informative. Another, less explored, possibility is that individuals take account of their knowledge of the past behavior of others when deciding which actions to play. While these two possibilities have been considered separately, there has been little research comparing the importance of these two devices as aids in achieving good outcomes. We design and run an experiment with human subjects that allows for such a comparison. The e ects of cheap talk and observation of past actions are compared with each other, and with the standard control case where neither cheap talk nor observation is allowed. We consider three di erent 2  2 games and explain why cheap talk or observation is likely to be the more e ective device for achieving good outcomes in each game. The experimental evidence suggests that both devices|cheap talk and observation| make cooperation and successful coordination more likely and increase payo s relative to the control. The relative success of cheap talk versus observation in achieving such good outcomes depends on the game played, in accordance with our predictions. We also nd that the signals players send are informative in the sense that they are cor related with their eventual actions, and that receivers of signals take this fact into account by conditioning their actions on the signal they receive. The results of this experiment can be used to extend game theoretic models of how individuals make use of the di erent types of information available in strategic environments. As a rst step in this direction, we construct a learning model in which individuals can condition their behavior on cheap talk or observed past actions, and we show that this model provides a good quantitative as well as qualitative t to the experimental data.},
  pages = {50},
  author = {Feltovich, Nick},
  file = {/Users/qualia/Documents/Papers/2002 - Duffy, Feltovich - Do actions speak louder than words An experimental comparison of observation and cheap talk.pdf}
}

@article{Fourcaud2002,
  langid = {english},
  title = {Dynamics of the {{Firing Probability}} of {{Noisy Integrate}}-and-{{Fire Neurons}}},
  volume = {14},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976602320264015},
  doi = {10.1162/089976602320264015},
  number = {9},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2002-09},
  pages = {2057-2110},
  author = {Fourcaud, Nicolas and Brunel, Nicolas},
  file = {/Users/qualia/Documents/Papers/2002 - Fourcaud, Brunel - Dynamics of the firing probability of noisy integrate-and-fire neurons.pdf}
}

@article{Gunnthorsdottir2002,
  langid = {english},
  title = {Using the {{Machiavellianism}} Instrument to Predict Trustworthiness in a Bargaining Game},
  volume = {23},
  issn = {01674870},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167487001000678},
  doi = {10.1016/S0167-4870(01)00067-8},
  abstract = {Game-theoretic experiments have revealed substantial individual differences where the game allows for off-equilibrium behavior such as trust and reciprocity. We explore the personality psychology and decision making literatures and conclude that these individual differences are likely to be mediated by differential emotional arousal. We argue that Christie and Geis's Machiavellianism scale (Mach-IV) is an instrument that allows the identification of types who vary in cooperativeness. We use that test to predict the behavior of participants in a two-person one-shot constituent game in which subjects face a choice between trust and distrust, and between reciprocation (trustworthiness) and defection. We find that the Mach-IV scale does not predict trusting behavior. It does, however, predict reciprocity. Over one half of those who score low to average on the scale reciprocate trust. High scorers overwhelmingly defect when it is to their advantage to do so. \'O 2002 Elsevier Science B.V. All rights reserved.},
  number = {1},
  journaltitle = {Journal of Economic Psychology},
  urldate = {2019-03-30},
  date = {2002-02},
  pages = {49-66},
  author = {Gunnthorsdottir, Anna and McCabe, Kevin and Smith, Vernon},
  file = {/Users/qualia/Documents/Papers/2002 - Gunnthorsdottir, McCabe, Smith - Using the Machiavellianism instrument to predict trustworthiness in a bargaining game.pdf}
}

@article{Hansel2002,
  langid = {english},
  title = {How {{Noise Contributes}} to {{Contrast Invariance}} of {{Orientation Tuning}} in {{Cat Visual Cortex}}},
  volume = {22},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.22-12-05118.2002},
  doi = {10.1523/JNEUROSCI.22-12-05118.2002},
  number = {12},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2002-06-15},
  pages = {5118-5128},
  author = {Hansel, D. and van Vreeswijk, C.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2002 - Hansel, van Vreeswijk - How noise contributes to contrast invariance of orientation tuning in cat visual cortex.pdf}
}

@article{Jensen2002,
  langid = {english},
  title = {Oscillations in the {{Alpha Band}} (9-12 {{Hz}}) {{Increase}} with {{Memory Load}} during {{Retention}} in a {{Short}}-Term {{Memory Task}}},
  volume = {12},
  issn = {14602199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/12.8.877},
  doi = {10.1093/cercor/12.8.877},
  number = {8},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2002-08-01},
  pages = {877-882},
  author = {Jensen, O.},
  file = {/Users/qualia/Documents/Papers/2002 - Jensen et al. - Oscillations in the alpha band (9-12 Hz) increase with memory load during retention in a short-term memory task.pdf}
}

@article{Kakade2002,
  langid = {english},
  title = {Dopamine: Generalization and Bonuses},
  volume = {15},
  issn = {08936080},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608002000485},
  doi = {10.1016/S0893-6080(02)00048-5},
  shorttitle = {Dopamine},
  abstract = {In the temporal difference model of primate dopamine neurons, their phasic activity reports a prediction error for future reward. This model is supported by a wealth of experimental data. However, in certain circumstances, the activity of the dopamine cells seems anomalous under the model, as they respond in particular ways to stimuli that are not obviously related to predictions of reward. In this paper, we address two important sets of anomalies, those having to do with generalization and novelty. Generalization responses are treated as the natural consequence of partial information; novelty responses are treated by the suggestion that dopamine cells multiplex information about reward bonuses, including exploration bonuses and shaping bonuses. We interpret this additional role for dopamine in terms of the mechanistic attentional and psychomotor effects of dopamine, having the computational role of guiding exploration. q 2002 Published by Elsevier Science Ltd.},
  number = {4-6},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2002-06},
  pages = {549-559},
  author = {Kakade, Sham and Dayan, Peter},
  file = {/Users/qualia/Documents/Papers/2002 - Kakade, Dayan - Dopamine Generalization and bonuses.pdf}
}

@article{Levy,
  langid = {english},
  title = {Galton's {{Two Papers}} on {{Voting}} as {{Robust Estimation}}},
  abstract = {The relationship between voting and robust estimation was discussed by Francis Galton in 1907. His two papers in Nature are discussed and reprinted.},
  pages = {10},
  author = {Levy, David M and Peart, Sandra},
  file = {/Users/qualia/Documents/Papers/2002 - Levy, Peart - Galton ’ s two papers on voting as robust estimation ∗.pdf}
}

@article{Lin2002,
  langid = {english},
  title = {Modulation of Synaptic Delay during Synaptic Plasticity},
  volume = {25},
  issn = {01662236},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0166223602022129},
  doi = {10.1016/S0166-2236(02)02212-9},
  number = {9},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {2002-09},
  pages = {449-455},
  author = {Lin, Jen-Wei and Faber, Donald S.},
  file = {/Users/qualia/Documents/Papers/2002 - Lin, Faber - Modulation of synaptic delay during synaptic plasticity.pdf}
}

@article{Logan2002,
  langid = {english},
  title = {An Instance Theory of Attention and Memory.},
  volume = {109},
  issn = {0033-295X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.109.2.376},
  doi = {10.1037//0033-295X.109.2.376},
  number = {2},
  journaltitle = {Psychological Review},
  urldate = {2019-03-30},
  date = {2002},
  pages = {376-400},
  author = {Logan, Gordon D.},
  file = {/Users/qualia/Documents/Papers/2002 - Logan - An instance theory of attention and memory.pdf}
}

@article{Maass2002,
  langid = {english},
  title = {Real-{{Time Computing Without Stable States}}: {{A New Framework}} for {{Neural Computation Based}} on {{Perturbations}}},
  volume = {14},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976602760407955},
  doi = {10.1162/089976602760407955},
  shorttitle = {Real-{{Time Computing Without Stable States}}},
  number = {11},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2002-11},
  pages = {2531-2560},
  author = {Maass, Wolfgang and Natschl\"ager, Thomas and Markram, Henry},
  file = {/Users/qualia/Documents/Papers/2002 - Maass, Natschläger, Markram - Real-Time Computing Without Stable States A New Framework for Neural Computation Based on Perturba.pdf}
}

@article{Macy,
  langid = {english},
  title = {Learning Dynamics in Social Dilemmas},
  pages = {8},
  author = {Macy, Michael W and Flache, Andreas},
  file = {/Users/qualia/Documents/Papers/2002 - Macy, Flache - Learning dynamics in social dilemmas.pdf}
}

@article{McIntyre2002,
  langid = {english},
  title = {Extracellular {{Stimulation}} of {{Central Neurons}}: {{Influence}} of {{Stimulus Waveform}} and {{Frequency}} on {{Neuronal Output}}},
  volume = {88},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.2002.88.4.1592},
  doi = {10.1152/jn.2002.88.4.1592},
  shorttitle = {Extracellular {{Stimulation}} of {{Central Neurons}}},
  number = {4},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2002-10},
  pages = {1592-1604},
  author = {McIntyre, Cameron C. and Grill, Warren M.},
  file = {/Users/qualia/Documents/Papers/2002 - McIntyre, Grill - Extracellular Stimulation of Central Neurons Influence of Stimulus Waveform and Frequency on Neuronal Output.pdf}
}

@article{Miller2002,
  langid = {english},
  title = {Neural {{Noise Can Explain Expansive}}, {{Power}}-{{Law Nonlinearities}} in {{Neural Response Functions}}},
  volume = {87},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00425.2001},
  doi = {10.1152/jn.00425.2001},
  number = {2},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2002-02},
  pages = {653-659},
  author = {Miller, Kenneth D. and Troyer, Todd W.},
  file = {/Users/qualia/Documents/Papers/2002 - Miller, Troyer - Neural noise can explain expansive, power-law nonlinearities in neural response functions.pdf}
}

@article{Newman2002,
  langid = {english},
  title = {Random Graph Models of Social Networks},
  volume = {99},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.012582999},
  doi = {10.1073/pnas.012582999},
  issue = {Supplement 1},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2002-02-19},
  pages = {2566-2572},
  author = {Newman, M. E. J. and Watts, D. J. and Strogatz, S. H.},
  file = {/Users/qualia/Documents/Papers/2002 - Newman, Watts, Strogatz - Random graph models of social networks.pdf}
}

@article{Nichols2002,
  langid = {english},
  title = {Nonparametric Permutation Tests for Functional Neuroimaging: {{A}} Primer with Examples},
  volume = {15},
  issn = {1065-9471, 1097-0193},
  url = {http://doi.wiley.com/10.1002/hbm.1058},
  doi = {10.1002/hbm.1058},
  shorttitle = {Nonparametric Permutation Tests for Functional Neuroimaging},
  abstract = {Requiring only minimal assumptions for validity, nonparametric permutation testing provides a flexible and intuitive methodology for the statistical analysis of data from functional neuroimaging experiments, at some computational expense. Introduced into the functional neuroimaging literature by Holmes et al. ([1996]: J Cereb Blood Flow Metab 16:7\textendash{}22), the permutation approach readily accounts for the multiple comparisons problem implicit in the standard voxel-by-voxel hypothesis testing framework. When the appropriate assumptions hold, the nonparametric permutation approach gives results similar to those obtained from a comparable Statistical Parametric Mapping approach using a general linear model with multiple comparisons corrections derived from random field theory. For analyses with low degrees of freedom, such as single subject PET/SPECT experiments or multi-subject PET/SPECT or fMRI designs assessed for population effects, the nonparametric approach employing a locally pooled (smoothed) variance estimate can outperform the comparable Statistical Parametric Mapping approach. Thus, these nonparametric techniques can be used to verify the validity of less computationally expensive parametric approaches. Although the theory and relative advantages of permutation approaches have been discussed by various authors, there has been no accessible explication of the method, and no freely distributed software implementing it. Consequently, there have been few practical applications of the technique. This article, and the accompanying MATLAB software, attempts to address these issues. The standard nonparametric randomization and permutation testing ideas are developed at an accessible level, using practical examples from functional neuroimaging, and the extensions for multiple comparisons described. Three worked examples from PET and fMRI are presented, with discussion, and comparisons with standard parametric approaches made where appropriate. Practical considerations are given throughout, and relevant statistical concepts are expounded in appendices. Hum. Brain Mapping 15:1\textendash{}25, 2001. \textcopyright{} 2001 Wiley-Liss, Inc.},
  number = {1},
  journaltitle = {Human Brain Mapping},
  urldate = {2019-03-30},
  date = {2002-01},
  pages = {1-25},
  author = {Nichols, Thomas E. and Holmes, Andrew P.},
  file = {/Users/qualia/Documents/Papers/2002 - Nichols, Holmes - Nonparametric permutation tests for functional neuroimaging a primer with examples.pdf}
}

@article{Shouval2002,
  langid = {english},
  title = {Converging Evidence for a Simplified Biophysical Model of Synaptic Plasticity},
  volume = {87},
  issn = {03401200},
  url = {http://link.springer.com/10.1007/s00422-002-0362-x},
  doi = {10.1007/s00422-002-0362-x},
  abstract = {Different mechanisms that could form the molecular basis for bi-directional synaptic plasticity have been identified experimentally and corresponding biophysical models can be constructed. However, such models are complex and therefore it is hard to deduce their consequences to compare them to existing abstract models of synaptic plasticity. In this paper we examine two such models: a phenomenological one inspired by the phenomena of AMPA receptor insertion, and a more complex biophysical model based on the phenomena of AMPA receptor phosphorylation. We show that under certain approximations both these models can be mapped on to an equivalent, calcium-dependent, differential equation. Intracellular calcium concentration varies locally in each postsynaptic compartment, thus the plasticity rule we extract is a single-synapse rule. We convert this single synapse plasticity equation to a multisynapse rule by incorporating a model of the NMDA receptor. Finally we suggest a mathematical embodiment of metaplasticity, which is consistent with observations on NMDA receptor properties and dependence on cellular activity. These results, in combination with some of our previous results, produce converging evidence for the calcium control hypothesis including a dependence of synaptic plasticity on the level of intercellular calcium as well as on the temporal pattern of calcium transients.},
  number = {5-6},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2002-12-01},
  pages = {383-391},
  author = {Shouval, Harel Z. and Castellani, Gastone C. and Blais, Brian S. and Yeung, Luk C. and Cooper, Leon N},
  file = {/Users/qualia/Documents/Papers/2002 - Shouval et al. - Converging evidence for a simplified biophysical model of synaptic plasticity.pdf}
}

@article{Terman2002,
  langid = {english},
  title = {Activity {{Patterns}} in a {{Model}} for the {{Subthalamopallidal Network}} of the {{Basal Ganglia}}},
  volume = {22},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.22-07-02963.2002},
  doi = {10.1523/JNEUROSCI.22-07-02963.2002},
  number = {7},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2002-04-01},
  pages = {2963-2976},
  author = {Terman, D. and Rubin, J. E. and Yew, A. C. and Wilson, C. J.},
  file = {/Users/qualia/Documents/Papers/2002 - Terman et al. - Activity patterns in a model for the subthalamopallidal network of the basal ganglia.pdf}
}

@article{Wang2002,
  langid = {english},
  title = {Probabilistic {{Decision Making}} by {{Slow Reverberation}} in {{Cortical Circuits}}},
  volume = {36},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627302010929},
  doi = {10.1016/S0896-6273(02)01092-9},
  abstract = {Recent physiological studies of alert primates have revealed cortical neural correlates of key steps in a perceptual decision-making process. To elucidate synaptic mechanisms of decision making, I investigated a biophysically realistic cortical network model for a visual discrimination experiment. In the model, slow recurrent excitation and feedback inhibition produce attractor dynamics that amplify the difference between conflicting inputs and generates a binary choice. The model is shown to account for salient characteristics of the observed decision-correlated neural activity, as well as the animal's psychometric function and reaction times. These results suggest that recurrent excitation mediated by NMDA receptors provides a candidate cellular mechanism for the slow time integration of sensory stimuli and the formation of categorical choices in a decision-making neocortical network.},
  number = {5},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2002-12},
  pages = {955-968},
  author = {Wang, Xiao-Jing},
  file = {/Users/qualia/Documents/Papers/2002 - Wang - by Slow Reverberation in Cortical Circuits.pdf}
}

@article{Wendling2002,
  langid = {english},
  title = {Epileptic Fast Activity Can Be Explained by a Model of Impaired {{GABAergic}} Dendritic Inhibition: {{Epileptic}} Activity Explained by Dendritic Dis-Inhibition},
  volume = {15},
  issn = {0953816X},
  url = {http://doi.wiley.com/10.1046/j.1460-9568.2002.01985.x},
  doi = {10.1046/j.1460-9568.2002.01985.x},
  shorttitle = {Epileptic Fast Activity Can Be Explained by a Model of Impaired {{GABAergic}} Dendritic Inhibition},
  abstract = {This paper focuses on high-frequency (gamma band) EEG activity, the most characteristic electrophysiological pattern in focal seizures of human epilepsy. It starts with recent hypotheses about: (i) the behaviour of inhibitory interneurons in hippocampal or neocortical networks in the generation of gamma frequency oscillations; (ii) the nonuniform alteration of GABAergic inhibition in experimental epilepsy (reduced dendritic inhibition and increased somatic inhibition); and (iii) the possible depression of GABAA,fast circuit activity by GABAA,slow inhibitory postsynaptic currents. In particular, these hypotheses are introduced in a new computational macroscopic model of EEG activity that includes a physiologically relevant fast inhibitory feedback loop. Results show that strikingly realistic activity is produced by the model when compared to real EEG signals recorded with intracerebral electrodes. They show that, in the model, the transition from interictal to fast ictal activity is explained by the impairment of dendritic inhibition.},
  number = {9},
  journaltitle = {European Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2002-05},
  pages = {1499-1508},
  author = {Wendling, F. and Bartolomei, F. and Bellanger, J. J. and Chauvel, P.},
  file = {/Users/qualia/Documents/Papers/2002 - Wendling et al. - Epileptic fast activity can be explained by a model of impaired GABAergic dendritic inhibition.pdf}
}

@article{Beierlein2003,
  langid = {english},
  title = {Two {{Dynamically Distinct Inhibitory Networks}} in {{Layer}} 4 of the {{Neocortex}}},
  volume = {90},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00283.2003},
  doi = {10.1152/jn.00283.2003},
  number = {5},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2003-11},
  pages = {2987-3000},
  author = {Beierlein, Michael and Gibson, Jay R. and Connors, Barry W.},
  file = {/Users/qualia/Documents/Papers/2003 - Beierlein - Two Dynamically Distinct Inhibitory Networks in Layer 4 of the Neocortex.pdf;/Users/qualia/Documents/Papers/2003 - Beierlein - Two Dynamically Distinct Inhibitory Networks in Layer 4 of the Neocortex(2).pdf}
}

@article{Breakspear2003,
  langid = {english},
  title = {Modulation of Excitatory Synaptic Coupling Facilitates Synchronization and Complex Dynamics in a Nonlinear Model of Neuronal Dynamics},
  volume = {52-54},
  issn = {09252312},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231202007403},
  doi = {10.1016/S0925-2312(02)00740-3},
  abstract = {We study dynamical synchronization in a model of a neural system constituted by local networks of densely interconnected excitatory and inhibitory neurons. Neural dynamics are determined by voltage- and ligand-gated ion channels. Coupling between the local networks is introduced via sparse excitatory connectivity. With modulation of this long-range synaptic coupling the system undergoes a transition from independent oscillations to chaotic synchronization. Between these states exists a 'weakly' stable state with epochs of synchronization and complex intermittent desynchronization. This may facilitate adaptive brain function by engendering a diverse repertoire of dynamics and contribute to the genesis of complexity in the EEG.},
  journaltitle = {Neurocomputing},
  urldate = {2019-03-30},
  date = {2003-06},
  pages = {151-158},
  author = {Breakspear, Michael and R. Terry, John and J. Friston, Karl},
  file = {/Users/qualia/Documents/Papers/2003 - Breakspear, Terry, Friston - Modulation of excitatory synaptic coupling facilitates synchronization and complex dynamics in a bio.pdf}
}

@article{Bressler2003,
  langid = {english},
  title = {Cortical {{Coordination Dynamics}} and the {{Disorganization Syndrome}} in {{Schizophrenia}}},
  volume = {28},
  issn = {0893-133X, 1740-634X},
  url = {http://www.nature.com/articles/1300145},
  doi = {10.1038/sj.npp.1300145},
  number = {S1},
  journaltitle = {Neuropsychopharmacology},
  urldate = {2019-03-30},
  date = {2003-07},
  pages = {S35-S39},
  author = {Bressler, Steven L},
  file = {/Users/qualia/Documents/Papers/2003 - Bressler - Cortical Coordination Dynamics and the Disorganization Syndrome in Schizophrenia.pdf}
}

@article{Brunel2003,
  langid = {english},
  title = {What {{Determines}} the {{Frequency}} of {{Fast Network Oscillations With Irregular Neural Discharges}}? {{I}}. {{Synaptic Dynamics}} and {{Excitation}}-{{Inhibition Balance}}},
  volume = {90},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.01095.2002},
  doi = {10.1152/jn.01095.2002},
  shorttitle = {What {{Determines}} the {{Frequency}} of {{Fast Network Oscillations With Irregular Neural Discharges}}?},
  number = {1},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2003-07},
  pages = {415-430},
  author = {Brunel, Nicolas and Wang, Xiao-Jing},
  file = {/Users/qualia/Documents/Papers/2003 - Brunel, Wang - What determines the frequency of fast network oscillations with irregular neural discharges I. Synaptic dynamics a.pdf}
}

@article{Camerer2003,
  langid = {english},
  title = {Behavioural Studies of Strategic Thinking in Games},
  volume = {7},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661303000949},
  doi = {10.1016/S1364-6613(03)00094-9},
  number = {5},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2003-05},
  pages = {225-231},
  author = {Camerer, Colin F.},
  file = {/Users/qualia/Documents/Papers/2003 - Camerer - Behavioural studies of strategic thinking in games.pdf}
}

@article{Camerer1999,
  langid = {english},
  title = {Experience-Weighted {{Attraction Learning}} in {{Normal Form Games}}},
  volume = {67},
  issn = {0012-9682, 1468-0262},
  url = {http://doi.wiley.com/10.1111/1468-0262.00054},
  doi = {10.1111/1468-0262.00054},
  abstract = {In `experience-weighted attraction' {\v Z}EWA. learning, strategies have attractions that reflect initial predispositions, are updated based on payoff experience, and determine choice probabilities according to some rule {\v Z}e.g., logit.. A key feature is a parameter ? that weights the strength of hypothetical reinforcement of strategies that were not chosen according to the payoff they would have yielded, relative to reinforcement of chosen strategies according to received payoffs. The other key features are two discount rates, ␾ and ␳, which separately discount previous attractions, and an experience weight. EWA includes reinforcement learning and weighted fictitious play {\v Z}belief learning. as special cases, and hybridizes their key elements. When ? s 0 and ␳ s 0, cumulative choice reinforcement results. When ? s 1 and ␳ s ␾, levels of reinforcement of strategies are exactly the same as expected payoffs given weighted fictitious play beliefs. Using three sets of experimental data, parameter estimates of the model were calibrated on part of the data and used to predict a holdout sample. Estimates of ? are generally around .50, ␾ around .8᎐1, and ␳ varies from 0 to ␾. Reinforcement and belief-learning special cases are generally rejected in favor of EWA, though belief models do better in some constant-sum games. EWA is able to combine the best features of previous approaches, allowing attractions to begin and grow flexibly as choice reinforcement does, but reinforcing unchosen strategies substantially as belief-based models implicitly do.},
  number = {4},
  journaltitle = {Econometrica},
  urldate = {2019-03-30},
  date = {1999-07},
  pages = {827-874},
  author = {Camerer, Colin and Hua Ho, Teck},
  file = {/Users/qualia/Documents/Papers/2003 - Camerer, Ho - Experience‐weighted Attraction Learning in Normal Form Games.pdf}
}

@article{Cooper2003,
  langid = {english},
  title = {Paradox Lost? {{Exploring}} the Role of Alpha Oscillations during Externally vs. Internally Directed Attention and the Implications for Idling and Inhibition Hypotheses},
  volume = {47},
  issn = {01678760},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167876002001071},
  doi = {10.1016/S0167-8760(02)00107-1},
  shorttitle = {Paradox Lost?},
  abstract = {Although slow waves of the electroencephalogram (EEG) have been associated with attentional processes, the functional significance of the alpha component in the EEG (8.1\textendash{}12 Hz) remains uncertain. Conventionally, synchronisation in the alpha frequency range is taken to be a marker of cognitive inactivity, i.e. `cortical idling'. However, it has been suggested that alpha may index the active inhibition of sensory information during internally directed attentional tasks such as mental imagery. More recently, this idea has been amended to encompass the notion of alpha synchronisation as a means of inhibition of non-task relevant cortical areas irrespective of the direction of attention. Here we test the adequacy of the one idling and two inhibition hypotheses about alpha. In two experiments we investigated the relation between alpha and internally vs. externally directed attention using mental imagery vs. sensory-intake paradigms. Results from both experiments showed a clear relationship between alpha and both attentional factors and increased task demands. At various scalp sites alpha amplitudes were greater during internally directed attention and during increased load, results incompatible with alpha reflecting cortical idling and more in keeping with suggestions of active inhibition necessary for internally driven mental operations.},
  number = {1},
  journaltitle = {International Journal of Psychophysiology},
  urldate = {2019-03-30},
  date = {2003-01},
  pages = {65-74},
  author = {Cooper, Nicholas R and Croft, Rodney J and Dominey, Samuel J.J and Burgess, Adrian P and Gruzelier, John H},
  file = {/Users/qualia/Documents/Papers/2003 - Cooper et al. - Paradox lost Exploring the role of alpha oscillations during externally vs. internally directed attention and the.pdf}
}

@article{Cox2003,
  langid = {english},
  title = {Functional Magnetic Resonance Imaging ({{fMRI}}) ``Brain Reading'': Detecting and Classifying Distributed Patterns of {{fMRI}} Activity in Human Visual Cortex},
  volume = {19},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811903000491},
  doi = {10.1016/S1053-8119(03)00049-1},
  shorttitle = {Functional Magnetic Resonance Imaging ({{fMRI}}) ``Brain Reading''},
  abstract = {Traditional (univariate) analysis of functional MRI (fMRI) data relies exclusively on the information contained in the time course of individual voxels. Multivariate analyses can take advantage of the information contained in activity patterns across space, from multiple voxels. Such analyses have the potential to greatly expand the amount of information extracted from fMRI data sets. In the present study, multivariate statistical pattern recognition methods, including linear discriminant analysis and support vector machines, were used to classify patterns of fMRI activation evoked by the visual presentation of various categories of objects. Classifiers were trained using data from voxels in predefined regions of interest during a subset of trials for each subject individually. Classification of subsequently collected fMRI data was attempted according to the similarity of activation patterns to prior training examples. Classification was done using only small amounts of data (20 s worth) at a time, so such a technique could, in principle, be used to extract information about a subject's percept on a near real-time basis. Classifiers trained on data acquired during one session were equally accurate in classifying data collected within the same session and across sessions separated by more than a week, in the same subject. Although the highest classification accuracies were obtained using patterns of activity including lower visual areas as input, classification accuracies well above chance were achieved using regions of interest restricted to higher-order object-selective visual areas. In contrast to typical fMRI data analysis, in which hours of data across many subjects are averaged to reveal slight differences in activation, the use of pattern recognition methods allows a subtle 10-way discrimination to be performed on an essentially trial-by-trial basis within individuals, demonstrating that fMRI data contain far more information than is typically appreciated.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2003-06},
  pages = {261-270},
  author = {Cox, David D and Savoy, Robert L},
  file = {/Users/qualia/Documents/Papers/2003 - Cox, Savoy - Functional magnetic resonance imaging (fMRI) “brain reading” detecting and classifying distributed patterns of f.pdf}
}

@article{David2003,
  langid = {english},
  title = {A Neural Mass Model for {{MEG}}/{{EEG}}:},
  volume = {20},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811903004579},
  doi = {10.1016/j.neuroimage.2003.07.015},
  shorttitle = {A Neural Mass Model for {{MEG}}/{{EEG}}},
  abstract = {Although MEG/EEG signals are highly variable, systematic changes in distinct frequency bands are commonly encountered. These frequency-specific changes represent robust neural correlates of cognitive or perceptual processes (for example, alpha rhythms emerge on closing the eyes). However, their functional significance remains a matter of debate. Some of the mechanisms that generate these signals are known at the cellular level and rest on a balance of excitatory and inhibitory interactions within and between populations of neurons. The kinetics of the ensuing population dynamics determine the frequency of oscillations. In this work we extended the classical nonlinear lumped-parameter model of alpha rhythms, initially developed by Lopes da Silva and colleagues [Kybernetik 15 (1974) 27], to generate more complex dynamics. We show that the whole spectrum of MEG/EEG signals can be reproduced within the oscillatory regime of this model by simply changing the population kinetics. We used the model to examine the influence of coupling strength and propagation delay on the rhythms generated by coupled cortical areas. The main findings were that (1) coupling induces phase-locked activity, with a phase shift of 0 or ␲ when the coupling is bidirectional, and (2) both coupling and propagation delay are critical determinants of the MEG/EEG spectrum. In forthcoming articles, we will use this model to (1) estimate how neuronal interactions are expressed in MEG/EEG oscillations and establish the construct validity of various indices of nonlinear coupling, and (2) generate event-related transients to derive physiologically informed basis functions for statistical modelling of average evoked responses.},
  number = {3},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2003-11},
  pages = {1743-1755},
  author = {David, Olivier and Friston, Karl J.},
  file = {/Users/qualia/Documents/Papers/2003 - David, Friston - A neural mass model for MEGEEG.pdf}
}

@article{Kamps2003,
  langid = {english},
  title = {A {{Simple}} and {{Stable Numerical Solution}} for the {{Population Density Equation}}},
  volume = {15},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976603322297322},
  doi = {10.1162/089976603322297322},
  number = {9},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2003-09},
  pages = {2129-2146},
  author = {de Kamps, M.},
  file = {/Users/qualia/Documents/Papers/2003 - de Kamps - A simple and stable numerical solution for the population density equation.pdf}
}

@article{Destexhe2003,
  langid = {english},
  title = {The High-Conductance State of Neocortical Neurons in Vivo},
  volume = {4},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn1198},
  doi = {10.1038/nrn1198},
  number = {9},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2003-09},
  pages = {739-751},
  author = {Destexhe, Alain and Rudolph, Michael and Par\'e, Denis},
  file = {/Users/qualia/Documents/Papers/2003 - Destexhe, Rudolph, Paré - The high-conductance state of neocortical neurons in vivo.pdf}
}

@article{Gao2003,
  langid = {english},
  title = {Dopamine {{Modulation}} of {{Perisomatic}} and {{Peridendritic Inhibition}} in {{Prefrontal Cortex}}},
  volume = {23},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.23-05-01622.2003},
  doi = {10.1523/JNEUROSCI.23-05-01622.2003},
  number = {5},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2003-03-01},
  pages = {1622-1630},
  author = {Gao, Wen-Jun and Wang, Yun and Goldman-Rakic, Patricia S.},
  file = {/Users/qualia/Documents/Papers/2003 - Gao, Wang, Goldman-Rakic - Dopamine modulation of perisomatic and peridendritic inhibition in prefrontal cortex.pdf}
}

@article{Guyon,
  langid = {english},
  title = {An {{Introduction}} to {{Variable}} and {{Feature Selection}}},
  abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.},
  pages = {26},
  author = {Guyon, Isabelle and Elisseeff, Andre},
  file = {/Users/qualia/Documents/Papers/2003 - Guyon, Elisseeff - An introduction to variable and feature selection.pdf}
}

@article{Hausler2003,
  langid = {english},
  title = {Perspectives of the High-Dimensional Dynamics of Neural Microcircuits from the Point of View of Low-Dimensional Readouts},
  volume = {8},
  issn = {10762787},
  url = {http://doi.wiley.com/10.1002/cplx.10089},
  doi = {10.1002/cplx.10089},
  number = {4},
  journaltitle = {Complexity},
  urldate = {2019-03-30},
  date = {2003-03},
  pages = {39-50},
  author = {H\"ausler, Stefan and Markram, Henry and Maass, Wolfgang},
  file = {/Users/qualia/Documents/Papers/2003 - Hausler, Markram, Maass - Perspectives of the high-dimensional dynamics of neural microcircuits from the point of view of low-dim.pdf}
}

@article{Hofbauer,
  langid = {english},
  title = {{{EVOLUTIONARY GAME DYNAMICS}}},
  abstract = {Evolutionary game dynamics is the application of population dynamical methods to game theory. It has been introduced by evolutionary biologists, anticipated in part by classical game theorists. In this survey, we present an overview of the many brands of deterministic dynamical systems motivated by evolutionary game theory, including ordinary differential equations (and, in particular, the replicator equation), differential inclusions (the best response dynamics), difference equations (as, for instance, fictitious play) and reaction-diffusion systems. A recurrent theme (the so-called `folk theorem of evolutionary game theory') is the close connection of the dynamical approach with the Nash equilibrium, but we show that a static, equilibriumbased viewpoint is, on principle, unable to always account for the long-term behaviour of players adjusting their behaviour to maximise their payoff.},
  pages = {41},
  author = {Hofbauer, Josef and Sigmund, Karl},
  file = {/Users/qualia/Documents/Papers/2003 - Hofbauer, Sigmund - Evolutionary Game Dynamics.pdf}
}

@article{Izhikevich2003a,
  langid = {english},
  title = {Simple Model of Spiking Neurons},
  volume = {14},
  issn = {1045-9227},
  url = {http://ieeexplore.ieee.org/document/1257420/},
  doi = {10.1109/TNN.2003.820440},
  abstract = {A model is presented that reproduces spiking and bursting behavior of known types of cortical neurons. The model combines the biologically plausibility of Hodgkin\textendash{}Huxley-type dynamics and the computational efficiency of integrate-and-fire neurons. Using this model, one can simulate tens of thousands of spiking cortical neurons in real time (1 ms resolution) using a desktop PC.},
  number = {6},
  journaltitle = {IEEE Transactions on Neural Networks},
  urldate = {2019-03-30},
  date = {2003-11},
  pages = {1569-1572},
  author = {Izhikevich, E.M.},
  file = {/Users/qualia/Documents/Papers/2003 - Izhikevich - Simple model of spiking neurons.pdf}
}

@article{Izhikevich2003,
  langid = {english},
  title = {Relating {{STDP}} to {{BCM}}},
  volume = {15},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976603321891783},
  doi = {10.1162/089976603321891783},
  number = {7},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2003-07},
  pages = {1511-1523},
  author = {Izhikevich, Eugene M. and Desai, Niraj S.},
  file = {/Users/qualia/Documents/Papers/2003 - Izhikevich, Desai - Relating STDP to BCM.pdf}
}

@article{MacKay,
  langid = {english},
  title = {Information {{Theory}}, {{Inference}}, and {{Learning Algorithms}}},
  pages = {640},
  author = {MacKay, David J C},
  file = {/Users/qualia/Documents/Papers/2003 - Mackay - Information Theory , Inference , and Learning Algorithms.pdf}
}

@article{McKeown2003,
  langid = {english},
  title = {Independent Component Analysis of Functional {{MRI}}: What Is Signal and What Is Noise?},
  volume = {13},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438803001338},
  doi = {10.1016/j.conb.2003.09.012},
  shorttitle = {Independent Component Analysis of Functional {{MRI}}},
  abstract = {Many sources of fluctuation contribute to the functional magnetic resonance imaging (fMRI) signal, complicating attempts to infer those changes that are truly related to brain activation. Unlike methods of analysis of fMRI data that test the time course of each voxel against a hypothesized waveform, data-driven methods, such as independent component analysis and clustering, attempt to find common features within the data. This exploratory approach can be revealing when the brain activation is difficult to predict beforehand, such as with complex stimuli and internal shifts of activation that are not time-locked to an easily specified sensory or motor event. These methods can be further improved by incorporating prior knowledge regarding the temporal and spatial extent of brain activation.},
  number = {5},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2003-10},
  pages = {620-629},
  author = {McKeown, M},
  file = {/Users/qualia/Documents/Papers/2003 - McKeown, Hansen, Sejnowski - Independent component analysis of functional MRI what is signal and what is noise.pdf}
}

@article{Miller2003,
  langid = {english},
  title = {Understanding {{Layer}} 4 of the {{Cortical Circuit}}: {{A Model Based}} on {{Cat V1}}},
  volume = {13},
  issn = {14602199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/13.1.73},
  doi = {10.1093/cercor/13.1.73},
  shorttitle = {Understanding {{Layer}} 4 of the {{Cortical Circuit}}},
  number = {1},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2003-01-01},
  pages = {73-82},
  author = {Miller, K. D.},
  file = {/Users/qualia/Documents/Papers/2003 - Miller - Understanding layer 4 of the cortical circuit a model based on cat V1.pdf}
}

@article{Murphy2003,
  langid = {english},
  title = {Multiplicative {{Gain Changes Are Induced}} by {{Excitation}} or {{Inhibition Alone}}},
  volume = {23},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.23-31-10040.2003},
  doi = {10.1523/JNEUROSCI.23-31-10040.2003},
  number = {31},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2003-11-05},
  pages = {10040-10051},
  author = {Murphy, Brendan K. and Miller, Kenneth D.},
  file = {/Users/qualia/Documents/Papers/2003 - Murphy, Miller - Multiplicative gain changes are induced by excitation or inhibition alone.pdf}
}

@article{Myerson2003,
  langid = {english},
  title = {Effects of {{Age}}, {{Domain}}, and {{Processing Demands}} on {{Memory Span}}: {{Evidence}} for {{Differential Decline}}},
  volume = {10},
  issn = {1382-5585, 1744-4128},
  url = {https://www.tandfonline.com/doi/full/10.1076/anec.10.1.20.13454},
  doi = {10.1076/anec.10.1.20.13454},
  shorttitle = {Effects of {{Age}}, {{Domain}}, and {{Processing Demands}} on {{Memory Span}}},
  abstract = {Analysis of cross-sectional data from the normative sample of the Wechsler Memory Scale \textendash{} Third Edition (WMS-III) revealed different patterns of age-related differences in memory span measures depending on the type of memory item, processing demands, and the age of the older adult group. Regression of memory span on age revealed that the slope for Spatial Span raw scores was significantly more negative than the slope for Digit Span raw scores. There was no significant difference, however, either between the slopes for forward and backward Digit Span or between the slopes for forward and backward Spatial Span. Regression of Letter-Number Sequencing raw scores on age showed a distinctive, curvilinear pattern. Taken together, the present findings suggest that at least two mechanisms are involved in age-related differences in memory span. One mechanism, associated with a relatively linear decrease in memory span as a function of age, may differentially affect the storage of different types of information (e.g., sequences of digits vs. spatial locations). The other mechanism, evidenced by the curvilinear trend in Letter-Number Sequencing scores, may be tentatively attributed to a decline in executive aspects of working memory that becomes increasingly pronounced with age.},
  number = {1},
  journaltitle = {Aging, Neuropsychology, and Cognition},
  urldate = {2019-03-30},
  date = {2003-03},
  pages = {20-27},
  author = {Myerson, Joel and Emery, Lisa and White, Desir\'ee A. and Hale, Sandra},
  file = {/Users/qualia/Documents/Papers/2003 - Myerson et al. - Effects of age, domain, and processing demands on memory span Evidence for differential decline.pdf}
}

@article{Norton2003,
  langid = {english},
  title = {Can Ultrasound Be Used to Stimulate Nerve Tissue?},
  abstract = {Background: The stimulation of nerve or cortical tissue by magnetic induction is a relatively new tool for the non-invasive study of the brain and nervous system. Transcranial magnetic stimulation (TMS), for example, has been used for the functional mapping of the motor cortex and may have potential for treating a variety of brain disorders.
Methods and Results: A new method of stimulating active tissue is proposed by propagating ultrasound in the presence of a magnetic field. Since tissue is conductive, particle motion created by an ultrasonic wave will induce an electric current density generated by Lorentz forces. An analytical derivation is given for the electric field distribution induced by a collimated ultrasonic beam. An example shows that peak electric fields of up to 8 V/m appear to be achievable at the upper range of diagnostic intensities. This field strength is about an order of magnitude lower than fields typically associated with TMS; however, the electric field gradients induced by ultrasound can be quite high (about 60 kV/m2 at 4 MHz), which theoretically play a more important role in activation than the field magnitude. The latter value is comparable to TMS-induced gradients.
Conclusion: The proposed method could be used to locally stimulate active tissue by inducing an electric field in regions where the ultrasound is focused. Potential advantages of this method compared to TMS is that stimulation of cortical tissue could be highly localized as well as achieved at greater depths in the brain than is currently possible with TMS.},
  journaltitle = {BioMedical Engineering OnLine},
  date = {2003},
  pages = {9},
  author = {Norton, Stephen J},
  file = {/Users/qualia/Documents/Papers/2003 - Norton - Can ultrasound be used to stimulate nerve tissue.pdf}
}

@article{Phillips2003,
  langid = {english},
  title = {Convergence of Biological and Psychological Perspectives on Cognitive Coordination in Schizophrenia},
  volume = {26},
  issn = {0140-525X, 1469-1825},
  url = {http://www.journals.cambridge.org/abstract_S0140525X03000025},
  doi = {10.1017/S0140525X03000025},
  abstract = {The concept of locally specialized functions dominates research on higher brain function and its disorders. Locally specialized functions must be complemented by processes that coordinate those functions, however, and impairment of coordinating processes may be central to some psychotic conditions. Evidence for processes that coordinate activity is provided by neurobiological and psychological studies of contextual disambiguation and dynamic grouping. Mechanisms by which this important class of cognitive functions could be achieved include those long-range connections within and between cortical regions that activate synaptic channels via NMDAreceptors, and which control gain through their voltage-dependent mode of operation. An impairment of these mechanisms is central to PCP-psychosis, and the cognitive capabilities that they could provide are impaired in some forms of schizophrenia. We conclude that impaired cognitive coordination due to reduced ion flow through NMDA-channels is involved in schizophrenia, and we suggest that it may also be involved in other disorders. This perspective suggests several ways in which further research could enhance our understanding of cognitive coordination, its neural basis, and its relevance to psychopathology.},
  number = {01},
  journaltitle = {Behavioral and Brain Sciences},
  urldate = {2019-03-30},
  date = {2003-02},
  author = {Phillips, William A. and Silverstein, Steven M.},
  file = {/Users/qualia/Documents/Papers/2003 - Phillips, Silverstein - Convergence of biological and psychological perspectives on cognitive coordination in schizophrenia.pdf}
}

@article{Poirazi2003,
  langid = {english},
  title = {Pyramidal {{Neuron}} as {{Two}}-{{Layer Neural Network}}},
  volume = {37},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627303001491},
  doi = {10.1016/S0896-6273(03)00149-1},
  abstract = {The pyramidal neuron is the principal cell type in the mammalian forebrain, but its function remains poorly understood. Using a detailed compartmental model of a hippocampal CA1 pyramidal cell, we recorded responses to complex stimuli consisting of dozens of high-frequency activated synapses distributed throughout the apical dendrites. We found the cell's firing rate could be predicted by a simple formula that maps the physical components of the cell onto those of an abstract two-layer ``neural network.'' In the first layer, synaptic inputs drive independent sigmoidal subunits corresponding to the cell's several dozen long, thin terminal dendrites. The subunit outputs are then summed within the main trunk and cell body prior to final thresholding. We conclude that insofar as the neural code is mediated by average firing rate, a twolayer neural network may provide a useful abstraction for the computing function of the individual pyramidal neuron.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2003-03},
  pages = {989-999},
  author = {Poirazi, Panayiota and Brannon, Terrence and Mel, Bartlett W.},
  file = {/Users/qualia/Documents/Papers/2003 - Poirazi, Brannon, Mel - Pyramidal Neuron as Two-Layered Neural Network.pdf}
}

@article{Kister,
  langid = {english},
  title = {Online {{Supplement}}: {{About}} the {{Model}}},
  pages = {20},
  author = {Kister, Robert},
  file = {/Users/qualia/Documents/Papers/2003 - Poirazi, Brannon, Mel - Pyramidal Neuron as Two-Layered Neural Network(2).pdf}
}

@article{Seung2003,
  langid = {english},
  title = {Learning in {{Spiking Neural Networks}} by {{Reinforcement}} of {{Stochastic Synaptic Transmission}}},
  volume = {40},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S089662730300761X},
  doi = {10.1016/S0896-6273(03)00761-X},
  abstract = {It is well-known that chemical synaptic transmission is an unreliable process, but the function of such unreliability remains unclear. Here I consider the hypothesis that the randomness of synaptic transmission is harnessed by the brain for learning, in analogy to the way that genetic mutation is utilized by Darwinian evolution. This is possible if synapses are ``hedonistic,'' responding to a global reward signal by increasing their probabilities of vesicle release or failure, depending on which action immediately preceded reward. Hedonistic synapses learn by computing a stochastic approximation to the gradient of the average reward. They are compatible with synaptic dynamics such as short-term facilitation and depression and with the intricacies of dendritic integration and action potential generation. A network of hedonistic synapses can be trained to perform a desired computation by administering reward appropriately, as illustrated here through numerical simulations of integrate-andfire model neurons.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2003-12},
  pages = {1063-1073},
  author = {Seung, H.Sebastian},
  file = {/Users/qualia/Documents/Papers/2003 - Seung - Learning in Spiking Neural Networks by Reinforcement of Stochastics Transmission.pdf}
}

@article{Shoham,
  langid = {english},
  title = {Multi-{{Agent Reinforcement Learning}}: A Critical Survey},
  abstract = {We survey the recent work in AI on multi-agent reinforcement learning (that is, learning in stochastic games). We then argue that, while exciting, this work is flawed. The fundamental flaw is unclarity about the problem or problems being addressed. After tracing a representative sample of the recent literature, we identify four well-defined problems in multi-agent reinforcement learning, single out the problem that in our view is most suitable for AI, and make some remarks about how we believe progress is to be made on this problem.},
  pages = {13},
  author = {Shoham, Yoav and Powers, Rob and Grenager, Trond},
  file = {/Users/qualia/Documents/Papers/2003 - Shoham, Powers, Grenager - Multi-agent reinforcement learning a critical survey.pdf}
}

@article{Shriki2003,
  langid = {english},
  title = {Rate {{Models}} for {{Conductance}}-{{Based Cortical Neuronal Networks}}},
  volume = {15},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/08997660360675053},
  doi = {10.1162/08997660360675053},
  number = {8},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2003-08},
  pages = {1809-1841},
  author = {Shriki, Oren and Hansel, David and Sompolinsky, Haim},
  file = {/Users/qualia/Documents/Papers/2003 - Shriki, Hansel, Sompolinsky - Rate models for conductance-based cortical neuronal networks.pdf}
}

@article{Spiliotis,
  langid = {english},
  title = {Micro to {{Macro Equation}}-{{Free Bifurcation Analysis}} of {{Neuronal Random Graphs}}: {{Symmetry Breaking}} of {{Majority Rule Dynamics}}},
  pages = {6},
  author = {Spiliotis, Konstantinos and Russo, Lucia and Siettos, Constantinos I},
  file = {/Users/qualia/Documents/Papers/2003 - Spiliotis et al. - Micro to Macro Equation-Free Bifurcation Analysis of Neuronal Random Graphs Symmetry Breaking of Majority Rul.pdf}
}

@article{Thomson2003,
  langid = {english},
  title = {Interlaminar {{Connections}} in the {{Neocortex}}},
  volume = {13},
  issn = {14602199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/13.1.5},
  doi = {10.1093/cercor/13.1.5},
  number = {1},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2003-01-01},
  pages = {5-14},
  author = {Thomson, A. M.},
  file = {/Users/qualia/Documents/Papers/2003 - Thomson, Bannister - Interlaminar connections in the neocortex.pdf}
}

@article{Winterer2003,
  langid = {english},
  title = {Cortical Signal-to-Noise Ratio: Insight into the Pathophysiology and Genetics of Schizophrenia},
  volume = {3},
  issn = {15662772},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1566277203000197},
  doi = {10.1016/S1566-2772(03)00019-7},
  shorttitle = {Cortical Signal-to-Noise Ratio},
  abstract = {During the past two decades, it has been convincingly demonstrated that schizophrenic patients and subjects genetically at risk for schizophrenia show abnormalities of cortical and particularly prefrontal function. Depending on clinical state and task conditions, hypo- and hyperfrontality have been frequently described with functional neuroimaging and electrophysiological techniques; however, the underlying neurophysiological deficits remained largely obscure. There is now growing empirical evidence that cortical signal-to-noise ratio (SNR) during information processing is fundamentally disturbed and may be key to a further understanding of schizophrenic pathophysiology. The evidence comes from animal and human electrophysiological and neuroimaging investigations as well as neuropsychological and computational simulation studies. This research has also shown that dopamine signaling in prefrontal cortex is a critical factor in modulation of cortical SNR and in neurocognitive performance. Moreover, it was recently demonstrated that genetically determined variations in dopamine signaling, mediated by a functional polymorphism in the gene for the enzyme catechol-o-methyltransferase, has a significant impact on the cortical SNR, prefrontal information processing, and as a result, is a susceptibility gene for schizophrenia. This review summarizes the current state of research on the pathophysiology of schizophrenia with emphasis on cortical-SNR and the involvement of potentially relevant, molecular and genetic determinants of the cortical dopaminergic signaling.},
  number = {1-2},
  journaltitle = {Clinical Neuroscience Research},
  urldate = {2019-03-30},
  date = {2003-05},
  pages = {55-66},
  author = {Winterer, Georg and Weinberger, Daniel R.},
  file = {/Users/qualia/Documents/Papers/2003 - Winterer, Weinberger - Cortical signal-to-noise ratio Insight into the pathophysiology and genetics of schizophrenia.pdf}
}

@article{Abrams2004,
  langid = {english},
  title = {Chimera {{States}} for {{Coupled Oscillators}}},
  volume = {93},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.93.174102},
  doi = {10.1103/PhysRevLett.93.174102},
  number = {17},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2004-10-22},
  author = {Abrams, Daniel M. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/2004 - Abrams, Strogatz - Chimera states for coupled oscillators.pdf}
}

@article{Alvarez2004,
  langid = {english},
  title = {Simulating Cortical Network Activity States Constrained by Intracellular Recordings},
  volume = {58-60},
  issn = {09252312},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231204000530},
  doi = {10.1016/j.neucom.2004.01.057},
  abstract = {We present a method for studying states of network activity while incorporating constraints provided by intracellular measurements. Taking into account measurements of the average membrane potential, input resistance changes and membrane potential uctuations, narrows down the possible region of parameter space (connectivity, quantal conductances) where this activity can appear in networks. Searching in those speci\"yc regions greatly enhances the e ciency of the network-level modeling because irrelevant parameter combinations are automatically eliminated. We illustrate this approach by modeling self-sustained stochastic states in networks of excitatory and inhibitory neurons, based on intracellular recordings in vivo.},
  journaltitle = {Neurocomputing},
  urldate = {2019-03-30},
  date = {2004-06},
  pages = {285-290},
  author = {Alvarez, Fabi\'an P. and Destexhe, Alain},
  file = {/Users/qualia/Documents/Papers/2004 - Alvarez, Destexhe - Simulating cortical network activity states constrained by intracellular recordings.pdf}
}

@article{Amirnovin2004,
  langid = {english},
  title = {Visually {{Guided Movements Suppress Subthalamic Oscillations}} in {{Parkinson}}'s {{Disease Patients}}},
  volume = {24},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3242-04.2004},
  doi = {10.1523/JNEUROSCI.3242-04.2004},
  number = {50},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2004-12-15},
  pages = {11302-11306},
  author = {Amirnovin, R.},
  file = {/Users/qualia/Documents/Papers/2004 - Amirnovin - Visually Guided Movements Suppress Subthalamic Oscillations in Parkinson's Disease Patients.pdf}
}

@article{Balkenius,
  langid = {english},
  title = {Cognitive {{Modeling}} with {{Context Sensitive Reinforcement Learning}}},
  pages = {12},
  author = {Balkenius, Christian and Winberg, Stefan},
  file = {/Users/qualia/Documents/Papers/2004 - Balkenius, Winberg - Cognitive modeling with context sensitive reinforcement learning.pdf}
}

@article{Barraclough2004,
  langid = {english},
  title = {Prefrontal Cortex and Decision Making in a Mixed-Strategy Game},
  volume = {7},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn1209},
  doi = {10.1038/nn1209},
  number = {4},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2004-04},
  pages = {404-410},
  author = {Barraclough, Dominic J and Conroy, Michelle L and Lee, Daeyeol},
  file = {/Users/qualia/Documents/Papers/2004 - Barraclough, Conroy, Lee - Prefrontal cortex and decision making in a mixed-strategy game.pdf}
}

@article{Bertschinger2004,
  langid = {english},
  title = {Real-{{Time Computation}} at the {{Edge}} of {{Chaos}} in {{Recurrent Neural Networks}}},
  volume = {16},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976604323057443},
  doi = {10.1162/089976604323057443},
  number = {7},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2004-07},
  pages = {1413-1436},
  author = {Bertschinger, Nils and Natschl\"ager, Thomas},
  file = {/Users/qualia/Documents/Papers/2004 - Bertschinger, Natschläger - Real-time computation at the edge of chaos in recurrent neural networks.pdf}
}

@article{Binzegger2004,
  langid = {english},
  title = {A {{Quantitative Map}} of the {{Circuit}} of {{Cat Primary Visual Cortex}}},
  volume = {24},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1400-04.2004},
  doi = {10.1523/JNEUROSCI.1400-04.2004},
  number = {39},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2004-09-29},
  pages = {8441-8453},
  author = {Binzegger, T.},
  file = {/Users/qualia/Documents/Papers/2004 - Binzegger - A Quantitative Map of the Circuit of Cat Primary Visual Cortex.pdf}
}

@article{Brockwell2004,
  langid = {english},
  title = {Recursive {{Bayesian Decoding}} of {{Motor Cortical Signals}} by {{Particle Filtering}}},
  volume = {91},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00438.2003},
  doi = {10.1152/jn.00438.2003},
  number = {4},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2004-04},
  pages = {1899-1907},
  author = {Brockwell, A. E. and Rojas, A. L. and Kass, R. E.},
  file = {/Users/qualia/Documents/Papers/2004 - Brockwell, Rojas, Kass - Recursive Bayesian Decoding of Motor Cortical Signals by Particle Filtering.pdf}
}

@article{Burnham2004,
  langid = {english},
  title = {Multimodel {{Inference}}: {{Understanding AIC}} and {{BIC}} in {{Model Selection}}},
  volume = {33},
  issn = {0049-1241, 1552-8294},
  url = {http://journals.sagepub.com/doi/10.1177/0049124104268644},
  doi = {10.1177/0049124104268644},
  shorttitle = {Multimodel {{Inference}}},
  number = {2},
  journaltitle = {Sociological Methods \& Research},
  urldate = {2019-03-30},
  date = {2004-11},
  pages = {261-304},
  author = {Burnham, Kenneth P. and Anderson, David R.},
  file = {/Users/qualia/Documents/Papers/2004 - Burnham - Multimodel Inference Understanding AIC and BIC in Model Selection.pdf}
}

@article{Carandini2004,
  langid = {english},
  title = {Amplification of {{Trial}}-to-{{Trial Response Variability}} by {{Neurons}} in {{Visual Cortex}}},
  volume = {2},
  issn = {1545-7885},
  url = {https://dx.plos.org/10.1371/journal.pbio.0020264},
  doi = {10.1371/journal.pbio.0020264},
  number = {9},
  journaltitle = {PLoS Biology},
  urldate = {2019-03-30},
  date = {2004-08-24},
  pages = {e264},
  author = {Carandini, Matteo},
  editor = {{Charles Stevens}},
  file = {/Users/qualia/Documents/Papers/2004 - Carandini - Amplification of trial-to-trial response variability by neurons in visual cortex.pdf}
}

@article{Cook,
  langid = {english},
  title = {It {{Takes Two Neurons To Ride}} a {{Bicycle}}},
  abstract = {Past attempts to get computers to ride bicycles have required an inordinate amount of learning time (1700 practice rides for a reinforcement learning approach [1], while still failing to be able to ride in a straight line), or have required an algebraic analysis of the exact equations of motion for the specific bicycle to be controlled [2, 3]. Mysteriously, humans do not need to do either of these when learning to ride a bicycle.},
  pages = {8},
  author = {Cook, Matthew},
  file = {/Users/qualia/Documents/Papers/2004 - Cook - It takes two neurons to ride a bicycle.pdf}
}

@article{Cragg2004,
  langid = {english},
  title = {Synaptic Release of Dopamine in the Subthalamic Nucleus},
  volume = {20},
  issn = {0953-816X, 1460-9568},
  url = {http://doi.wiley.com/10.1111/j.1460-9568.2004.03629.x},
  doi = {10.1111/j.1460-9568.2004.03629.x},
  abstract = {The direct modulation of subthalamic nucleus (STN) neurons by dopamine (DA) neurons of the substantia nigra (SN) is controversial owing to the thick caliber and low density of DA axons in the STN. The abnormal activity of the STN in Parkinson's disease (PD), which is central to the appearance of symptoms, is therefore thought to result from the loss of DA in the striatum. We carried out three experiments in rats to explore the function of DA in the STN: (i) light and electron microscopic analysis of tyrosine hydroxylase (TH)-, dopamine b-hydroxylase (DbH)- and DA-immunoreactive structures to determine whether DA axons form synapses; (ii) fast-scan cyclic voltammetry (FCV) to determine whether DA axons release DA; and (iii) patch clamp recording to determine whether DA, at a concentration similar to that detected by FCV, can modulate activity and synaptic transmission {$\fracslash$} integration. TH- and DAimmunoreactive axons mostly formed symmetric synapses. Because DbH-immunoreactive axons were rare and formed asymmetric synapses, they comprised the minority of TH-immunoreactive synapses. Voltammetry demonstrated that DA release was sufficient for the activation of receptors and abolished by blockade of voltage-dependent Na+ channels or removal of extracellular Ca2+. The lifetime and concentration of extracellular DA was increased by blockade of the DA transporter. Dopamine application depolarized STN neurons, increased their frequency of activity and reduced the impact of c-aminobutyric acid (GABA)-ergic inputs. These findings suggest that SN DA neurons directly modulate the activity of STN neurons and their loss may contribute to the abnormal activity of STN neurons in PD.},
  number = {7},
  journaltitle = {European Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2004-10},
  pages = {1788-1802},
  author = {Cragg, Stephanie J. and Baufreton, Jerome and Xue, Yi and Bolam, J. Paul and Bevan, Mark D.},
  file = {/Users/qualia/Documents/Papers/2004 - Cragg et al. - Synaptic release of dopamine in the subthalamic nucleus.pdf}
}

@article{Cunningham2004,
  langid = {english},
  title = {A Role for Fast Rhythmic Bursting Neurons in Cortical Gamma Oscillations in Vitro},
  volume = {101},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0402060101},
  doi = {10.1073/pnas.0402060101},
  number = {18},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2004-05-04},
  pages = {7152-7157},
  author = {Cunningham, M. O. and Whittington, M. A. and Bibbig, A. and Roopun, A. and LeBeau, F. E. N. and Vogt, A. and Monyer, H. and Buhl, E. H. and Traub, R. D.},
  file = {/Users/qualia/Documents/Papers/2004 - Cunningham et al. - A role for fast rhythmic bursting neurons in cortical gamma oscillations in vitro.pdf}
}

@article{delaFuente-Fernandez2004,
  langid = {english},
  title = {Presynaptic Mechanisms of Motor Fluctuations in {{Parkinson}}'s Disease: A Probabilistic Model},
  volume = {127},
  issn = {1460-2156, 0006-8950},
  url = {https://academic.oup.com/brain/article-lookup/doi/10.1093/brain/awh102},
  doi = {10.1093/brain/awh102},
  shorttitle = {Presynaptic Mechanisms of Motor Fluctuations in {{Parkinson}}'s Disease},
  number = {4},
  journaltitle = {Brain},
  urldate = {2019-03-30},
  date = {2004-04},
  pages = {888-899},
  author = {de la Fuente-Fern\'andez, Ra\'ul and Schulzer, Michael and Mak, Edwin and Calne, Donald B. and Stoessl, A. Jon},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2004 - De La Fuente-Fernández et al. - Presynaptic mechanisms of motor fluctuations in Parkinson's disease A probabilistic model.pdf}
}

@article{Evensen2004,
  langid = {english},
  title = {Sampling Strategies and Square Root Analysis Schemes for the {{EnKF}}},
  volume = {54},
  issn = {1616-7341, 1616-7228},
  url = {http://link.springer.com/10.1007/s10236-004-0099-2},
  doi = {10.1007/s10236-004-0099-2},
  abstract = {The purpose of this paper is to examine how different sampling strategies and implementations of the analysis scheme influence the quality of the results in the EnKF. It is shown that by selecting the initial ensemble, the model noise and the measurement perturbations wisely, it is possible to achieve a significant improvement in the EnKF results, using the same number of members in the ensemble. The results are also compared with a square root implementation of the EnKF analysis scheme where the analyzed ensemble is computed without the perturbation of measurements. It is shown that the measurement perturbations introduce sampling errors which can be reduced using improved sampling schemes in the standard EnKF or fully eliminated when the square root analysis algorithm is used. Further, a new computationally efficient square root algorithm is proposed which allows for the use of a low-rank representation of the measurement error covariance matrix. It is shown that this algorithm in fact solves the full problem at a low cost without introducing any new approximations.},
  number = {6},
  journaltitle = {Ocean Dynamics},
  urldate = {2019-03-30},
  date = {2004-12},
  pages = {539-560},
  author = {Evensen, Geir},
  file = {/Users/qualia/Documents/Papers/2004 - Evensen - Sampling strategies and square root analysis schemes for the EnKF.pdf}
}

@article{Garcia-Ojalvo2004,
  langid = {english},
  title = {Modeling a Synthetic Multicellular Clock: {{Repressilators}} Coupled by Quorum Sensing},
  volume = {101},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0307095101},
  doi = {10.1073/pnas.0307095101},
  shorttitle = {Modeling a Synthetic Multicellular Clock},
  number = {30},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2004-07-27},
  pages = {10955-10960},
  author = {Garcia-Ojalvo, J. and Elowitz, M. B. and Strogatz, S. H.},
  file = {/Users/qualia/Documents/Papers/2004 - Garcia-Ojalvo, Elowitz, Strogatz - Modeling a synthetic multicellular clock Repressilators coupled by quorum sensing.pdf}
}

@article{Gillies2004,
  langid = {english},
  title = {Models of the Subthalamic Nucleus},
  volume = {26},
  issn = {13504533},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1350453304000955},
  doi = {10.1016/j.medengphy.2004.06.003},
  abstract = {A coherent set of models is presented that provide novel and testable predictions about the functional role of the subthalamic nucleus (STN) in the basal ganglia. The STN is emerging as an important target for novel therapeutic strategies for the alleviation of Parkinsonian type symptoms [Lancet 345 (1995) 91; Science 249 (1990) 1436]. Computational and mathematical models based on the properties of the STN and its interactions are reviewed. These models focus on core anatomical and physiological data that span many levels. By assessing models of anatomy, dynamic network models, and a detailed model of a recent pharmacological experiment, we can expose the primary modes of STN function and highlight their underlying properties. We show that the presence of functional interactions between STN projection neurons is critical in defining its behaviour and how it interacts with other basal ganglia nuclei. Pulses or switch-like activity patterns emerge in the models as a consequence of these local interactions. Furthermore, the models demonstrate that this behaviour can break down under abnormal conditions resulting in low frequency bursting oscillations. Such oscillations may play a role in symptoms of Parkinson's disease.},
  number = {9},
  journaltitle = {Medical Engineering \& Physics},
  urldate = {2019-03-30},
  date = {2004-11},
  pages = {723-732},
  author = {Gillies, A. and Willshaw, D.},
  file = {/Users/qualia/Documents/Papers/2004 - Gillies, Willshaw - Models of the subthalamic nucleus The importance of intranuclear connectivity.pdf}
}

@article{GrEGoire1997,
  langid = {english},
  title = {Effect of Age on Forward and Backward Digit Spans},
  volume = {4},
  issn = {1382-5585, 1744-4128},
  url = {http://www.tandfonline.com/doi/abs/10.1080/13825589708256642},
  doi = {10.1080/13825589708256642},
  abstract = {A number of studies has suggested that aging is characterized by a decline in the central executive while the automatic processes (in particular operations by the phonological loop) remain intact. According to interpretation, age differences should be minimal in verbal forward digit span while they should be more important in backward verbal digit span. A sample of 1,000 subjects with ages ranging from 16 years to 79 years was used to test this hypothesis. The results show no significant effect of age on the difference between digit span forward and backward. The theoretical implications of these results are discussed.},
  number = {2},
  journaltitle = {Aging, Neuropsychology, and Cognition},
  urldate = {2019-03-30},
  date = {1997-06},
  pages = {140-149},
  author = {Gr\'EGoire, Jacques and Van Der Linden, Martial},
  file = {/Users/qualia/Documents/Papers/2004 - Gregoire, Van Der Linden - Effect of age on forward and backward span tasks.pdf}
}

@article{Gurney,
  langid = {english},
  title = {Testing Computational Hypotheses of Brain Systems Function: A Case Study with the Basal Ganglia},
  abstract = {We develop a methodology for testing computational hypotheses about neural functionality articulated in models at the systems level of description. In this approach, the first step is to attempt the construction of a model of the underlying brain system which is consistent with the known anatomy and physiology, but which is also able to exhibit functional properties consistent with a putative computational hypothesis. If this is successful, the second step consists of including additional known pathways into the model and testing the new models to see whether they show an improvement in functional performance (using appropriate performance metrics). A positive outcome is taken as evidence in support of the hypothesis. A final step is to construct `control' models by including pathways that are not consistent with biological data. In this case a performance detriment is taken as support for the hypothesis. The methodology is applied to the basal ganglia, and builds on a previously published model of this system (Gurney et al 2001 Biol. Cybern. 84 401\textendash{}23) which was based on the hypothesis that the basal ganglia perform action selection. The realistically constrained models show a selection benefit, while control models show a decrement in selection ability. These results, taken together, provide further validation of our selection hypothesis of basal ganglia function.},
  pages = {29},
  author = {Gurney, K N and Humphries, M and Wood, R and Prescott, T J and Redgrave, P},
  file = {/Users/qualia/Documents/Papers/2004 - Gurney et al. - Testing computational hypotheses of brain systems function a case study with the basal ganglia K.pdf}
}

@article{Hasson2004,
  langid = {english},
  title = {Intersubject {{Synchronization}} of {{Cortical Activity During Natural Vision}}},
  volume = {303},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1089506},
  doi = {10.1126/science.1089506},
  number = {5664},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2004-03-12},
  pages = {1634-1640},
  author = {Hasson, U.},
  file = {/Users/qualia/Documents/Papers/2004 - Hasson et al. - Intersubject synchronization of cortical activity during natural vision.pdf}
}

@article{Heekeren2004,
  langid = {english},
  title = {A General Mechanism for Perceptual Decision-Making in the Human Brain},
  volume = {431},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature02966},
  doi = {10.1038/nature02966},
  number = {7010},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2004-10},
  pages = {859-862},
  author = {Heekeren, H. R. and Marrett, S. and Bandettini, P. A. and Ungerleider, L. G.},
  file = {/Users/qualia/Documents/Papers/2004 - Heekeren et al. - A general mechanism for perceptual decision-making in the human brain.pdf}
}

@article{Hsu2004,
  langid = {english},
  title = {Quantifying Variability in Neural Responses and Its Application for the Validation of Model Predictions},
  volume = {15},
  issn = {0954-898X, 1361-6536},
  url = {http://www.informaworld.com/openurl?genre=article&doi=10.1088/0954-898X/15/2/002&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
  doi = {10.1088/0954-898X/15/2/002},
  abstract = {A rate code assumes that a neuron's response is completely characterized by its time-varying mean firing rate. This assumption has successfully described neural responses in many systems. The noise in rate coding neurons can be quantified by the coherence function or the correlation coefficient between the neuron's deterministic time-varying mean rate and noise corrupted single spike trains. Because of the finite data size, the mean rate cannot be known exactly and must be approximated. We introduce novel unbiased estimators for the measures of coherence and correlation which are based on the extrapolation of the signal to noise ratio in the neural response to infinite data size. We then describe the application of these estimates to the validation of the class of stimulus\textendash{}response models that assume that the mean firing rate captures all the information embedded in the neural response. We explain how these quantifiers can be used to separate response prediction errors that are due to inaccurate model assumptions from errors due to noise inherent in neuronal spike trains.},
  number = {2},
  journaltitle = {Network: Computation in Neural Systems},
  urldate = {2019-03-30},
  date = {2004-05-01},
  pages = {91-109},
  author = {Hsu, Anne and Borst, Alexander and Theunissen, Fr\'ed\'eric},
  file = {/Users/qualia/Documents/Papers/2004 - Hsu, Borst, Theunissen - Quantifying variability in neural responses and its application for the validation of model predictions.pdf}
}

@book{Izhikevich2006,
  langid = {english},
  title = {Dynamical {{Systems}} in {{Neuroscience}}: {{The Geometry}} of {{Excitability}} and {{Bursting}}},
  isbn = {978-0-262-27607-8},
  url = {https://direct.mit.edu/books/book/2589/dynamical-systems-in-neurosciencethe-geometry-of},
  shorttitle = {Dynamical {{Systems}} in {{Neuroscience}}},
  publisher = {{The MIT Press}},
  urldate = {2019-03-30},
  date = {2006},
  author = {Izhikevich, Eugene M.},
  file = {/Users/qualia/Documents/Papers/2004 - Izhikevich - Dynamical Systems in Neuroscience.pdf},
  doi = {10.7551/mitpress/2526.001.0001}
}

@article{Izhikevich2004,
  langid = {english},
  title = {Which {{Model}} to {{Use}} for {{Cortical Spiking Neurons}}?},
  volume = {15},
  issn = {1045-9227},
  url = {http://ieeexplore.ieee.org/document/1333071/},
  doi = {10.1109/TNN.2004.832719},
  abstract = {We discuss the biological plausibility and computational efficiency of some of the most useful models of spiking and bursting neurons. We compare their applicability to large-scale simulations of cortical neural networks.},
  number = {5},
  journaltitle = {IEEE Transactions on Neural Networks},
  urldate = {2019-03-30},
  date = {2004-09},
  pages = {1063-1070},
  author = {Izhikevich, E.M.},
  file = {/Users/qualia/Documents/Papers/2004 - Izhikevich - Which model to use for cortical spiking neurons.pdf}
}

@article{Jolivet2004,
  langid = {english},
  title = {Generalized {{Integrate}}-and-{{Fire Models}} of {{Neuronal Activity Approximate Spike Trains}} of a {{Detailed Model}} to a {{High Degree}} of {{Accuracy}}},
  volume = {92},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00190.2004},
  doi = {10.1152/jn.00190.2004},
  number = {2},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2004-08},
  pages = {959-976},
  author = {Jolivet, Renaud and Lewis, Timothy J. and Gerstner, Wulfram},
  file = {/Users/qualia/Documents/Papers/2004 - Jolivet, Lewis, Gerstner - Generalized integrate-and-fire models of neuronal activity approximate spike trains of a detailed mode.pdf}
}

@article{Kivinen2004,
  langid = {english},
  title = {Online {{Learning}} with {{Kernels}}},
  volume = {52},
  issn = {1053-587X},
  url = {http://ieeexplore.ieee.org/document/1315937/},
  doi = {10.1109/TSP.2004.830991},
  abstract = {Kernel-based algorithms such as support vector machines have achieved considerable success in various problems in batch setting, where all of the training data is available in advance. Support vector machines combine the so-called kernel trick with the large margin idea. There has been little use of these methods in an online setting suitable for real-time applications. In this paper, we consider online learning in a reproducing kernel Hilbert space. By considering classical stochastic gradient descent within a feature space and the use of some straightforward tricks, we develop simple and computationally efficient algorithms for a wide range of problems such as classification, regression, and novelty detection.},
  number = {8},
  journaltitle = {IEEE Transactions on Signal Processing},
  urldate = {2019-03-30},
  date = {2004-08},
  pages = {2165-2176},
  author = {Kivinen, J. and Smola, A.J. and Williamson, R.C.},
  file = {/Users/qualia/Documents/Papers/2004 - Kivinen, Smola, Williamson - Online Learning with Kernels.pdf}
}

@article{Mel2004,
  langid = {english},
  title = {On the {{Fight Between Excitation}} and {{Inhibition}}: {{Location Is Everything}}},
  volume = {2004},
  issn = {1945-0877, 1937-9145},
  url = {http://stke.sciencemag.org/cgi/doi/10.1126/stke.2502004pe44},
  doi = {10.1126/stke.2502004pe44},
  shorttitle = {On the {{Fight Between Excitation}} and {{Inhibition}}},
  number = {250},
  journaltitle = {Science Signaling},
  urldate = {2019-03-30},
  date = {2004-09-14},
  pages = {pe44-pe44},
  author = {Mel, B. W. and Schiller, J.},
  file = {/Users/qualia/Documents/Papers/2004 - Mel, Schiller - On the fight between excitation and inhibition location is everything.pdf}
}

@article{Mitchell2004,
  langid = {english},
  title = {Learning to {{Decode Cognitive States}} from {{Brain Images}}},
  volume = {57},
  issn = {0885-6125},
  url = {http://link.springer.com/10.1023/B:MACH.0000035475.85309.1b},
  doi = {10.1023/B:MACH.0000035475.85309.1b},
  abstract = {Over the past decade, functional Magnetic Resonance Imaging (fMRI) has emerged as a powerful new instrument to collect vast quantities of data about activity in the human brain. A typical fMRI experiment can produce a three-dimensional image related to the human subject's brain activity every half second, at a spatial resolution of a few millimeters. As in other modern empirical sciences, this new instrumentation has led to a flood of new data, and a corresponding need for new data analysis methods. We describe recent research applying machine learning methods to the problem of classifying the cognitive state of a human subject based on fRMI data observed over a single time interval. In particular, we present case studies in which we have successfully trained classifiers to distinguish cognitive states such as (1) whether the human subject is looking at a picture or a sentence, (2) whether the subject is reading an ambiguous or non-ambiguous sentence, and (3) whether the word the subject is viewing is a word describing food, people, buildings, etc. This learning problem provides an interesting case study of classifier learning from extremely high dimensional (105 features), extremely sparse (tens of training examples), noisy data. This paper summarizes the results obtained in these three case studies, as well as lessons learned about how to successfully apply machine learning methods to train classifiers in such settings.},
  number = {1/2},
  journaltitle = {Machine Learning},
  urldate = {2019-03-30},
  date = {2004-10},
  pages = {145-175},
  author = {Mitchell, Tom M. and Hutchinson, Rebecca and Niculescu, Radu S. and Pereira, Francisco and Wang, Xuerui and Just, Marcel and Newman, Sharlene},
  file = {/Users/qualia/Documents/Papers/2004 - Mitchell et al. - Learning to Decode Cognitive States from Brain Images.pdf}
}

@article{Montgomery2004,
  langid = {english},
  title = {Discrete Synaptic States Define a Major Mechanism of Synapse Plasticity},
  volume = {27},
  issn = {01662236},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223604003340},
  doi = {10.1016/j.tins.2004.10.006},
  number = {12},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {2004-12},
  pages = {744-750},
  author = {Montgomery, Johanna M. and Madison, Daniel V.},
  file = {/Users/qualia/Documents/Papers/2004 - Montgomery, Madison - Discrete synaptic states define a major mechanism of synapse plasticity.pdf}
}

@article{Parkes2004,
  langid = {english},
  title = {Reduced {{BOLD}} Response to Periodic Visual Stimulation},
  volume = {21},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811903005160},
  doi = {10.1016/j.neuroimage.2003.08.025},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2004-01},
  pages = {236-243},
  author = {Parkes, Laura M and Fries, Pascal and Kerskens, Christian M and Norris, David G},
  file = {/Users/qualia/Documents/Papers/2004 - Parkes et al. - Reduced BOLD response to periodic visual stimulation.pdf}
}

@article{Polsky2004,
  langid = {english},
  title = {Computational Subunits in Thin Dendrites of Pyramidal Cells},
  volume = {7},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn1253},
  doi = {10.1038/nn1253},
  number = {6},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2004-06},
  pages = {621-627},
  author = {Polsky, Alon and Mel, Bartlett W and Schiller, Jackie},
  file = {/Users/qualia/Documents/Papers/2004 - Polsky, Mel, Schiller - Computational subunits in thin dendrites of pyramidal cells.pdf}
}

@article{Prinz2004,
  langid = {english},
  title = {The Dynamic Clamp Comes of Age},
  volume = {27},
  issn = {01662236},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223604000554},
  doi = {10.1016/j.tins.2004.02.004},
  number = {4},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {2004-04},
  pages = {218-224},
  author = {Prinz, Astrid A and Abbott, L.F and Marder, Eve},
  file = {/Users/qualia/Documents/Papers/2004 - Prinz, Abbott, Marder - The dynamic clamp comes of age.pdf}
}

@article{Rubin2004,
  langid = {english},
  title = {High {{Frequency Stimulation}} of the {{Subthalamic Nucleus Eliminates Pathological Thalamic Rhythmicity}} in a {{Computational Model}}},
  volume = {16},
  issn = {0929-5313},
  url = {http://link.springer.com/10.1023/B:JCNS.0000025686.47117.67},
  doi = {10.1023/B:JCNS.0000025686.47117.67},
  abstract = {Deep brain stimulation (DBS) of the subthalamic nucleus (STN) or the internal segment of the globus pallidus (GPi) has recently been recognized as an important form of intervention for alleviating motor symptoms associated with Parkinson's disease, but the mechanism underlying its effectiveness remains unknown. Using a computational model, this paper considers the hypothesis that DBS works by replacing pathologically rhythmic basal ganglia output with tonic, high frequency firing. In our simulations of parkinsonian conditions, rhythmic inhibition from GPi to the thalamus compromises the ability of thalamocortical relay (TC) cells to respond to depolarizing inputs, such as sensorimotor signals. High frequency stimulation of STN regularizes GPi firing, and this restores TC responsiveness, despite the increased frequency and amplitude of GPi inhibition to thalamus that result. We provide a mathematical phase plane analysis of the mechanisms that determine TC relay capabilities in normal, parkinsonian, and DBS states in a reduced model. This analysis highlights the differences in deinactivation of the low-threshold calcium T -current that we observe in TC cells in these different conditions. Alternative scenarios involving convergence of thalamic signals in the cortex are also discussed, and predictions associated with these results, including the occurrence of rhythmic rebound bursts in certain TC cells in parkinsonian states and their drastic reduction by DBS, are stated. These results demonstrate how DBS could work by increasing firing rates of target cells, rather than shutting them down.},
  number = {3},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2004-05},
  pages = {211-235},
  author = {Rubin, Jonathan E. and Terman, David},
  file = {/Users/qualia/Documents/Papers/2004 - Rubin, Terman - High Frequency Stimulation of the Subthalamic Nucleus Eliminates .pdf}
}

@article{Schreckenberger2004,
  langid = {english},
  title = {The Thalamus as the Generator and Modulator of {{EEG}} Alpha Rhythm: A Combined {{PET}}/{{EEG}} Study with Lorazepam Challenge in Humans},
  volume = {22},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811904000886},
  doi = {10.1016/j.neuroimage.2004.01.047},
  shorttitle = {The Thalamus as the Generator and Modulator of {{EEG}} Alpha Rhythm},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2004-06},
  pages = {637-644},
  author = {Schreckenberger, Mathias and Lange-Asschenfeld, Christian and Lochmann, Matthias and Mann, Klaus and Siessmeier, Thomas and Buchholz, Hans-Georg and Bartenstein, Peter and Gr\"under, Gerhard},
  file = {/Users/qualia/Documents/Papers/2004 - Schreckenberger et al. - The thalamus as the generator and modulator of EEG alpha rhythm A combined PETEEG study with lorazepam c.pdf}
}

@article{Serences2004,
  langid = {english},
  title = {A Comparison of Methods for Characterizing the Event-Related {{BOLD}} Timeseries in Rapid {{fMRI}}},
  volume = {21},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811903007870},
  doi = {10.1016/j.neuroimage.2003.12.021},
  number = {4},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2004-04},
  pages = {1690-1700},
  author = {Serences, John T.},
  file = {/Users/qualia/Documents/Papers/2004 - Serences - A comparison of methods for characterizing the event-related BOLD timeseries in rapid fMRI.pdf}
}

@article{Silberberg2004,
  langid = {english},
  title = {Synaptic Dynamics Control the Timing of Neuronal Excitation in the Activated Neocortical Microcircuit: {{Synaptic}} Dynamics Shape Cross-Correlations},
  volume = {556},
  issn = {00223751},
  url = {http://doi.wiley.com/10.1113/jphysiol.2004.060962},
  doi = {10.1113/jphysiol.2004.060962},
  shorttitle = {Synaptic Dynamics Control the Timing of Neuronal Excitation in the Activated Neocortical Microcircuit},
  number = {1},
  journaltitle = {The Journal of Physiology},
  urldate = {2019-03-30},
  date = {2004-04},
  pages = {19-27},
  author = {Silberberg, Gilad and Wu, Caizhi and Markram, Henry},
  file = {/Users/qualia/Documents/Papers/2004 - Silberberg, Wu, Markram - Synaptic dynamics control the timing of neuronal excitation in the activated neocortical microcircuit.pdf}
}

@article{Spencer2004,
  langid = {english},
  title = {Neural Synchrony Indexes Disordered Perception and Cognition in Schizophrenia},
  volume = {101},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0406074101},
  doi = {10.1073/pnas.0406074101},
  number = {49},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2004-12-07},
  pages = {17288-17293},
  author = {Spencer, K. M. and Nestor, P. G. and Perlmutter, R. and Niznikiewicz, M. A. and Klump, M. C. and Frumin, M. and Shenton, M. E. and McCarley, R. W.},
  file = {/Users/qualia/Documents/Papers/2004 - Spencer et al. - Neural synchrony indexes disordered perception and cognition in schizophrenia.pdf}
}

@article{Vogel2004,
  langid = {english},
  title = {Neural Activity Predicts Individual Differences in Visual Working Memory Capacity},
  volume = {428},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature02447},
  doi = {10.1038/nature02447},
  number = {6984},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2004-04},
  pages = {748-751},
  author = {Vogel, Edward K. and Machizawa, Maro G.},
  file = {/Users/qualia/Documents/Papers/2004 - Vogel, Machizawa - Neural activity predicts individual differences in visual working memory capacity.pdf}
}

@article{Wagenmakers2004,
  langid = {english},
  title = {{{AIC}} Model Selection Using {{Akaike}} Weights},
  volume = {11},
  issn = {1069-9384, 1531-5320},
  url = {http://www.springerlink.com/index/10.3758/BF03206482},
  doi = {10.3758/BF03206482},
  number = {1},
  journaltitle = {Psychonomic Bulletin \& Review},
  urldate = {2019-03-30},
  date = {2004-02},
  pages = {192-196},
  author = {Wagenmakers, Eric-Jan and Farrell, Simon},
  file = {/Users/qualia/Documents/Papers/2004 - Wagenmakers, Farrell - AIC model selection using Akaike weights.pdf}
}

@incollection{Abbott2005,
  langid = {english},
  title = {Drivers and Modulators from Push-Pull and Balanced Synaptic Input},
  volume = {149},
  isbn = {978-0-444-51679-4},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0079612305490111},
  abstract = {In 1998, Sherman and Guillery proposed that there are two types of inputs to cortical neurons; drivers and modulators. These two forms of input are required to explain how, for example, sensory driven responses are controlled and modified by attention and other internally generated gating signals. One might imagine that driver signals are carried by fast ionotropic receptors, whereas modulators correspond to slower metabotropic receptors. Instead, we have proposed a novel mechanism by which both driver and modulator inputs could be carried by transmission through the same types of ionotropic receptors. In this scheme, the distinction between driver and modulator inputs is functional and changeable rather than anatomical and fixed. Driver inputs are carried by excitation and inhibition acting in a push-pull manner. This means that increases in excitation are accompanied by decreases in inhibition and vice versa. Modulators correspond to excitation and inhibition that covary so that they increase or decrease together. Theoretical and experimental work has shown that such an arrangement modulates the gain of a neuron, rather than driving it to respond. Constructing drivers and modulators in this manner allows individual excitatory synaptic inputs to play either role, and indeed to switch between roles, depending on how they are linked with inhibition.},
  booktitle = {Progress in {{Brain Research}}},
  publisher = {{Elsevier}},
  urldate = {2019-03-30},
  date = {2005},
  pages = {147-155},
  author = {Abbott, L.F. and Chance, Frances S.},
  file = {/Users/qualia/Documents/Papers/2005 - Abbott, Chance - Drivers and modulators from push-pull and balanced synaptic input.pdf},
  doi = {10.1016/S0079-6123(05)49011-1}
}

@article{Bannister2005,
  langid = {english},
  title = {Inter- and Intra-Laminar Connections of Pyramidal Cells in the Neocortex},
  volume = {53},
  issn = {01680102},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0168010205001884},
  doi = {10.1016/j.neures.2005.06.019},
  abstract = {The flow of excitation through cortical columns has long since been predicted by studying the axonal projection patterns of excitatory neurones situated within different laminae. In grossly simplified terms and assuming random connectivity, such studies predict that input from the thalamus terminates primarily in layer 4, is relayed `forward' to layer 3, then to layers 5 and 6 from where the modified signal may exit the cortex. Projection patterns also indicate `back' projections from layer 5 to 3 and layer 6 to 4. More recently it has become clear that the interconnections between these layers are not random; forward projections primarily contact specific pyramidal subclasses and intracortical back projections innervate interneurones. This indicates that presynaptic axons or postsynaptic dendrites are capable of selecting their synaptic partners and that this selectivity is layer dependent.},
  number = {2},
  journaltitle = {Neuroscience Research},
  urldate = {2019-03-30},
  date = {2005-10},
  pages = {95-103},
  author = {Bannister, A. Peter},
  file = {/Users/qualia/Documents/Papers/2005 - Bannister - Inter- and intra-laminar connections of pyramidal cells in the neocortex.pdf}
}

@article{Bopp2005,
  langid = {english},
  title = {Aging and {{Verbal Memory Span}}: {{A Meta}}-{{Analysis}}},
  volume = {60},
  issn = {1079-5014, 1758-5368},
  url = {https://academic.oup.com/psychsocgerontology/article-lookup/doi/10.1093/geronb/60.5.P223},
  doi = {10.1093/geronb/60.5.P223},
  shorttitle = {Aging and {{Verbal Memory Span}}},
  number = {5},
  journaltitle = {The Journals of Gerontology Series B: Psychological Sciences and Social Sciences},
  urldate = {2019-03-30},
  date = {2005-09-01},
  pages = {P223-P233},
  author = {Bopp, K. L. and Verhaeghen, P.},
  file = {/Users/qualia/Documents/Papers/2005 - Bopp, Verhaeghen - Aging and verbal memory span A meta-analysis.pdf}
}

@article{Brown2005,
  langid = {english},
  title = {A {{Ballistic Model}} of {{Choice Response Time}}.},
  volume = {112},
  issn = {1939-1471, 0033-295X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.112.1.117},
  doi = {10.1037/0033-295X.112.1.117},
  number = {1},
  journaltitle = {Psychological Review},
  urldate = {2019-03-30},
  date = {2005},
  pages = {117-128},
  author = {Brown, Scott and Heathcote, Andrew},
  file = {/Users/qualia/Documents/Papers/2005 - Brown, Heathcote - A ballistic model of choice response time.pdf}
}

@article{Cardin2005,
  langid = {english},
  title = {Stimulus-{{Dependent}} (30-50 {{Hz}}) {{Oscillations}} in {{Simple}} and {{Complex Fast Rhythmic Bursting Cells}} in {{Primary Visual Cortex}}},
  volume = {25},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0374-05.2005},
  doi = {10.1523/JNEUROSCI.0374-05.2005},
  number = {22},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2005-06-01},
  pages = {5339-5350},
  author = {Cardin, J. A.},
  file = {/Users/qualia/Documents/Papers/2005 - Cardin, Palmer, Contreras - Stimulus-Dependent gamma (30-50 Hz) Oscillations in Simple and Complex Fast Rhythmic Bursting Cell.pdf}
}

@article{Charness,
  langid = {english},
  title = {When {{Optimal Choices Feel Wrong}}: {{A Laboratory Study}} of {{Bayesian Updating}}, {{Complexity}}, and {{Affect}}},
  abstract = {We examine decision-making under risk and uncertainty in a laboratory experiment. The heart of our design examines how one's propensity to use Bayes' rule is affected by whether this rule is aligned with reinforcement or clashes with it. In some cases, we create environments where Bayesian updating after a successful outcome should lead a decision-maker to make a change, while no change should be made after observing an unsuccessful outcome.},
  pages = {41},
  author = {Charness, Gary and Levin, Dan},
  file = {/Users/qualia/Documents/Papers/2005 - Charness, Levin - When optimal choices feel wrong A laboratory study of bayesian updating, complexity, and affect.pdf}
}

@article{Coombes2005,
  langid = {english},
  title = {Waves, Bumps, and Patterns in Neural Field Theories},
  volume = {93},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-005-0574-y},
  doi = {10.1007/s00422-005-0574-y},
  abstract = {Neural field models of firing rate activity have had a major impact in helping to develop an understanding of the dynamics seen in brain slice preparations. These models typically take the form of integrodifferential equations. Their non-local nature has led to the development of a set of analytical and numerical tools for the study of waves, bumps and patterns, based around natural extensions of those used for local differential equation models. In this paper we present a review of such techniques and show how recent advances have opened the way for future studies of neural fields in both one and two dimensions that can incorporate realistic forms of axo-dendritic interactions and the slow intrinsic currents that underlie bursting behaviour in single neurons.},
  number = {2},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2005-08},
  pages = {91-108},
  author = {Coombes, S.},
  file = {/Users/qualia/Documents/Papers/2005 - Coombes - Waves, bumps, and patterns in neural field theories.pdf}
}

@article{Deneve,
  langid = {english},
  title = {Bayesian Inference in Spiking Neurons},
  abstract = {We propose a new interpretation of spiking neurons as Bayesian integrators accumulating evidence over time about events in the external world or the body, and communicating to other neurons their certainties about these events. In this model, spikes signal the occurrence of new information, i.e. what cannot be predicted from the past activity. As a result, firing statistics are close to Poisson, albeit providing a deterministic representation of probabilities. We proceed to develop a theory of Bayesian inference in spiking neural networks, recurrent interactions implementing a variant of belief propagation.},
  pages = {8},
  author = {Deneve, Sophie},
  file = {/Users/qualia/Documents/Papers/2005 - Deneve - Bayesian Inference in Spiking Neurons.pdf}
}

@article{Ekstrom2005,
  langid = {english},
  title = {Human Hippocampal Theta Activity during Virtual Navigation},
  volume = {15},
  issn = {1050-9631, 1098-1063},
  url = {http://doi.wiley.com/10.1002/hipo.20109},
  doi = {10.1002/hipo.20109},
  abstract = {This study examines whether 4\textendash{}8-Hz theta oscillations can be seen in the human hippocampus, and whether these oscillations increase during virtual movement and searching, as they do in rodents. Recordings from both hippocampal and neocortical depth electrodes were analyzed while six epileptic patients played a virtual taxi-driver game. During the game, the patients alternated between searching for passengers, whose locations were random, and delivering them to stores, whose locations remained constant. In both hippocampus and neocortex, theta increased during virtual movement in all phases of the game. Hippocampal and neocortical theta activity were also significantly correlated with each other, but this correlation did not differ between neocortex and hippocampus and within disparate neocortical electrodes. Our findings demonstrate the existence of movement-related theta oscillations in human hippocampus, and suggest that both cortical and hippocampal oscillations play a role in attention and sensorimotor integration. VC 2005 Wiley-Liss, Inc.},
  number = {7},
  journaltitle = {Hippocampus},
  urldate = {2019-03-30},
  date = {2005},
  pages = {881-889},
  author = {Ekstrom, Arne D. and Caplan, Jeremy B. and Ho, Emily and Shattuck, Kirk and Fried, Itzhak and Kahana, Michael J.},
  file = {/Users/qualia/Documents/Papers/2005 - Ekstrom et al. - Human hippocampal theta activity during virtual navigation.pdf}
}

@article{Gabaix,
  langid = {english},
  title = {Bounded {{Rationality}} and {{Directed Cognition}}},
  abstract = {This paper proposes a psychological bounded rationality algorithm that uses partially myopic option value calculations to allocate scarce cognitive resources. The model can be operationalized even when decision problems require an arbitrarily large number of state variables. We evaluate the model using experimental data on a class of complex one-person games with full information. The model explains the experimental data better than the rational actor model with zero cognition costs.},
  pages = {46},
  author = {Gabaix, Xavier and Laibson, David},
  file = {/Users/qualia/Documents/Papers/2005 - Gabaix, Laibson - Bounded Rationality and Directed Cognition.pdf}
}

@article{Haeri2005,
  langid = {english},
  title = {Modeling the {{Parkinson}}'s Tremor and Its Treatments},
  volume = {236},
  issn = {00225193},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022519305001232},
  doi = {10.1016/j.jtbi.2005.03.014},
  abstract = {In this paper, we discuss modeling issues of the Parkinson's tremor. Through the work we have employed physiological structure as well as functioning of the parts in brain that are involved in the disease. To obtain more practical similarity, random behaviors of the connection paths are also considered. Medication or treatment of the disease both by drug prescription and electrical signal stimulation are modeled based on the same model introduced for the disease itself. Two new medication strategies are proposed based on the model to reduce the side effects caused by the present drug prescription.},
  number = {3},
  journaltitle = {Journal of Theoretical Biology},
  urldate = {2019-03-30},
  date = {2005-10},
  pages = {311-322},
  author = {Haeri, Mohammad and Sarbaz, Yashar and Gharibzadeh, Shahriar},
  file = {/Users/qualia/Documents/Papers/2005 - Haeri, Sarbaz, Gharibzadeh - Modeling the Parkinson's tremor and its treatments.pdf}
}

@article{Haynes2005,
  langid = {english},
  title = {Predicting the Orientation of Invisible Stimuli from Activity in Human Primary Visual Cortex},
  volume = {8},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn1445},
  doi = {10.1038/nn1445},
  number = {5},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2005-05},
  pages = {686-691},
  author = {Haynes, John-Dylan and Rees, Geraint},
  file = {/Users/qualia/Documents/Papers/2005 - Haynes, Rees - Predicting the orientation of invisible stimuli from activity in human primary visual cortex.pdf}
}

@article{Hopkins2005,
  langid = {english},
  title = {Attainability of Boundary Points under Reinforcement Learning},
  volume = {53},
  issn = {08998256},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0899825604001241},
  doi = {10.1016/j.geb.2004.08.002},
  abstract = {This paper investigates the properties of the most common form of reinforcement learning (the ``basic model'' of Erev and Roth, American Economic Review, 88, 848-881, 1998). Stochastic approximation theory has been used to analyse the local stability of fixed points under this learning process. However, as we show, when such points are on the boundary of the state space, for example, pure strategy equilibria, standard results from the theory of stochastic approximation do not apply. We offer what we believe to be the correct treatment of boundary points, and provide a new and more general result: this model of learning converges with zero probability to fixed points which are unstable under the Maynard Smith or adjusted version of the evolutionary replicator dynamics. For two player games these are the fixed points that are linearly unstable under the standard replicator dynamics.},
  number = {1},
  journaltitle = {Games and Economic Behavior},
  urldate = {2019-03-30},
  date = {2005-10},
  pages = {110-125},
  author = {Hopkins, Ed and Posch, Martin},
  file = {/Users/qualia/Documents/Papers/2005 - Hopkins, Posch - Attainability of boundary points under reinforcement learning.pdf}
}

@article{Jehiel,
  langid = {english},
  title = {Analogy Based Expectation Equilibrium},
  abstract = {It is assumed that players bundle nodes in which other players must move into analogy classes, and players only have expectations about the average behavior in every class. A solution concept is proposed for multi-stage games with perfect information: at every node players choose best-responses to their analogy-based expectations, and expectations are correct on average over those various nodes pooled together into the same analogy classes. The approach is applied to a variety of games. It is shown that a player may bene\TH{}t from having a coarse analogy partitioning. And for simple analogy partitioning, (1) initial cooperation followed by an end opportunistic behavior may emerge in the \TH{}nitely repeated prisoner's dilemma (or in the centipede game), (2) an agreement need not be reached immediately in bargaining games with complete information.},
  pages = {38},
  author = {Jehiel, P},
  file = {/Users/qualia/Documents/Papers/2005 - Jehiel - Analogy-based expectation equilibrium.pdf}
}

@article{Kamitani2005,
  langid = {english},
  title = {Decoding the Visual and Subjective Contents of the Human Brain},
  volume = {8},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn1444},
  doi = {10.1038/nn1444},
  number = {5},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2005-05},
  pages = {679-685},
  author = {Kamitani, Yukiyasu and Tong, Frank},
  file = {/Users/qualia/Documents/Papers/2005 - Kamitani, Tong - Decoding the visual and subjective contents of the human brain.pdf}
}

@article{Laconte2005,
  langid = {english},
  title = {Support Vector Machines for Temporal Classification of Block Design {{fMRI}} Data},
  volume = {26},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811905000893},
  doi = {10.1016/j.neuroimage.2005.01.048},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2005-06},
  pages = {317-329},
  author = {Laconte, S and Strother, S and Cherkassky, V and Anderson, J and Hu, X},
  file = {/Users/qualia/Documents/Papers/2005 - LaConte et al. - Support vector machines for temporal classification of block design fMRI data.pdf}
}

@article{Lee2005,
  langid = {english},
  title = {Learning and Decision Making in Monkeys during a Rock\textendash{}Paper\textendash{}Scissors Game},
  volume = {25},
  issn = {09266410},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0926641005001953},
  doi = {10.1016/j.cogbrainres.2005.07.003},
  abstract = {Game theory provides a solution to the problem of finding a set of optimal decision-making strategies in a group. However, people seldom play such optimal strategies and adjust their strategies based on their experience. Accordingly, many theories postulate a set of variables related to the probabilities of choosing various strategies and describe how such variables are dynamically updated. In reinforcement learning, these value functions are updated based on the outcome of the player's choice, whereas belief learning allows the value functions of all available choices to be updated according to the choices of other players. We investigated the nature of learning process in monkeys playing a competitive game with ternary choices, using a rock \textendash{} paper \textendash{} scissors game. During the baseline condition in which the computer selected its targets randomly, each animal displayed biases towards some targets. When the computer exploited the pattern of animal's choice sequence but not its reward history, the animal's choice was still systematically biased by the previous choice of the computer. This bias was reduced when the computer exploited both the choice and reward histories of the animal. Compared to simple models of reinforcement learning or belief learning, these adaptive processes were better described by a model that incorporated the features of both models. These results suggest that stochastic decision-making strategies in primates during social interactions might be adjusted according to both actual and hypothetical payoffs.},
  number = {2},
  journaltitle = {Cognitive Brain Research},
  urldate = {2019-03-30},
  date = {2005-10},
  pages = {416-430},
  author = {Lee, Daeyeol and McGreevy, Benjamin P. and Barraclough, Dominic J.},
  file = {/Users/qualia/Documents/Papers/2005 - Lee, McGreevy, Barraclough - Learning and decision making in monkeys during a rock-paper-scissors game.pdf}
}

@article{Levesque2005,
  langid = {english},
  title = {{{GABAergic}} Interneurons in Human Subthalamic Nucleus},
  volume = {20},
  issn = {0885-3185, 1531-8257},
  url = {http://doi.wiley.com/10.1002/mds.20374},
  doi = {10.1002/mds.20374},
  number = {5},
  journaltitle = {Movement Disorders},
  urldate = {2019-03-30},
  date = {2005-05},
  pages = {574-584},
  author = {L\'evesque, Julie-Christine and Parent, Andr\'e},
  file = {/Users/qualia/Documents/Papers/2005 - Lévesque, André - GABAergic interneurons in human subthalamic nucleus.pdf}
}

@article{Mao,
  langid = {english},
  title = {Modeling the {{Role}} of the {{Basal Ganglia}} in {{Motor Control}} and {{Motor Programming}}},
  abstract = {The basal ganglia (BG) are a group of highly interconnected nuclei buried deep in the brain. They are involved in an important range of brain functions, including both lower-level movement control and higher-level cognitive decision making. Dysfunction of the BG has been linked to the human neurological disorders such as Parkinson's disease, Huntington's disease, and schizophrenia.},
  pages = {166},
  author = {Mao, Zhi-Hong},
  file = {/Users/qualia/Documents/Papers/2005 - Mao - Modeling the Role of the Basal Ganglia in Motor Control and Motor Programming.pdf}
}

@article{Netoff2005,
  langid = {english},
  title = {Synchronization in {{Hybrid Neuronal Networks}} of the {{Hippocampal Formation}}},
  volume = {93},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00982.2004},
  doi = {10.1152/jn.00982.2004},
  number = {3},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2005-03},
  pages = {1197-1208},
  author = {Netoff, Theoden I. and Banks, Matthew I. and Dorval, Alan D. and Acker, Corey D. and Haas, Julie S. and Kopell, Nancy and White, John A.},
  file = {/Users/qualia/Documents/Papers/2005 - Netoff et al. - Synchronization in hybrid neuronal networks of the hippocampal formation(2).pdf}
}

@article{OToole2005,
  langid = {english},
  title = {Partially {{Distributed Representations}} of {{Objects}} and {{Faces}} in {{Ventral Temporal Cortex}}},
  volume = {17},
  issn = {0898-929X, 1530-8898},
  url = {http://www.mitpressjournals.org/doi/10.1162/0898929053467550},
  doi = {10.1162/0898929053467550},
  number = {4},
  journaltitle = {Journal of Cognitive Neuroscience},
  urldate = {2019-03-30},
  date = {2005-04},
  pages = {580-590},
  author = {O'Toole, Alice J. and Jiang, Fang and Abdi, Herv\'e and Haxby, James V.},
  file = {/Users/qualia/Documents/Papers/2005 - O'Toole et al. - Partially distributed representations of objects and faces in ventral temporal cortex.pdf}
}

@article{Song2005,
  langid = {english},
  title = {Highly {{Nonrandom Features}} of {{Synaptic Connectivity}} in {{Local Cortical Circuits}}},
  volume = {3},
  issn = {1545-7885},
  url = {https://dx.plos.org/10.1371/journal.pbio.0030068},
  doi = {10.1371/journal.pbio.0030068},
  number = {3},
  journaltitle = {PLoS Biology},
  urldate = {2019-03-30},
  date = {2005-03-01},
  pages = {e68},
  author = {Song, Sen and Sj\"ostr\"om, Per Jesper and Reigl, Markus and Nelson, Sacha and Chklovskii, Dmitri B},
  editor = {Friston, Karl J.},
  file = {/Users/qualia/Documents/Papers/2005 - Song et al. - Highly nonrandom features of synaptic connectivity in local cortical circuits.pdf}
}

@article{Stacy2005,
  langid = {english},
  title = {Identification of Motor and Nonmotor Wearing-off in {{Parkinson}}'s Disease: {{Comparison}} of a Patient Questionnaire versus a Clinician Assessment},
  volume = {20},
  issn = {0885-3185, 1531-8257},
  url = {http://doi.wiley.com/10.1002/mds.20383},
  doi = {10.1002/mds.20383},
  shorttitle = {Identification of Motor and Nonmotor Wearing-off in {{Parkinson}}'s Disease},
  number = {6},
  journaltitle = {Movement Disorders},
  urldate = {2019-03-30},
  date = {2005-06},
  pages = {726-733},
  author = {Stacy, Mark and Bowron, Annette and Guttman, Mark and Hauser, Robert and Hughes, Kim and Larsen, Jan Petter and LeWitt, Peter and Oertel, Wolfgang and Quinn, Niall and Sethi, Kapil and Stocchi, Fabrizio},
  file = {/Users/qualia/Documents/Papers/2005 - Stacy et al. - Identification of motor and nonmotor wearing-off in Parkinson's disease Comparison of a patient questionnaire vers.pdf}
}

@article{Majumder2005,
  langid = {english},
  title = {Enhanced Flow in Carbon Nanotubes},
  volume = {438},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/438044a},
  doi = {10.1038/438044a},
  number = {7064},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2005-11},
  pages = {44-44},
  author = {Majumder, Mainak and Chopra, Nitin and Andrews, Rodney and Hinds, Bruce J.},
  file = {/Users/qualia/Documents/Papers/2005 - Strogatz et al. - Crowd synchrony on the Millennium Bridge.pdf}
}

@article{Yoshimura2005,
  langid = {english},
  title = {Fine-Scale Specificity of Cortical Networks Depends on Inhibitory Cell Type and Connectivity},
  volume = {8},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn1565},
  doi = {10.1038/nn1565},
  number = {11},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2005-11},
  pages = {1552-1559},
  author = {Yoshimura, Yumiko and Callaway, Edward M},
  file = {/Users/qualia/Documents/Papers/2005 - Yoshimura, Callaway - Fine-scale specificity of cortical networks depends on inhibitory cell type and connectivity.pdf}
}

@article{Alonso-Frech2006,
  langid = {english},
  title = {Slow Oscillatory Activity and Levodopa-Induced Dyskinesias in {{Parkinson}}'s Disease},
  volume = {129},
  issn = {0006-8950, 1460-2156},
  url = {https://academic.oup.com/brain/article-lookup/doi/10.1093/brain/awl103},
  doi = {10.1093/brain/awl103},
  number = {7},
  journaltitle = {Brain},
  urldate = {2019-03-30},
  date = {2006-07-01},
  pages = {1748-1757},
  author = {Alonso-Frech, F.},
  file = {/Users/qualia/Documents/Papers/2006 - Alonso-Frech et al. - Slow oscillatory activity and levodopa-induced dyskinesias in Parkinson's disease.pdf}
}

@article{Churchland2006,
  langid = {english},
  title = {A {{Central Source}} of {{Movement Variability}}},
  volume = {52},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627306008713},
  doi = {10.1016/j.neuron.2006.10.034},
  abstract = {Movements are universally, sometimes frustratingly, variable. When such variability causes error, we typically assume that something went wrong during the movement. The same assumption is made by recent and influential models of motor control. These posit that the principal limit on repeatable performance is neuromuscular noise that corrupts movement as it occurs. An alternative hypothesis is that movement variability arises before movements begin, during motor preparation. We examined this possibility directly by recording the preparatory activity of single cortical neurons during a highly practiced reach task. Small variations in preparatory neural activity were predictive of small variations in the upcoming reach. Effect magnitudes were such that at least half of the observed movement variability likely had its source during motor preparation. Thus, even for a highly practiced task, the ability to repeatedly plan the same movement limits our ability to repeatedly execute the same movement.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2006-12},
  pages = {1085-1096},
  author = {Churchland, Mark M. and Afshar, Afsheen and Shenoy, Krishna V.},
  file = {/Users/qualia/Documents/Papers/2006 - Baudouin-Cornu, Bragg - Analyzing proteomic, genomic and transcriptomic elemental compositions to uncover the intimate evolution.pdf}
}

@article{Bereby-Meyer2006,
  langid = {english},
  title = {The {{Speed}} of {{Learning}} in {{Noisy Games}}: {{Partial Reinforcement}} and the {{Sustainability}} of {{Cooperation}}},
  volume = {96},
  issn = {0002-8282},
  url = {http://pubs.aeaweb.org/doi/10.1257/aer.96.4.1029},
  doi = {10.1257/aer.96.4.1029},
  shorttitle = {The {{Speed}} of {{Learning}} in {{Noisy Games}}},
  abstract = {In an experiment, players' ability to learn to cooperate in the repeated prisoner's dilemma was substantially diminished when the payoffs were noisy, even though players could monitor one another's past actions perfectly. In contrast, in one-time play against a succession of opponents, noisy payoffs increased cooperation, by slowing the rate at which cooperation decays. These observations are consistent with the robust observation from the psychology literature that partial reinforcement (adding randomness to the link between an action and its consequences while holding expected payoffs constant) slows learning. This effect is magnified in the repeated game: When others are slow to learn to cooperate, the benefits of cooperation are reduced, which further hampers cooperation. These results show that a small change in the payoff environment, which changes the speed of individual learning, can have a large effect on collective behavior. And they show that there may be interesting comparative dynamics that can be derived from careful attention to the fact that at least some economic behavior is learned from experience.},
  number = {4},
  journaltitle = {American Economic Review},
  urldate = {2019-03-30},
  date = {2006-08},
  pages = {1029-1042},
  author = {Bereby-Meyer, Yoella and Roth, Alvin E},
  file = {/Users/qualia/Documents/Papers/2006 - Bereby-Meyer, Roth - The speed of learning in noisy games Partial reinforcement and the sustainability of cooperation.pdf}
}

@article{Bruno2006,
  langid = {english},
  title = {Cortex {{Is Driven}} by {{Weak}} but {{Synchronously Active Thalamocortical Synapses}}},
  volume = {312},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1124593},
  doi = {10.1126/science.1124593},
  number = {5780},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2006-06-16},
  pages = {1622-1627},
  author = {Bruno, R. M.},
  file = {/Users/qualia/Documents/Papers/2006 - Bruno, Sakmann - Cortex is driven by weak but synchronously active thalamocortical synapses.pdf}
}

@article{Bunzeck2006,
  langid = {english},
  title = {Absolute {{Coding}} of {{Stimulus Novelty}} in the {{Human Substantia Nigra}}/{{VTA}}},
  volume = {51},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627306004752},
  doi = {10.1016/j.neuron.2006.06.021},
  abstract = {Novelty exploration can enhance hippocampal plasticity in animals through dopaminergic neuromodulation arising in the substantia nigra/ventral tegmental area (SN/VTA). This enhancement can outlast the exploration phase by several minutes. Currently, little is known about dopaminergic novelty processing and its relationship to hippocampal function in humans. In two functional magnetic resonance imaging (fMRI) studies, SN/VTA activations in humans were indeed driven by stimulus novelty rather than other forms of stimulus salience such as rareness, negative emotional valence, or targetness of familiar stimuli, whereas hippocampal responses were less selective. SN/VTA novelty responses were scaled according to absolute rather than relative novelty in a given context, unlike adaptive SN/VTA responses recently reported for reward outcome in animal studies. Finally, novelty enhanced learning and perirhinal/parahippocampal processing of familiar items presented in the same context. Thus, the human SN/VTA can code absolute stimulus novelty and might contribute to enhancing learning in the context of novelty.},
  number = {3},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2006-08},
  pages = {369-379},
  author = {Bunzeck, Nico and D\"uzel, Emrah},
  file = {/Users/qualia/Documents/Papers/2006 - Bunzeck, Düzel - Absolute Coding of Stimulus Novelty in the Human Substantia NigraVTA.pdf}
}

@article{Busemeyer2006,
  langid = {english},
  title = {Quantum Dynamics of Human Decision-Making},
  volume = {50},
  issn = {00222496},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S002224960600006X},
  doi = {10.1016/j.jmp.2006.01.003},
  abstract = {A quantum dynamic model of decision-making is presented, and it is compared with a previously established Markov model. Both the quantum and the Markov models are formulated as random walk decision processes, but the probabilistic principles differ between the two approaches. Quantum dynamics describe the evolution of complex valued probability amplitudes over time, whereas Markov models describe the evolution of real valued probabilities over time. Quantum dynamics generate interference effects, which are not possible with Markov models. An interference effect occurs when the probability of the union of two possible paths is smaller than each individual path alone. The choice probabilities and distribution of choice response time for the quantum model are derived, and the predictions are contrasted with the Markov model.},
  number = {3},
  journaltitle = {Journal of Mathematical Psychology},
  urldate = {2019-03-30},
  date = {2006-06},
  pages = {220-241},
  author = {Busemeyer, Jerome R. and Wang, Zheng and Townsend, James T.},
  file = {/Users/qualia/Documents/Papers/2006 - Busemeyer, Wang, Townsend - Quantum dynamics of human decision-making.pdf}
}

@article{Canolty2006,
  langid = {english},
  title = {High {{Gamma Power Is Phase}}-{{Locked}} to {{Theta Oscillations}} in {{Human Neocortex}}},
  volume = {313},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1128115},
  doi = {10.1126/science.1128115},
  number = {5793},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2006-09-15},
  pages = {1626-1628},
  author = {Canolty, R. T. and Edwards, E. and Dalal, S. S. and Soltani, M. and Nagarajan, S. S. and Kirsch, H. E. and Berger, M. S. and Barbaro, N. M. and Knight, R. T.},
  file = {/Users/qualia/Documents/Papers/2006 - Canolty et al. - High gamma power is phase-locked to theta oscillations in human neocortex(2).pdf;/Users/qualia/Documents/Papers/2006 - Canolty et al. - High gamma power is phase-locked to theta oscillations in human neocortex(3).pdf;/Users/qualia/Documents/Papers/2009 - Canolty et al. - NIH Public Access.pdf}
}

@article{Cools2006,
  langid = {english},
  title = {Dopaminergic Modulation of Cognitive Function-Implications for l-{{DOPA}} Treatment in {{Parkinson}}'s Disease},
  volume = {30},
  issn = {01497634},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763405000540},
  doi = {10.1016/j.neubiorev.2005.03.024},
  abstract = {It is well recognised that patients with Parkinson's disease exhibit cognitive deficits, even in the earliest disease stages. Whereas, L-DOPA therapy in early Parkinson's disease is accepted to improve the motor symptoms, the effects on cognitive performance are more complex: both positive and negative effects have been observed. The purpose of the present article is to review the effects of L-DOPA medication in Parkinson's disease on cognitive functions in the broad domains of cognitive flexibility and working memory. The review places the effects in Parkinson's disease within a framework of evidence from studies with healthy human volunteers, rodents and non-human primates as well as computational modeling work. It is suggested that beneficial or detrimental effects of L-DOPA are observed depending on task demands and basal dopamine levels in distinct parts of the striatum. The study of the beneficial and detrimental cognitive effects of L-DOPA in Parkinson's disease has substantial implications for the understanding and treatment development of cognitive abnormalities in Parkinson's disease as well as normal health.},
  number = {1},
  journaltitle = {Neuroscience \& Biobehavioral Reviews},
  urldate = {2019-03-30},
  date = {2006-01},
  pages = {1-23},
  author = {Cools, Roshan},
  file = {/Users/qualia/Documents/Papers/2006 - Cools - Dopaminergic modulation of cognitive function-implications for L-DOPA treatment in Parkinson's disease.pdf}
}

@article{Engle-Warnick2006,
  langid = {english},
  title = {Learning to Trust in Indefinitely Repeated Games},
  volume = {54},
  issn = {08998256},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0899825604001678},
  doi = {10.1016/j.geb.2004.10.009},
  abstract = {Although it is well known that trust and trustworthiness (i.e., the fulfillment of trust) are important behaviors for the fulfillment of incomplete contracts, less is known about how the economic environment influences them. In this paper we design an experiment to examine how exogenously determined (stochastic) past relationship lengths affect trust and trustworthiness in new relationships. We find that shorter-lasting relationships have an immediate negative impact on both behaviors in the relationships that immediately follow, while longer-lasting relationships have the opposite effect. The effect of stochastic end-points declines for trustworthiness but not for trust as subjects gain experience, indicating that trust is able to rebound when longer-lasting relationships follow shorter-lasting ones.},
  number = {1},
  journaltitle = {Games and Economic Behavior},
  urldate = {2019-03-30},
  date = {2006-01},
  pages = {95-114},
  author = {Engle-Warnick, J. and Slonim, Robert L.},
  file = {/Users/qualia/Documents/Papers/2006 - Engle-Warnick, Slonim - Learning to trust in indefinitely repeated games.pdf}
}

@article{Fiete2006,
  langid = {english},
  title = {Gradient {{Learning}} in {{Spiking Neural Networks}} by {{Dynamic Perturbation}} of {{Conductances}}},
  volume = {97},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.97.048104},
  doi = {10.1103/PhysRevLett.97.048104},
  number = {4},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2006-07-28},
  author = {Fiete, Ila R. and Seung, H. Sebastian},
  file = {/Users/qualia/Documents/Papers/2006 - Fiete, Seung - Gradient learning in spiking neural networks by dynamic perturbation of conductances.pdf}
}

@article{Foster,
  langid = {english},
  title = {Regret {{Testing}}: {{Learning}} to {{Play Nash Equilibrium Without Knowing You Have}} an {{Opponent}}},
  abstract = {A learning rule is uncoupled if a player does not condition his strategy on the opponent's payoffs. It is radically uncoupled if a player does not condition his strategy on the opponent's actions or payoffs. We demonstrate a family of simple, radically uncoupled learning rules whose period-by-period behavior comes arbitrarily close to Nash equilibrium behavior in any finite two-person game.},
  pages = {29},
  author = {Foster, Dean P and Young, H Peyton},
  file = {/Users/qualia/Documents/Papers/2006 - Foster, Young - Regret testing learning to play Nash equilibrium without knowing you have an opponent.pdf}
}

@article{Frank2006,
  langid = {english},
  title = {Hold Your Horses: {{A}} Dynamic Computational Role for the Subthalamic Nucleus in Decision Making},
  volume = {19},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S089360800600150X},
  doi = {10.1016/j.neunet.2006.03.006},
  shorttitle = {Hold Your Horses},
  abstract = {The basal ganglia (BG) coordinate decision making processes by facilitating adaptive frontal motor commands while suppressing others. In previous work, neural network simulations accounted for response selection deficits associated with BG dopamine depletion in Parkinson's disease. Novel predictions from this model have been subsequently confirmed in Parkinson patients and in healthy participants under pharmacological challenge. Nevertheless, one clear limitation of that model is in its omission of the subthalamic nucleus (STN), a key BG structure that participates in both motor and cognitive processes. The present model incorporates the STN and shows that by modulating when a response is executed, the STN reduces premature responding and therefore has substantial effects on which response is ultimately selected, particularly when there are multiple competing responses. Increased cortical response conflict leads to dynamic adjustments in response thresholds via cortico-subthalamicpallidal pathways. The model accurately captures the dynamics of activity in various BG areas during response selection. Simulated dopamine depletion results in emergent oscillatory activity in BG structures, which has been linked with Parkinson's tremor. Finally, the model accounts for the beneficial effects of STN lesions on these oscillations, but suggests that this benefit may come at the expense of impaired decision making.},
  number = {8},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2006-10},
  pages = {1120-1136},
  author = {Frank, Michael J.},
  file = {/Users/qualia/Documents/Papers/2006 - Frank - Hold your horses A dynamic computational role for the subthalamic nucleus in decision making.pdf}
}

@article{Frank2006a,
  langid = {english},
  title = {Mechanisms {{Underlying}} the {{Rapid Induction}} and {{Sustained Expression}} of {{Synaptic Homeostasis}}},
  volume = {52},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627306007367},
  doi = {10.1016/j.neuron.2006.09.029},
  abstract = {Homeostatic signaling systems are thought to interface with the mechanisms of neural plasticity to achieve stable yet flexible neural circuitry. However, the time course, molecular design, and implementation of homeostatic signaling remain poorly defined. Here we demonstrate that a homeostatic increase in presynaptic neurotransmitter release can be induced within minutes following postsynaptic glutamate receptor blockade. The rapid induction of synaptic homeostasis is independent of new protein synthesis and does not require evoked neurotransmission, indicating that a change in the efficacy of spontaneous quantal release events is sufficient to trigger the induction of synaptic homeostasis. Finally, both the rapid induction and the sustained expression of synaptic homeostasis are blocked by mutations that disrupt the pore-forming subunit of the presynaptic CaV2.1 calcium channel encoded by cacophony. These data confirm the presynaptic expression of synaptic homeostasis and implicate presynaptic CaV2.1 in a homeostatic retrograde signaling system.},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2006-11},
  pages = {663-677},
  author = {Frank, C. Andrew and Kennedy, Matthew J. and Goold, Carleton P. and Marek, Kurt W. and Davis, Graeme W.},
  file = {/Users/qualia/Documents/Papers/2006 - Frank et al. - Mechanisms Underlying the Rapid Induction and Sustained Expression of Synaptic Homeostasis.pdf}
}

@article{Gabaix2006,
  langid = {english},
  title = {Costly {{Information Acquisition}}: {{Experimental Analysis}} of a {{Boundedly Rational Model}}},
  volume = {96},
  number = {4},
  journaltitle = {THE AMERICAN ECONOMIC REVIEW},
  date = {2006},
  pages = {26},
  author = {Gabaix, Xavier and Laibson, David and Moloche, Guillermo and Weinberg, Stephen},
  file = {/Users/qualia/Documents/Papers/2006 - Gabaix et al. - Costly Information Acquisition Experimental Analysis of a Boundedly Rational Model Costly Information Acquisition.pdf}
}

@article{Grimbert2006,
  langid = {english},
  title = {Bifurcation {{Analysis}} of {{Jansen}}'s {{Neural Mass Model}}},
  volume = {18},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.2006.18.12.3052},
  doi = {10.1162/neco.2006.18.12.3052},
  number = {12},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2006-12},
  pages = {3052-3068},
  author = {Grimbert, Fran{\c c}ois and Faugeras, Olivier},
  file = {/Users/qualia/Documents/Papers/2006 - Grimbert, Faugeras - Bifurcation analysis of Jansen's neural mass model.pdf}
}

@article{Haynes2006,
  langid = {english},
  title = {Decoding Mental States from Brain Activity in Humans},
  volume = {7},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn1931},
  doi = {10.1038/nrn1931},
  abstract = {Recent advances in human neuroimaging have shown that it is possible to accurately decode a person's conscious experience based only on non-invasive measurements of their brain activity. Such `brain reading' has mostly been studied in the domain of visual perception, where it helps reveal the way in which individual experiences are encoded in the human brain. The same approach can also be extended to other types of mental state, such as covert attitudes and lie detection. Such applications raise important ethical issues concerning the privacy of personal thought.},
  number = {7},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2006-07},
  pages = {523-534},
  author = {Haynes, John-Dylan and Rees, Geraint},
  file = {/Users/qualia/Documents/Papers/2006 - Haynes, Rees - Decoding mental states from brain activity in humans.pdf}
}

@article{Humphries2006,
  langid = {english},
  title = {A {{Physiologically Plausible Model}} of {{Action Selection}} and {{Oscillatory Activity}} in the {{Basal Ganglia}}},
  volume = {26},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3486-06.2006},
  doi = {10.1523/JNEUROSCI.3486-06.2006},
  number = {50},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2006-12-13},
  pages = {12921-12942},
  author = {Humphries, M. D. and Stewart, R. D. and Gurney, K. N.},
  file = {/Users/qualia/Documents/Papers/2006 - Humphries, Stewart, Gurney - A Physiologically Plausible Model of Action Selection and Oscillatory Activity in the Basal Ganglia.pdf}
}

@article{Izhikevich2006a,
  langid = {english},
  title = {Polychronization: {{Computation}} with {{Spikes}}},
  volume = {18},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/089976606775093882},
  doi = {10.1162/089976606775093882},
  shorttitle = {Polychronization},
  number = {2},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2006-02},
  pages = {245-282},
  author = {Izhikevich, Eugene M.},
  file = {/Users/qualia/Documents/Papers/2006 - Izhikevich - Polychronization computation with spikes.pdf}
}

@article{Kuhn2006,
  langid = {english},
  title = {Modulation of Beta Oscillations in the Subthalamic Area during Motor Imagery in {{Parkinson}}'s Disease},
  volume = {129},
  issn = {1460-2156, 0006-8950},
  url = {http://academic.oup.com/brain/article/129/3/695/390814/Modulation-of-beta-oscillations-in-the-subthalamic},
  doi = {10.1093/brain/awh715},
  number = {3},
  journaltitle = {Brain},
  urldate = {2019-03-30},
  date = {2006-03-01},
  pages = {695-706},
  author = {K\"uhn, Andrea A. and Doyle, Louise and Pogosyan, Alek and Yarrow, Kielan and Kupsch, Andreas and Schneider, Gerd-Helge and Hariz, Marwan I. and Trottenberg, Thomas and Brown, Peter},
  file = {/Users/qualia/Documents/Papers/2006 - Kühn et al. - Modulation of beta oscillations in the subthalamic area during motor imagery in Parkinson's disease.pdf}
}

@article{Laing2006,
  langid = {english},
  title = {On the Application of ``Equation-Free Modelling'' to Neural Systems},
  volume = {20},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-006-3843-z},
  doi = {10.1007/s10827-006-3843-z},
  abstract = {Equation-free modelling'' is a recentlydeveloped technique for bridging the gap between detailed, microscopic descriptions of systems and macroscopic descriptions of their collective behaviour. It uses short, repeated bursts of simulation of the microscopic dynamics to analyse the effective macroscopic equations, even though such equations are not directly available for evaluation. This paper demonstrates these techniques on a variety of networks of model neurons, and discusses the advantages and limitations of such an approach. New results include an understanding of the effects of including gap junctions in a model capable of sustaining spatially localised ``bumps'' of activity, and an investigation of a network of coupled bursting neurons.},
  number = {1},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2006-02},
  pages = {5-23},
  author = {Laing, Carlo R.},
  file = {/Users/qualia/Documents/Papers/2006 - Laing - On the application of equation-free modelling to neural systems.pdf}
}

@article{Leblois2006,
  langid = {english},
  title = {Competition between {{Feedback Loops Underlies Normal}} and {{Pathological Dynamics}} in the {{Basal Ganglia}}},
  volume = {26},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5050-05.2006},
  doi = {10.1523/JNEUROSCI.5050-05.2006},
  number = {13},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2006-03-29},
  pages = {3567-3583},
  author = {Leblois, A.},
  file = {/Users/qualia/Documents/Papers/2006 - Leblois - Competition between Feedback Loops Underlies Normal and Pathological Dynamics in the Basal Ganglia.pdf}
}

@article{Martinez-Ramon2006,
  langid = {english},
  title = {{{fMRI}} Pattern Classification Using Neuroanatomically Constrained Boosting},
  volume = {31},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811906000498},
  doi = {10.1016/j.neuroimage.2006.01.022},
  number = {3},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2006-07},
  pages = {1129-1141},
  author = {Mart\'inez-Ram\'on, Manel and Koltchinskii, Vladimir and Heileman, Gregory L. and Posse, Stefan},
  file = {/Users/qualia/Documents/Papers/2006 - Martínez-Ramón et al. - fMRI pattern classification using neuroanatomically constrained boosting.pdf}
}

@article{Miocinovic2006,
  langid = {english},
  title = {Computational {{Analysis}} of {{Subthalamic Nucleus}} and {{Lenticular Fasciculus Activation During Therapeutic Deep Brain Stimulation}}},
  volume = {96},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00305.2006},
  doi = {10.1152/jn.00305.2006},
  number = {3},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2006-09},
  pages = {1569-1580},
  author = {Miocinovic, Svjetlana and Parent, Martin and Butson, Christopher R. and Hahn, Philip J. and Russo, Gary S. and Vitek, Jerrold L. and McIntyre, Cameron C.},
  file = {/Users/qualia/Documents/Papers/2006 - Miocinovic et al. - Computational analysis of subthalamic nucleus and lenticular fasciculus activation during therapeutic deep br.pdf;/Users/qualia/Documents/Papers/2006 - Miocinovic et al. - Computational analysis of subthalamic nucleus and lenticular fasciculus activation during therapeutic deep(2).pdf}
}

@article{Mishra2006,
  langid = {english},
  title = {Selective Attention through Phase Relationship of Excitatory and Inhibitory Input Synchrony in a Model Cortical Neuron},
  volume = {19},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608006001808},
  doi = {10.1016/j.neunet.2006.08.005},
  abstract = {Neurons in area V 2 and V 4 exhibit stimulus specific tuning to single stimuli, and respond at intermediate firing rates when presented with two differentially preferred stimuli (`pair response'). Selective attention to one of the two stimuli causes the neuron's firing rate to shift from the intermediate pair response towards the response to the attended stimulus as if it were presented alone. Attention to single stimuli reduces the response threshold of the neuron and increases spike synchronization at gamma frequencies. The intrinsic and network mechanisms underlying these phenomena were investigated in a multi-compartmental biophysical model of a reconstructed cat V 4 neuron. Differential stimulus preference was generated through a greater ratio of excitatory to inhibitory synapses projecting from one of two input V 2 populations. Feedforward inhibition and synaptic depression dynamics were critical to generating the intermediate pair response. Neuronal gain effects were simulated using gamma frequency range correlations in the feedforward excitatory and inhibitory inputs to the V 4 neuron. For single preferred stimulus presentations, correlations within the inhibitory population out of phase with correlations within the excitatory input significantly reduced the response threshold of the V 4 neuron. The pair response to simultaneously active preferred and non-preferred V 2 populations could also undergo an increase or decrease in gain via the same mechanism, where correlations in feedforward inhibition are out of phase with gamma band correlations within the excitatory input corresponding to the attended stimulus. The results of this model predict that top-down attention may bias the V 4 neuron's response using an inhibitory correlation phase shift mechanism.},
  number = {9},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2006-11},
  pages = {1329-1346},
  author = {Mishra, Jyoti and Fellous, Jean-Marc and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/2006 - Mishra, Fellous, Sejnowski - Selective attention through phase relationship of excitatory and inhibitory input synchrony in a mod.pdf}
}

@article{Norman2006,
  langid = {english},
  title = {Beyond Mind-Reading: Multi-Voxel Pattern Analysis of {{fMRI}} Data},
  volume = {10},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661306001847},
  doi = {10.1016/j.tics.2006.07.005},
  shorttitle = {Beyond Mind-Reading},
  number = {9},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2006-09},
  pages = {424-430},
  author = {Norman, Kenneth A. and Polyn, Sean M. and Detre, Greg J. and Haxby, James V.},
  file = {/Users/qualia/Documents/Papers/2006 - Norman et al. - Beyond mind-reading multi-voxel pattern analysis of fMRI data.pdf}
}

@article{Prescott2006,
  langid = {english},
  title = {A Robot Model of the Basal Ganglia: {{Behavior}} and Intrinsic Processing},
  volume = {19},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608005001589},
  doi = {10.1016/j.neunet.2005.06.049},
  shorttitle = {A Robot Model of the Basal Ganglia},
  abstract = {The existence of multiple parallel loops connecting sensorimotor systems to the basal ganglia has given rise to proposals that these nuclei serve as a selection mechanism resolving competitions between the alternative actions available in a given context. A strong test of this hypothesis is to require a computational model of the basal ganglia to generate integrated selection sequences in an autonomous agent, we therefore describe a robot architecture into which such a model is embedded, and require it to control action selection in a robotic task inspired by animal observations. Our results demonstrate effective action selection by the embedded model under a wide range of sensory and motivational conditions. When confronted with multiple, high salience alternatives, the robot also exhibits forms of behavioral disintegration that show similarities to animal behavior in conflict situations. The model is shown to cast light on recent neurobiological findings concerning behavioral switching and sequencing.},
  number = {1},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2006-01},
  pages = {31-61},
  author = {Prescott, Tony J. and Montes Gonz\'alez, Fernando M. and Gurney, Kevin and Humphries, Mark D. and Redgrave, Peter},
  file = {/Users/qualia/Documents/Papers/2006 - Prescott et al. - A robot model of the basal ganglia Behavior and intrinsic processing.pdf}
}

@article{Rajan2006,
  langid = {english},
  title = {Eigenvalue {{Spectra}} of {{Random Matrices}} for {{Neural Networks}}},
  volume = {97},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.97.188104},
  doi = {10.1103/PhysRevLett.97.188104},
  number = {18},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2006-11-02},
  author = {Rajan, Kanaka and Abbott, L. F.},
  file = {/Users/qualia/Documents/Papers/2006 - Rajan, Abbott - Eigenvalue spectra of random matrices for neural networks.pdf}
}

@article{Rieskamp2006,
  langid = {english},
  title = {{{SSL}}: {{A Theory}} of {{How People Learn}} to {{Select Strategies}}.},
  volume = {135},
  issn = {1939-2222, 0096-3445},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-3445.135.2.207},
  doi = {10.1037/0096-3445.135.2.207},
  shorttitle = {{{SSL}}},
  abstract = {The assumption that people possess a repertoire of strategies to solve the inference problems they face has been raised repeatedly. However, a computational model specifying how people select strategies from their repertoire is still lacking. The proposed strategy selection learning (SSL) theory predicts a strategy selection process on the basis of reinforcement learning. The theory assumes that individuals develop subjective expectations for the strategies they have and select strategies proportional to their expectations, which are then updated on the basis of subsequent experience. The learning assumption was supported in 4 experimental studies. Participants substantially improved their inferences through feedback. In all 4 studies, the best-performing strategy from the participants' repertoires most accurately predicted the inferences after sufficient learning opportunities. When testing SSL against 3 models representing extensions of SSL and against an exemplar model assuming a memory-based inference process, the authors found that SSL predicted the inferences most accurately.},
  number = {2},
  journaltitle = {Journal of Experimental Psychology: General},
  urldate = {2019-03-30},
  date = {2006},
  pages = {207-236},
  author = {Rieskamp, J\"org and Otto, Philipp E.},
  file = {/Users/qualia/Documents/Papers/2006 - Rieskamp, Otto - SSL A theory of how people learn to select strategies.pdf}
}

@article{Rottenstreich2006,
  langid = {english},
  title = {On Decision Making without Likelihood Judgment},
  volume = {101},
  issn = {07495978},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749597806000707},
  doi = {10.1016/j.obhdp.2006.06.004},
  abstract = {Subjective expected utility, prospect theory and most other formal models of decision making under uncertainty are probabilistic: they assume that in making choices people judge the likelihood of relevant uncertainties. Clearly, in many situations people do indeed judge likelihood. However, we present studies suggesting that there are also many situations in which people do not judge likelihood and instead base their decisions on intuitively generated, non-probabilistic rules or rationales. Thus, we argue that real-world situations are of two types. In situations eliciting a probabilistic mindset, people rely on judgments of likelihood. In situations eliciting a non-probabilistic mindset, they neglect judgments of likelihood. We suggest three factors that may inXuence the tendency towards either probabilistic or non-probabilistic mindsets. We also outline how extant probabilistic theories may be complemented by non-probabilistic models.},
  number = {1},
  journaltitle = {Organizational Behavior and Human Decision Processes},
  urldate = {2019-03-30},
  date = {2006-09},
  pages = {74-88},
  author = {Rottenstreich, Yuval and Kivetz, Ran},
  file = {/Users/qualia/Documents/Papers/2006 - Rottenstreich, Kivetz - On decision making without likelihood judgment.pdf}
}

@article{Schulz2006,
  langid = {english},
  title = {Plasticity and Stability in Neuronal Output via Changes in Intrinsic Excitability: It's What's inside That Counts},
  volume = {209},
  issn = {0022-0949, 1477-9145},
  url = {http://jeb.biologists.org/cgi/doi/10.1242/jeb.02567},
  doi = {10.1242/jeb.02567},
  shorttitle = {Plasticity and Stability in Neuronal Output via Changes in Intrinsic Excitability},
  abstract = {Summary The nervous system faces an extremely difficult task. It must be flexible, both during development and in adult life, so that it can respond to a variety of environmental demands and produce adaptive behavior. At the same time the nervous system must be stable, so that the neural circuits that produce behavior function throughout the lifetime of the animal and that changes produced by learning endure. We are only beginning to understand how neural networks strike a balance between altering individual neurons in the name of plasticity, while maintaining long-term stability in neural system function. The balance of this plasticity and stability in neural networks undoubtedly plays a critical role in the normal functioning of the nervous system. While mechanisms of synaptic plasticity have garnered extensive study over the past three decades, it is only recently that more attention has been turned to plasticity of intrinsic excitability as a key player in neural network function. This review will focus on this emerging area of research that undoubtedly will contribute a great deal to our understanding of the functionality of the nervous system.},
  number = {24},
  journaltitle = {Journal of Experimental Biology},
  urldate = {2019-03-30},
  date = {2006-12-15},
  pages = {4821-4827},
  author = {Schulz, D. J.},
  file = {/Users/qualia/Documents/Papers/2006 - Schulz - Plasticity and stability in neuronal output via changes in intrinsic excitability it's what's inside that counts.pdf}
}

@article{Schwabe2006,
  langid = {english},
  title = {The {{Role}} of {{Feedback}} in {{Shaping}} the {{Extra}}-{{Classical Receptive Field}} of {{Cortical Neurons}}: {{A Recurrent Network Model}}},
  volume = {26},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1253-06.2006},
  doi = {10.1523/JNEUROSCI.1253-06.2006},
  shorttitle = {The {{Role}} of {{Feedback}} in {{Shaping}} the {{Extra}}-{{Classical Receptive Field}} of {{Cortical Neurons}}},
  number = {36},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2006-09-06},
  pages = {9117-9129},
  author = {Schwabe, L.},
  file = {/Users/qualia/Documents/Papers/2006 - Schwabe et al. - The role of feedback in shaping the extra-classical receptive field of cortical neurons a recurrent network mode.pdf}
}

@article{Thirion2006,
  langid = {english},
  title = {Inverse Retinotopy: {{Inferring}} the Visual Content of Images from Brain Activation Patterns},
  volume = {33},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811906007373},
  doi = {10.1016/j.neuroimage.2006.06.062},
  shorttitle = {Inverse Retinotopy},
  number = {4},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2006-12},
  pages = {1104-1116},
  author = {Thirion, Bertrand and Duchesnay, Edouard and Hubbard, Edward and Dubois, Jessica and Poline, Jean-Baptiste and Lebihan, Denis and Dehaene, Stanislas},
  file = {/Users/qualia/Documents/Papers/2006 - Thirion et al. - Inverse retinotopy inferring the visual content of images from brain activation patterns.pdf}
}

@article{Thut2006,
  langid = {english},
  title = {-{{Band Electroencephalographic Activity}} over {{Occipital Cortex Indexes Visuospatial Attention Bias}} and {{Predicts Visual Target Detection}}},
  volume = {26},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0875-06.2006},
  doi = {10.1523/JNEUROSCI.0875-06.2006},
  number = {37},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2006-09-13},
  pages = {9494-9502},
  author = {Thut, G.},
  file = {/Users/qualia/Documents/Papers/2006 - Thut - -Band Electroencephalographic Activity over Occipital Cortex Indexes Visuospatial Attention Bias and Predicts Visual Targe.pdf}
}

@article{Toyoizumi2006,
  langid = {english},
  title = {Fisher {{Information}} for {{Spike}}-{{Based Population Decoding}}},
  volume = {97},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.97.098102},
  doi = {10.1103/PhysRevLett.97.098102},
  number = {9},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2006-08-30},
  author = {Toyoizumi, Taro and Aihara, Kazuyuki and Amari, Shun-ichi},
  file = {/Users/qualia/Documents/Papers/2006 - Toyoizumi, Aihara, Amari - Fisher information for spike-based population decoding.pdf}
}

@article{Varma2006,
  langid = {english},
  title = {Bias in Error Estimation When Using Cross-Validation for Model Selection},
  abstract = {Background: Cross-validation (CV) is an effective method for estimating the prediction error of a classifier. Some recent articles have proposed methods for optimizing classifiers by choosing classifier parameter values that minimize the CV error estimate. We have evaluated the validity of using the CV error estimate of the optimized classifier as an estimate of the true error expected on independent data.
Results: We used CV to optimize the classification parameters for two kinds of classifiers; Shrunken Centroids and Support Vector Machines (SVM). Random training datasets were created, with no difference in the distribution of the features between the two classes. Using these "null" datasets, we selected classifier parameter values that minimized the CV error estimate. 10-fold CV was used for Shrunken Centroids while Leave-One-Out-CV (LOOCV) was used for the SVM. Independent test data was created to estimate the true error. With "null" and "non null" (with differential expression between the classes) data, we also tested a nested CV procedure, where an inner CV loop is used to perform the tuning of the parameters while an outer CV is used to compute an estimate of the error. The CV error estimate for the classifier with the optimal parameters was found to be a substantially biased estimate of the true error that the classifier would incur on independent data. Even though there is no real difference between the two classes for the "null" datasets, the CV error estimate for the Shrunken Centroid with the optimal parameters was less than 30\% on 18.5\% of simulated training data-sets. For SVM with optimal parameters the estimated error rate was less than 30\% on 38\% of "null" data-sets. Performance of the optimized classifiers on the independent test set was no better than chance. The nested CV procedure reduces the bias considerably and gives an estimate of the error that is very close to that obtained on the independent testing set for both Shrunken Centroids and SVM classifiers for "null" and "non-null" data distributions.
Conclusion: We show that using CV to compute an error estimate for a classifier that has itself been tuned using CV gives a significantly biased estimate of the true error. Proper use of CV for estimating true error of a classifier developed using a well defined algorithm requires that all steps of the algorithm, including classifier parameter tuning, be repeated in each CV loop. A nested CV procedure provides an almost unbiased estimate of the true error.},
  journaltitle = {BMC Bioinformatics},
  date = {2006},
  pages = {8},
  author = {Varma, Sudhir and Simon, Richard},
  file = {/Users/qualia/Documents/Papers/2006 - Varma, Simon - Bias in error estimation when using cross-validation for model selection.pdf}
}

@article{Wong2006,
  langid = {english},
  title = {A {{Recurrent Network Mechanism}} of {{Time Integration}} in {{Perceptual Decisions}}},
  volume = {26},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3733-05.2006},
  doi = {10.1523/JNEUROSCI.3733-05.2006},
  number = {4},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2006-01-25},
  pages = {1314-1328},
  author = {Wong, K.-F.},
  file = {/Users/qualia/Documents/Papers/2006 - Wong - A Recurrent Network Mechanism of Time Integration in Perceptual Decisions(2).pdf;/Users/qualia/Documents/Papers/2006 - Wong, Wang - A Recurrent Network Mechanism of Time Integration in Perceptual Decisions.pdf}
}

@article{Bartos2007,
  langid = {english},
  title = {Synaptic Mechanisms of Synchronized Gamma Oscillations in Inhibitory Interneuron Networks},
  volume = {8},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn2044},
  doi = {10.1038/nrn2044},
  abstract = {Gamma frequency oscillations are thought to provide a temporal structure for information processing in the brain. They contribute to cognitive functions, such as memory formation and sensory processing, and are disturbed in some psychiatric disorders. Fast-spiking, parvalbumin-expressing, soma-inhibiting interneurons have a key role in the generation of these oscillations. Experimental analysis in the hippocampus and the neocortex reveals that synapses among these interneurons are highly specialized. Computational analysis further suggests that synaptic specialization turns interneuron networks into robust gamma frequency oscillators.},
  number = {1},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2007-01},
  pages = {45-56},
  author = {Bartos, Marlene and Vida, Imre and Jonas, Peter},
  file = {/Users/qualia/Documents/Papers/2007 - Bartos, Vida, Jonas - Synaptic mechanisms of synchronized gamma oscillations in inhibitory interneuron networks(2).pdf}
}

@article{Bogacz2007,
  langid = {english},
  title = {The {{Basal Ganglia}} and {{Cortex Implement Optimal Decision Making Between Alternative Actions}}},
  volume = {19},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.2007.19.2.442},
  doi = {10.1162/neco.2007.19.2.442},
  number = {2},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2007-02},
  pages = {442-477},
  author = {Bogacz, Rafal and Gurney, Kevin},
  file = {/Users/qualia/Documents/Papers/2007 - Bogacz, Gurney - The Basal Ganglia and Cortex Implement Optimal Decision Making Between Alternative Actions.pdf}
}

@article{Brette2007,
  langid = {english},
  title = {Simulation of Networks of Spiking Neurons: {{A}} Review of Tools and Strategies},
  volume = {23},
  issn = {1573-6873},
  url = {http://link.springer.com/10.1007/s10827-007-0038-6},
  doi = {10.1007/s10827-007-0038-6},
  shorttitle = {Simulation of Networks of Spiking Neurons},
  number = {3},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2007-12},
  pages = {349-398},
  author = {Brette, Romain and Rudolph, Michelle and Carnevale, Ted and Hines, Michael and Beeman, David and Bower, James M. and Diesmann, Markus and Morrison, Abigail and Goodman, Philip H. and Harris, Frederick C. and Zirpe, Milind and Natschl\"ager, Thomas and Pecevski, Dejan and Ermentrout, Bard and Djurfeldt, Mikael and Lansner, Anders and Rochel, Olivier and Vieville, Thierry and Muller, Eilif and Davison, Andrew P. and El Boustani, Sami and Destexhe, Alain},
  file = {/Users/qualia/Documents/Papers/2007 - Brette et al. - Simulation of networks of spiking neurons a review of tools and strategies.pdf}
}

@article{Butson2007,
  langid = {english},
  title = {Patient-Specific Analysis of the Volume of Tissue Activated during Deep Brain Stimulation},
  volume = {34},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811906009669},
  doi = {10.1016/j.neuroimage.2006.09.034},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2007-01},
  pages = {661-670},
  author = {Butson, Christopher R. and Cooper, Scott E. and Henderson, Jaimie M. and McIntyre, Cameron C.},
  file = {/Users/qualia/Documents/Papers/2007 - Butson et al. - Patient-specific analysis of the volume of tissue activated during deep brain stimulation.pdf}
}

@article{Carandini2007,
  langid = {english},
  title = {Melting the {{Iceberg}}: {{Contrast Invariance}} in {{Visual Cortex}}},
  volume = {54},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627307002152},
  doi = {10.1016/j.neuron.2007.03.019},
  shorttitle = {Melting the {{Iceberg}}},
  number = {1},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2007-04},
  pages = {11-13},
  author = {Carandini, Matteo},
  file = {/Users/qualia/Documents/Papers/2007 - Carandini - Melting the Iceberg Contrast Invariance in Visual Cortex.pdf}
}

@article{Churchland2007a,
  langid = {english},
  title = {Techniques for Extracting Single-Trial Activity Patterns from Large-Scale Neural Recordings},
  volume = {17},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438807001195},
  doi = {10.1016/j.conb.2007.11.001},
  number = {5},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2007-10},
  pages = {609-618},
  author = {Churchland, Mark M and Yu, Byron M and Sahani, Maneesh and Shenoy, Krishna V},
  file = {/Users/qualia/Documents/Papers/2007 - Churchland et al. - Techniques for extracting single-trial activity patterns from large-scale neural recordings.pdf}
}

@article{Churchland2007,
  langid = {english},
  title = {Delay of {{Movement Caused}} by {{Disruption}} of {{Cortical Preparatory Activity}}},
  volume = {97},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00808.2006},
  doi = {10.1152/jn.00808.2006},
  number = {1},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2007-01},
  pages = {348-359},
  author = {Churchland, Mark M. and Shenoy, Krishna V.},
  file = {/Users/qualia/Documents/Papers/2007 - Churchland, Shenoy - Delay of movement caused by disruption of cortical preparatory activity.pdf}
}

@article{Druckmann2007,
  langid = {english},
  title = {A Novel Multiple Objective Optimization Framework for Constraining Conductance-Based Neuron Models by Experimental Data},
  volume = {1},
  issn = {16624548},
  url = {http://journal.frontiersin.org/article/10.3389/neuro.01.1.1.001.2007/abstract},
  doi = {10.3389/neuro.01.1.1.001.2007},
  number = {1},
  journaltitle = {Frontiers in Neuroscience},
  urldate = {2019-03-30},
  date = {2007-11-01},
  pages = {7-18},
  author = {Druckmann, Shaul},
  file = {/Users/qualia/Documents/Papers/2007 - Druckmann et al. - A novel multiple objective optimization framework for constraining conductance-based neuron models by experime.pdf}
}

@article{Prinz2007,
  langid = {english},
  title = {Shaul {{Druckmann}} 1,{${_\ast}$}, {{Yoav Banitt}} 2, {{Albert Gidon}} 2, {{Felix Schu}}\textasciidieresis{} Rmann 3, {{Henry Markram Idan Segev}}},
  journaltitle = {Frontiers in Neuroscience},
  date = {2007},
  pages = {12},
  author = {Prinz, Astrid},
  file = {/Users/qualia/Documents/Papers/2007 - Druckmann et al. - Idan Segev.pdf}
}

@article{Eckhardt2007,
  langid = {english},
  title = {Modeling Walker Synchronization on the {{Millennium Bridge}}},
  volume = {75},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.75.021110},
  doi = {10.1103/PhysRevE.75.021110},
  number = {2},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2007-02-12},
  author = {Eckhardt, Bruno and Ott, Edward and Strogatz, Steven H. and Abrams, Daniel M. and McRobie, Allan},
  file = {/Users/qualia/Documents/Papers/2007 - Eckhardt et al. - Modeling walker synchronization on the millennium bridge.pdf}
}

@article{ElBoustani2007,
  langid = {english},
  title = {Activated Cortical States: {{Experiments}}, Analyses and Models},
  volume = {101},
  issn = {09284257},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0928425707000319},
  doi = {10.1016/j.jphysparis.2007.10.001},
  shorttitle = {Activated Cortical States},
  abstract = {In awake animals, the cerebral cortex displays an ``activated'' state, with distinct characteristics compared to other states like slow-wave sleep or anesthesia. These characteristics include a sustained depolarized membrane potential (Vm) and irregular firing activity. In the present paper, we evaluate our understanding of cortical activated states from a computational neuroscience point of view. We start by reviewing the electrophysiological characteristics of activated cortical states based on recordings and analysis performed in awake cat association cortex. These analyses show that cortical activity is characterized by an apparent Poisson-distributed stochastic dynamics, both at the single-cell and population levels, and that single cells display a high-conductance state dominated by inhibition. We next overview computational models of the ``awake'' cortex, and perform the same analyses as in the experiments. Many properties identified experimentally are indeed reproduced by models, such as depolarized Vm, irregular firing with apparent Poisson statistics, and the determinant role of inhibitory fluctuations on spiking. However, other features are not well reproduced, such as firing statistics and the conductance state of the membrane, suggesting that the network state displayed by models is not entirely correct. We also show how networks can approach a correct conductance state, suggesting ways by which future models will generate activity fully consistent with experimental data.},
  number = {1-3},
  journaltitle = {Journal of Physiology-Paris},
  urldate = {2019-03-30},
  date = {2007-01},
  pages = {99-109},
  author = {El Boustani, Sami and Pospischil, Martin and Rudolph-Lilith, Michelle and Destexhe, Alain},
  file = {/Users/qualia/Documents/Papers/2007 - El Boustani et al. - Activated cortical states Experiments, analyses and models.pdf}
}

@article{Filatrella2007,
  langid = {english},
  title = {Generalized Coupling in the {{Kuramoto}} Model},
  volume = {75},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.75.017201},
  doi = {10.1103/PhysRevE.75.017201},
  number = {1},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2007-01-29},
  author = {Filatrella, G. and Pedersen, N. F. and Wiesenfeld, K.},
  file = {/Users/qualia/Documents/Papers/2007 - Filatrella, Pedersen, Wiesenfeld - Generalized coupling in the Kuramoto model.pdf}
}

@article{Frank2007,
  langid = {english},
  title = {Hold {{Your Horses}}: {{Impulsivity}}, {{Deep Brain Stimulation}}, and {{Medication}} in {{Parkinsonism}}},
  volume = {318},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1146157},
  doi = {10.1126/science.1146157},
  shorttitle = {Hold {{Your Horses}}},
  number = {5854},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2007-11-23},
  pages = {1309-1312},
  author = {Frank, M. J. and Samanta, J. and Moustafa, A. A. and Sherman, S. J.},
  file = {/Users/qualia/Documents/Papers/2007 - Frank et al. - Hold Your Horses Impulsivity, Deep Brain Stimulation, and Medication in Parkinsonism.pdf}
}

@article{Hammond2007,
  langid = {english},
  title = {Pathological Synchronization in {{Parkinson}}'s Disease: Networks, Models and Treatments},
  volume = {30},
  issn = {01662236},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223607001233},
  doi = {10.1016/j.tins.2007.05.004},
  shorttitle = {Pathological Synchronization in {{Parkinson}}'s Disease},
  number = {7},
  journaltitle = {Trends in Neurosciences},
  urldate = {2019-03-30},
  date = {2007-07},
  pages = {357-364},
  author = {Hammond, Constance and Bergman, Hagai and Brown, Peter},
  file = {/Users/qualia/Documents/Papers/2007 - Hammond, Bergman, Brown - Pathological synchronization in Parkinson's disease networks, models and treatments.pdf}
}

@article{Helmstaedter2007,
  langid = {english},
  title = {Reconstruction of an Average Cortical Column in Silico},
  volume = {55},
  issn = {01650173},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0165017307001361},
  doi = {10.1016/j.brainresrev.2007.07.011},
  abstract = {The characterization of individual neurons by Golgi and Cajal has been the basis of neuroanatomy for a century. A new challenge is to anatomically describe, at cellular resolution, complete local circuits that can drive behavior. In this essay, we review the possibilities to obtain a model cortical column by using in vitro and in vivo pair recordings, followed by anatomical reconstructions of the projecting and target cells. These pairs establish connection modules that eventually may be useful to synthesize an average cortical column in silico. Together with data on sensory evoked neuronal activity measured in vivo, this will allow to model the anatomical and functional cellular basis of behavior based on more realistic assumptions than previously attempted.},
  number = {2},
  journaltitle = {Brain Research Reviews},
  urldate = {2019-03-30},
  date = {2007-10},
  pages = {193-203},
  author = {Helmstaedter, M. and de Kock, C.P.J. and Feldmeyer, D. and Bruno, R.M. and Sakmann, B.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2007 - Helmstaedter et al. - Reconstruction of an average cortical column in silico.pdf}
}

@article{Ho2007,
  langid = {english},
  title = {Self-Tuning Experience Weighted Attraction Learning in Games},
  volume = {133},
  issn = {00220531},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022053106000056},
  doi = {10.1016/j.jet.2005.12.008},
  number = {1},
  journaltitle = {Journal of Economic Theory},
  urldate = {2019-03-30},
  date = {2007-03},
  pages = {177-198},
  author = {Ho, Teck H. and Camerer, Colin F. and Chong, Juin-Kuan},
  file = {/Users/qualia/Documents/Papers/2007 - Ho, Camerer, Chong - Self-tuning Experience-Weighted Attraction Learning in Games.pdf}
}

@article{Kempster2007,
  langid = {english},
  title = {Patterns of Levodopa Response in {{Parkinson}}'s Disease: A Clinico-Pathological Study},
  volume = {130},
  issn = {0006-8950, 1460-2156},
  url = {https://academic.oup.com/brain/article-lookup/doi/10.1093/brain/awm142},
  doi = {10.1093/brain/awm142},
  shorttitle = {Patterns of Levodopa Response in {{Parkinson}}'s Disease},
  number = {8},
  journaltitle = {Brain},
  urldate = {2019-03-30},
  date = {2007-08-01},
  pages = {2123-2128},
  author = {Kempster, P. A. and Williams, D. R. and Selikhova, M. and Holton, J. and Revesz, T. and Lees, A. J.},
  file = {/Users/qualia/Documents/Papers/2007 - Kempster et al. - Patterns of levodopa response in Parkinson's disease A clinico-pathological study.pdf}
}

@article{Kriegeskorte2007,
  langid = {english},
  title = {Analyzing for Information, Not Activation, to Exploit High-Resolution {{fMRI}}},
  volume = {38},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811907001188},
  doi = {10.1016/j.neuroimage.2007.02.022},
  number = {4},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2007-12},
  pages = {649-662},
  author = {Kriegeskorte, Nikolaus and Bandettini, Peter},
  file = {/Users/qualia/Documents/Papers/2007 - Kriegeskorte, Bandettini - Analyzing for information, not activation, to exploit high-resolution fMRI.pdf}
}

@article{Kriegeskorte2007a,
  langid = {english},
  title = {Combining the Tools: {{Activation}}- and Information-Based {{fMRI}} Analysis},
  volume = {38},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811907006088},
  doi = {10.1016/j.neuroimage.2007.06.030},
  shorttitle = {Combining the Tools},
  number = {4},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2007-12},
  pages = {666-668},
  author = {Kriegeskorte, Nikolaus and Bandettini, Peter},
  file = {/Users/qualia/Documents/Papers/2007 - Kriegeskorte, Bandettini - Combining the tools activation- and information-based fMRI analysis.pdf}
}

@article{LaConte2007,
  langid = {english},
  title = {Real-Time {{fMRI}} Using Brain-State Classification},
  volume = {28},
  issn = {10659471, 10970193},
  url = {http://doi.wiley.com/10.1002/hbm.20326},
  doi = {10.1002/hbm.20326},
  abstract = {We have implemented a real-time functional magnetic resonance imaging system based on multivariate classification. This approach is distinctly different from spatially localized real-time implementations, since it does not require prior assumptions about functional localization and individual performance strategies, and has the ability to provide feedback based on intuitive translations of brain state rather than localized fluctuations. Thus this approach provides the capability for a new class of experimental designs in which real-time feedback control of the stimulus is possible\textemdash{}rather than using a fixed paradigm, experiments can adaptively evolve as subjects receive brain-state feedback. In this report, we describe our implementation and characterize its performance capabilities. We observed \$80\% classification accuracy using whole brain, block-design, motor data. Within both left and right motor task conditions, important differences exist between the initial transient period produced by task switching (changing between rapid left or right index finger button presses) and the subsequent stable period during sustained activity. Further analysis revealed that very high accuracy is achievable during stable task periods, and that the responsiveness of the classifier to changes in task condition can be much faster than signal time-to-peak rates. Finally, we demonstrate the versatility of this implementation with respect to behavioral task, suggesting that our results are applicable across a spectrum of cognitive domains. Beyond basic research, this technology can complement electroencephalography-based brain computer interface research, and has potential applications in the areas of biofeedback rehabilitation, lie detection, learning studies, virtual reality-based training, and enhanced conscious awareness. Hum Brain Mapp 28:1033\textendash{}1044, 2007. VC 2006 Wiley-Liss, Inc.},
  number = {10},
  journaltitle = {Human Brain Mapping},
  urldate = {2019-03-30},
  date = {2007-10},
  pages = {1033-1044},
  author = {LaConte, Stephen M. and Peltier, Scott J. and Hu, Xiaoping P.},
  file = {/Users/qualia/Documents/Papers/2007 - LaConte, Peltier, Hu - Real-time fMRI using brain-state classification.pdf}
}

@article{Levya,
  langid = {english},
  title = {The {{Tale}} of {{Galton}}'s {{Mean}}: {{The Influence}} of {{Experts}}},
  pages = {12},
  author = {Levy, David M and Peart, Sandra J},
  file = {/Users/qualia/Documents/Papers/2007 - Levy, Peart - The Influence of Experts.pdf}
}

@article{Li2007,
  langid = {english},
  title = {Flexible {{Coding}} for {{Categorical Decisions}} in the {{Human Brain}}},
  volume = {27},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3795-07.2007},
  doi = {10.1523/JNEUROSCI.3795-07.2007},
  number = {45},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2007-11-07},
  pages = {12321-12330},
  author = {Li, S. and Ostwald, D. and Giese, M. and Kourtzi, Z.},
  file = {/Users/qualia/Documents/Papers/2007 - Li et al. - Flexible coding for categorical decisions in the human brain.pdf}
}

@article{Lopez-Fidalgo2007,
  langid = {english},
  title = {An Optimal Experimental Design Criterion for Discriminating between Non-Normal Models},
  volume = {69},
  issn = {1369-7412, 1467-9868},
  url = {http://doi.wiley.com/10.1111/j.1467-9868.2007.00586.x},
  doi = {10.1111/j.1467-9868.2007.00586.x},
  abstract = {Typically T -optimality is used to obtain optimal designs to discriminate between homoscedastic models with normally distributed observations. Some extensions of this criterion have been made for the heteroscedastic case and binary response models in the literature. In this paper, a new criterion based on the Kullback\textendash{}Leibler distance is proposed to discriminate between rival models with non-normally distributed observations. The criterion is coherent with the approaches mentioned above. An equivalence theorem is provided for this criterion and an algorithm to compute optimal designs is developed. The criterion is applied to discriminate between the popular Michaelis\textendash{}Menten model and a typical extension of it under the log-normal and the gamma distributions.},
  number = {2},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  urldate = {2019-03-30},
  date = {2007-04},
  pages = {231-242},
  author = {L\'opez-Fidalgo, J. and Tommasi, C. and Trandafir, P. C.},
  file = {/Users/qualia/Documents/Papers/2007 - López-Fidalgo, Tommasi, Trandafir - An optimal experimental design criterion for discriminating between non-normal models.pdf}
}

@article{Mallet2007,
  langid = {english},
  title = {Stimulation of Subterritories of the Subthalamic Nucleus Reveals Its Role in the Integration of the Emotional and Motor Aspects of Behavior},
  volume = {104},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0610849104},
  doi = {10.1073/pnas.0610849104},
  number = {25},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2007-06-19},
  pages = {10661-10666},
  author = {Mallet, L. and Schupbach, M. and N'Diaye, K. and Remy, P. and Bardinet, E. and Czernecki, V. and Welter, M.-L. and Pelissolo, A. and Ruberg, M. and Agid, Y. and Yelnik, J.},
  file = {/Users/qualia/Documents/Papers/2007 - Mallet et al. - Stimulation of subterritories of the subthalamic nucleus reveals its role in the integration of the emotional and.pdf}
}

@article{Mourao-Miranda2007,
  langid = {english},
  title = {Dynamic Discrimination Analysis: {{A}} Spatial\textendash{}Temporal {{SVM}}},
  volume = {36},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811907001073},
  doi = {10.1016/j.neuroimage.2007.02.020},
  shorttitle = {Dynamic Discrimination Analysis},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2007-05},
  pages = {88-99},
  author = {Mour\~ao-Miranda, Janaina and Friston, Karl J. and Brammer, Michael},
  file = {/Users/qualia/Documents/Papers/2007 - Mourão-Miranda, Friston, Brammer - Dynamic discrimination analysis a spatial-temporal SVM.pdf}
}

@article{OToole2007,
  langid = {english},
  title = {Theoretical, {{Statistical}}, and {{Practical Perspectives}} on {{Pattern}}-Based {{Classification Approaches}} to the {{Analysis}} of {{Functional Neuroimaging Data}}},
  volume = {19},
  issn = {0898-929X, 1530-8898},
  url = {http://www.mitpressjournals.org/doi/10.1162/jocn.2007.19.11.1735},
  doi = {10.1162/jocn.2007.19.11.1735},
  number = {11},
  journaltitle = {Journal of Cognitive Neuroscience},
  urldate = {2019-03-30},
  date = {2007-11},
  pages = {1735-1752},
  author = {O'Toole, Alice J. and Jiang, Fang and Abdi, Herv\'e and P\'enard, Nils and Dunlop, Joseph P. and Parent, Marc A.},
  file = {/Users/qualia/Documents/Papers/2007 - O'Toole et al. - Theoretical, statistical, and practical perspectives on pattern-based classification approaches to the analysis.pdf}
}

@article{Parent2007,
  langid = {english},
  title = {The Microcircuitry of Primate Subthalamic Nucleus},
  volume = {13},
  issn = {13538020},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S135380200870018X},
  doi = {10.1016/S1353-8020(08)70018-X},
  abstract = {Single-cell labeling experiments in cynomolgus monkeys have revealed that the subthalamic nucleus (STN) harbors several subtypes of projection neurons, each endowed with a highly patterned set of axon collaterals. This organizational feature allows single STN neurons to act directly upon the two major output structures of the basal ganglia \textendash{} the substantia nigra pars reticulata and the internal pallidum \textendash{} and, at the same time, to exert a multifarious effect upon the external pallidum with which the STN is reciprocally connected. These findings have clarified the role of the STN in basal ganglia organization and led to the elaboration of more accurate computational models of deep brain stimulation, a therapeutic approach currently used to alleviate the motor symptoms of Parkinson's Disease.},
  journaltitle = {Parkinsonism \& Related Disorders},
  urldate = {2019-03-30},
  date = {2007},
  pages = {S292-S295},
  author = {Parent, Martin and Parent, Andr\'e},
  file = {/Users/qualia/Documents/Papers/2007 - Parent, Parent - The microcircuitry of primate subthalamic nucleus.pdf}
}

@article{Parikh2007,
  langid = {english},
  title = {Prefrontal {{Acetylcholine Release Controls Cue Detection}} on {{Multiple Timescales}}},
  volume = {56},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627307006745},
  doi = {10.1016/j.neuron.2007.08.025},
  abstract = {Cholinergic neurons originating from the basal forebrain innervate the entire cortical mantle. Choline-sensitive microelectrodes were used to measure the synaptic release of cortical acetylcholine (ACh) at a sub-second resolution in rats performing a task involving the detection of cues. Cues that were detected, defined behaviorally, evoked transient increases in cholinergic activity (at the scale of seconds) in the medial prefrontal cortex (mPFC), but not in a non-associational control region (motor cortex). In trials involving missed cues, cholinergic transients were not observed. Cholinergic deafferentation of the mPFC, but not motor cortex, impaired cue detection. Furthermore, decreases and increases in pre-cue cholinergic activity predicted subsequent cue detection or misses, respectively. Finally, cue-evoked cholinergic transients were superimposed over slower (at the time scale of minutes) changes in cholinergic activity. Cortical cholinergic neurotransmission is regulated on multiple time scales to mediate the detection of behaviorally significant cues and to support cognitive performance.},
  number = {1},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2007-10},
  pages = {141-154},
  author = {Parikh, Vinay and Kozak, Rouba and Martinez, Vicente and Sarter, Martin},
  file = {/Users/qualia/Documents/Papers/2007 - Parikh et al. - Prefrontal acetylcholine release controls cue detection on multiple time scales.pdf}
}

@article{Pessoa2006,
  langid = {english},
  title = {Decoding {{Near}}-{{Threshold Perception}} of {{Fear}} from {{Distributed Single}}-{{Trial Brain Activation}}},
  volume = {17},
  issn = {1047-3211, 1460-2199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhk020},
  doi = {10.1093/cercor/bhk020},
  abstract = {Instead of contrasting functional magnetic resonance imaging (fMRI) signals associated with 2 conditions, as customarily done in neuroimaging, we reversed the direction of analysis and probed whether brain signals could be used to ``predict'' perceptual states. We probed the neural correlates of perceptual decisions by ``decoding'' brain states during near-threshold fear detection. Decoding was attempted by using support vector machines and other related techniques. Although previous decoding studies have employed relatively ``blocked'' data, our objective was to probe how the ``moment-to-moment'' fluctuation in fMRI signals across a population of voxels reflected the participant's perceptual decision. Accuracy increased from when 1 region was considered (\textasciitilde{}64\%) to when 10 regions were used (\textasciitilde{}78\%). When the best classifications per subject were averaged, accuracy levels ranged between 74\% and 86\% correct. An information theoretic analysis revealed that the information carried by pairs of regions reliably exceeded the sum of the information carried by individual regions, suggesting that information was combined ``synergistically'' across regions. Our results indicate that the representation of behavioral choice is ``distributed'' across several brain regions. Such distributed encoding may help prepare the organism to appropriately handle emotional stimuli and regulate the associated emotional response upon the conscious decision that a fearful face is present. In addition, the results show that challenging brain states can be decoded with high accuracy even when ``single-trial'' data are employed and suggest that multivariate analysis strategies have considerable potential in helping to elucidate the neural correlates of visual awareness and the encoding of perceptual decisions.},
  number = {3},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2006-03-31},
  pages = {691-701},
  author = {Pessoa, L. and Padmala, S.},
  file = {/Users/qualia/Documents/Papers/2007 - Pessoa, Padmala - Decoding near-threshold perception of fear from distributed single-trial brain activation.pdf}
}

@article{Shmuel2007,
  langid = {english},
  title = {Spatio-Temporal Point-Spread Function of {{fMRI}} Signal in Human Gray Matter at 7 {{Tesla}}},
  volume = {35},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811906012444},
  doi = {10.1016/j.neuroimage.2006.12.030},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2007-04},
  pages = {539-552},
  author = {Shmuel, Amir and Yacoub, Essa and Chaimow, Denis and Logothetis, Nikos K. and Ugurbil, Kamil},
  file = {/Users/qualia/Documents/Papers/2007 - Shmuel et al. - Spatio-temporal point-spread function of fMRI signal in human gray matter at 7 Tesla.pdf}
}

@article{Shoham2007,
  langid = {english},
  title = {If Multi-Agent Learning Is the Answer, What Is the Question?},
  volume = {171},
  issn = {00043702},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370207000495},
  doi = {10.1016/j.artint.2006.02.006},
  number = {7},
  journaltitle = {Artificial Intelligence},
  urldate = {2019-03-30},
  date = {2007-05},
  pages = {365-377},
  author = {Shoham, Yoav and Powers, Rob and Grenager, Trond},
  file = {/Users/qualia/Documents/Papers/2007 - Shoham, Powers, Grenager - If multi-agent learning is the answer, what is the question.pdf}
}

@article{Sotero2007,
  langid = {english},
  title = {Realistically {{Coupled Neural Mass Models Can Generate EEG Rhythms}}},
  volume = {19},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.2007.19.2.478},
  doi = {10.1162/neco.2007.19.2.478},
  number = {2},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2007-02},
  pages = {478-512},
  author = {Sotero, Roberto C. and Trujillo-Barreto, Nelson J. and Iturria-Medina, Yasser and Carbonell, Felix and Jimenez, Juan C.},
  file = {/Users/qualia/Documents/Papers/2007 - Sotero, Trujillo-barreto - Realistically Coupled Neural Mass Models Can Generate EEG Rhythms.pdf}
}

@article{Apesteguia2007,
  langid = {english},
  title = {Imitation\textemdash{}Theory and Experimental Evidence},
  volume = {136},
  issn = {00220531},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022053106001268},
  doi = {10.1016/j.jet.2006.07.006},
  abstract = {We introduce a generalized theoretical approach to study imitation models and subject the models to rigorous experimental testing. In our theoretical analysis we \TH{}nd that the different predictions of previous imitation models are due to different informational assumptions, not to different behavioral rules. It is more important whom one imitates rather than how. In a laboratory experiment we test the different theories by systematically varying information conditions. We \TH{}nd that the generalized imitation model predicts the differences between treatments well. The data also provide support for imitation on the individual level, both in terms of choice and in terms of perception. But imitation is not unconditional. Rather individuals' propensity to imitate more successful actions is increasing in payoff differences.},
  number = {1},
  journaltitle = {Journal of Economic Theory},
  urldate = {2019-03-30},
  date = {2007-09},
  pages = {217-235},
  author = {Apesteguia, Jose and Huck, Steffen and Oechssler, J\"org},
  file = {/Users/qualia/Documents/Papers/2007 - Steffen Huck - Imitation - theory and experimental evidence.pdf}
}

@article{Tripp2007,
  langid = {english},
  title = {Neural {{Populations Can Induce Reliable Postsynaptic Currents}} without {{Observable Spike Rate Changes}} or {{Precise Spike Timing}}},
  volume = {17},
  issn = {1047-3211, 1460-2199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhl092},
  doi = {10.1093/cercor/bhl092},
  number = {8},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2007-08-01},
  pages = {1830-1840},
  author = {Tripp, B. and Eliasmith, C.},
  file = {/Users/qualia/Documents/Papers/2007 - Tripp, Eliasmith - Neural populations can induce reliable postsynaptic currents without observable spike rate changes or precise.pdf}
}

@article{Tuyls2007,
  langid = {english},
  title = {What Evolutionary Game Theory Tells Us about Multiagent Learning},
  volume = {171},
  issn = {00043702},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370207000082},
  doi = {10.1016/j.artint.2007.01.004},
  abstract = {This paper discusses If multi-agent learning is the answer, what is the question? [Y. Shoham, R. Powers, T. Grenager, If multiagent learning is the answer, what is the question? Artificial Intelligence 171 (7) (2007) 365\textendash{}377, this issue] from the perspective of evolutionary game theory. We briefly discuss the concepts of evolutionary game theory, and examine the main conclusions from [Y. Shoham, R. Powers, T. Grenager, If multi-agent learning is the answer, what is the question? Artificial Intelligence 171 (7) (2007) 365\textendash{}377, this issue] with respect to some of our previous work. Overall we find much to agree with, concluding, however, that the central concerns of multiagent learning are rather narrow compared with the broad variety of work identified in [Y. Shoham, R. Powers, T. Grenager, If multi-agent learning is the answer, what is the question? Artificial Inteligence 171 (7) (2007) 365\textendash{}377, this issue].},
  number = {7},
  journaltitle = {Artificial Intelligence},
  urldate = {2019-03-30},
  date = {2007-05},
  pages = {406-416},
  author = {Tuyls, Karl and Parsons, Simon},
  file = {/Users/qualia/Documents/Papers/2007 - Tuyls, Parsons - What evolutionary game theory tells us about multiagent learning.pdf}
}

@article{Unsworth2007,
  langid = {english},
  title = {On the Division of Short-Term and Working Memory: {{An}} Examination of Simple and Complex Span and Their Relation to Higher Order Abilities.},
  volume = {133},
  issn = {1939-1455, 0033-2909},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-2909.133.6.1038},
  doi = {10.1037/0033-2909.133.6.1038},
  shorttitle = {On the Division of Short-Term and Working Memory},
  abstract = {Research has suggested that short-term memory and working memory (as measured by simple and complex span tasks, respectively) are separate constructs that are differentially related to higher order cognitive abilities. This claim is critically evaluated by reviewing research that has compared simple and complex span tasks in both experimental and correlational studies. In addition, a meta-analysis and re-analyses of key data sets were conducted. The review and analyses suggest that simple and complex span tasks largely measure the same basic subcomponent processes (e.g., rehearsal, maintenance, updating, controlled search) but differ in the extent to which these processes operate in a particular task. These differences largely depend on the extent to which phonological processes are maximized and variability from long list lengths is present. Potential methodological, psychometric, and assessment implications are discussed and a theoretical account of the data is proposed.},
  number = {6},
  journaltitle = {Psychological Bulletin},
  urldate = {2019-03-30},
  date = {2007},
  pages = {1038-1066},
  author = {Unsworth, Nash and Engle, Randall W.},
  file = {/Users/qualia/Documents/Papers/2007 - Unsworth, Engle - On the division of short-term and working memory An examination of simple and complex span and their relatio(2).pdf;/Users/qualia/Documents/Papers/2007 - Unsworth, Engle - On the division of short-term and working memory An examination of simple and complex span and their relation t.pdf}
}

@article{Yamazaki2007,
  langid = {english},
  title = {The Cerebellum as a Liquid State Machine},
  volume = {20},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608007000366},
  doi = {10.1016/j.neunet.2007.04.004},
  abstract = {We examined closely the cerebellar circuit model that we have proposed previously. The model granular layer generates a finite but very long sequence of active neuron populations without recurrence, which is able to represent the passage of time. For all the possible binary patterns fed into mossy fibres, the circuit generates the same number of different sequences of active neuron populations. Model Purkinje cells that receive parallel fiber inputs from neurons in the granular layer learn to stop eliciting spikes at the timing instructed by the arrival of signals from the inferior olive. These functional roles of the granular layer and Purkinje cells are regarded as a liquid state generator and readout neurons, respectively. Thus, the cerebellum that has been considered to date as a biological counterpart of a perceptron is reinterpreted to be a liquid state machine that possesses powerful information processing capability more than a perceptron.},
  number = {3},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2007-04},
  pages = {290-297},
  author = {Yamazaki, Tadashi and Tanaka, Shigeru},
  file = {/Users/qualia/Documents/Papers/2007 - Yamazaki, Tanaka - The cerebellum as a liquid state machine.pdf}
}

@article{Ahn2008,
  langid = {english},
  title = {Comparison of {{Decision Learning Models Using}} the {{Generalization Criterion Method}}},
  volume = {32},
  issn = {0364-0213},
  url = {http://doi.wiley.com/10.1080/03640210802352992},
  doi = {10.1080/03640210802352992},
  abstract = {It is a hallmark of a good model to make accurate a priori predictions to new conditions (Busemeyer \& Wang, 2000). This study compared 8 decision learning models with respect to their generalizability. Participants performed 2 tasks (the Iowa Gambling Task and the Soochow Gambling Task), and each model made a priori predictions by estimating the parameters for each participant from 1 task and using those same parameters to predict on the other task. Three methods were used to evaluate the models at the individual level of analysis. The first method used a post hoc fit criterion, the second method used a generalization criterion for short-term predictions, and the third method again used a generalization criterion for long-term predictions. The results suggest that the models with the prospect utility function can make generalizable predictions to new conditions, and different learning models are needed for making short- versus long-term predictions on simple gambling tasks.},
  number = {8},
  journaltitle = {Cognitive Science: A Multidisciplinary Journal},
  urldate = {2019-03-30},
  date = {2008-12},
  pages = {1376-1402},
  author = {Ahn, Woo-Young and Busemeyer, Jerome and Wagenmakers, Eric-Jan and Stout, Julie},
  file = {/Users/qualia/Documents/Papers/2008 - Ahn et al. - Comparison of decision learning models using the generalization criterion method.pdf}
}

@article{Barrett2008,
  langid = {english},
  title = {Optimal {{Learning Rules}} for {{Discrete Synapses}}},
  volume = {4},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1000230},
  doi = {10.1371/journal.pcbi.1000230},
  abstract = {There is evidence that biological synapses have a limited number of discrete weight states. Memory storage with such synapses behaves quite differently from synapses with unbounded, continuous weights, as old memories are automatically overwritten by new memories. Consequently, there has been substantial discussion about how this affects learning and storage capacity. In this paper, we calculate the storage capacity of discrete, bounded synapses in terms of Shannon information. We use this to optimize the learning rules and investigate how the maximum information capacity depends on the number of synapses, the number of synaptic states, and the coding sparseness. Below a certain critical number of synapses per neuron (comparable to numbers found in biology), we find that storage is similar to unbounded, continuous synapses. Hence, discrete synapses do not necessarily have lower storage capacity.},
  number = {11},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2008-11-28},
  pages = {e1000230},
  author = {Barrett, Adam B. and van Rossum, M. C. W.},
  editor = {Graham, Lyle J.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2008 - Barrett, Van Rossum - Optimal learning rules for discrete synapses.pdf}
}

@article{Bollimunta2008,
  langid = {english},
  title = {Neuronal {{Mechanisms}} of {{Cortical Alpha Oscillations}} in {{Awake}}-{{Behaving Macaques}}},
  volume = {28},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2699-08.2008},
  doi = {10.1523/JNEUROSCI.2699-08.2008},
  number = {40},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2008-10-01},
  pages = {9976-9988},
  author = {Bollimunta, A. and Chen, Y. and Schroeder, C. E. and Ding, M.},
  file = {/Users/qualia/Documents/Papers/2008 - Bollimunta et al. - Neuronal mechanisms of cortical alpha oscillations in awake-behaving macaques.pdf}
}

@article{Borella2008,
  langid = {english},
  title = {Working Memory and Inhibition across the Adult Life-Span},
  volume = {128},
  issn = {00016918},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0001691807001096},
  doi = {10.1016/j.actpsy.2007.09.008},
  abstract = {Research has shown that age-related changes in cognitive performance are due mostly to the decline of general factors such as working memory and inhibition. The present study is aimed at investigating age-related changes in these mechanisms across the adult life-span from 20 to 86 years of age. Results indicate a linear relationship between each working memory measure and age, independently of the nature of the task, and a quadratic relationship between the single inhibitory measures and age. Moreover, hierarchical regression analyses show that inhibition accounts for a significant, but modest, part of the age-related variance in working memory. Taken together, these results suggest that inhibition is not as crucial a contributor of age-related changes in the functional capacity of working memory across the adult life-span as previously thought.},
  number = {1},
  journaltitle = {Acta Psychologica},
  urldate = {2019-03-30},
  date = {2008-05},
  pages = {33-44},
  author = {Borella, Erika and Carretti, Barbara and De Beni, Rossana},
  file = {/Users/qualia/Documents/Papers/2008 - Borella, Carretti, De Beni - Working memory and inhibition across the adult life-span.pdf}
}

@article{Borgers2008,
  langid = {english},
  title = {Gamma Oscillations Mediate Stimulus Competition and Attentional Selection in a Cortical Network Model},
  volume = {105},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0809511105},
  doi = {10.1073/pnas.0809511105},
  number = {46},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2008-11-18},
  pages = {18023-18028},
  author = {Borgers, C. and Epstein, S. and Kopell, N. J.},
  file = {/Users/qualia/Documents/Papers/2008 - Börgers, Epstein, Kopell - Gamma oscillations mediate stimulus competition and attentional selection in a cortical network model.pdf}
}

@article{Brozovic2008,
  langid = {english},
  title = {Mechanism of Gain Modulation at Single Neuron and Network Levels},
  volume = {25},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-007-0070-6},
  doi = {10.1007/s10827-007-0070-6},
  abstract = {Gain modulation, in which the sensitivity of a neural response to one input is modified by a second input, is studied at single-neuron and network levels. At the single neuron level, gain modulation can arise if the two inputs are subject to a direct multiplicative interaction. Alternatively, these inputs can be summed in a linear manner by the neuron and gain modulation can arise, instead, from a nonlinear input\textendash{}output relationship. We derive a mathematical constraint that can distinguish these two mechanisms even though they can look very similar, provided sufficient data of the appropriate type are available. Previously, it has been shown in coordinate transformation studies that artificial neurons with sigmoid transfer functions can acquire a nonlinear additive form of gain modulation through learning-driven adjustment of synaptic weights. We use the constraint derived for single-neuron studies to compare responses in this network with those of another network model based on a biologically inspired transfer function that can support approximately multiplicative interactions.},
  number = {1},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2008-08},
  pages = {158-168},
  author = {Brozovi\'c, M. and Abbott, L. F. and Andersen, R. A.},
  file = {/Users/qualia/Documents/Papers/2008 - Brozovi, Abbott, Andersen - Mechanism of gain modulation at single neuron and network levels.pdf}
}

@article{Candes2008,
  langid = {english},
  title = {An {{Introduction To Compressive Sampling}}},
  volume = {25},
  issn = {1053-5888},
  url = {http://ieeexplore.ieee.org/document/4472240/},
  doi = {10.1109/MSP.2007.914731},
  number = {2},
  journaltitle = {IEEE Signal Processing Magazine},
  urldate = {2019-03-30},
  date = {2008-03},
  pages = {21-30},
  author = {Candes, E.J. and Wakin, M.B.},
  file = {/Users/qualia/Documents/Papers/2008 - Candes, Wakin - An Introduction To Compressive Sampling.pdf}
}

@article{Casanova2008,
  langid = {english},
  title = {The Impact of Temporal Regularization on Estimates of the {{BOLD}} Hemodynamic Response Function: {{A}} Comparative Analysis},
  volume = {40},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811908000335},
  doi = {10.1016/j.neuroimage.2008.01.011},
  shorttitle = {The Impact of Temporal Regularization on Estimates of the {{BOLD}} Hemodynamic Response Function},
  number = {4},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2008-05},
  pages = {1606-1618},
  author = {Casanova, Ramon and Ryali, Srikanth and Serences, John and Yang, Lucie and Kraft, Robert and Laurienti, Paul J. and Maldjian, Joseph A.},
  file = {/Users/qualia/Documents/Papers/2008 - Casanova et al. - The impact of temporal regularization on estimates of the BOLD hemodynamic response function a comparative anal.pdf}
}

@article{Childs2008,
  langid = {english},
  title = {Stability Diagram for the Forced {{Kuramoto}} Model},
  volume = {18},
  issn = {1054-1500, 1089-7682},
  url = {http://aip.scitation.org/doi/10.1063/1.3049136},
  doi = {10.1063/1.3049136},
  number = {4},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  urldate = {2019-03-30},
  date = {2008-12},
  pages = {043128},
  author = {Childs, Lauren M. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/2008 - Childs, Strogatz - Stability diagram for the forced Kuramoto model.pdf}
}

@article{Curto2008,
  langid = {english},
  title = {Cell {{Groups Reveal Structure}} of {{Stimulus Space}}},
  volume = {4},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1000205},
  doi = {10.1371/journal.pcbi.1000205},
  abstract = {An important task of the brain is to represent the outside world. It is unclear how the brain may do this, however, as it can only rely on neural responses and has no independent access to external stimuli in order to ``decode'' what those responses mean. We investigate what can be learned about a space of stimuli using only the action potentials (spikes) of cells with stereotyped\textemdash{}but unknown\textemdash{}receptive fields. Using hippocampal place cells as a model system, we show that one can (1) extract global features of the environment and (2) construct an accurate representation of space, up to an overall scale factor, that can be used to track the animal's position. Unlike previous approaches to reconstructing position from place cell activity, this information is derived without knowing place fields or any other functions relating neural responses to position. We find that simply knowing which groups of cells fire together reveals a surprising amount of structure in the underlying stimulus space; this may enable the brain to construct its own internal representations.},
  number = {10},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2008-10-31},
  pages = {e1000205},
  author = {Curto, Carina and Itskov, Vladimir},
  editor = {Friston, Karl J.},
  file = {/Users/qualia/Documents/Papers/2008 - Curto, Itskov - Cell groups reveal structure of stimulus space.pdf}
}

@article{Daw,
  langid = {english},
  title = {The Pigeon as Particle filter},
  abstract = {Although theorists have interpreted classical conditioning as a laboratory model of Bayesian belief updating, a recent reanalysis showed that the key features that theoretical models capture about learning are artifacts of averaging over subjects. Rather than learning smoothly to asymptote (reflecting, according to Bayesian models, the gradual tradeoff from prior to posterior as data accumulate), subjects learn suddenly, and their predictions fluctuate perpetually. We suggest that abrupt and unstable learning can be modeled by assuming subjects are conducting inference using sequential Monte Carlo sampling with a small number of samples \textemdash{} one, in our simulations. Ensemble behavior resembles exact Bayesian models since, as in particle filters, it averages over many samples. Further, the model is capable of exhibiting sophisticated behaviors like retrospective revaluation at the ensemble level, even given minimally sophisticated individuals that do not track uncertainty in their beliefs over trials.},
  pages = {8},
  author = {Daw, Nathaniel D and Courville, Aaron C},
  file = {/Users/qualia/Documents/Papers/2008 - Daw, Courville - The pigeon as particle filter.pdf}
}

@article{DeMartino2008,
  langid = {english},
  title = {Combining Multivariate Voxel Selection and Support Vector Machines for Mapping and Classification of {{fMRI}} Spatial Patterns},
  volume = {43},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811908007854},
  doi = {10.1016/j.neuroimage.2008.06.037},
  abstract = {In functional brain mapping, pattern recognition methods allow detecting multivoxel patterns of brain activation which are informative with respect to a subject's perceptual or cognitive state. The sensitivity of these methods, however, is greatly reduced when the proportion of voxels that convey the discriminative information is small compared to the total number of measured voxels. To reduce this dimensionality problem, previous studies employed univariate voxel selection or region-of-interest-based strategies as a preceding step to the application of machine learning algorithms.},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2008-10},
  pages = {44-58},
  author = {De Martino, Federico and Valente, Giancarlo and Staeren, No\"el and Ashburner, John and Goebel, Rainer and Formisano, Elia},
  file = {/Users/qualia/Documents/Papers/2008 - De Martino et al. - Combining multivariate voxel selection and support vector machines for mapping and classification of fMRI spa.pdf}
}

@article{Druckmann2008,
  langid = {english},
  title = {Evaluating Automated Parameter Constraining Procedures of Neuron Models by Experimental and Surrogate Data},
  volume = {99},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-008-0269-2},
  doi = {10.1007/s00422-008-0269-2},
  number = {4-5},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2008-11},
  pages = {371-379},
  author = {Druckmann, Shaul and Berger, Thomas K. and Hill, Sean and Sch\"urmann, Felix and Markram, Henry and Segev, Idan},
  file = {/Users/qualia/Documents/Papers/2008 - Druckmann et al. - Evaluating automated parameter constraining procedures of neuron models by experimental and surrogate data.pdf}
}

@article{Faisal2008,
  langid = {english},
  title = {Noise in the Nervous System},
  volume = {9},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn2258},
  doi = {10.1038/nrn2258},
  abstract = {Random disturbances of signals, termed `noise', pose a fundamental problem for information processing and affect all aspects of nervous-system function. However, the nature, amount and impact of noise in the nervous system have only recently been addressed in a quantitative manner. Experimental and computational methods have shown that multiple noise sources contribute to cellular and behavioural trial-to-trial variability. We review the sources of noise in the nervous system, from the molecular to the behavioural level, and show how noise contributes to trial-totrial variability. We highlight how noise affects neuronal networks and the principles the nervous system applies to counter detrimental effects of noise, and briefly discuss noise's potential benefits.},
  number = {4},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2008-04},
  pages = {292-303},
  author = {Faisal, A. Aldo and Selen, Luc P. J. and Wolpert, Daniel M.},
  file = {/Users/qualia/Documents/Papers/2008 - Faisal, Selen, Wolpert - Noise in the nervous system.pdf;/Users/qualia/Documents/Papers/2008 - Faisal, Selen, Wolpert - Noise in the nervous system(2).pdf}
}

@article{Formisano2008,
  langid = {english},
  title = {Multivariate Analysis of {{fMRI}} Time Series: Classification and Regression of Brain Responses Using Machine Learning},
  volume = {26},
  issn = {0730725X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0730725X08000775},
  doi = {10.1016/j.mri.2008.01.052},
  shorttitle = {Multivariate Analysis of {{fMRI}} Time Series},
  abstract = {Machine learning and pattern recognition techniques are being increasingly employed in functional magnetic resonance imaging (fMRI) data analysis. By taking into account the full spatial pattern of brain activity measured simultaneously at many locations, these methods allow detecting subtle, non-strictly localized effects that may remain invisible to the conventional analysis with univariate statistical methods. In typical fMRI applications, pattern recognition algorithms ``learn'' a functional relationship between brain response patterns and a perceptual, cognitive or behavioral state of a subject expressed in terms of a label, which may assume discrete (classification) or continuous (regression) values. This learned functional relationship is then used to predict the unseen labels from a new data set (``brain reading''). In this article, we describe the mathematical foundations of machine learning applications in fMRI. We focus on two methods, support vector machines and relevance vector machines, which are respectively suited for the classification and regression of fMRI patterns. Furthermore, by means of several examples and applications, we illustrate and discuss the methodological challenges of using machine learning algorithms in the context of fMRI data analysis.},
  number = {7},
  journaltitle = {Magnetic Resonance Imaging},
  urldate = {2019-03-30},
  date = {2008-09},
  pages = {921-934},
  author = {Formisano, Elia and De Martino, Federico and Valente, Giancarlo},
  file = {/Users/qualia/Documents/Papers/2008 - Formisano, De Martino, Valente - Multivariate analysis of fMRI time series classification and regression of brain responses using.pdf}
}

@article{Ganguli2008,
  langid = {english},
  title = {Memory Traces in Dynamical Systems},
  volume = {105},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0804451105},
  doi = {10.1073/pnas.0804451105},
  number = {48},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2008-12-02},
  pages = {18970-18975},
  author = {Ganguli, S. and Huh, D. and Sompolinsky, H.},
  file = {/Users/qualia/Documents/Papers/2008 - Ganguli, Huh, Sompolinsky - Memory traces in dynamical systems.pdf}
}

@article{Girard2008,
  langid = {english},
  title = {Where Neuroscience and Dynamic System Theory Meet Autonomous Robotics: {{A}} Contracting Basal Ganglia Model for Action Selection},
  volume = {21},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608008000671},
  doi = {10.1016/j.neunet.2008.03.009},
  shorttitle = {Where Neuroscience and Dynamic System Theory Meet Autonomous Robotics},
  abstract = {Action selection, the problem of choosing what to do next, is central to any autonomous agent architecture. We use here a multi-disciplinary approach at the convergence of neuroscience, dynamical system theory and autonomous robotics, in order to propose an efficient action selection mechanism based on a new model of the basal ganglia. We first describe new developments of contraction theory regarding locally projected dynamical systems. We exploit these results to design a stable computational model of the cortico-baso-thalamo-cortical loops. Based on recent anatomical data, we include usually neglected neural projections, which participate in performing accurate selection. Finally, the efficiency of this model as an autonomous robot action selection mechanism is assessed in a standard survival task. The model exhibits valuable dithering avoidance and energy-saving properties, when compared with a simple if-then-else decision rule.},
  number = {4},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2008-05},
  pages = {628-641},
  author = {Girard, B. and Tabareau, N. and Pham, Q.C. and Berthoz, A. and Slotine, J.-J.},
  file = {/Users/qualia/Documents/Papers/2008 - Girard et al. - Where neuroscience and dynamic system theory meet autonomous robotics A contracting basal ganglia model for actio.pdf}
}

@article{Hanson2008,
  langid = {english},
  title = {Brain {{Reading Using Full Brain Support Vector Machines}} for {{Object Recognition}}: {{There Is No}} ``{{Face}}'' {{Identification Area}}},
  volume = {20},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.2007.09-06-340},
  doi = {10.1162/neco.2007.09-06-340},
  shorttitle = {Brain {{Reading Using Full Brain Support Vector Machines}} for {{Object Recognition}}},
  number = {2},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2008-02},
  pages = {486-503},
  author = {Hanson, Stephen Jos\'e and Halchenko, Yaroslav O.},
  file = {/Users/qualia/Documents/Papers/2008 - Hanson, Halchenko - Brain reading using full brain support vector machines for object recognition there is no face identification.pdf}
}

@article{Ibata2008,
  langid = {english},
  title = {Rapid {{Synaptic Scaling Induced}} by {{Changes}} in {{Postsynaptic Firing}}},
  volume = {57},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627308002134},
  doi = {10.1016/j.neuron.2008.02.031},
  abstract = {Homeostatic synaptic scaling adjusts a neuron's excitatory synaptic strengths up or down to compensate for perturbations in activity. Little is known about the molecular pathway(s) involved, nor is it clear which aspect of ``activity''\textemdash{}local synaptic signaling, postsynaptic firing, or large-scale changes in network activity\textemdash{}is required to induce synaptic scaling. Here, we selectively block either postsynaptic firing in individual neurons or a fraction of presynaptic inputs, while optically monitoring changes in synaptic strength. We find that synaptic scaling is rapidly induced by block of postsynaptic firing, but not by local synaptic blockade, and is mediated through a drop in somatic calcium influx, reduced activation of CaMKIV, and an increase in transcription. Cortical neurons thus homeostatically adjust synaptic strengths in response to changes in their own firing rate, a mechanism with the computational advantage of efficiently normalizing synaptic strengths without interfering with synapse-specific mechanisms of information storage.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2008-03},
  pages = {819-826},
  author = {Ibata, Keiji and Sun, Qian and Turrigiano, Gina G.},
  file = {/Users/qualia/Documents/Papers/2008 - Ibata, Sun, Turrigiano - Rapid Synaptic Scaling Induced by Changes in Postsynaptic Firing.pdf}
}

@article{Zhang2005,
  langid = {english},
  title = {Fixed Points and Stability in Differential Equations with Variable Delays},
  volume = {63},
  issn = {0362546X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0362546X05002531},
  doi = {10.1016/j.na.2005.02.081},
  abstract = {In this paper we consider a linear scalar differential equation with variable delays and give conditions to ensure that the zero solution is asymptotically stable by means of fixed point theory. These conditions do not require the boundedness of delays, nor do they ask for a fixed sign on the coefficient functions. An asymptotic stability theorem with a necessary and sufficient condition is proved.},
  number = {5-7},
  journaltitle = {Nonlinear Analysis: Theory, Methods \& Applications},
  urldate = {2019-03-30},
  date = {2005-11},
  pages = {e233-e242},
  author = {Zhang, Bo},
  file = {/Users/qualia/Documents/Papers/2008 - Jin, Luo - Fixed points and stability in neutral differential equations with variable delays.pdf}
}

@article{Kay2008,
  langid = {english},
  title = {Identifying Natural Images from Human Brain Activity},
  volume = {452},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature06713},
  doi = {10.1038/nature06713},
  number = {7185},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2008-03},
  pages = {352-355},
  author = {Kay, Kendrick N. and Naselaris, Thomas and Prenger, Ryan J. and Gallant, Jack L.},
  file = {/Users/qualia/Documents/Papers/2008 - Kay et al. - Identifying natural images from human brain activity.pdf}
}

@article{Koyama2008,
  langid = {english},
  title = {Spike {{Train Probability Models}} for {{Stimulus}}-{{Driven Leaky Integrate}}-and-{{Fire Neurons}}},
  volume = {20},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.2008.06-07-540},
  doi = {10.1162/neco.2008.06-07-540},
  number = {7},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2008-07},
  pages = {1776-1795},
  author = {Koyama, Shinsuke and Kass, Robert E.},
  file = {/Users/qualia/Documents/Papers/2008 - Koyama, Kass - Spike train probability models for stimulus-driven leaky integrate-and-fire neurons.pdf}
}

@article{Kriegeskorte2008,
  langid = {english},
  title = {Representational Similarity Analysis \textendash{} Connecting the Branches of Systems Neuroscience},
  issn = {16625137},
  url = {http://journal.frontiersin.org/article/10.3389/neuro.06.004.2008/abstract},
  doi = {10.3389/neuro.06.004.2008},
  abstract = {A fundamental challenge for systems neuroscience is to quantitatively relate its three major branches of research: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities.The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
  journaltitle = {Frontiers in Systems Neuroscience},
  urldate = {2019-03-30},
  date = {2008},
  author = {Kriegeskorte, Nikolaus},
  file = {/Users/qualia/Documents/Papers/2008 - Kriegeskorte, Mur, Bandettini - Representational similarity analysis - connecting the branches of systems neuroscience.pdf}
}

@article{Ku2008,
  langid = {english},
  title = {Comparison of Pattern Recognition Methods in Classifying High-Resolution {{BOLD}} Signals Obtained at High Magnetic Field in Monkeys},
  volume = {26},
  issn = {0730725X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0730725X08000994},
  doi = {10.1016/j.mri.2008.02.016},
  abstract = {Pattern recognition methods have shown that functional magnetic resonance imaging (fMRI) data can reveal significant information about brain activity. For example, in the debate of how object categories are represented in the brain, multivariate analysis has been used to provide evidence of a distributed encoding scheme [Science 293:5539 (2001) 2425\textendash{}2430]. Many follow-up studies have employed different methods to analyze human fMRI data with varying degrees of success [Nature reviews 7:7 (2006) 523\textendash{}534]. In this study, we compare four popular pattern recognition methods: correlation analysis, support-vector machines (SVM), linear discriminant analysis (LDA) and Gaussian na\"ive Bayes (GNB), using data collected at high field (7 Tesla) with higher resolution than usual fMRI studies. We investigate prediction performance on single trials and for averages across varying numbers of stimulus presentations. The performance of the various algorithms depends on the nature of the brain activity being categorized: for several tasks, many of the methods work well, whereas for others, no method performs above chance level. An important factor in overall classification performance is careful preprocessing of the data, including dimensionality reduction, voxel selection and outlier elimination.},
  number = {7},
  journaltitle = {Magnetic Resonance Imaging},
  urldate = {2019-03-30},
  date = {2008-09},
  pages = {1007-1014},
  author = {Ku, Shih-pi and Gretton, Arthur and Macke, Jakob and Logothetis, Nikos K.},
  file = {/Users/qualia/Documents/Papers/2008 - Ku et al. - Comparison of pattern recognition methods in classifying high-resolution BOLD signals obtained at high magnetic field.pdf}
}

@article{Leibold2008,
  langid = {english},
  title = {Temporal Compression Mediated by Short-Term Synaptic Plasticity},
  volume = {105},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0708711105},
  doi = {10.1073/pnas.0708711105},
  number = {11},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2008-03-18},
  pages = {4417-4422},
  author = {Leibold, C. and Gundlfinger, A. and Schmidt, R. and Thurley, K. and Schmitz, D. and Kempter, R.},
  file = {/Users/qualia/Documents/Papers/2008 - Leibold et al. - Temporal compression mediated by short-term synaptic plasticity.pdf}
}

@article{Lewis-Peacock2008,
  langid = {english},
  title = {Temporary {{Activation}} of {{Long}}-{{Term Memory Supports Working Memory}}},
  volume = {28},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1953-08.2008},
  doi = {10.1523/JNEUROSCI.1953-08.2008},
  number = {35},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2008-08-27},
  pages = {8765-8771},
  author = {Lewis-Peacock, J. A. and Postle, B. R.},
  file = {/Users/qualia/Documents/Papers/2008 - Lewis-Peacock, Postle - Temporary activation of long-term memory supports working memory.pdf}
}

@article{Nir2008,
  langid = {english},
  title = {{{BOLD}} and Spiking Activity},
  volume = {11},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn0508-523},
  doi = {10.1038/nn0508-523},
  number = {5},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2008-05},
  pages = {523-524},
  author = {Nir, Yuval and Dinstein, Ilan and Malach, Rafael and Heeger, David J},
  file = {/Users/qualia/Documents/Papers/2008 - Malach, Nir, Heeger - Co r r e s p on d e n c e.pdf}
}

@article{Marchiori2008,
  langid = {english},
  title = {Predicting {{Human Interactive Learning}} by {{Regret}}-{{Driven Neural Networks}}},
  volume = {319},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1151185},
  doi = {10.1126/science.1151185},
  number = {5866},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2008-02-22},
  pages = {1111-1113},
  author = {Marchiori, D. and Warglien, M.},
  file = {/Users/qualia/Documents/Papers/2008 - Marchiori, Warglien - Predicting human interactive learning by regret-driven neural networks.pdf}
}

@article{Markowitz2008,
  langid = {english},
  title = {Rate-Specific Synchrony: {{Using}} Noisy Oscillations to Detect Equally Active Neurons},
  volume = {105},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0803183105},
  doi = {10.1073/pnas.0803183105},
  shorttitle = {Rate-Specific Synchrony},
  number = {24},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2008-06-17},
  pages = {8422-8427},
  author = {Markowitz, D. A. and Collman, F. and Brody, C. D. and Hopfield, J. J. and Tank, D. W.},
  file = {/Users/qualia/Documents/Papers/2008 - Markowitz et al. - Rate-specific synchrony using noisy oscillations to detect equally active neurons.pdf}
}

@article{Modolo2008,
  langid = {english},
  title = {Dynamics of the {{Subthalamo}}-Pallidal {{Complex}} in {{Parkinson}}'s {{Disease During Deep Brain Stimulation}}},
  volume = {34},
  issn = {0092-0606, 1573-0689},
  url = {http://link.springer.com/10.1007/s10867-008-9095-y},
  doi = {10.1007/s10867-008-9095-y},
  abstract = {The dynamics of the subthalamo-pallidal complex in Parkinson's disease during deep brain stimulation (DBS) were studied using two models, a simple firing-rate model and a population-based model. We extended the simple firing-rate model of the complex formed by the subthalamic nucleus (STN) and the external segment of the Globus Pallidus (GPe) to explore its dynamical regime during DBS. More specifically, the modulation of neuronal activity (i.e., pattern and amplitude) during DBS was studied. A similar approach was used with the population-based model. Simulation results revealed a gradual decrease in bursting activity in STN cells when the DBS frequency increased. In addition, the contribution of the stimulation current type (mono- or biphasic) to the results was also examined. A comparison of the two models indicated that the population-based model was more biologically realistic and more appropriate for exploring DBS mechanisms. Understanding the underlying mechanisms of DBS is a prerequisite for developing new stimulation protocols.},
  number = {3-4},
  journaltitle = {Journal of Biological Physics},
  urldate = {2019-03-30},
  date = {2008-08},
  pages = {251-266},
  author = {Modolo, J. and Henry, J. and Beuter, A.},
  file = {/Users/qualia/Documents/Papers/2008 - Modolo, Henry, Beuter - Dynamics of the subthalamo-pallidal complex in Parkinson's disease during deep brain stimulation.pdf}
}

@article{Moran2008,
  langid = {english},
  title = {Bayesian Estimation of Synaptic Physiology from the Spectral Responses of Neural Masses},
  volume = {42},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S105381190800027X},
  doi = {10.1016/j.neuroimage.2008.01.025},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2008-08},
  pages = {272-284},
  author = {Moran, R.J. and Stephan, K.E. and Kiebel, S.J. and Rombach, N. and O'Connor, W.T. and Murphy, K.J. and Reilly, R.B. and Friston, K.J.},
  file = {/Users/qualia/Documents/Papers/2008 - Moran et al. - Bayesian estimation of synaptic physiology from the spectral responses of neural masses.pdf}
}

@article{Moran2008a,
  langid = {english},
  title = {Subthalamic Nucleus Functional Organization Revealed by Parkinsonian Neuronal Oscillations and Synchrony},
  volume = {131},
  issn = {1460-2156, 0006-8950},
  url = {https://academic.oup.com/brain/article-lookup/doi/10.1093/brain/awn270},
  doi = {10.1093/brain/awn270},
  number = {12},
  journaltitle = {Brain},
  urldate = {2019-03-30},
  date = {2008-12},
  pages = {3395-3409},
  author = {Moran, A. and Bergman, H. and Israel, Z. and Bar-Gad, I.},
  file = {/Users/qualia/Documents/Papers/2008 - Moran et al. - Subthalamic nucleus functional organization revealed by parkinsonian neuronal oscillations and synchrony.pdf}
}

@article{Naud2008,
  langid = {english},
  title = {Firing Patterns in the Adaptive Exponential Integrate-and-Fire Model},
  volume = {99},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-008-0264-7},
  doi = {10.1007/s00422-008-0264-7},
  abstract = {For simulations of large spiking neuron networks, an accurate, simple and versatile single-neuron modeling framework is required. Here we explore the versatility of a simple two-equation model: the adaptive exponential integrate-and-fire neuron. We show that this model generates multiple firing patterns depending on the choice of parameter values, and present a phase diagram describing the transition from one firing type to another. We give an analytical criterion to distinguish between continuous adaption, initial bursting, regular bursting and two types of tonic spiking. Also, we report that the deterministic model is capable of producing irregular spiking when stimulated with constant current, indicating low-dimensional chaos. Lastly, the simple model is fitted to real experiments of cortical neurons under step current stimulation. The results provide support for the suitability of simple models such as the adaptive exponential integrate-and-fire neuron for large network simulations.},
  number = {4-5},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2008-11},
  pages = {335-347},
  author = {Naud, Richard and Marcille, Nicolas and Clopath, Claudia and Gerstner, Wulfram},
  file = {/Users/qualia/Documents/Papers/2008 - Naud et al. - Firing patterns in the adaptive exponential integrate-and-fire model.pdf}
}

@article{Ngamga2007,
  langid = {english},
  title = {Recurrence Analysis of Strange Nonchaotic Dynamics},
  volume = {75},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.75.036222},
  doi = {10.1103/PhysRevE.75.036222},
  number = {3},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2007-03-29},
  author = {Ngamga, E. J. and Nandi, A. and Ramaswamy, R. and Romano, M. C. and Thiel, M. and Kurths, J.},
  file = {/Users/qualia/Documents/Papers/2008 - Ngamga et al. - Recurrence analysis of strange nonchaotic dynamics in driven excitable systems.pdf}
}

@article{Panzeri2008,
  langid = {english},
  title = {On the Use of Information Theory for the Analysis of the Relationship between Neural and Imaging Signals},
  volume = {26},
  issn = {0730725X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0730725X08001033},
  doi = {10.1016/j.mri.2008.02.019},
  abstract = {Functional magnetic resonance imaging (fMRI) is a widely used method for studying the neural basis of cognition and of sensory function. A potential problem in the interpretation of fMRI data is that fMRI measures neural activity only indirectly, as a local change of deoxyhemoglobin concentration due to the metabolic demands of neural function. To build correct sensory and cognitive maps in the human brain, it is thus crucial to understand whether fMRI and neural activity convey the same type of information about external correlates. While a substantial experimental effort has been devoted to the simultaneous recordings of hemodynamic and neural signals, so far, the development of analysis methods that elucidate how neural and hemodynamic signals represent sensory information has received less attention. In this article, we critically review why the analytical framework of information theory, the mathematical theory of communication, is ideally suited to this purpose. We review the principles of information theory and explain how they could be applied to the analysis of fMRI and neural signals. We show that a critical advantage of information theory over more traditional analysis paradigms commonly used in the fMRI literature is that it can elucidate, within a single framework, whether an empirically observed correlation between neural and fMRI signals reflects either a similar stimulus tuning or a common source of variability unrelated to the external stimuli. In addition, information theory determines the extent to which these shared sources of stimulus signal and of variability lead fMRI and neural signals to convey similar information about external correlates. We then illustrate the formalism by applying it to the analysis of the information carried by different bands of the local field potential. We conclude by discussing the current methodological challenges that need to be addressed to make the information-theoretic approach more robustly applicable to the simultaneous recordings of neural and imaging data.},
  number = {7},
  journaltitle = {Magnetic Resonance Imaging},
  urldate = {2019-03-30},
  date = {2008-09},
  pages = {1015-1025},
  author = {Panzeri, Stefano and Magri, Cesare and Logothetis, Nikos K.},
  file = {/Users/qualia/Documents/Papers/2008 - Panzeri, Magri, Logothetis - On the use of information theory for the analysis of the relationship between neural and imaging sig.pdf}
}

@report{Pebay2008,
  langid = {english},
  title = {Formulas for Robust, One-Pass Parallel Computation of Covariances and Arbitrary-Order Statistical Moments.},
  url = {http://www.osti.gov/servlets/purl/1028931},
  abstract = {We present a formula for the pairwise update of arbitrary-order centered statistical moments. This formula is of particular interest to compute such moments in parallel for large-scale, distributed data sets. As a corollary, we indicate a specialization of this formula for incremental updates, of particular interest to streaming implementations. Finally, we provide pairwise and incremental update formulas for the covariance.},
  number = {SAND2008-6212, 1028931},
  urldate = {2019-03-30},
  date = {2008-09-01},
  author = {Pebay, Philippe Pierre},
  file = {/Users/qualia/Documents/Papers/2008 - Pébay - Formulas for Robust, One-Pass Parallel Computation of Covariances and Arbitrary-Order Statistical Moments.pdf},
  doi = {10.2172/1028931}
}

@article{Preston2008,
  langid = {english},
  title = {Multivoxel {{Pattern Selectivity}} for {{Perceptually Relevant Binocular Disparities}} in the {{Human Brain}}},
  volume = {28},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2728-08.2008},
  doi = {10.1523/JNEUROSCI.2728-08.2008},
  number = {44},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2008-10-29},
  pages = {11315-11327},
  author = {Preston, T. J. and Li, S. and Kourtzi, Z. and Welchman, A. E.},
  file = {/Users/qualia/Documents/Papers/2008 - Preston et al. - Multivoxel pattern selectivity for perceptually relevant binocular disparities in the human brain.pdf}
}

@article{Rutstrom2009,
  langid = {english},
  title = {Stated Beliefs versus Inferred Beliefs: {{A}} Methodological Inquiry and Experimental Test},
  volume = {67},
  issn = {08998256},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0899825609000591},
  doi = {10.1016/j.geb.2009.04.001},
  shorttitle = {Stated Beliefs versus Inferred Beliefs},
  abstract = {If asking subjects their beliefs during repeated game play changes the way those subjects play, using those stated beliefs to evaluate and compare theories of strategic behavior is problematic. We experimentally verify that belief elicitation can alter paths of play in a repeated asymmetric matching pennies game. In this setting, belief elicitation improves the goodness of fit of structural models of belief learning, and the prior beliefs implied by such structural models are both stronger and more realistic when beliefs are elicited than when they are not. These effects are, however, confined to the player type who sees a strong asymmetry between payoff possibilities for her two strategies in the game. We also find that ``inferred beliefs'' (beliefs estimated from past observed actions of opponents) can be better predictors of observed actions than the ``stated beliefs'' resulting from belief elicitation.},
  number = {2},
  journaltitle = {Games and Economic Behavior},
  urldate = {2019-03-30},
  date = {2009-11},
  pages = {616-632},
  author = {Rutstr\"om, E. Elisabet and Wilcox, Nathaniel T.},
  file = {/Users/qualia/Documents/Papers/2008 - Rutstrom, Wilcox - Stated Beliefs Versus Inferred Beliefs.pdf}
}

@article{Shattuck2008,
  langid = {english},
  title = {Construction of a {{3D}} Probabilistic Atlas of Human Cortical Structures},
  volume = {39},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811907008099},
  doi = {10.1016/j.neuroimage.2007.09.031},
  number = {3},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2008-02},
  pages = {1064-1080},
  author = {Shattuck, David W. and Mirza, Mubeena and Adisetiyo, Vitria and Hojatkashani, Cornelius and Salamon, Georges and Narr, Katherine L. and Poldrack, Russell A. and Bilder, Robert M. and Toga, Arthur W.},
  file = {/Users/qualia/Documents/Papers/2008 - Shattuck et al. - Construction of a 3D probabilistic atlas of human cortical structures.pdf}
}

@article{Soon2008,
  langid = {english},
  title = {Unconscious Determinants of Free Decisions in the Human Brain},
  volume = {11},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.2112},
  doi = {10.1038/nn.2112},
  number = {5},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2008-05},
  pages = {543-545},
  author = {Soon, Chun Siong and Brass, Marcel and Heinze, Hans-Jochen and Haynes, John-Dylan},
  file = {/Users/qualia/Documents/Papers/2008 - Soon et al. - Unconscious determinants of free decisions in the human brain.pdf}
}

@article{Stiefel2008,
  langid = {english},
  title = {Cholinergic {{Neuromodulation Changes Phase Response Curve Shape}} and {{Type}} in {{Cortical Pyramidal Neurons}}},
  volume = {3},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0003947},
  doi = {10.1371/journal.pone.0003947},
  abstract = {Spike generation in cortical neurons depends on the interplay between diverse intrinsic conductances. The phase response curve (PRC) is a measure of the spike time shift caused by perturbations of the membrane potential as a function of the phase of the spike cycle of a neuron. Near the rheobase, purely positive (type I) phase-response curves are associated with an onset of repetitive firing through a saddle-node bifurcation, whereas biphasic (type II) phase-response curves point towards a transition based on a Hopf-Andronov bifurcation. In recordings from layer 2/3 pyramidal neurons in cortical slices, cholinergic action, consistent with down-regulation of slow voltage-dependent potassium currents such as the M-current, switched the PRC from type II to type I. This is the first report showing that cholinergic neuromodulation may cause a qualitative switch in the PRCs type implying a change in the fundamental dynamical mechanism of spike generation.},
  number = {12},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2008-12-16},
  pages = {e3947},
  author = {Stiefel, Klaus M. and Gutkin, Boris S. and Sejnowski, Terrence J.},
  editor = {Ermentrout, Bard},
  file = {/Users/qualia/Documents/Papers/2008 - Stiefel, Gutkin, Sejnowski - Cholinergic neuromodulation changes phase response curve shape and type in cortical pyramidal neuron.pdf}
}

@article{Tiesinga2008,
  langid = {english},
  title = {Regulation of Spike Timing in Visual Cortical Circuits},
  volume = {9},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn2315},
  doi = {10.1038/nrn2315},
  abstract = {A train of action potentials (a spike train) can carry information in both the average firing rate and the pattern of spikes in the train. But can such a spike-pattern code be supported by cortical circuits? Neurons in vitro produce a spike pattern in response to the injection of a fluctuating current. However, cortical neurons in vivo are modulated by local oscillatory neuronal activity and by top-down inputs. In a cortical circuit, precise spike patterns thus reflect the interaction between internally generated activity and sensory information encoded by input spike trains. We review the evidence for precise and reliable spike timing in the cortex and discuss its computational role.},
  number = {2},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2008-02},
  pages = {97-107},
  author = {Tiesinga, Paul and Fellous, Jean-Marc and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/2008 - Tiesinga, Fellous, Sejnowski - Regulation of spike timing in visual cortical circuits.pdf}
}

@article{Touboul2008,
  langid = {english},
  title = {Bifurcation {{Analysis}} of a {{General Class}} of {{Nonlinear Integrate}}-and-{{Fire Neurons}}},
  volume = {68},
  issn = {0036-1399, 1095-712X},
  url = {http://epubs.siam.org/doi/10.1137/070687268},
  doi = {10.1137/070687268},
  abstract = {In this paper we define a class of formal neuron models being computationally efficient and biologically plausible, i.e., able to reproduce a wide range of behaviors observed in in vivo or in vitro recordings of cortical neurons. This class includes, for instance, two models widely used in computational neuroscience, the Izhikevich and the Brette\textendash{}Gerstner models. These models consist of a 4-parameter dynamical system. We provide the full local bifurcation diagram of the members of this class and show that they all present the same bifurcations: an Andronov\textendash{}Hopf bifurcation manifold, a saddle-node bifurcation manifold, a Bogdanov\textendash{}Takens bifurcation, and possibly a Bautin bifurcation, i.e., all codimension two local bifurcations in a two-dimensional phase space except the cusp. Among other global bifurcations, this system shows a saddle homoclinic bifurcation curve. We show how this bifurcation diagram generates the most prominent cortical neuron behaviors. This study leads us to introduce a new neuron model, the quartic model, able to reproduce among all the behaviors of the Izhikevich and Brette\textendash{}Gerstner models self-sustained subthreshold oscillations, which are of great interest in neuroscience.},
  number = {4},
  journaltitle = {SIAM Journal on Applied Mathematics},
  urldate = {2019-03-30},
  date = {2008-01},
  pages = {1045-1079},
  author = {Touboul, Jonathan},
  file = {/Users/qualia/Documents/Papers/2008 - Touboul - Bifurcation Analysis of a General Class of Nonlinear Integrate-and-Fire Neurons.pdf}
}

@article{Touboul2008a,
  langid = {english},
  title = {Dynamics and Bifurcations of the Adaptive Exponential Integrate-and-Fire Model},
  volume = {99},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-008-0267-4},
  doi = {10.1007/s00422-008-0267-4},
  abstract = {Recently, several two-dimensional spiking neuron models have been introduced, with the aim of reproducing the diversity of electrophysiological features displayed by real neurons while keeping a simple model, for simulation and analysis purposes. Among these models, the adaptive integrate-and-fire model is physiologically relevant in that its parameters can be easily related to physiological quantities. The interaction of the differential equations with the reset results in a rich and complex dynamical structure. We relate the subthreshold features of the model to the dynamical properties of the differential system and the spike patterns to the properties of a Poincare\textasciiacute{} map defined by the sequence of spikes. We find a complex bifurcation structure which has a direct interpretation in terms of spike trains. For some parameter values, spike patterns are chaotic.},
  number = {4-5},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2008-11},
  pages = {319-334},
  author = {Touboul, Jonathan and Brette, Romain},
  file = {/Users/qualia/Documents/Papers/2008 - Touboul, Brette - Dynamics and bifurcations of the adaptive exponential integrate-and-fire model.pdf}
}

@article{Uhlhaas2008,
  langid = {english},
  title = {The {{Role}} of {{Oscillations}} and {{Synchrony}} in {{Cortical Networks}} and {{Their Putative Relevance}} for the {{Pathophysiology}} of {{Schizophrenia}}},
  volume = {34},
  issn = {0586-7614, 1745-1701},
  url = {https://academic.oup.com/schizophreniabulletin/article-lookup/doi/10.1093/schbul/sbn062},
  doi = {10.1093/schbul/sbn062},
  number = {5},
  journaltitle = {Schizophrenia Bulletin},
  urldate = {2019-03-30},
  date = {2008-07-21},
  pages = {927-943},
  author = {Uhlhaas, P. J. and Haenschel, C. and Nikolic, D. and Singer, W.},
  file = {/Users/qualia/Documents/Papers/2008 - Uhlhaas et al. - The role of oscillations and synchrony in cortical networks and their putative relevance for the pathophysiology.pdf}
}

@article{vanDijk2008,
  langid = {english},
  title = {Prestimulus {{Oscillatory Activity}} in the {{Alpha Band Predicts Visual Discrimination Ability}}},
  volume = {28},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1853-07.2008},
  doi = {10.1523/JNEUROSCI.1853-07.2008},
  number = {8},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2008-02-20},
  pages = {1816-1823},
  author = {van Dijk, H. and Schoffelen, J.-M. and Oostenveld, R. and Jensen, O.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2008 - Van Dijk et al. - Prestimulus Oscillatory Activity in the Alpha Band Predicts Visual Discrimination Ability.pdf}
}

@article{Vicente2008,
  langid = {english},
  title = {Dynamical Relaying Can Yield Zero Time Lag Neuronal Synchrony despite Long Conduction Delays},
  volume = {105},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0809353105},
  doi = {10.1073/pnas.0809353105},
  number = {44},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2008-11-04},
  pages = {17157-17162},
  author = {Vicente, R. and Gollo, L. L. and Mirasso, C. R. and Fischer, I. and Pipa, G.},
  file = {/Users/qualia/Documents/Papers/2008 - Vicente et al. - Dynamical relaying can yield zero time lag neuronal synchrony despite long conduction delays.pdf}
}

@article{Vul2008,
  langid = {english},
  title = {Measuring the {{Crowd Within}}: {{Probabilistic Representations Within Individuals}}},
  volume = {19},
  issn = {0956-7976, 1467-9280},
  url = {http://journals.sagepub.com/doi/10.1111/j.1467-9280.2008.02136.x},
  doi = {10.1111/j.1467-9280.2008.02136.x},
  shorttitle = {Measuring the {{Crowd Within}}},
  number = {7},
  journaltitle = {Psychological Science},
  urldate = {2019-03-30},
  date = {2008-07},
  pages = {645-647},
  author = {Vul, Edward and Pashler, Harold},
  file = {/Users/qualia/Documents/Papers/2008 - Vul, Pashler - Measuring the crowd within probabilistic representations within individuals.pdf}
}

@article{Yoon2008,
  langid = {english},
  title = {Multivariate {{Pattern Analysis}} of {{Functional Magnetic Resonance Imaging Data Reveals Deficits}} in {{Distributed Representations}} in {{Schizophrenia}}},
  volume = {64},
  issn = {00063223},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0006322308008998},
  doi = {10.1016/j.biopsych.2008.07.025},
  abstract = {Background: Multivariate pattern analysis is an alternative method of analyzing functional magnetic resonance imaging (fMRI) data, which is capable of decoding distributed neural representations. We applied this method to test the hypothesis of the impairment in distributed representations in schizophrenia. We also compared the results of this method with traditional general linear model (GLM)-based univariate analysis.
Methods: Nineteen schizophrenia and 15 control subjects viewed two runs of stimuli\textemdash{} exemplars of faces, scenes, objects, and scrambled images. To verify engagement with stimuli, subjects completed a 1-back matching task. A multivoxel pattern classifier was trained to identify category-specific activity patterns on one run of fMRI data. Classification testing was conducted on the remaining run. Correlation of voxelwise activity across runs evaluated variance over time in activity patterns.
Results: Patients performed the task less accurately. This group difference was reflected in the pattern analysis results with diminished classification accuracy in patients compared with control subjects, 59\% and 72\%, respectively. In contrast, there was no group difference in GLM-based univariate measures. In both groups, classification accuracy was significantly correlated with behavioral measures. Both groups showed highly significant correlation between interrun correlations and classification accuracy.
Conclusions: Distributed representations of visual objects are impaired in schizophrenia. This impairment is correlated with diminished task performance, suggesting that decreased integrity of cortical activity patterns is reflected in impaired behavior. Comparisons with univariate results suggest greater sensitivity of pattern analysis in detecting group differences in neural activity and reduced likelihood of nonspecific factors driving these results.},
  number = {12},
  journaltitle = {Biological Psychiatry},
  urldate = {2019-03-30},
  date = {2008-12},
  pages = {1035-1041},
  author = {Yoon, Jong H. and Tamir, Diana and Minzenberg, Michael J. and Ragland, J. Daniel and Ursu, Stefan and Carter, Cameron S.},
  file = {/Users/qualia/Documents/Papers/2008 - Yoon et al. - Multivariate pattern analysis of functional magnetic resonance imaging data reveals deficits in distributed represe.pdf}
}

@article{Yuval-Greenberg2008,
  langid = {english},
  title = {Transient {{Induced Gamma}}-{{Band Response}} in {{EEG}} as a {{Manifestation}} of {{Miniature Saccades}}},
  volume = {58},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627308003012},
  doi = {10.1016/j.neuron.2008.03.027},
  abstract = {The induced gamma-band EEG response (iGBR) recorded on the scalp is widely assumed to reflect synchronous neural oscillation associated with object representation, attention, memory, and consciousness. The most commonly reported EEG iGBR is a broadband transient increase in power at the gamma range \$200\textendash{}300 ms following stimulus onset. A conspicuous feature of this iGBR is the trial-to-trial poststimulus latency variability, which has been insufficiently addressed. Here, we show, using singletrial analysis of concomitant EEG and eye tracking, that this iGBR is tightly time locked to the onset of involuntary miniature eye movements and reflects a saccadic ``spike potential.'' The time course of the iGBR is related to an increase in the rate of saccades following a period of poststimulus saccadic inhibition. Thus, whereas neuronal gamma-band oscillations were shown conclusively with other methods, the broadband transient iGBR recorded by scalp EEG reflects properties of miniature saccade dynamics rather than neuronal oscillations.},
  number = {3},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2008-05},
  pages = {429-441},
  author = {Yuval-Greenberg, Shlomit and Tomer, Orr and Keren, Alon S. and Nelken, Israel and Deouell, Leon Y.},
  file = {/Users/qualia/Documents/Papers/2008 - Yuval-Greenberg et al. - Transient Induced Gamma-Band Response in EEG as a Manifestation of Miniature Saccades.pdf}
}

@article{Abdi2009,
  langid = {english},
  title = {How to Compute Reliability Estimates and Display Confidence and Tolerance Intervals for Pattern Classifiers Using the {{Bootstrap}} and 3-Way Multidimensional Scaling ({{DISTATIS}})},
  volume = {45},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811908012081},
  doi = {10.1016/j.neuroimage.2008.11.008},
  abstract = {When used to analyze brain imaging data, pattern classifiers typically produce results that can be interpreted as a measure of discriminability or as a distance between some experimental categories. These results can be analyzed with techniques such as multidimensional scaling (MDS), which represent the experimental categories as points on a map. While such a map reveals the configuration of the categories, it does not provide a reliability estimate of the position of the experimental categories, and therefore cannot be used for inferential purposes. In this paper, we present a procedure that provides reliability estimates for pattern classifiers. This procedure combines bootstrap estimation (to estimate the variability of the experimental conditions) and a new 3-way extension of MDS, called DISTATIS, that can be used to integrate the distance matrices generated by the bootstrap procedure and to represent the results as MDS-like maps. Reliability estimates are expressed as (1) tolerance intervals which reflect the accuracy of the assignment of scans to experimental categories and as (2) confidence intervals which generalize standard hypothesis testing. When more than two categories are involved in the application of a pattern classifier, the use of confidence intervals for null hypothesis testing inflates Type I error. We address this problem with a Bonferonni-like correction. Our methodology is illustrated with the results of a pattern classifier described by O'Toole et al. (O'Toole, A., Jiang, F., Abdi, H., Haxby, J., 2005. Partially distributed representations of objects and faces in ventral temporal cortex. J. Cogn. Neurosci. 17, 580\textendash{}590) who re-analyzed data originally collected by Haxby et al. (Haxby, J., Gobbini, M., Furey, M., Ishai, A., Schouten, J., Pietrini, P., 2001. Distributed and overlapping representation of faces and objects in ventral temporal cortex. Science 293, 2425\textendash{}2430).},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2009-03},
  pages = {89-95},
  author = {Abdi, Herv\'e and Dunlop, Joseph P. and Williams, Lynne J.},
  file = {/Users/qualia/Documents/Papers/2009 - Abdi, Dunlop, Williams - How to compute reliability estimates and display confidence and tolerance intervals for pattern classifi.pdf}
}

@article{Arbesman2009,
  langid = {english},
  title = {Superlinear Scaling for Innovation in Cities},
  volume = {79},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.79.016115},
  doi = {10.1103/PhysRevE.79.016115},
  number = {1},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2009-01-30},
  author = {Arbesman, Samuel and Kleinberg, Jon M. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/2009 - Arbesman, Kleinberg, Strogatz - Superlinear scaling for innovation in cities.pdf}
}

@article{Atallah2009,
  langid = {english},
  title = {Instantaneous {{Modulation}} of {{Gamma Oscillation Frequency}} by {{Balancing Excitation}} with {{Inhibition}}},
  volume = {62},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309003511},
  doi = {10.1016/j.neuron.2009.04.027},
  abstract = {Neurons recruited for local computations exhibit rhythmic activity at gamma frequencies. The amplitude and frequency of these oscillations are continuously modulated depending on stimulus and behavioral state. This modulation is believed to crucially control information flow across cortical areas. Here we report that in the rat hippocampus gamma oscillation amplitude and frequency vary rapidly, from one cycle to the next. Strikingly, the amplitude of one oscillation predicts the interval to the next. Using in vivo and in vitro whole-cell recordings, we identify the underlying mechanism. We show that cycle-bycycle fluctuations in amplitude reflect changes in synaptic excitation spanning over an order of magnitude. Despite these rapid variations, synaptic excitation is immediately and proportionally counterbalanced by inhibition. These rapid adjustments in inhibition instantaneously modulate oscillation frequency. So, by rapidly balancing excitation with inhibition, the hippocampal network is able to swiftly modulate gamma oscillations over a wide band of frequencies.},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2009-05},
  pages = {566-577},
  author = {Atallah, Bassam V. and Scanziani, Massimo},
  file = {/Users/qualia/Documents/Papers/2009 - Atallah, Scanziani - Instantaneous Modulation of Gamma Oscillation Frequency by Balancing Excitation with Inhibition.pdf}
}

@article{Benaim2009,
  langid = {english},
  title = {Learning in Games with Unstable Equilibria},
  volume = {144},
  issn = {00220531},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022053108001324},
  doi = {10.1016/j.jet.2008.09.003},
  abstract = {We propose a new concept for the analysis of games, the TASP, which gives a precise prediction about non-equilibrium play in games whose Nash equilibria are mixed and are unstable under fictitious play-like learning processes. We show that, when players learn using weighted stochastic fictitious play and so place greater weight on more recent experience, the time average of play often converges in these ``unstable'' games, even while mixed strategies and beliefs continue to cycle. This time average, the TASP, is related to the best response cycle first identified by Shapley (1964). Though conceptually distinct from Nash equilibrium, for many games the TASP is close enough to Nash to create the appearance of convergence to equilibrium. We discuss how these theoretical results may help to explain data from recent experimental studies of price dispersion.},
  number = {4},
  journaltitle = {Journal of Economic Theory},
  urldate = {2019-03-30},
  date = {2009-07},
  pages = {1694-1709},
  author = {Bena\"im, Michel and Hofbauer, Josef and Hopkins, Ed},
  file = {/Users/qualia/Documents/Papers/2009 - Benaïm, Hofbauer, Hopkins - Learning in games with unstable equilibria.pdf}
}

@article{Bengio2009,
  langid = {english},
  title = {Learning {{Deep Architectures}} for {{AI}}},
  volume = {2},
  issn = {1935-8237, 1935-8245},
  url = {http://www.nowpublishers.com/article/Details/MAL-006},
  doi = {10.1561/2200000006},
  abstract = {Theoretical results suggest that in order to learn the kind of complicated functions that can represent highlevel abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This paper discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.},
  number = {1},
  journaltitle = {Foundations and Trends\textregistered{} in Machine Learning},
  urldate = {2019-03-30},
  date = {2009},
  pages = {1-127},
  author = {Bengio, Y.},
  file = {/Users/qualia/Documents/Papers/2009 - Bengio - Learning Deep Architectures for AI.pdf}
}

@article{Binzegger2009,
  langid = {english},
  title = {Topology and Dynamics of the Canonical Circuit of Cat {{V1}}},
  volume = {22},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608009001683},
  doi = {10.1016/j.neunet.2009.07.011},
  abstract = {The neocortex is a major component of the most sophisticated and economically significant computer in existence, nevertheless the organisation and operation of its computational circuit is not yet understood. Here we make some steps toward relating anatomical structure to computational function. We use methods of quantitative neuroanatomy to estimate the cortical circuit by defining the projection matrix between the various cells types of the neocortex of the cat, and then we consider the implications of this connectivity for cortical signal processing. Our analyses show that for a reasonable choice of the ratio between excitatory and inhibitory efficacy, the overall cortical circuit lies near the border of dynamical stability. We discuss a model of co-operative competitive processing that is consistent with the observed connectivity in the superficial layers of the cortex, and consider also how the topology of the overall cortical circuit could be configured dynamically through average inhibition.},
  number = {8},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2009-10},
  pages = {1071-1078},
  author = {Binzegger, T. and Douglas, R.J. and Martin, K.A.C.},
  file = {/Users/qualia/Documents/Papers/2009 - Binzegger, Douglas, Martin - Topology and dynamics of the canonical circuit of cat V1.pdf}
}

@article{Buonomano2009,
  langid = {english},
  title = {Harnessing {{Chaos}} in {{Recurrent Neural Networks}}},
  volume = {63},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309005881},
  doi = {10.1016/j.neuron.2009.08.003},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2009-08},
  pages = {423-425},
  author = {Buonomano, Dean V.},
  file = {/Users/qualia/Documents/Papers/2009 - Buonomano - Harnessing Chaos in Recurrent Neural Networks.pdf}
}

@article{Carvalho2009,
  langid = {english},
  title = {Differential {{Effects}} of {{Excitatory}} and {{Inhibitory Plasticity}} on {{Synaptically Driven Neuronal Input}}-{{Output Functions}}},
  volume = {61},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309000804},
  doi = {10.1016/j.neuron.2009.01.013},
  abstract = {Ultimately, whether or not a neuron produces a spike determines its contribution to local computations. In response to brief stimuli the probability a neuron will fire can be described by its input-output function, which depends on the net balance and timing of excitatory and inhibitory currents. While excitatory and inhibitory synapses are plastic, most studies examine plasticity of subthreshold events. Thus, the effects of concerted regulation of excitatory and inhibitory synaptic strength on neuronal inputoutput functions are not well understood. Here, theoretical analyses reveal that excitatory synaptic strength controls the threshold of the neuronal input-output function, while inhibitory plasticity alters the threshold and gain. Experimentally, changes in the balance of excitation and inhibition in CA1 pyramidal neurons also altered their inputoutput function as predicted by the model. These results support the existence of two functional modes of plasticity that can be used to optimize information processing: threshold and gain plasticity.},
  number = {5},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2009-03},
  pages = {774-785},
  author = {Carvalho, Tiago P. and Buonomano, Dean V.},
  file = {/Users/qualia/Documents/Papers/2009 - Carvalho, Buonomano - Differential Effects of Excitatory and Inhibitory Plasticity on Synaptically Driven Neuronal Input-Output F.pdf}
}

@article{Cisek2009,
  langid = {english},
  title = {Decisions in {{Changing Conditions}}: {{The Urgency}}-{{Gating Model}}},
  volume = {29},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1844-09.2009},
  doi = {10.1523/JNEUROSCI.1844-09.2009},
  shorttitle = {Decisions in {{Changing Conditions}}},
  number = {37},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2009-09-16},
  pages = {11560-11571},
  author = {Cisek, P. and Puskas, G. A. and El-Murr, S.},
  file = {/Users/qualia/Documents/Papers/2009 - Cisek, Puskas, El-Murr - Decisions in changing conditions the urgency-gating model.pdf}
}

@article{Conroy,
  langid = {english},
  title = {{{fMRI}}-{{Based Inter}}-{{Subject Cortical Alignment Using Functional Connectivity}}},
  abstract = {The inter-subject alignment of functional MRI (fMRI) data is important for improving the statistical power of fMRI group analyses. In contrast to existing anatomically-based methods, we propose a novel multi-subject algorithm that derives a functional correspondence by aligning spatial patterns of functional connectivity across a set of subjects. We test our method on fMRI data collected during a movie viewing experiment. By cross-validating the results of our algorithm, we show that the correspondence successfully generalizes to a secondary movie dataset not used to derive the alignment.},
  pages = {9},
  author = {Conroy, Bryan R and Singer, Benjamin D and Haxby, James V and Ramadge, Peter J},
  file = {/Users/qualia/Documents/Papers/2009 - Conroy, Singer - fMRI-based inter-subject cortical alignment using functional connectivity.pdf}
}

@article{Ethofer2009,
  langid = {english},
  title = {Decoding of {{Emotional Information}} in {{Voice}}-{{Sensitive Cortices}}},
  volume = {19},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982209010537},
  doi = {10.1016/j.cub.2009.04.054},
  abstract = {The ability to correctly interpret emotional signals from others is crucial for successful social interaction. Previous neuroimaging studies showed that voice-sensitive auditory areas [1\textendash{}3] activate to a broad spectrum of vocally expressed emotions more than to neutral speech melody (prosody). However, this enhanced response occurs irrespective of the specific emotion category, making it impossible to distinguish different vocal emotions with conventional analyses [4\textendash{}8]. Here, we presented pseudowords spoken in five prosodic categories (anger, sadness, neutral, relief, joy) during event-related functional magnetic resonance imaging (fMRI), then employed multivariate pattern analysis [9, 10] to discriminate between these categories on the basis of the spatial response pattern within the auditory cortex. Our results demonstrate successful decoding of vocal emotions from fMRI responses in bilateral voicesensitive areas, which could not be obtained by using averaged response amplitudes only. Pairwise comparisons showed that each category could be classified against all other alternatives, indicating for each emotion a specific spatial signature that generalized across speakers. These results demonstrate for the first time that emotional information is represented by distinct spatial patterns that can be decoded from brain activity in modality-specific cortical areas.},
  number = {12},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2009-06},
  pages = {1028-1033},
  author = {Ethofer, Thomas and Van De Ville, Dimitri and Scherer, Klaus and Vuilleumier, Patrik},
  file = {/Users/qualia/Documents/Papers/2009 - Ethofer et al. - Decoding of emotional information in voice-sensitive cortices.pdf}
}

@article{Globerson2009,
  langid = {english},
  title = {The Minimum Information Principle and Its Application to Neural Code Analysis},
  volume = {106},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0806782106},
  doi = {10.1073/pnas.0806782106},
  number = {9},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2009-03-03},
  pages = {3490-3495},
  author = {Globerson, A. and Stark, E. and Vaadia, E. and Tishby, N.},
  file = {/Users/qualia/Documents/Papers/2009 - Globerson et al. - The minimum information principle and its application to neural code analysis.pdf}
}

@article{Hassabis2009,
  langid = {english},
  title = {Decoding {{Neuronal Ensembles}} in the {{Human Hippocampus}}},
  volume = {19},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982209007416},
  doi = {10.1016/j.cub.2009.02.033},
  abstract = {Background: The hippocampus underpins our ability to navigate, to form and recollect memories, and to imagine future experiences. How activity across millions of hippocampal neurons supports these functions is a fundamental question in neuroscience, wherein the size, sparseness, and organization of the hippocampal neural code are debated.
Results: Here, by using multivariate pattern classification and high spatial resolution functional MRI, we decoded activity across the population of neurons in the human medial temporal lobe while participants navigated in a virtual reality environment. Remarkably, we could accurately predict the position of an individual within this environment solely from the pattern of activity in his hippocampus even when visual input and task were held constant. Moreover, we observed a dissociation between responses in the hippocampus and parahippocampal gyrus, suggesting that they play differing roles in navigation.
Conclusions: These results show that highly abstracted representations of space are expressed in the human hippocampus. Furthermore, our findings have implications for understanding the hippocampal population code and suggest that, contrary to current consensus, neuronal ensembles representing place memories must be large and have an anisotropic structure.},
  number = {7},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2009-04},
  pages = {546-554},
  author = {Hassabis, Demis and Chu, Carlton and Rees, Geraint and Weiskopf, Nikolaus and Molyneux, Peter D. and Maguire, Eleanor A.},
  file = {/Users/qualia/Documents/Papers/2009 - Hassabis et al. - Decoding neuronal ensembles in the human hippocampus.pdf}
}

@article{Humphries2009,
  langid = {english},
  title = {Dopamine-Modulated Dynamic Cell Assemblies Generated by the {{GABAergic}} Striatal Microcircuit},
  volume = {22},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608009001646},
  doi = {10.1016/j.neunet.2009.07.018},
  abstract = {The striatum, the principal input structure of the basal ganglia, is crucial to both motor control and learning. It receives convergent input from all over the neocortex, hippocampal formation, amygdala and thalamus, and is the primary recipient of dopamine in the brain. Within the striatum is a GABAergic microcircuit that acts upon these inputs, formed by the dominant medium-spiny projection neurons (MSNs) and fast-spiking interneurons (FSIs). There has been little progress in understanding the computations it performs, hampered by the non-laminar structure that prevents identification of a repeating canonical microcircuit. We here begin the identification of potential dynamically-defined computational elements within the striatum. We construct a new three-dimensional model of the striatal microcircuit's connectivity, and instantiate this with our dopamine-modulated neuron models of the MSNs and FSIs. A new model of gap junctions between the FSIs is introduced and tuned to experimental data. We introduce a novel multiple spike-train analysis method, and apply this to the outputs of the model to find groups of synchronised neurons at multiple time-scales. We find that, with realistic in vivo background input, small assemblies of synchronised MSNs spontaneously appear, consistent with experimental observations, and that the number of assemblies and the time-scale of synchronisation is strongly dependent on the simulated concentration of dopamine. We also show that feed-forward inhibition from the FSIs counter-intuitively increases the firing rate of the MSNs. Such small cell assemblies forming spontaneously only in the absence of dopamine may contribute to motor control problems seen in humans and animals following a loss of dopamine cells.},
  number = {8},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2009-10},
  pages = {1174-1188},
  author = {Humphries, Mark D. and Wood, Ric and Gurney, Kevin},
  file = {/Users/qualia/Documents/Papers/2009 - Humphries, Wood, Gurney - Dopamine-modulated dynamic cell assemblies generated by the GABAergic striatal microcircuit.pdf}
}

@article{Huys2009,
  langid = {english},
  title = {Smoothing of, and {{Parameter Estimation}} from, {{Noisy Biophysical Recordings}}},
  volume = {5},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1000379},
  doi = {10.1371/journal.pcbi.1000379},
  abstract = {Biophysically detailed models of single cells are difficult to fit to real data. Recent advances in imaging techniques allow simultaneous access to various intracellular variables, and these data can be used to significantly facilitate the modelling task. These data, however, are noisy, and current approaches to building biophysically detailed models are not designed to deal with this. We extend previous techniques to take the noisy nature of the measurements into account. Sequential Monte Carlo (``particle filtering'') methods, in combination with a detailed biophysical description of a cell, are used for principled, model-based smoothing of noisy recording data. We also provide an alternative formulation of smoothing where the neural nonlinearities are estimated in a non-parametric manner. Biophysically important parameters of detailed models (such as channel densities, intercompartmental conductances, input resistances, and observation noise) are inferred automatically from noisy data via expectation-maximisation. Overall, we find that model-based smoothing is a powerful, robust technique for smoothing of noisy biophysical data and for inference of biophysical parameters in the face of recording noise.},
  number = {5},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2009-05-08},
  pages = {e1000379},
  author = {Huys, Quentin J. M. and Paninski, Liam},
  editor = {Friston, Karl J.},
  file = {/Users/qualia/Documents/Papers/2009 - Huys, Paninski - Smoothing of, and parameter estimation from, noisy biophysical recordings.pdf}
}

@article{Itti2009,
  langid = {english},
  title = {Bayesian Surprise Attracts Human Attention},
  volume = {49},
  issn = {00426989},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698908004380},
  doi = {10.1016/j.visres.2008.09.007},
  abstract = {We propose a formal Bayesian definition of surprise to capture subjective aspects of sensory information. Surprise measures how data affects an observer, in terms of differences between posterior and prior beliefs about the world. Only data observations which substantially affect the observer's beliefs yield surprise, irrespectively of how rare or informative in Shannon's sense these observations are. We test the framework by quantifying the extent to which humans may orient attention and gaze towards surprising events or items while watching television. To this end, we implement a simple computational model where a low-level, sensory form of surprise is computed by simple simulated early visual neurons. Bayesian surprise is a strong attractor of human attention, with 72\% of all gaze shifts directed towards locations more surprising than the average, a figure rising to 84\% when focusing the analysis onto regions simultaneously selected by all observers. The proposed theory of surprise is applicable across different spatiotemporal scales, modalities, and levels of abstraction.},
  number = {10},
  journaltitle = {Vision Research},
  urldate = {2019-03-30},
  date = {2009-06},
  pages = {1295-1306},
  author = {Itti, Laurent and Baldi, Pierre},
  file = {/Users/qualia/Documents/Papers/2009 - Itti, Baldi - Bayesian surprise attracts human attention.pdf}
}

@article{Jakel2009,
  langid = {english},
  title = {Does {{Cognitive Science Need Kernels}}?},
  volume = {13},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661309001430},
  doi = {10.1016/j.tics.2009.06.002},
  number = {9},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2009-09},
  pages = {381-388},
  author = {J\"akel, Frank and Sch\"olkopf, Bernhard and Wichmann, Felix A.},
  file = {/Users/qualia/Documents/Papers/2009 - Jäkel, Schölkopf, Wichmann - Does cognitive science need kernels.pdf}
}

@article{Jastorff2009,
  langid = {english},
  title = {Visual {{Learning Shapes}} the {{Processing}} of {{Complex Movement Stimuli}} in the {{Human Brain}}},
  volume = {29},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3070-09.2009},
  doi = {10.1523/JNEUROSCI.3070-09.2009},
  number = {44},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2009-11-04},
  pages = {14026-14038},
  author = {Jastorff, J. and Kourtzi, Z. and Giese, M. A.},
  file = {/Users/qualia/Documents/Papers/2009 - Jastorff, Kourtzi, Giese - Visual learning shapes the processing of complex movement stimuli in the human brain.pdf}
}

@article{Kao2009,
  langid = {english},
  title = {Multi-{{Objective Optimal Experimental Designs}} for {{ER}}-{{fMRI Using}} {{{\emph{MATLAB}}}}},
  volume = {30},
  issn = {1548-7660},
  url = {http://www.jstatsoft.org/v30/i11/},
  doi = {10.18637/jss.v030.i11},
  abstract = {Designs for event-related functional magnetic resonance imaging (ER-fMRI) that help to efficiently achieve the statistical goals while taking into account the psychological constraints and customized requirements are in great demand. This is not only because of the popularity of ER-fMRI but also because of the high cost of ER-fMRI experiments; being able to collect highly informative data is crucial. In this paper, we develop a MATLAB program which can accommodate many user-specified experimental conditions to efficiently find ER-fMRI optimal designs.},
  number = {11},
  journaltitle = {Journal of Statistical Software},
  urldate = {2019-03-30},
  date = {2009},
  author = {Kao, Ming-Hung},
  file = {/Users/qualia/Documents/Papers/2009 - Kao - Multi-Objective Optimal Experimental Designs for.pdf}
}

@article{Lehnertz2009,
  langid = {english},
  title = {Synchronization Phenomena in Human Epileptic Brain Networks},
  volume = {183},
  issn = {01650270},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S016502700900274X},
  doi = {10.1016/j.jneumeth.2009.05.015},
  abstract = {Epilepsy is a malfunction of the brain that affects over 50 million people worldwide. Epileptic seizures are usually characterized by an abnormal synchronized firing of neurons involved in the epileptic process. In human epilepsy the exact mechanisms underlying seizure generation are still uncertain as are mechanisms underlying seizure spreading and termination. There is now growing evidence that an improved understanding of the epileptic process can be achieved through the analysis of properties of epileptic brain networks and through the analysis of interactions in such networks. In this overview, we summarize recent methodological developments to assess synchronization phenomena in human epileptic brain networks and present findings obtained from analyses of brain electromagnetic signals recorded in epilepsy patients.},
  number = {1},
  journaltitle = {Journal of Neuroscience Methods},
  urldate = {2019-03-30},
  date = {2009-09},
  pages = {42-48},
  author = {Lehnertz, Klaus and Bialonski, Stephan and Horstmann, Marie-Therese and Krug, Dieter and Rothkegel, Alexander and Staniek, Matth\"aus and Wagner, Tobias},
  file = {/Users/qualia/Documents/Papers/2009 - Lehnertz et al. - Synchronization phenomena in human epileptic brain networks.pdf}
}

@article{Li2009,
  langid = {english},
  title = {Learning {{Shapes}} the {{Representation}} of {{Behavioral Choice}} in the {{Human Brain}}},
  volume = {62},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309002396},
  doi = {10.1016/j.neuron.2009.03.016},
  abstract = {Making successful decisions under uncertainty due to noisy sensory signals is thought to benefit from previous experience. However, the human brain mechanisms that mediate flexible decisions through learning remain largely unknown. Comparing behavioral choices of human observers with those of a pattern classifier based on multivoxel single-trial fMRI signals, we show that category learning shapes processes related to decision variables in frontal and higher occipitotemporal regions rather than signal detection or response execution in primary visual or motor areas. In particular, fMRI signals in prefrontal regions reflect the observers' behavioral choice according to the learned decision criterion only in the context of the categorization task. In contrast, higher occipitotemporal areas show learning-dependent changes in the representation of perceived categories that are sustained after training independent of the task. These findings demonstrate that learning shapes selective representations of sensory readout signals in accordance with the decision criterion to support flexible decisions.},
  number = {3},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2009-05},
  pages = {441-452},
  author = {Li, Sheng and Mayhew, Stephen D. and Kourtzi, Zoe},
  file = {/Users/qualia/Documents/Papers/2009 - Li, Mayhew, Kourtzi - Learning shapes the representation of behavioral choice in the human brain.pdf}
}

@article{Liu2009,
  langid = {english},
  title = {Embedding {{Multiple Trajectories}} in {{Simulated Recurrent Neural Networks}} in a {{Self}}-{{Organizing Manner}}},
  volume = {29},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2358-09.2009},
  doi = {10.1523/JNEUROSCI.2358-09.2009},
  number = {42},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2009-10-21},
  pages = {13172-13181},
  author = {Liu, J. K. and Buonomano, D. V.},
  file = {/Users/qualia/Documents/Papers/2009 - Liu, Buonomano - Embedding Multiple Trajectories in Simulated Recurrent Neural Networks in a Self-Organizing Manner.pdf}
}

@article{Luczak2009,
  langid = {english},
  title = {Spontaneous {{Events Outline}} the {{Realm}} of {{Possible Sensory Responses}} in {{Neocortical Populations}}},
  volume = {62},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309002372},
  doi = {10.1016/j.neuron.2009.03.014},
  abstract = {Neocortical assemblies produce complex activity patterns both in response to sensory stimuli and spontaneously without sensory input. To investigate the structure of these patterns, we recorded from populations of 40\textendash{}100 neurons in auditory and somatosensory cortices of anesthetized and awake rats using silicon microelectrodes. Population spike time patterns were broadly conserved across multiple sensory stimuli and spontaneous events. Although individual neurons showed timing variations between stimuli, these were not sufficient to disturb a generally conserved sequential organization observed at the population level, lasting for approximately 100 ms with spiking reliability decaying progressively after event onset. Preserved constraints were also seen in population firing rate vectors, with vectors evoked by individual stimuli occupying subspaces of a larger but still constrained space outlined by the set of spontaneous events. These results suggest that population spike patterns are drawn from a limited ``vocabulary,'' sampled widely by spontaneous events but more narrowly by sensory responses.},
  number = {3},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2009-05},
  pages = {413-425},
  author = {Luczak, Artur and Barth\'o, Peter and Harris, Kenneth D.},
  file = {/Users/qualia/Documents/Papers/2009 - Luczak, Barth, Harris - Spontaneous Events Outline the Realm of Possible Sensory Responses in Neocortical Populations.pdf}
}

@article{Maimon2009,
  langid = {english},
  title = {Beyond {{Poisson}}: {{Increased Spike}}-{{Time Regularity}} across {{Primate Parietal Cortex}}},
  volume = {62},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309002463},
  doi = {10.1016/j.neuron.2009.03.021},
  shorttitle = {Beyond {{Poisson}}},
  abstract = {Cortical areas differ in their patterns of connectivity, cellular composition, and functional architecture. Spike trains, on the other hand, are commonly assumed to follow similarly irregular dynamics across neocortex. We examined spike-time statistics in four parietal areas using a method that accounts for nonstationarities in firing rate. We found that, whereas neurons in visual areas fire irregularly, many cells in association and motor-like parietal regions show increasingly regular spike trains by comparison. Regularity was evident both in the shape of interspike interval distributions and in spike-count variability across trials. Thus, Poisson-like randomness is not a universal feature of neocortex. Rather, many parietal cells have reduced trial-to-trial variability in spike counts that could provide for more reliable firing-rate signals. These results suggest that spiking dynamics may play different roles in different cortical areas and should not be assumed to arise from fundamentally irreducible noise sources.},
  number = {3},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2009-05},
  pages = {426-440},
  author = {Maimon, Gaby and Assad, John A.},
  file = {/Users/qualia/Documents/Papers/2009 - Maimon, Assad - Beyond Poisson Increased Spike-Time Regularity across Primate Parietal Cortex.pdf}
}

@article{Mainen1995,
  eprinttype = {jstor},
  eprint = {2887763},
  title = {Reliability of {{Spike Timing}} in {{Neocortical Neurons}}},
  volume = {268},
  number = {5216},
  journaltitle = {Science, New Series},
  date = {1995},
  pages = {1503-1506},
  author = {Mainen, Zachary F. and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/2009 - Mainen, Sejnowski - Reliability of Spike Timing in Neocortical Neurons.pdf}
}

@article{Marreiros2009,
  langid = {english},
  title = {Population Dynamics under the {{Laplace}} Assumption},
  volume = {44},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811908011063},
  doi = {10.1016/j.neuroimage.2008.10.008},
  abstract = {In this paper, we describe a generic approach to modelling dynamics in neuronal populations. This approach models a full density on the states of neuronal populations but finesses this high-dimensional problem by reformulating density dynamics in terms of ordinary differential equations on the sufficient statistics of the densities considered (c.f., the method of moments). The particular form for the population density we adopt is a Gaussian density (c.f., the Laplace assumption). This means population dynamics are described by equations governing the evolution of the population's mean and covariance. We derive these equations from the Fokker-Planck formalism and illustrate their application to a conductance-based model of neuronal exchanges. One interesting aspect of this formulation is that we can uncouple the mean and covariance to furnish a neural-mass model, which rests only on the populations mean. This enables us to compare equivalent mean-field and neural-mass models of the same populations and evaluate, quantitatively, the contribution of population variance to the expected dynamics. The mean-field model presented here will form the basis of a dynamic causal model of observed electromagnetic signals in future work.},
  number = {3},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2009-02},
  pages = {701-714},
  author = {Marreiros, Andr\'e C. and Kiebel, Stefan J. and Daunizeau, Jean and Harrison, Lee M. and Friston, Karl J.},
  file = {/Users/qualia/Documents/Papers/2009 - Marreiros et al. - Population dynamics under the Laplace assumption.pdf}
}

@article{Martens2009,
  langid = {english},
  title = {Exact Results for the {{Kuramoto}} Model with a Bimodal Frequency Distribution},
  volume = {79},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.79.026204},
  doi = {10.1103/PhysRevE.79.026204},
  number = {2},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2009-02-06},
  author = {Martens, E. A. and Barreto, E. and Strogatz, S. H. and Ott, E. and So, P. and Antonsen, T. M.},
  file = {/Users/qualia/Documents/Papers/2009 - Martens et al. - Exact results for the Kuramoto model with a bimodal frequency distribution.pdf}
}

@article{Marvel2009,
  langid = {english},
  title = {Energy {{Landscape}} of {{Social Balance}}},
  volume = {103},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.103.198701},
  doi = {10.1103/PhysRevLett.103.198701},
  number = {19},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2009-11-04},
  author = {Marvel, Seth A. and Strogatz, Steven H. and Kleinberg, Jon M.},
  file = {/Users/qualia/Documents/Papers/2009 - Marvel, Strogatz, Kleinberg - Energy landscape of social balance.pdf}
}

@article{Mathewson2009,
  langid = {english},
  title = {To {{See}} or {{Not}} to {{See}}: {{Prestimulus Phase Predicts Visual Awareness}}},
  volume = {29},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3963-08.2009},
  doi = {10.1523/JNEUROSCI.3963-08.2009},
  shorttitle = {To {{See}} or {{Not}} to {{See}}},
  number = {9},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2009-03-04},
  pages = {2725-2732},
  author = {Mathewson, K. E. and Gratton, G. and Fabiani, M. and Beck, D. M. and Ro, T.},
  file = {/Users/qualia/Documents/Papers/2009 - Mathewson et al. - To See or Not to See Prestimulus α Phase Predicts Visual Awareness.pdf}
}

@article{McDuff2009,
  langid = {english},
  title = {Multivoxel {{Pattern Analysis Reveals Increased Memory Targeting}} and {{Reduced Use}} of {{Retrieved Details}} during {{Single}}-{{Agenda Source Monitoring}}},
  volume = {29},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3587-08.2009},
  doi = {10.1523/JNEUROSCI.3587-08.2009},
  number = {2},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2009-01-14},
  pages = {508-516},
  author = {McDuff, S. G. R. and Frankel, H. C. and Norman, K. A.},
  file = {/Users/qualia/Documents/Papers/2009 - McDuff, Frankel, Norman - Multivoxel pattern analysis reveals increased memory targeting and reduced use of retrieved details dur.pdf}
}

@article{Mur2009,
  langid = {english},
  title = {Revealing Representational Content with Pattern-Information {{fMRI}}\textemdash{}an Introductory Guide},
  volume = {4},
  issn = {1749-5024, 1749-5016},
  url = {https://academic.oup.com/scan/article/4/1/101/1613450},
  doi = {10.1093/scan/nsn044},
  number = {1},
  journaltitle = {Social Cognitive and Affective Neuroscience},
  urldate = {2019-03-30},
  date = {2009-03-01},
  pages = {101-109},
  author = {Mur, Marieke and Bandettini, Peter A. and Kriegeskorte, Nikolaus},
  file = {/Users/qualia/Documents/Papers/2009 - Mur, Bandettini, Kriegeskorte - Revealing representational content with pattern-information fMRI--an introductory guide.pdf}
}

@article{Uhlhaas2009,
  langid = {english},
  title = {Neural Synchrony in Cortical Networks: History, Concept and Current Status},
  volume = {3},
  issn = {16625145},
  url = {http://journal.frontiersin.org/article/10.3389/neuro.07.017.2009/abstract},
  doi = {10.3389/neuro.07.017.2009},
  shorttitle = {Neural Synchrony in Cortical Networks},
  abstract = {Following the discovery of context-dependent synchronization of oscillatory neuronal responses in the visual system, the role of neural synchrony in cortical networks has been expanded to provide a general mechanism for the coordination of distributed neural activity patterns. In the current paper, we present an update of the status of this hypothesis through summarizing recent results from our laboratory that suggest important new insights regarding the mechanisms, function and relevance of this phenomenon. In the first part, we present recent results derived from animal experiments and mathematical simulations that provide novel explanations and mechanisms for zero and nero-zero phase lag synchronization. In the second part, we shall discuss the role of neural synchrony for expectancy during perceptual organization and its role in conscious experience. This will be followed by evidence that indicates that in addition to supporting conscious cognition, neural synchrony is abnormal in major brain disorders, such as schizophrenia and autism spectrum disorders. We conclude this paper with suggestions for further research as well as with critical issues that need to be addressed in future studies.},
  journaltitle = {Frontiers in Integrative Neuroscience},
  urldate = {2019-03-30},
  date = {2009},
  author = {Uhlhaas, Peter},
  file = {/Users/qualia/Documents/Papers/2009 - Neuroscience et al. - Neural synchrony in cortical networks history , concept and current status.pdf}
}

@article{Parkes2009,
  langid = {english},
  title = {Multivoxel {{fMRI}} Analysis of Color Tuning in Human Primary Visual Cortex},
  volume = {9},
  issn = {1534-7362},
  url = {http://jov.arvojournals.org/Article.aspx?doi=10.1167/9.1.1},
  doi = {10.1167/9.1.1},
  abstract = {We use multivoxel pattern analysis (MVPA) to study the spatial clustering of color-selective neurons in the human brain. Our main objective was to investigate whether MVPA reveals the spatial arrangements of color-selective neurons in human primary visual cortex (V1). We measured the distributed fMRI activation patterns for different color stimuli (Experiment 1: cardinal colors (to which the LGN is known to be tuned), Experiment 2: perceptual hues) in V1. Our two main findings were that (i) cone-opponent cardinal color modulations produce highly reproducible patterns of activity in V1, but these were not unique to each color. This suggests that V1 neurons with tuning characteristics similar to those found in LGN are not spatially clustered. (ii) Unique activation patterns for perceptual hues in V1 support current evidence for a spatially clustered hue map. We believe that our work is the first to show evidence of spatial clustering of neurons with similar color preferences in human V1.},
  number = {1},
  journaltitle = {Journal of Vision},
  urldate = {2019-03-30},
  date = {2009-01-01},
  pages = {1-1},
  author = {Parkes, L. M. and Marsman, J. B. C. and Oxley, D. C. and Goulermas, J. Y. and Wuerger, S. M.},
  file = {/Users/qualia/Documents/Papers/2009 - Parkes, Marsman - Multivoxel fMRI analysis of color tuning in human primary visual cortex.pdf}
}

@article{Pereira2009,
  langid = {english},
  title = {Machine Learning Classifiers and {{fMRI}}: {{A}} Tutorial Overview},
  volume = {45},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811908012263},
  doi = {10.1016/j.neuroimage.2008.11.007},
  shorttitle = {Machine Learning Classifiers and {{fMRI}}},
  abstract = {Interpreting brain image experiments requires analysis of complex, multivariate data. In recent years, one analysis approach that has grown in popularity is the use of machine learning algorithms to train classifiers to decode stimuli, mental states, behaviours and other variables of interest from fMRI data and thereby show the data contain information about them. In this tutorial overview we review some of the key choices faced in using this approach as well as how to derive statistically significant results, illustrating each point from a case study. Furthermore, we show how, in addition to answering the question of `is there information about a variable of interest' (pattern discrimination), classifiers can be used to tackle other classes of question, namely `where is the information' (pattern localization) and `how is that information encoded' (pattern characterization).},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2009-03},
  pages = {S199-S209},
  author = {Pereira, Francisco and Mitchell, Tom and Botvinick, Matthew},
  file = {/Users/qualia/Documents/Papers/2009 - Pereira, Mitchell, Botvinick - Machine learning classifiers and fMRI a tutorial overview.pdf}
}

@article{Pogosyan2009,
  langid = {english},
  title = {Boosting {{Cortical Activity}} at {{Beta}}-{{Band Frequencies Slows Movement}} in {{Humans}}},
  volume = {19},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982209016996},
  doi = {10.1016/j.cub.2009.07.074},
  abstract = {Neurons have a striking tendency to engage in oscillatory activities. One important type of oscillatory activity prevalent in the motor system occurs in the beta frequency band, at about 20 Hz. It is manifest during the maintenance of tonic contractions and is suppressed prior to and during voluntary movement [1\textendash{}7]. This and other correlative evidence suggests that beta activity might promote tonic contraction, while impairing motor processing related to new movements [3, 8, 9]. Hence, bursts of beta activity in the cortex are associated with a strengthening of the motor effects of sensory feedback during tonic contraction and with reductions in the velocity of voluntary movements [9\textendash{}11]. Moreover, beta activity is increased when movement has to be resisted or voluntarily suppressed [7, 12, 13]. Here we use imperceptible transcranial alternating-current stimulation to entrain cortical activity at 20 Hz in healthy subjects and show that this slows voluntary movement. The present findings are the first direct evidence of causality between any physiological oscillatory brain activity and concurrent motor behavior in the healthy human and help explain how the exaggerated beta activity found in Parkinson's disease can lead to motor slowing in this illness [14].},
  number = {19},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2009-10},
  pages = {1637-1641},
  author = {Pogosyan, Alek and Gaynor, Louise Doyle and Eusebio, Alexandre and Brown, Peter},
  file = {/Users/qualia/Documents/Papers/2009 - Pogosyan et al. - Boosting Cortical Activity at Beta-Band Frequencies Slows Movement in Humans.pdf}
}

@article{Poo2009,
  langid = {english},
  title = {Odor {{Representations}} in {{Olfactory Cortex}}: ``{{Sparse}}'' {{Coding}}, {{Global Inhibition}}, and {{Oscillations}}},
  volume = {62},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309003973},
  doi = {10.1016/j.neuron.2009.05.022},
  shorttitle = {Odor {{Representations}} in {{Olfactory Cortex}}},
  abstract = {The properties of cortical circuits underlying central representations of sensory stimuli are poorly understood. Here we use in vivo cell-attached and wholecell voltage-clamp recordings to reveal how excitatory and inhibitory synaptic input govern odor representations in rat primary olfactory (piriform) cortex. We show that odors evoke spiking activity that is sparse across the cortical population. We find that unbalanced synaptic excitation and inhibition underlie sparse activity: inhibition is widespread and broadly tuned, while excitation is less common and odor-specific. ``Global'' inhibition can be explained by local interneurons that receive ubiquitous and nonselective odor-evoked excitation. In the temporal domain, while respiration imposes a slow rhythm to olfactory cortical responses, odors evoke fast (15-30 Hz) oscillations in synaptic activity. Oscillatory excitation precedes inhibition, generating brief time windows for precise and temporally sparse spike output. Together, our results reveal that global inhibition and oscillations are major synaptic mechanisms shaping odor representations in olfactory cortex.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2009-06},
  pages = {850-861},
  author = {Poo, Cindy and Isaacson, Jeffry S.},
  file = {/Users/qualia/Documents/Papers/2009 - Poo, Isaacson - Odor Representations in Olfactory Cortex Sparse Coding, Global Inhibition, and Oscillations.pdf}
}

@article{Saalmann2009,
  langid = {english},
  title = {Gain Control in the Visual Thalamus during Perception and Cognition},
  volume = {19},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S095943880900049X},
  doi = {10.1016/j.conb.2009.05.007},
  number = {4},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2009-08},
  pages = {408-414},
  author = {Saalmann, Yuri B and Kastner, Sabine},
  file = {/Users/qualia/Documents/Papers/2009 - Saalmann, Kastner - Gain control in the visual thalamus during perception and cognition.pdf}
}

@article{Serences2009,
  langid = {english},
  title = {Stimulus-{{Specific Delay Activity}} in {{Human Primary Visual Cortex}}},
  volume = {20},
  issn = {0956-7976, 1467-9280},
  url = {http://journals.sagepub.com/doi/10.1111/j.1467-9280.2009.02276.x},
  doi = {10.1111/j.1467-9280.2009.02276.x},
  abstract = {Working memory (WM) involves maintaining information in an on-line state. One emerging view is that information in WM is maintained via sensory recruitment, such that information is stored via sustained activity in the sensory areas that encode the to-be-remembered information. Using functional magnetic resonance imaging, we observed that key sensory regions such as primary visual cortex (V1) showed little evidence of sustained increases in mean activation during a WM delay period, though such amplitude increases have typically been used to determine whether a region is involved in on-line maintenance. However, a multivoxel pattern analysis of delay-period activity revealed a sustained pattern of activation in V1 that represented only the intentionally stored feature of a multifeature object. Moreover, the pattern of delay activity was qualitatively similar to that observed during the discrimination of sensory stimuli, suggesting that WM representations in V1 are reasonable ``copies'' of those evoked during pure sensory processing.},
  number = {2},
  journaltitle = {Psychological Science},
  urldate = {2019-03-30},
  date = {2009-02},
  pages = {207-214},
  author = {Serences, John T. and Ester, Edward F. and Vogel, Edward K. and Awh, Edward},
  file = {/Users/qualia/Documents/Papers/2009 - Serences et al. - Stimulus-specific delay activity in human primary visual cortex.pdf}
}

@article{Stiefel2009,
  langid = {english},
  title = {The Effects of Cholinergic Neuromodulation on Neuronal Phase-Response Curves of Modeled Cortical Neurons},
  volume = {26},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-008-0111-9},
  doi = {10.1007/s10827-008-0111-9},
  number = {2},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2009-04},
  pages = {289-301},
  author = {Stiefel, Klaus M. and Gutkin, Boris S. and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/2009 - Stiefel, Gutkin, Sejnowski - The effects of cholinergic neuromodulation on neuronal phase-response curves of modeled cortical neu.pdf}
}

@article{Stokes2009,
  langid = {english},
  title = {Top-{{Down Activation}} of {{Shape}}-{{Specific Population Codes}} in {{Visual Cortex}} during {{Mental Imagery}}},
  volume = {29},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4657-08.2009},
  doi = {10.1523/JNEUROSCI.4657-08.2009},
  number = {5},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2009-02-04},
  pages = {1565-1572},
  author = {Stokes, M. and Thompson, R. and Cusack, R. and Duncan, J.},
  file = {/Users/qualia/Documents/Papers/2009 - Stokes et al. - Top-down activation of shape-specific population codes in visual cortex during mental imagery.pdf}
}

@article{Sui2009,
  langid = {english},
  title = {An {{ICA}}-Based Method for the Identification of Optimal {{FMRI}} Features and Components Using Combined Group-Discriminative Techniques},
  volume = {46},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811909000706},
  doi = {10.1016/j.neuroimage.2009.01.026},
  abstract = {Extraction of relevant features from multitask functional MRI (fMRI) data in order to identify potential biomarkers for disease, is an attractive goal. In this paper, we introduce a novel feature-based framework, which is sensitive and accurate in detecting group differences (e.g. controls vs. patients) by proposing three key ideas. First, we integrate two goal-directed techniques: coefficient-constrained independent component analysis (CC-ICA) and principal component analysis with reference (PCA-R), both of which improve sensitivity to group differences. Secondly, an automated artifact-removal method is developed for selecting components of interest derived from CC-ICA, with an average accuracy of 91\%. Finally, we propose a strategy for optimal feature/component selection, aiming to identify optimal group-discriminative brain networks as well as the tasks within which these circuits are engaged. The group-discriminating performance is evaluated on 15 fMRI feature combinations (5 single features and 10 joint features) collected from 28 healthy control subjects and 25 schizophrenia patients. Results show that a feature from a sensorimotor task and a joint feature from a Sternberg working memory (probe) task and an auditory oddball (target) task are the top two feature combinations distinguishing groups. We identified three optimal features that best separate patients from controls, including brain networks consisting of temporal lobe, default mode and occipital lobe circuits, which when grouped together provide improved capability in classifying group membership. The proposed framework provides a general approach for selecting optimal brain networks which may serve as potential biomarkers of several brain diseases and thus has wide applicability in the neuroimaging research community.},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2009-05-15},
  pages = {73-86},
  author = {Sui, Jing and Adali, T\"ulay and Pearlson, Godfrey D. and Calhoun, Vince D.},
  file = {/Users/qualia/Documents/Papers/2009 - Sui et al. - An ICA-based method for the identification of optimal FMRI features and components using combined group-discriminati.pdf}
}

@article{Sussillo2009,
  langid = {english},
  title = {Generating {{Coherent Patterns}} of {{Activity}} from {{Chaotic Neural Networks}}},
  volume = {63},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309005479},
  doi = {10.1016/j.neuron.2009.07.018},
  abstract = {Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2009-08},
  pages = {544-557},
  author = {Sussillo, David and Abbott, L.F.},
  file = {/Users/qualia/Documents/Papers/2009 - Sussillo, Abbott - Generating Coherent Patterns of Activity from Chaotic Neural Networks.pdf}
}

@article{Vogels2009,
  langid = {english},
  title = {Gating Multiple Signals through Detailed Balance of Excitation and Inhibition in Spiking Networks},
  volume = {12},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.2276},
  doi = {10.1038/nn.2276},
  number = {4},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2009-04},
  pages = {483-491},
  author = {Vogels, Tim P and Abbott, L F},
  file = {/Users/qualia/Documents/Papers/2009 - Vogels, Abbott - Gating Multiple Signals through Detailed Balance of Excitation and Inhibition in Spiking Networks T.P.pdf;/Users/qualia/Documents/Papers/2009 - Vogels, Abbott - Gating Multiple Signals through Detailed Balance of Excitation and Inhibition in Spiking Networks T.P(2).pdf}
}

@article{Walther2009,
  langid = {english},
  title = {Natural {{Scene Categories Revealed}} in {{Distributed Patterns}} of {{Activity}} in the {{Human Brain}}},
  volume = {29},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0559-09.2009},
  doi = {10.1523/JNEUROSCI.0559-09.2009},
  number = {34},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2009-08-26},
  pages = {10573-10581},
  author = {Walther, D. B. and Caddigan, E. and Fei-Fei, L. and Beck, D. M.},
  file = {/Users/qualia/Documents/Papers/2009 - Walther et al. - Natural scene categories revealed in distributed patterns of activity in the human brain.pdf;/Users/qualia/Zotero/storage/B245PG9T/2015 - Biphenyls - HHS Public Access.pdf}
}

@article{Yu2009,
  langid = {english},
  title = {Gaussian-{{Process Factor Analysis}} for {{Low}}-{{Dimensional Single}}-{{Trial Analysis}} of {{Neural Population Activity}}},
  volume = {102},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.90941.2008},
  doi = {10.1152/jn.90941.2008},
  number = {1},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2009-07},
  pages = {614-635},
  author = {Yu, Byron M. and Cunningham, John P. and Santhanam, Gopal and Ryu, Stephen I. and Shenoy, Krishna V. and Sahani, Maneesh},
  file = {/Users/qualia/Documents/Papers/2009 - Yu et al. - Gaussian-Process Factor Analysis for Low-Dimensional Single-Trial Analysis of Neural Population Activity (vol 102, pg.pdf}
}

@article{Yu,
  langid = {english},
  title = {Sequential Effects: {{Superstition}} or Rational Behavior?},
  abstract = {In a variety of behavioral tasks, subjects exhibit an automatic and apparently suboptimal sequential effect: they respond more rapidly and accurately to a stimulus if it reinforces a local pattern in stimulus history, such as a string of repetitions or alternations, compared to when it violates such a pattern. This is often the case even if the local trends arise by chance in the context of a randomized design, such that stimulus history has no real predictive power. In this work, we use a normative Bayesian framework to examine the hypothesis that such idiosyncrasies may reflect the inadvertent engagement of mechanisms critical for adapting to a changing environment. We show that prior belief in non-stationarity can induce experimentally observed sequential effects in an otherwise Bayes-optimal algorithm. The Bayesian algorithm is shown to be well approximated by linear-exponential filtering of past observations, a feature also apparent in the behavioral data. We derive an explicit relationship between the parameters and computations of the exact Bayesian algorithm and those of the approximate linear-exponential filter. Since the latter is equivalent to a leaky-integration process, a commonly used model of neuronal dynamics underlying perceptual decision-making and trial-to-trial dependencies, our model provides a principled account of why such dynamics are useful. We also show that parameter-tuning of the leaky-integration process is possible, using stochastic gradient descent based only on the noisy binary inputs. This is a proof of concept that not only can neurons implement near-optimal prediction based on standard neuronal dynamics, but that they can also learn to tune the processing parameters without explicitly representing probabilities.},
  pages = {8},
  author = {Yu, Angela J and Cohen, Jonathan D},
  file = {/Users/qualia/Documents/Papers/2009 - Yu, Cohen - Sequential effects Superstition or rational behavior.pdf}
}

@article{Barreiro2010,
  langid = {english},
  title = {Time Scales of Spike-Train Correlation for Neural Oscillators with Common Drive},
  volume = {81},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.81.011916},
  doi = {10.1103/PhysRevE.81.011916},
  number = {1},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2010-01-27},
  author = {Barreiro, Andrea K. and Shea-Brown, Eric and Thilo, Evan L.},
  file = {/Users/qualia/Documents/Papers/2010 - Barreiro, Shea-Brown, Thilo - Time scales of spike-train correlation for neural oscillators with common drive.pdf}
}

@article{Briggs2010,
  langid = {english},
  title = {Organizing Principles of Cortical Layer 6},
  issn = {16625110},
  url = {http://journal.frontiersin.org/article/10.3389/neuro.04.003.2010/abstract},
  doi = {10.3389/neuro.04.003.2010},
  journaltitle = {Frontiers in Neural Circuits},
  urldate = {2019-03-30},
  date = {2010},
  author = {{Briggs}},
  file = {/Users/qualia/Documents/Papers/2010 - Briggs - Organizing principles of cortical layer 6.pdf}
}

@article{Buesing2010,
  langid = {english},
  title = {A {{Spiking Neuron}} as {{Information Bottleneck}}},
  volume = {22},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.2010.08-09-1084},
  doi = {10.1162/neco.2010.08-09-1084},
  number = {8},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2010-08},
  pages = {1961-1992},
  author = {Buesing, Lars and Maass, Wolfgang},
  file = {/Users/qualia/Documents/Papers/2010 - Buesing, Maass - A Spiking Neuron as Information Bottleneck.pdf}
}

@article{Carp2010,
  langid = {english},
  title = {Age {{Differences}} in the {{Neural Representation}} of {{Working Memory Revealed}} by {{Multi}}-{{Voxel Pattern Analysis}}},
  volume = {4},
  issn = {1662-5161},
  url = {http://journal.frontiersin.org/article/10.3389/fnhum.2010.00217/abstract},
  doi = {10.3389/fnhum.2010.00217},
  abstract = {Working memory function declines across the lifespan. Computational models of aging attribute such memory impairments to reduced distinctiveness between neural representations of different mental states in old age, a phenomenon termed dedifferentiation. These models predict that neural distinctiveness should be reduced uniformly across experimental conditions in older adults. In contrast, the Compensation-Related Utilization of Neural Circuits Hypothesis (CRUNCH) model predicts that the distinctiveness of neural representations should be increased in older adults (relative to young adults) at low levels of task demand but reduced at high levels of demand. The present study used multi-voxel pattern analysis to measure the effects of age and task demands on the distinctiveness of the neural representations of verbal and visuospatial working memory. Neural distinctiveness was estimated separately for memory encoding, maintenance, and retrieval, and for low, medium, and high memory loads. Results from sensory cortex during encoding and retrieval were consistent with the dedifferentiation hypothesis: distinctiveness of visual cortical representations during these phases was uniformly reduced in older adults, irrespective of memory load. However, maintenance-related responses in prefrontal and parietal regions yielded a strikingly different pattern of results. At low loads, older adults showed higher distinctiveness than younger adults; at high loads, this pattern reversed, such that distinctiveness was higher in young adults. This interaction between age group and memory load is at odds with the dedifferentiation hypothesis but consistent with CRUNCH. In sum, our results provide partial support for both dedifferentiation- and compensation-based models; we argue that comprehensive theories of cognitive aging must incorporate aspects of both models to fully explain complex patterns of age-related neuro-cognitive change.},
  journaltitle = {Frontiers in Human Neuroscience},
  urldate = {2019-03-30},
  date = {2010},
  author = {Carp, Joshua and Gmeindl, Leon and Reuter-Lorenz, Patricia A.},
  file = {/Users/qualia/Documents/Papers/2010 - Carp, Gmeindl, Reuter-Lorenz - Age differences in the neural representation of working memory revealed by multi-voxel pattern ana.pdf}
}

@article{Chadwick2010,
  langid = {english},
  title = {Decoding {{Individual Episodic Memory Traces}} in the {{Human Hippocampus}}},
  volume = {20},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982210001429},
  doi = {10.1016/j.cub.2010.01.053},
  abstract = {In recent years, multivariate pattern analyses have been performed on functional magnetic resonance imaging (fMRI) data, permitting prediction of mental states from local patterns of blood oxygen-level-dependent (BOLD) signal across voxels [1, 2]. We previously demonstrated that it is possible to predict the position of individuals in a virtualreality environment from the pattern of activity across voxels in the hippocampus [3]. Although this shows that spatial memories can be decoded, substantially more challenging, and arguably only possible to investigate in humans [4], is whether it is feasible to predict which complex everyday experience, or episodic memory, a person is recalling. Here we document for the first time that traces of individual rich episodic memories are detectable and distinguishable solely from the pattern of fMRI BOLD signals across voxels in the human hippocampus. In so doing, we uncovered a possible functional topography in the hippocampus, with preferential episodic processing by some hippocampal regions over others. Moreover, our results imply that the neuronal traces of episodic memories are stable (and thus predictable) even over many re-activations. Finally, our data provide further evidence for functional differentiation within the medial temporal lobe, in that we show the hippocampus contains significantly more episodic information than adjacent structures.},
  number = {6},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2010-03},
  pages = {544-547},
  author = {Chadwick, Martin J. and Hassabis, Demis and Weiskopf, Nikolaus and Maguire, Eleanor A.},
  file = {/Users/qualia/Documents/Papers/2010 - Chadwick et al. - Decoding individual episodic memory traces in the human hippocampus.pdf}
}

@article{Churchland2010,
  langid = {english},
  title = {Cortical {{Preparatory Activity}}: {{Representation}} of {{Movement}} or {{First Cog}} in a {{Dynamical Machine}}?},
  volume = {68},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627310007579},
  doi = {10.1016/j.neuron.2010.09.015},
  shorttitle = {Cortical {{Preparatory Activity}}},
  abstract = {The motor cortices are active during both movement and movement preparation. A common assumption is that preparatory activity constitutes a subthreshold form of movement activity: a neuron active during rightward movements becomes modestly active during preparation of a rightward movement. We asked whether this pattern of activity is, in fact, observed. We found that it was not: at the level of a single neuron, preparatory tuning was weakly correlated with movement-period tuning. Yet, somewhat paradoxically, preparatory tuning could be captured by a preferred direction in an abstract ``space'' that described the population-level pattern of movement activity. In fact, this relationship accounted for preparatory responses better than did traditional tuning models. These results are expected if preparatory activity provides the initial state of a dynamical system whose evolution produces movement activity. Our results thus suggest that preparatory activity may not represent specific factors, and may instead play a more mechanistic role.},
  number = {3},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2010-11},
  pages = {387-400},
  author = {Churchland, Mark M. and Cunningham, John P. and Kaufman, Matthew T. and Ryu, Stephen I. and Shenoy, Krishna V.},
  file = {/Users/qualia/Documents/Papers/2010 - Churchland et al. - Cortical Preparatory Activity Representation of Movement or First Cog in a Dynamical Machine.pdf}
}

@article{Churchland2010a,
  langid = {english},
  title = {Stimulus Onset Quenches Neural Variability: A Widespread Cortical Phenomenon},
  volume = {13},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.2501},
  doi = {10.1038/nn.2501},
  shorttitle = {Stimulus Onset Quenches Neural Variability},
  number = {3},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2010-03},
  pages = {369-378},
  author = {Churchland, Mark M and Yu, Byron M and Cunningham, John P and Sugrue, Leo P and Cohen, Marlene R and Corrado, Greg S and Newsome, William T and Clark, Andrew M and Hosseini, Paymon and Scott, Benjamin B and Bradley, David C and Smith, Matthew A and Kohn, Adam and Movshon, J Anthony and Armstrong, Katherine M and Moore, Tirin and Chang, Steve W and Snyder, Lawrence H and Lisberger, Stephen G and Priebe, Nicholas J and Finn, Ian M and Ferster, David and Ryu, Stephen I and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V},
  file = {/Users/qualia/Documents/Papers/2010 - Churchland et al. - Stimulus onset quenches neural variability a widespread cortical phenomenon.pdf;/Users/qualia/Documents/Papers/2010 - Churchland et al. - Stimulus onset quenches neural variability a widespread cortical phenomenon(2).pdf}
}

@article{Contin2010,
  langid = {english},
  title = {Pharmacokinetics of Levodopa},
  volume = {257},
  issn = {0340-5354, 1432-1459},
  url = {http://link.springer.com/10.1007/s00415-010-5728-8},
  doi = {10.1007/s00415-010-5728-8},
  number = {S2},
  journaltitle = {Journal of Neurology},
  urldate = {2019-03-30},
  date = {2010-11},
  pages = {253-261},
  author = {Contin, Manuela and Martinelli, Paolo},
  file = {/Users/qualia/Documents/Papers/2010 - Contin, Martinelli - Pharmacokinetics of levodopa.pdf}
}

@incollection{Douglas2010,
  langid = {english},
  title = {Canonical {{Cortical Circuits}}},
  isbn = {978-0-19-538988-3},
  url = {http://oxfordmedicine.com/view/10.1093/med/9780195389883.001.0001/med-9780195389883-chapter-002},
  booktitle = {Handbook of {{Brain Microcircuits}}},
  publisher = {{Oxford University Press}},
  urldate = {2019-03-30},
  date = {2010-08},
  pages = {15-21},
  author = {Douglas, Rodney J. and Martin, Kevan A. C.},
  editor = {Shepherd, MD, DPhil, Gordon and Grillner, MD, Sten},
  file = {/Users/qualia/Documents/Papers/2010 - Douglas - Canonical cortical circuits.pdf;/Users/qualia/Documents/Papers/2010 - Douglas - Canonical cortical circuits(2).pdf},
  doi = {10.1093/med/9780195389883.003.0002}
}

@book{Ermentrout2010,
  langid = {english},
  location = {{New York}},
  title = {Mathematical Foundations of Neuroscience},
  isbn = {978-0-387-87707-5},
  pagetotal = {422},
  number = {v. 35},
  series = {Interdisciplinary Applied Mathematics},
  publisher = {{Springer}},
  date = {2010},
  keywords = {Computational neuroscience,Mathematics,Neurosciences},
  author = {Ermentrout, Bard and Terman, David H.},
  file = {/Users/qualia/Documents/Papers/2010 - Ermentrout, Terman - Mathematical foundations of neuroscience.pdf}
}

@article{Foutz2010,
  langid = {english},
  title = {Evaluation of Novel Stimulus Waveforms for Deep Brain Stimulation},
  volume = {7},
  issn = {1741-2560, 1741-2552},
  url = {http://stacks.iop.org/1741-2552/7/i=6/a=066008?key=crossref.95bccb7b5d8fda3742b961c8d9996b7d},
  doi = {10.1088/1741-2560/7/6/066008},
  abstract = {Deep brain stimulation (DBS) is an established therapy for the treatment of a wide range of neurological disorders. Historically, DBS and other neurostimulation technologies have relied on rectangular stimulation waveforms to impose their effects on the nervous system. Recent work has suggested that non-rectangular waveforms may have advantages over the traditional rectangular pulse. Therefore, we used detailed computer models to compare a range of charge-balanced biphasic waveforms with rectangular, exponential, triangular, Gaussian and sinusoidal stimulus pulse shapes. We explored the neural activation energy of these waveforms for both intracellular and extracellular current-controlled stimulation conditions. In the context of extracellular stimulation, we compared their effects on both axonal fibers of passage and projection neurons. Finally, we evaluated the impact of delivering the waveforms through a clinical DBS electrode, as opposed to a theoretical point source. Our results suggest that DBS with a 1 ms centered-triangular pulse can decrease energy consumption by 64\% when compared with the standard 100 {$\mu$}s rectangular pulse (energy cost of 48 and 133 nJ, respectively, to stimulate 50\% of a distributed population of axons) and can decrease energy consumption by 10\% when compared with the most energy efficient rectangular pulse (1.25 ms duration). In turn, there may be measureable energy savings when using appropriately designed non-rectangular pulses in clinical DBS applications, thereby warranting further experimental investigation.},
  number = {6},
  journaltitle = {Journal of Neural Engineering},
  urldate = {2019-03-30},
  date = {2010-12-01},
  pages = {066008},
  author = {Foutz, Thomas J and McIntyre, Cameron C},
  file = {/Users/qualia/Documents/Papers/2010 - Foutz, McIntyre - Evaluation of novel stimulus waveforms for deep brain stimulation.pdf}
}

@article{Ganguli,
  langid = {english},
  title = {Short-Term Memory in Neuronal Networks through Dynamical Compressed Sensing},
  abstract = {Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that exceeds the number of neurons. This enhanced capacity is achieved by a class of ``orthogonal'' recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance.},
  pages = {9},
  author = {Ganguli, Surya and Sompolinsky, Haim},
  file = {/Users/qualia/Documents/Papers/2010 - Ganguli, Sompolinsky - Short-term memory in neuronal networks through dynamical compressed sensing.pdf}
}

@article{Ghuman2010,
  langid = {english},
  title = {Face {{Adaptation}} without a {{Face}}},
  volume = {20},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982209019940},
  doi = {10.1016/j.cub.2009.10.077},
  abstract = {Prolonged viewing of a stimulus results in a subsequent perceptual bias [1\textendash{}3]. This perceptual adaptation and the resulting aftereffect reveal important characteristics regarding how perceptual systems are tuned [2, 4\textendash{}6]. These aftereffects occur not only for simple stimulus features but also for high-level stimulus properties [7\textendash{}10]. Here we report a novel cross-category adaptation aftereffect demonstrating that prolonged viewing of a human body without a face shifts the perceptual tuning curve for face gender and face identity. This contradicts a central assumption underlying perceptual adaptation: that adaptation depends on physical similarity between how the adapting and the adapted features are perceived [5]. Additionally, this aftereffect was not due to response bias, because its dependence on adaptation duration resembled traditional perceptual aftereffects. These body-to-face adaptation results demonstrate that bodies alone can alter the tuning properties of neurons that code for the gender and identity of faces. More generally, these results reveal that high-level perceptual adaptation can occur when the property or features being adapted are automatically inferred rather than perceived in the adapting stimulus.},
  number = {1},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2010-01},
  pages = {32-36},
  author = {Ghuman, Avniel Singh and McDaniel, Jonathan R. and Martin, Alex},
  file = {/Users/qualia/Documents/Papers/2010 - Ghuman, McDaniel, Martin - Face adaptation without a face.pdf}
}

@article{Giannicola2010,
  langid = {english},
  title = {The Effects of Levodopa and Ongoing Deep Brain Stimulation on Subthalamic Beta Oscillations in {{Parkinson}}'s Disease},
  volume = {226},
  issn = {00144886},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0014488610002931},
  doi = {10.1016/j.expneurol.2010.08.011},
  abstract = {Local field potentials (LFPs) recorded through electrodes implanted in the subthalamic nucleus (STN) for deep brain stimulation (DBS) in patients with Parkinson's disease (PD) show that oscillations in the beta frequency range (8\textendash{}20 Hz) decrease after levodopa intake. Whether and how DBS influences the beta oscillations and whether levodopa- and DBS-induced changes interact remains unclear. We examined the combined effect of levodopa and DBS on subthalamic beta LFP oscillations, recorded in nine patients with PD under four experimental conditions: without levodopa with DBS turned off; without levodopa with DBS turned on; with levodopa with DBS turned on; and with levodopa with DBS turned off. The analysis of STNLFP oscillations showed that whereas levodopa abolished beta STN oscillations in all the patients (p = 0.026), DBS significantly decreased the beta oscillation only in five of the nine patients studied (p = 0.043). Another difference was that whereas levodopa completely suppressed beta oscillations, DBS merely decreased them. When we combined levodopa and DBS, the levodopa-induced beta disruption prevailed and combining levodopa and DBS induced no significant additive effect (p = 0.500). Our observations suggest that levodopa and DBS both modulate LFP beta oscillations.},
  number = {1},
  journaltitle = {Experimental Neurology},
  urldate = {2019-03-30},
  date = {2010-11},
  pages = {120-127},
  author = {Giannicola, Gaia and Marceglia, Sara and Rossi, Lorenzo and Mrakic-Sposta, Simona and Rampini, Paolo and Tamma, Filippo and Cogiamanian, Filippo and Barbieri, Sergio and Priori, Alberto},
  file = {/Users/qualia/Documents/Papers/2010 - Giannicola et al. - The effects of levodopa and ongoing deep brain stimulation on subthalamic beta oscillations in Parkinson's di.pdf}
}

@article{Hahn2010,
  langid = {english},
  title = {Modeling Shifts in the Rate and Pattern of Subthalamopallidal Network Activity during Deep Brain Stimulation},
  volume = {28},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-010-0225-8},
  doi = {10.1007/s10827-010-0225-8},
  abstract = {Deep brain stimulation (DBS) of the subthlamic nucleus (STN) represents an effective treatment for medically refractory Parkinson's disease; however, understanding of its effects on basal ganglia network activity remains limited. We constructed a computational model of the subthalamopallidal network, trained it to fit in vivo recordings from parkinsonian monkeys, and evaluated its response to STN DBS. The network model was created with synaptically connected single compartment biophysical models of STN and pallidal neurons, and stochastically defined inputs driven by cortical beta rhythms. A least mean square error training algorithm was developed to parameterize network connections and minimize error when compared to experimental spike and burst rates in the parkinsonian condition. The output of the trained network was then compared to experimental data not used in the training process. We found that reducing the influence of the cortical beta input on the model generated activity that agreed well with recordings from normal monkeys. Further, during STN DBS in the parkinsonian condition the simulations reproduced the reduction in GPi bursting found in existing experimental data. The model also provided the opportunity to greatly expand analysis of GPi bursting activity, generating three major predictions. First, its reduction was proportional to the volume of STN activated by DBS. Second, GPi bursting decreased in a stimulation frequency dependent manner, saturating at values consistent with clinically therapeutic DBS. And third, ablating STN neurons, reported to generate similar therapeutic outcomes as STN DBS, also reduced GPi bursting. Our theoretical analysis of stimulation induced network activity suggests that regularization of GPi firing is dependent on the volume of STN tissue activated and a threshold level of burst reduction may be necessary for therapeutic effect.},
  number = {3},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2010-06},
  pages = {425-441},
  author = {Hahn, Philip J. and McIntyre, Cameron C.},
  file = {/Users/qualia/Documents/Papers/2010 - Hahn, McIntyre - Modeling shifts in the rate and pattern of subthalamopallidal network activity during deep brain stimulation.pdf}
}

@article{Holgado2010,
  langid = {english},
  title = {Conditions for the {{Generation}} of {{Beta Oscillations}} in the {{Subthalamic Nucleus}}-{{Globus Pallidus Network}}},
  volume = {30},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0817-10.2010},
  doi = {10.1523/JNEUROSCI.0817-10.2010},
  number = {37},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2010-09-15},
  pages = {12340-12352},
  author = {Holgado, A. J. N. and Terry, J. R. and Bogacz, R.},
  file = {/Users/qualia/Documents/Papers/2010 - Holgado, Terry, Bogacz - Conditions for the Generation of Beta Oscillations in the Subthalamic Nucleus-Globus Pallidus Network.pdf}
}

@article{Hsieh2010,
  langid = {english},
  title = {``{{Brain}}-Reading'' of Perceived Colors Reveals a Feature Mixing Mechanism Underlying Perceptual Filling-in in Cortical Area {{V1}}},
  volume = {31},
  issn = {10659471},
  url = {http://doi.wiley.com/10.1002/hbm.20946},
  doi = {10.1002/hbm.20946},
  abstract = {Visual filling-in occurs when a retinally stabilized object undergoes perceptual fading. As the term ``filling-in'' implies, it is commonly believed that information about the apparently vanished object is lost and replaced solely by information arising from the surrounding background. Here we report multivoxel pattern analysis fMRI data that challenge this long-held belief. When subjects view blue disks on a red background while fixating, the stimulus and background appear to turn a uniform purple upon perceptual fading, suggesting that a feature mixing mechanism may underlie color fillingin. We find that ensemble fMRI signals in retinotopic visual areas reliably predict (i) which of three colors a subject reports seeing; (ii) whether a subject is in a perceptually filled-in state or not; and (iii) furthermore, while subjects are in the perceptual state of filling-in, the BOLD signal activation pattern in the sub-areas of V1 corresponding to the location of the blue disks behaves as if subjects are in fact viewing a perceptually mixed color (purple), rather than the color of the disks (blue) or the color of the background (red). These results imply that the mechanism of filling-in in stimuli in which figure and background surfaces are equated is a process of ``feature mixing'', not ``feature replacement''. These data indicate that feature mixing may involve cortical areas as early as V1. Hum Brain Mapp 31:1395\textendash{}1407, 2010. VC 2010 Wiley-Liss, Inc.},
  number = {9},
  journaltitle = {Human Brain Mapping},
  urldate = {2019-03-30},
  date = {2010-09},
  pages = {1395-1407},
  author = {Hsieh, Po-Jang and Tse, Peter U.},
  file = {/Users/qualia/Documents/Papers/2010 - Hsieh, Tse - Brain-reading of perceived colors reveals a feature mixing mechanism underlying perceptual filling-in in cortical ar.pdf}
}

@article{Humphries2010,
  langid = {english},
  title = {Reconstructing the {{Three}}-{{Dimensional GABAergic Microcircuit}} of the {{Striatum}}},
  volume = {6},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1001011},
  doi = {10.1371/journal.pcbi.1001011},
  abstract = {A system's wiring constrains its dynamics, yet modelling of neural structures often overlooks the specific networks formed by their neurons. We developed an approach for constructing anatomically realistic networks and reconstructed the GABAergic microcircuit formed by the medium spiny neurons (MSNs) and fast-spiking interneurons (FSIs) of the adult rat striatum. We grew dendrite and axon models for these neurons and extracted probabilities for the presence of these neurites as a function of distance from the soma. From these, we found the probabilities of intersection between the neurites of two neurons given their inter-somatic distance, and used these to construct three-dimensional striatal networks. The MSN dendrite models predicted that half of all dendritic spines are within 100mm of the soma. The constructed networks predict distributions of gap junctions between FSI dendrites, synaptic contacts between MSNs, and synaptic inputs from FSIs to MSNs that are consistent with current estimates. The models predict that to achieve this, FSIs should be at most 1\% of the striatal population. They also show that the striatum is sparsely connected: FSI-MSN and MSN-MSN contacts respectively form 7\% and 1.7\% of all possible connections. The models predict two striking network properties: the dominant GABAergic input to a MSN arises from neurons with somas at the edge of its dendritic field; and FSIs are interconnected on two different spatial scales: locally by gap junctions and distally by synapses. We show that both properties influence striatal dynamics: the most potent inhibition of a MSN arises from a region of striatum at the edge of its dendritic field; and the combination of local gap junction and distal synaptic networks between FSIs sets a robust input-output regime for the MSN population. Our models thus intimately link striatal micro-anatomy to its dynamics, providing a biologically grounded platform for further study.},
  number = {11},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2010-11-24},
  pages = {e1001011},
  author = {Humphries, Mark D. and Wood, Ric and Gurney, Kevin},
  editor = {Friston, Karl J.},
  file = {/Users/qualia/Documents/Papers/2010 - Humphries, Wood, Gurney - Reconstructing the Three-Dimensional GABAergic Microcircuit of the Striatum.pdf}
}

@article{Hurzook,
  langid = {english},
  title = {Visual Motion Processing and Perceptual Decision Making},
  abstract = {We present a biologically plausible spiking network model of visual motion processing and perceptual decision making, independent of the number of choice alternatives. As an application we simulate the two-alternative forced choice (2AFC) task.},
  pages = {1},
  author = {Hurzook, Aziz and Trujillo, Oliver and Eliasmith, Chris},
  file = {/Users/qualia/Documents/Papers/2010 - Hurzook, Trujillo, Eliasmith - Visual motion processing and perceptual decision making.pdf;/Users/qualia/Documents/Papers/2010 - Hurzook, Trujillo, Eliasmith - Visual motion processing and perceptual decision making(2).pdf}
}

@article{Hutt2010,
  langid = {english},
  title = {Activity Spread and Breathers Induced by Finite Transmission Speeds in Two-Dimensional Neural Fields},
  volume = {82},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.82.055701},
  doi = {10.1103/PhysRevE.82.055701},
  number = {5},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2010-11-12},
  author = {Hutt, Axel and Rougier, Nicolas},
  file = {/Users/qualia/Documents/Papers/2010 - Hutt, Rougier - Activity spread and breathers induced by finite transmission speeds in two-dimensional neural fields.pdf}
}

@article{Jin2010,
  langid = {english},
  title = {Start/Stop Signals Emerge in Nigrostriatal Circuits during Sequence Learning},
  volume = {466},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature09263},
  doi = {10.1038/nature09263},
  number = {7305},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2010-07},
  pages = {457-462},
  author = {Jin, Xin and Costa, Rui M.},
  file = {/Users/qualia/Documents/Papers/2010 - Jin, Costa - Startstop signals emerge in nigrostriatal circuits during sequence learning.pdf}
}

@article{Kayser2010,
  langid = {english},
  title = {Neural {{Representations}} of {{Relevant}} and {{Irrelevant Features}} in {{Perceptual Decision Making}}},
  volume = {30},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3163-10.2010},
  doi = {10.1523/JNEUROSCI.3163-10.2010},
  number = {47},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2010-11-24},
  pages = {15778-15789},
  author = {Kayser, A. S. and Erickson, D. T. and Buchsbaum, B. R. and D'Esposito, M.},
  file = {/Users/qualia/Documents/Papers/2010 - Kayser et al. - Neural representations of relevant and irrelevant features in perceptual decision making.pdf}
}

@article{Lee2003,
  langid = {english},
  title = {"{{Gamma}} (40 {{Hz}}) Phase Synchronicity" and Symptom Dimensions in Schizophrenia},
  volume = {8},
  issn = {1354-6805, 1464-0619},
  url = {https://www.tandfonline.com/doi/full/10.1080/713752240},
  doi = {10.1080/713752240},
  number = {1},
  journaltitle = {Cognitive Neuropsychiatry},
  urldate = {2019-03-30},
  date = {2003-01},
  pages = {57-71},
  author = {Lee, Kwang-Hyuk and Williams, Leanne and Haig, Albert and Gordon, Evian},
  file = {/Users/qualia/Documents/Papers/2010 - Lee et al. - Gamma ( 40 Hz ) phase synchronicity and symptom dimensions in schizophrenia.pdf}
}

@article{Li2010,
  langid = {english},
  title = {Estimating Coupling Direction between Neuronal Populations with Permutation Conditional Mutual Information},
  volume = {52},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910007068},
  doi = {10.1016/j.neuroimage.2010.05.003},
  abstract = {To further understand functional connectivity in the brain, we need to identify the coupling direction between neuronal signals recorded from different brain areas. In this paper, we present a novel methodology based on permutation analysis and conditional mutual information for estimation of a directionality index between two neuronal populations. First, the reliability of this method is numerically assessed with a coupled mass neural model; the simulations show that this method is superior to the conditional mutual information method and the Granger causality method for identifying the coupling direction between unidirectional or bidirectional neuronal populations that are generated by the mass neuronal model. The method is also applied to investigate the coupling direction between neuronal populations in CA1 and CA3 in the rat hippocampal tetanus toxin model of focal epilepsy; the propagation direction of the seizure events could be elucidated through this coupling direction estimation method. All together, these results suggest that the permutation conditional mutual information method is a promising technique for estimating directional coupling between mutually interconnected neuronal populations.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2010-08-15},
  pages = {497-507},
  author = {Li, Xiaoli and Ouyang, Gaoxiang},
  file = {/Users/qualia/Documents/Papers/2010 - Li, Ouyang - Estimating coupling direction between neuronal populations with permutation conditional mutual information.pdf}
}

@article{Lopez-Azcarate2010,
  langid = {english},
  title = {Coupling between {{Beta}} and {{High}}-{{Frequency Activity}} in the {{Human Subthalamic Nucleus May Be}} a {{Pathophysiological Mechanism}} in {{Parkinson}}'s {{Disease}}},
  volume = {30},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5459-09.2010},
  doi = {10.1523/JNEUROSCI.5459-09.2010},
  number = {19},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2010-05-12},
  pages = {6667-6677},
  author = {Lopez-Azcarate, J. and Tainta, M. and Rodriguez-Oroz, M. C. and Valencia, M. and Gonzalez, R. and Guridi, J. and Iriarte, J. and Obeso, J. A. and Artieda, J. and Alegre, M.},
  file = {/Users/qualia/Documents/Papers/2010 - Lopez-Azcarate et al. - Coupling between Beta and High-Frequency Activity in the Human Subthalamic Nucleus May Be a Pathophysiolo.pdf}
}

@article{Lundqvist2010,
  langid = {english},
  title = {Bistable, {{Irregular Firing}} and {{Population Oscillations}} in a {{Modular Attractor Memory Network}}},
  volume = {6},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1000803},
  doi = {10.1371/journal.pcbi.1000803},
  abstract = {Attractor neural networks are thought to underlie working memory functions in the cerebral cortex. Several such models have been proposed that successfully reproduce firing properties of neurons recorded from monkeys performing working memory tasks. However, the regular temporal structure of spike trains in these models is often incompatible with experimental data. Here, we show that the in vivo observations of bistable activity with irregular firing at the single cell level can be achieved in a large-scale network model with a modular structure in terms of several connected hypercolumns. Despite high irregularity of individual spike trains, the model shows population oscillations in the beta and gamma band in ground and active states, respectively. Irregular firing typically emerges in a high-conductance regime of balanced excitation and inhibition. Population oscillations can produce such a regime, but in previous models only a non-coding ground state was oscillatory. Due to the modular structure of our network, the oscillatory and irregular firing was maintained also in the active state without fine-tuning. Our model provides a novel mechanistic view of how irregular firing emerges in cortical populations as they go from beta to gamma oscillations during memory retrieval.},
  number = {6},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2010-06-03},
  pages = {e1000803},
  author = {Lundqvist, Mikael and Compte, Albert and Lansner, Anders},
  editor = {Morrison, Abigail},
  file = {/Users/qualia/Documents/Papers/2010 - Lundqvist, Compte, Lansner - Bistable, irregular firing and population oscillations in a modular attractor memory network.pdf}
}

@inbook{Maass2011,
  langid = {english},
  title = {Liquid {{State Machines}}: {{Motivation}}, {{Theory}}, and {{Applications}}},
  isbn = {978-1-84816-245-7 978-1-84816-277-8},
  url = {http://www.worldscientific.com/doi/abs/10.1142/9781848162778_0008},
  shorttitle = {Liquid {{State Machines}}},
  booktitle = {Computability in {{Context}}},
  publisher = {{IMPERIAL COLLEGE PRESS}},
  urldate = {2019-03-30},
  date = {2011-02},
  pages = {275-296},
  author = {Maass, Wolfgang},
  bookauthor = {Cooper, S Barry and Sorbi, Andrea},
  file = {/Users/qualia/Documents/Papers/2010 - Maass - Liquid State Machines Motivation, Theory, and Applications.pdf},
  doi = {10.1142/9781848162778_0008}
}

@article{Mahon2010,
  langid = {english},
  title = {Judging Semantic Similarity: An Event-Related {{fMRI}} Study with Auditory Word Stimuli},
  volume = {169},
  issn = {03064522},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0306452210005725},
  doi = {10.1016/j.neuroscience.2010.04.029},
  shorttitle = {Judging Semantic Similarity},
  abstract = {Much of mental life consists in thinking about object concepts that are not currently within the scope of perception. The general system that enables multiple representations to be maintained and compared is referred to as ``working memory'' [Repov{\v s} G, Baddeley A (2006) Neuroscience 139:5\textendash{}21], and involves regions in medial and lateral parietal and frontal cortex [e.g., Smith EE, Jonides J (1999) Science 283:1657\textendash{}1661]. It has been assumed that the contents of working memory index information in regions of the brain that are critical for processing and storing object knowledge. To study the processes involved in thinking about common object concepts, we used event related fMRI to study BOLD activity while participants made judgments of conceptual similarity over pairs of sequentially presented auditory words. Through a combination of conventional fMRI analysis approaches and multi-voxel pattern analysis (MVPA), we show that the brain responses associated with the second word in a pair carry information about the conceptual similarity between the two members of the pair. This was the case in frontal and parietal regions involved in the working memory and decision components of the task for both analysis approaches. However, in other regions of the brain, including early visual regions, MVPA permitted classification of semantic distance relationships where conventional averaging approaches failed to show a difference. These findings suggest that diffuse and statistically sub-threshold ``scattering'' of BOLD activity in some regions may carry substantial information about the contents of mental representations. \textcopyright{} 2010 IBRO. Published by Elsevier Ltd. All rights reserved.},
  number = {1},
  journaltitle = {Neuroscience},
  urldate = {2019-03-30},
  date = {2010-08},
  pages = {279-286},
  author = {Mahon, B.Z. and Caramazza, A.},
  file = {/Users/qualia/Documents/Papers/2010 - Mahon, Caramazza - Judging semantic similarity an event-related fMRI study with auditory word stimuli.pdf}
}

@article{Meyer2010,
  langid = {english},
  title = {Predicting Visual Stimuli on the Basis of Activity in Auditory Cortices},
  volume = {13},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.2533},
  doi = {10.1038/nn.2533},
  number = {6},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2010-06},
  pages = {667-668},
  author = {Meyer, Kaspar and Kaplan, Jonas T and Essex, Ryan and Webber, Cecelia and Damasio, Hanna and Damasio, Antonio},
  file = {/Users/qualia/Documents/Papers/2010 - Meyer et al. - Predicting visual stimuli on the basis of activity in auditory cortices.pdf}
}

@article{Nevin2010,
  langid = {english},
  title = {Focusing on Optic Tectum Circuitry through the Lens of Genetics},
  volume = {8},
  issn = {1741-7007},
  url = {http://bmcbiol.biomedcentral.com/articles/10.1186/1741-7007-8-126},
  doi = {10.1186/1741-7007-8-126},
  abstract = {The visual pathway is tasked with processing incoming signals from the retina and converting this information into adaptive behavior. Recent studies of the larval zebrafish tectum have begun to clarify how the `microcircuitry' of this highly organized midbrain structure filters visual input, which arrives in the superficial layers and directs motor output through efferent projections from its deep layers. The new emphasis has been on the specific function of neuronal cell types, which can now be reproducibly labeled, imaged and manipulated using genetic and optical techniques. Here, we discuss recent advances and emerging experimental approaches for studying tectal circuits as models for visual processing and sensorimotor transformation by the vertebrate brain.},
  number = {1},
  journaltitle = {BMC Biology},
  urldate = {2019-03-30},
  date = {2010},
  pages = {126},
  author = {Nevin, Linda M and Robles, Estuardo and Baier, Herwig and Scott, Ethan K},
  file = {/Users/qualia/Documents/Papers/2010 - Nevin et al. - Focusing on optic tectum circuitry through the lens of genetics.pdf}
}

@article{Oliveira2010,
  langid = {english},
  title = {Transcranial Magnetic Stimulation of Posterior Parietal Cortex Affects Decisions of Hand Choice},
  volume = {107},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1006223107},
  doi = {10.1073/pnas.1006223107},
  number = {41},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2010-10-12},
  pages = {17751-17756},
  author = {Oliveira, Flavio T. P. and Diedrichsen, J\"orn and Verstynen, Timothy and Duque, Julie and Ivry, Richard B.},
  file = {/Users/qualia/Documents/Papers/2010 - Oliveira et al. - Transcranial magnetic stimulation of posterior parietal cortex affects decisions of hand choice.pdf}
}

@article{OpdeBeeck2010,
  langid = {english},
  title = {Probing the Mysterious Underpinnings of Multi-Voxel {{fMRI}} Analyses},
  volume = {50},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811909013615},
  doi = {10.1016/j.neuroimage.2009.12.072},
  abstract = {Various arguments have been proposed for or against sub-voxel sensitivity or hyperacuity in functional magnetic resonance imaging (fMRI) at standard resolution. Sub-voxel sensitivity might exist, but nevertheless the performance of multi-voxel fMRI analyses is very likely to be dominated by a largerscale organization, even if this organization is very weak. Up to now, most arguments are indirect in nature: they do not in themselves proof or contradict sub-voxel sensitivity, but they are suggestive, seem consistent or not with sub-voxel sensitivity, or show that the principle might or might not work. Here the previously proposed smoothing argument against hyperacuity is extended with simulations that include more realistic signal, noise, and analysis properties than any of the simulations presented before. These simulations confirm the relevance of the smoothing approach to find out the scale of the functional maps that underlie the outcome of multi-voxel analyses, at least in relative terms (differences in the scale of different maps). However, image smoothing, like most other arguments in the literature, is an indirect argument, and at the end of the day such arguments are not sufficient to decide the issue on whether and how much sub-voxel maps contribute. A few suggestions are made about the type of evidence that is needed to help us understand the as yet mysterious underpinnings of multi-voxel fMRI analyses.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2010-04},
  pages = {567-571},
  author = {Op de Beeck, Hans P.},
  file = {/Users/qualia/Documents/Papers/2010 - Op de Beeck - Probing the mysterious underpinnings of multi-voxel fMRI analyses.pdf}
}

@article{Raizada2010,
  langid = {english},
  title = {Linking Brain-Wide Multivoxel Activation Patterns to Behaviour: {{Examples}} from Language and Math},
  volume = {51},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910001023},
  doi = {10.1016/j.neuroimage.2010.01.080},
  shorttitle = {Linking Brain-Wide Multivoxel Activation Patterns to Behaviour},
  abstract = {A key goal of cognitive neuroscience is to find simple and direct connections between brain and behaviour. However, fMRI analysis typically involves choices between many possible options, with each choice potentially biasing any brain\textendash{}behaviour correlations that emerge. Standard methods of fMRI analysis assess each voxel individually, but then face the problem of selection bias when combining those voxels into a region-of-interest, or ROI. Multivariate pattern-based fMRI analysis methods use classifiers to analyse multiple voxels together, but can also introduce selection bias via data-reduction steps as feature selection of voxels, pre-selecting activated regions, or principal components analysis. We show here that strong brain\textendash{}behaviour links can be revealed without any voxel selection or data reduction, using just plain linear regression as a classifier applied to the whole brain at once, i.e. treating each entire brain volume as a single multi-voxel pattern. The brain\textendash{}behaviour correlations emerged despite the fact that the classifier was not provided with any information at all about subjects' behaviour, but instead was given only the neural data and its condition-labels. Surprisingly, more powerful classifiers such as a linear SVM and regularised logistic regression produce very similar results. We discuss some possible reasons why the very simple brain-wide linear regression model is able to find correlations with behaviour that are as strong as those obtained on the one hand from a specific ROI and on the other hand from more complex classifiers. In a manner which is unencumbered by arbitrary choices, our approach offers a method for investigating connections between brain and behaviour which is simple, rigorous and direct.},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2010-05},
  pages = {462-471},
  author = {Raizada, Rajeev D.S. and Tsao, Feng-Ming and Liu, Huei-Mei and Holloway, Ian D. and Ansari, Daniel and Kuhl, Patricia K.},
  file = {/Users/qualia/Documents/Papers/2010 - Raizada et al. - Linking brain-wide multivoxel activation patterns to behaviour Examples from language and math.pdf}
}

@article{Reddy2010,
  langid = {english},
  title = {Reading the Mind's Eye: {{Decoding}} Category Information during Mental Imagery},
  volume = {50},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811909012701},
  doi = {10.1016/j.neuroimage.2009.11.084},
  shorttitle = {Reading the Mind's Eye},
  abstract = {Category information for visually presented objects can be read out from multi-voxel patterns of fMRI activity in ventral\textendash{}temporal cortex. What is the nature and reliability of these patterns in the absence of any bottom\textendash{}up visual input, for example, during visual imagery? Here, we first ask how well category information can be decoded for imagined objects and then compare the representations evoked during imagery and actual viewing. In an fMRI study, four object categories (food, tools, faces, buildings) were either visually presented to subjects, or imagined by them. Using pattern classification techniques, we could reliably decode category information (including for non-special categories, i.e., food and tools) from ventral\textendash{}temporal cortex in both conditions, but only during actual viewing from retinotopic areas. Interestingly, in temporal cortex when the classifier was trained on the viewed condition and tested on the imagery condition, or vice versa, classification performance was comparable to within the imagery condition. The above results held even when we did not use information in the specialized category-selective areas. Thus, the patterns of representation during imagery and actual viewing are in fact surprisingly similar to each other. Consistent with this observation, the maps of ``diagnostic voxels'' (i.e., the classifier weights) for the perception and imagery classifiers were more similar in ventral\textendash{}temporal cortex than in retinotopic cortex. These results suggest that in the absence of any bottom\textendash{}up input, cortical back projections can selectively re-activate specific patterns of neural activity.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2010-04},
  pages = {818-825},
  author = {Reddy, Leila and Tsuchiya, Naotsugu and Serre, Thomas},
  file = {/Users/qualia/Documents/Papers/2010 - Reddy, Tsuchiya, Serre - Reading the mind's eye decoding category information during mental imagery.pdf}
}

@article{Rodrigues2010,
  langid = {english},
  title = {Mappings between a Macroscopic Neural-Mass Model and a Reduced Conductance-Based Model},
  volume = {102},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-010-0372-z},
  doi = {10.1007/s00422-010-0372-z},
  abstract = {We present two alternative mappings between macroscopic neuronal models and a reduction of a conductance-based model. These provide possible explanations of the relationship between parameters of these two different approaches to modelling neuronal activity. Obtaining a physical interpretation of neural-mass models is of fundamental importance as they could provide direct and accessible tools for use in diagnosing neurological conditions. Detailed consideration of the assumptions required for the validity of each mapping elucidates strengths and weaknesses of each macroscopic model and suggests improvements for future development.},
  number = {5},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2010-05},
  pages = {361-371},
  author = {Rodrigues, Serafim and Chizhov, Anton V. and Marten, Frank and Terry, John R.},
  file = {/Users/qualia/Documents/Papers/2010 - Rodrigues et al. - Mappings between a macroscopic neural-mass model and a reduced conductance-based model.pdf}
}

@article{Rowe2010,
  langid = {english},
  title = {Action Selection: {{A}} Race Model for Selected and Non-Selected Actions Distinguishes the Contribution of Premotor and Prefrontal Areas},
  volume = {51},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910002132},
  doi = {10.1016/j.neuroimage.2010.02.045},
  shorttitle = {Action Selection},
  abstract = {Race models have been used to explain perceptual, motor and oculomotor decisions. Here we developed a race model to explain how human subjects select actions when there are no overt rewards and no external cues to specify which action to make. Critically, we were able to estimate the cumulative activity of neuronal decision-units for selected and non-selected actions. We used functional magnetic resonance imaging (fMRI) to test for regional brain activity that correlated with the predictions of this race model. Activity in the preSMA, cingulate motor and premotor areas correlated with prospective selection between responses according to the race model. Activity in the lateral prefrontal cortex did not correlate with the race model, even though this area was active during action selection. This activity related to the degree to which individuals switched between alternative actions. Crucially, a follow-up experiment showed that it was not present on the first trial. Taken together, these results suggest that the lateral prefrontal cortex is not the source for the generation of action. It is more likely that it is involved in switching to alternatives or monitoring previous actions. Thus, our experiment shows the power of the race model in distinguishing the contribution of different areas in the selection of action.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2010-06},
  pages = {888-896},
  author = {Rowe, J.B. and Hughes, L. and Nimmo-Smith, I.},
  file = {/Users/qualia/Documents/Papers/2010 - Rowe, Hughes, Nimmo-Smith - Action selection a race model for selected and non-selected actions distinguishes the contribution of.pdf}
}

@article{Sabuncu2010,
  langid = {english},
  title = {Function-Based {{Intersubject Alignment}} of {{Human Cortical Anatomy}}},
  volume = {20},
  issn = {1460-2199, 1047-3211},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhp085},
  doi = {10.1093/cercor/bhp085},
  number = {1},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2010-01},
  pages = {130-140},
  author = {Sabuncu, Mert R. and Singer, Benjamin D. and Conroy, Bryan and Bryan, Ronald E. and Ramadge, Peter J. and Haxby, James V.},
  file = {/Users/qualia/Documents/Papers/2010 - Sabuncu et al. - Function-based intersubject alignment of human cortical anatomy.pdf}
}

@article{Said2010,
  langid = {english},
  title = {Distributed Representations of Dynamic Facial Expressions in the Superior Temporal Sulcus},
  volume = {10},
  issn = {1534-7362},
  url = {http://jov.arvojournals.org/Article.aspx?doi=10.1167/10.5.11},
  doi = {10.1167/10.5.11},
  abstract = {Previous research on the superior temporal sulcus (STS) has shown that it responds more to facial expressions than to neutral faces. Here, we extend our understanding of the STS in two ways. First, using targeted high-resolution fMRI measurements of the lateral cortex and multivoxel pattern analysis, we show that the response to seven categories of dynamic facial expressions can be decoded in both the posterior STS (pSTS) and anterior STS (aSTS). We were also able to decode patterns corresponding to these expressions in the frontal operculum (FO), a structure that has also been shown to respond to facial expressions. Second, we measured the similarity structure of these representations and found that the similarity structure in the pSTS significantly correlated with the perceptual similarity structure of the expressions. This was the case regardless of whether we used pattern classification or more traditional correlation techniques to extract the neural similarity structure. These results suggest that distributed representations in the pSTS could underlie the perception of facial expressions.},
  number = {5},
  journaltitle = {Journal of Vision},
  urldate = {2019-03-30},
  date = {2010-05-01},
  pages = {11-11},
  author = {Said, C. P. and Moore, C. D. and Engell, A. D. and Todorov, A. and Haxby, J. V.},
  file = {/Users/qualia/Documents/Papers/2010 - Said, Moore - Distributed representations of dynamic facial expressions in the superior temporal sulcus.pdf}
}

@article{Sapountzis2010,
  langid = {english},
  title = {A Comparison of {{fMRI}} Adaptation and Multivariate Pattern Classification Analysis in Visual Cortex},
  volume = {49},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811909010659},
  doi = {10.1016/j.neuroimage.2009.09.066},
  abstract = {Functional magnetic resonance imaging (fMRI) has become a ubiquitous tool in cognitive neuroscience. The technique allows noninvasive measurements of cortical responses in the human brain, but only on the millimeter scale. Because a typical voxel contains many thousands of neurons with varied properties, establishing the selectivity of their responses directly is impossible. In recent years, two methods using fMRI aimed at studying the selectivity of neuronal populations on a `subvoxel' scale have been heavily used. The first technique, fMRI adaptation, relies on the observation that the blood oxygen level-dependent (BOLD) response in a given voxel is reduced after prolonged presentation of a stimulus, and that this reduction is selective to the characteristics of the repeated stimuli (adapters). The second technique, multivariate pattern analysis (MVPA), makes use of multivariate statistics to recover small biases in individual voxels in their responses to different stimuli. It is thought that these biases arise due to the uneven distribution of neurons (with different properties) sampled by the many voxels in the imaged volume. These two techniques have not been compared explicitly, however, and little is known about their relative sensitivities. Here, we compared fMRI results from orientation-specific visual adaptation and orientation\textendash{}classification by MVPA, using optimized experimental designs for each, and found that the multivariate pattern classification approach was more sensitive to small differences in stimulus orientation than the adaptation paradigm. Estimates of orientation selectivity obtained with the two methods were, however, very highly correlated across visual areas.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2010-01},
  pages = {1632-1640},
  author = {Sapountzis, Panagiotis and Schluppeck, Denis and Bowtell, Richard and Peirce, Jonathan W.},
  file = {/Users/qualia/Documents/Papers/2010 - Sapountzis et al. - A comparison of fMRI adaptation and multivariate pattern classification analysis in visual cortex.pdf}
}

@article{Schmah2010,
  langid = {english},
  title = {Comparing {{Classification Methods}} for {{Longitudinal fMRI Studies}}},
  volume = {22},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00024},
  doi = {10.1162/NECO_a_00024},
  number = {11},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2010-11},
  pages = {2729-2762},
  author = {Schmah, Tanya and Yourganov, Grigori and Zemel, Richard S. and Hinton, Geoffrey E. and Small, Steven L. and Strother, Stephen C.},
  file = {/Users/qualia/Documents/Papers/2010 - Schmah et al. - Comparing classification methods for longitudinal fMRI studies.pdf}
}

@article{Schurger2010,
  langid = {english},
  title = {Reproducibility {{Distinguishes Conscious}} from {{Nonconscious Neural Representations}}},
  volume = {327},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1180029},
  doi = {10.1126/science.1180029},
  number = {5961},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2010-01-01},
  pages = {97-99},
  author = {Schurger, A. and Pereira, F. and Treisman, A. and Cohen, J. D.},
  file = {/Users/qualia/Documents/Papers/2010 - Schurger et al. - Reproducibility distinguishes conscious from nonconscious neural representations.pdf}
}

@article{Spiliotis2010,
  langid = {english},
  title = {{{MULTISCALE COMPUTATIONS ON NEURAL NETWORKS}}: {{FROM THE INDIVIDUAL NEURON INTERACTIONS TO THE MACROSCOPIC}}-{{LEVEL ANALYSIS}}},
  volume = {20},
  issn = {0218-1274, 1793-6551},
  url = {http://www.worldscientific.com/doi/abs/10.1142/S0218127410025442},
  doi = {10.1142/S0218127410025442},
  shorttitle = {{{MULTISCALE COMPUTATIONS ON NEURAL NETWORKS}}},
  abstract = {We show how the ``Equation-Free'' approach for multi-scale computations can be exploited to systematically study the dynamics of neural interactions on a random regular connected graph under a pairwise representation perspective. Using an individual-based microscopic simulator as a black box coarse-grained timestepper and with the aid of simulated annealing we compute the coarse-grained equilibrium bifurcation diagram and analyze the stability of the stationary states sidestepping the necessity of obtaining explicit closures at the macroscopic level. We also exploit the scheme to perform a rare-events analysis by estimating an effective Fokker-Planck describing the evolving probability density function of the corresponding coarse-grained observables.},
  number = {01},
  journaltitle = {International Journal of Bifurcation and Chaos},
  urldate = {2019-03-30},
  date = {2010-01},
  pages = {121-134},
  author = {Spiliotis, Konstantinos G. and Siettos, Constantinos I.},
  file = {/Users/qualia/Documents/Papers/2010 - Spiliotis, Siettos - Multiscale Computations On Neural Networks From The Individual Neuron Interactions To The Macroscopic-Level.pdf}
}

@article{Swisher2010,
  langid = {english},
  title = {Multiscale {{Pattern Analysis}} of {{Orientation}}-{{Selective Activity}} in the {{Primary Visual Cortex}}},
  volume = {30},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4811-09.2010},
  doi = {10.1523/JNEUROSCI.4811-09.2010},
  number = {1},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2010-01-06},
  pages = {325-330},
  author = {Swisher, J. D. and Gatenby, J. C. and Gore, J. C. and Wolfe, B. A. and Moon, C.-H. and Kim, S.-G. and Tong, F.},
  file = {/Users/qualia/Documents/Papers/2010 - Swisher et al. - Multiscale pattern analysis of orientation-selective activity in the primary visual cortex.pdf}
}

@article{Szepesvari2010,
  langid = {english},
  title = {Algorithms for {{Reinforcement Learning}}},
  volume = {4},
  issn = {1939-4608, 1939-4616},
  url = {http://www.morganclaypool.com/doi/abs/10.2200/S00268ED1V01Y201005AIM009},
  doi = {10.2200/S00268ED1V01Y201005AIM009},
  number = {1},
  journaltitle = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
  urldate = {2019-03-30},
  date = {2010-01},
  pages = {1-103},
  author = {Szepesv\'ari, Csaba},
  file = {/Users/qualia/Documents/Papers/2010 - Szepesvári - Algorithms for reinforcement learning.pdf}
}

@article{Thomson2010,
  langid = {english},
  title = {Neocortical Layer 6, a Review},
  issn = {16625129},
  url = {http://journal.frontiersin.org/article/10.3389/fnana.2010.00013/abstract},
  doi = {10.3389/fnana.2010.00013},
  abstract = {This review attempts to summarise some of the major areas of neocortical research as it pertains to neocortical layer 6. After a brief summary of the development of this intriguing layer, the major pyramidal cell classes to be found in layer 6 are described and compared.The connections made and received by these different classes of neurones are then discussed and the possible functions of these connections, with particular reference to the shaping of responses in visual cortex and thalamus. Inhibition in layer 6 is discussed where appropriate, but not in great detail. Many types of interneurones are to be found in each cortical layer and layer 6 is no exception, but the functions of each type remain to be elucidated (Gonchar et al., 2007).},
  journaltitle = {Frontiers in Neuroanatomy},
  urldate = {2019-03-30},
  date = {2010},
  author = {{Thomson}},
  file = {/Users/qualia/Documents/Papers/2010 - Thomson - Neocortical layer 6, a review.pdf}
}

@article{Tian2010,
  langid = {english},
  title = {Cortical Depth-Specific Microvascular Dilation Underlies Laminar Differences in Blood Oxygenation Level-Dependent Functional {{MRI}} Signal},
  volume = {107},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1006735107},
  doi = {10.1073/pnas.1006735107},
  number = {34},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2010-08-24},
  pages = {15246-15251},
  author = {Tian, P. and Teng, I. C. and May, L. D. and Kurz, R. and Lu, K. and Scadeng, M. and Hillman, E. M. C. and De Crespigny, A. J. and D'Arceuil, H. E. and Mandeville, J. B. and Marota, J. J. A. and Rosen, B. R. and Liu, T. T. and Boas, D. A. and Buxton, R. B. and Dale, A. M. and Devor, A.},
  file = {/Users/qualia/Documents/Papers/2010 - Tian et al. - Cortical depth-specific microvascular dilation underlies laminar differences in blood oxygenation level-dependent f.pdf}
}

@article{Tiesinga2010,
  langid = {english},
  title = {Mechanisms for {{Phase Shifting}} in {{Cortical Networks}} and Their {{Role}} in {{Communication}} through {{Coherence}}},
  volume = {4},
  issn = {1662-5161},
  url = {http://journal.frontiersin.org/article/10.3389/fnhum.2010.00196/abstract},
  doi = {10.3389/fnhum.2010.00196},
  abstract = {In the primate visual cortex, the phase of spikes relative to oscillations in the local field potential (LFP) in the gamma frequency range (30\textendash{}80 Hz) can be shifted by stimulus features such as orientation and thus the phase may carry information about stimulus identity. According to the principle of communication through coherence (CTC), the relative LFP phase between the LFPs in the sending and receiving circuits affects the effectiveness of the transmission. CTC predicts that phase shifting can be used for stimulus selection. We review and investigate phase shifting in models of periodically driven single neurons and compare it with phase shifting in models of cortical networks. In a single neuron, as the driving current is increased, the spike phase varies systematically while the firing rate remains constant. In a network model of reciprocally connected excitatory (E) and inhibitory (I) cells phase shifting occurs in response to both injection of constant depolarizing currents and to brief pulses to I cells. These simple models provide an account for phase-shifting observed experimentally and suggest a mechanism for implementing CTC. We discuss how this hypothesis can be tested experimentally using optogenetic techniques.},
  journaltitle = {Frontiers in Human Neuroscience},
  urldate = {2019-03-30},
  date = {2010},
  author = {Tiesinga, Paul H. and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/2010 - Tiesinga, Sejnowski - Mechanisms for Phase Shifting in Cortical Networks and their Role in Communication through Coherence.pdf}
}

@article{Tokdar2010,
  langid = {english},
  title = {Detection of Bursts in Extracellular Spike Trains Using Hidden Semi-{{Markov}} Point Process Models},
  volume = {29},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-009-0182-2},
  doi = {10.1007/s10827-009-0182-2},
  number = {1-2},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2010-08},
  pages = {203-212},
  author = {Tokdar, Surya and Xi, Peiyi and Kelly, Ryan C. and Kass, Robert E.},
  file = {/Users/qualia/Documents/Papers/2010 - Tokdar et al. - Detection of bursts in extracellular spike trains using hidden semi-Markov point process models.pdf}
}

@article{Tort2010,
  langid = {english},
  title = {Measuring {{Phase}}-{{Amplitude Coupling Between Neuronal Oscillations}} of {{Different Frequencies}}},
  volume = {104},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00106.2010},
  doi = {10.1152/jn.00106.2010},
  number = {2},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2010-08},
  pages = {1195-1210},
  author = {Tort, Adriano B. L. and Komorowski, Robert and Eichenbaum, Howard and Kopell, Nancy},
  file = {/Users/qualia/Documents/Papers/2010 - Tort et al. - Measuring phase-amplitude coupling between neuronal oscillations of different frequencies(2).pdf}
}

@article{Tsirogiannis2010,
  langid = {english},
  title = {A Population Level Computational Model of the Basal Ganglia That Generates Parkinsonian Local Field Potential Activity},
  volume = {102},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-009-0360-3},
  doi = {10.1007/s00422-009-0360-3},
  abstract = {Recordings from the basal ganglia's subthalamic nucleus are acquired via microelectrodes immediately prior to the application of Deep Brain Stimulation (DBS) treatment for Parkinson's Disease (PD) to assist in the selection of the final point for the implantation of the DBS electrode. The acquired recordings reveal a persistent characteristic beta band peak in the power spectral density function of the Local Field Potential (LFP) signals. This peak is considered to lie at the core of the causality\textendash{}effect relationships of the parkinsonian pathophysiology. Based on LFPs acquired from human subjects during DBS for PD, we constructed a computational model of the basal ganglia on the population level that generates LFPs to identify the critical pathophysiological alterations that lead to the expression of the beta band peak. To this end, we used experimental data reporting that the strengths of the synaptic connections are modified under dopamine depletion. The hypothesis that the altered dopaminergic modulation may affect both the amplitude and the time course of the postsynaptic potentials is validated by the model. The results suggest a pivotal role of both of these parameters to the pathophysiology of PD.},
  number = {2},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2010-02},
  pages = {155-176},
  author = {Tsirogiannis, George L. and Tagaris, George A. and Sakas, Damianos and Nikita, Konstantina S.},
  file = {/Users/qualia/Documents/Papers/2010 - Tsirogiannis et al. - A population level computational model of the basal ganglia that generates parkinsonian local field potenti.pdf}
}

@article{Ursino2010,
  langid = {english},
  title = {The Generation of Rhythms within a Cortical Region: {{Analysis}} of a Neural Mass Model},
  volume = {52},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811909013731},
  doi = {10.1016/j.neuroimage.2009.12.084},
  shorttitle = {The Generation of Rhythms within a Cortical Region},
  abstract = {Rhythms in brain electrical activity are assumed to play a significant role in many cognitive and perceptual processes. It is thus of great value to analyze these rhythms and their mutual relationships in large scale models of cortical regions. In the present work, we modified the neural mass model by Wendling et al. (Eur. J. Neurosci. 15 (2002) 1499\textendash{}1508) by including a new inhibitory self-loop among GABAA,fast interneurons. A theoretical analysis was performed to demonstrate that, thanks to this loop, GABAA,fast interneurons can produce a {$\gamma$} rhythm in the power spectral density (PSD) even without the participation of the other neural populations. Then, the model of a whole cortical region, built upon four interconnected neural populations (pyramidal cells, excitatory, GABAA,slow and GABAA,fast interneurons) was investigated by changing the internal connectivity parameters. Results show that different rhythm combinations ({$\beta$} and {$\gamma$}, {$\alpha$} and {$\gamma$}, or a wide spectrum) can be obtained within the same region by simply altering connectivity values, without the need to change synaptic kinetics. Finally, two or three cortical regions were connected by using different topologies of long range connections. Results show that long-range connections directed from pyramidal neurons to GABAA,fast interneurons are the most efficient to transmit rhythms from one region to another. In this way, PSD with three or four peaks can be obtained using simple connectivity patterns. The model can be of value to gain a deeper insight into the mechanisms involved in the generation of {$\gamma$} rhythms and provide a better understanding of cortical EEG spectra.},
  number = {3},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2010-09},
  pages = {1080-1094},
  author = {Ursino, Mauro and Cona, Filippo and Zavaglia, Melissa},
  file = {/Users/qualia/Documents/Papers/2010 - Ursino, Cona, Zavaglia - The generation of rhythms within a cortical region Analysis of a neural mass model.pdf}
}

@article{Wang2010,
  langid = {english},
  title = {Neurophysiological and {{Computational Principles}} of {{Cortical Rhythms}} in {{Cognition}}},
  volume = {90},
  issn = {0031-9333, 1522-1210},
  url = {http://www.physiology.org/doi/10.1152/physrev.00035.2008},
  doi = {10.1152/physrev.00035.2008},
  number = {3},
  journaltitle = {Physiological Reviews},
  urldate = {2019-03-30},
  date = {2010-07},
  pages = {1195-1268},
  author = {Wang, Xiao-Jing},
  file = {/Users/qualia/Documents/Papers/2010 - Wang - Neurophysiological and computational principles of cortical rhythms in cognition.pdf;/Users/qualia/Documents/Papers/2010 - Wang - Neurophysiological and computational principles of cortical rhythms in cognition(2).pdf}
}

@article{Wang2010a,
  langid = {english},
  title = {Synchrony of {{Thalamocortical Inputs Maximizes Cortical Reliability}}},
  volume = {328},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1183108},
  doi = {10.1126/science.1183108},
  number = {5974},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2010-04-02},
  pages = {106-109},
  author = {Wang, H. P. and Spencer, D. and Fellous, J. M. and Sejnowski, T. J.},
  file = {/Users/qualia/Documents/Papers/2010 - Wang et al. - Synchrony of Thalamocortical Inputs Maximizes Cortical Reliability.pdf}
}

@article{Wongsarnpigoon2010,
  langid = {english},
  title = {Efficiency {{Analysis}} of {{Waveform Shape}} for {{Electrical Excitation}} of {{Nerve Fibers}}},
  volume = {18},
  issn = {1534-4320, 1558-0210},
  url = {http://ieeexplore.ieee.org/document/5446391/},
  doi = {10.1109/TNSRE.2010.2047610},
  abstract = {Stimulation efficiency is an important consideration in the stimulation parameters of implantable neural stimulators. The objective of this study was to analyze the effects of waveform shape and duration on the charge, power, and energy efficiency of neural stimulation. Using a population model of mammalian axons and in vivo experiments on cat sciatic nerve, we analyzed the stimulation efficiency of four waveform shapes: square, rising exponential, decaying exponential, and rising ramp. No waveform was simultaneously energy-, charge-, and power-optimal, and differences in efficiency among waveform shapes varied with pulse width (PW) For short PWs ({$\leq$} 0.1 ms), square waveforms were no less energy-efficient than exponential waveforms, and the most charge-efficient shape was the ramp. For long PWs ({$\geq$}0.5 ms), the square was the least energy-efficient and charge-efficient shape, but across most PWs, the square was the most powerefficient shape. Rising exponentials provided no practical gains in efficiency over the other shapes, and our results refute previous claims that the rising exponential is the energy-optimal shape. An improved understanding of how stimulation parameters affect stimulation efficiency will help improve the design and programming of implantable stimulators to minimize tissue damage and extend battery life.},
  number = {3},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  urldate = {2019-03-30},
  date = {2010-06},
  pages = {319-328},
  author = {Wongsarnpigoon, Amorn and Woock, John P and Grill, Warren M},
  file = {/Users/qualia/Documents/Papers/2010 - Wongsarnpigoon, Woock, Grill - Efficiency analysis of waveform shape for electrical excitation of nerve fibers.pdf}
}

@article{Afshar2011,
  langid = {english},
  title = {Single-{{Trial Neural Correlates}} of {{Arm Movement Preparation}}},
  volume = {71},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627311005174},
  doi = {10.1016/j.neuron.2011.05.047},
  abstract = {The process by which neural circuitry in the brain plans and executes movements is not well understood. Until recently, most available data were limited either to single-neuron electrophysiological recordings or to measures of aggregate field or metabolism. Neither approach reveals how individual neurons' activities are coordinated within the population, and thus inferences about how the neural circuit forms a motor plan for an upcoming movement have been indirect. Here we build on recent advances in the measurement and description of population activity to frame and test an ``initial condition hypothesis'' of arm movement preparation and initiation. This hypothesis leads to a model in which the timing of movements may be predicted on each trial using neurons' moment-by-moment firing rates and rates of change of those rates. Using simultaneous microelectrode array recordings from premotor cortex of monkeys performing delayed-reach movements, we compare such single-trial predictions to those of other theories. We show that our model can explain approximately 4-fold more arm-movement reaction-time variance than the best alternative method. Thus, the initial condition hypothesis elucidates a view of the relationship between single-trial preparatory neural population dynamics and single-trial behavior.},
  number = {3},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2011-08},
  pages = {555-564},
  author = {Afshar, Afsheen and Santhanam, Gopal and Yu, Byron M. and Ryu, Stephen I. and Sahani, Maneesh and Shenoy, Krishna V.},
  file = {/Users/qualia/Documents/Papers/2011 - Afshar et al. - Single-trial neural correlates of arm movement preparation.pdf}
}

@article{Assisi2011,
  langid = {english},
  title = {Using the {{Structure}} of {{Inhibitory Networks}} to {{Unravel Mechanisms}} of {{Spatiotemporal Patterning}}},
  volume = {69},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627310010421},
  doi = {10.1016/j.neuron.2010.12.019},
  abstract = {Neuronal networks exhibit a rich dynamical repertoire, a consequence of both the intrinsic properties of neurons and the structure of the network. It has been hypothesized that inhibitory interneurons corral principal neurons into transiently synchronous ensembles that encode sensory information and subserve behavior. How does the structure of the inhibitory network facilitate such spatiotemporal patterning? We established a relationship between an important structural property of a network, its colorings, and the dynamics it constrains. Using a model of the insect antennal lobe, we show that our description allows the explicit identification of the groups of inhibitory interneurons that switch, during odor stimulation, between activity and quiescence in a coordinated manner determined by features of the network structure. This description optimally matches the perspective of the downstream neurons looking for synchrony in ensembles of presynaptic cells and allows a low-dimensional description of seemingly complex high-dimensional network activity.},
  number = {2},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2011-01},
  pages = {373-386},
  author = {Assisi, Collins and Stopfer, Mark and Bazhenov, Maxim},
  file = {/Users/qualia/Documents/Papers/2011 - Assisi, Stopfer, Bazhenov - Using the structure of inhibitory networks to unravel mechanisms of spatiotemporal patterning.pdf}
}

@article{Chersi2011,
  langid = {english},
  title = {Neuronal {{Chains}} for {{Actions}} in the {{Parietal Lobe}}: {{A Computational Model}}},
  volume = {6},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0027652},
  doi = {10.1371/journal.pone.0027652},
  shorttitle = {Neuronal {{Chains}} for {{Actions}} in the {{Parietal Lobe}}},
  abstract = {The inferior part of the parietal lobe (IPL) is known to play a very important role in sensorimotor integration. Neurons in this region code goal-related motor acts performed with the mouth, with the hand and with the arm. It has been demonstrated that most IPL motor neurons coding a specific motor act (e.g., grasping) show markedly different activation patterns according to the final goal of the action sequence in which the act is embedded (grasping for eating or grasping for placing). Some of these neurons (parietal mirror neurons) show a similar selectivity also during the observation of the same action sequences when executed by others. Thus, it appears that the neuronal response occurring during the execution and the observation of a specific grasping act codes not only the executed motor act, but also the agent's final goal (intention). In this work we present a biologically inspired neural network architecture that models mechanisms of motor sequences execution and recognition. In this network, pools composed of motor and mirror neurons that encode motor acts of a sequence are arranged in form of action goal-specific neuronal chains. The execution and the recognition of actions is achieved through the propagation of activity bursts along specific chains modulated by visual and somatosensory inputs. The implemented spiking neuron network is able to reproduce the results found in neurophysiological recordings of parietal neurons during task performance and provides a biologically plausible implementation of the action selection and recognition process. Finally, the present paper proposes a mechanism for the formation of new neural chains by linking together in a sequential manner neurons that represent subsequent motor acts, thus producing goal-directed sequences.},
  number = {11},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2011-11-28},
  pages = {e27652},
  author = {Chersi, Fabian and Ferrari, Pier Francesco and Fogassi, Leonardo},
  editor = {Meck, Warren H.},
  file = {/Users/qualia/Documents/Papers/2011 - Chersi, Ferrari, Fogassi - Neuronal chains for actions in the parietal lobe A computational model.pdf}
}

@article{Childs2011,
  langid = {english},
  title = {From {{Inflammation}} to {{Wound Healing}}: {{Using}} a {{Simple Model}} to {{Understand}} the {{Functional Versatility}} of {{Murine Macrophages}}},
  volume = {73},
  issn = {0092-8240, 1522-9602},
  url = {http://link.springer.com/10.1007/s11538-011-9637-5},
  doi = {10.1007/s11538-011-9637-5},
  shorttitle = {From {{Inflammation}} to {{Wound Healing}}},
  number = {11},
  journaltitle = {Bulletin of Mathematical Biology},
  urldate = {2019-03-30},
  date = {2011-11},
  pages = {2575-2604},
  author = {Childs, Lauren M. and Paskow, Michael and Morris, Sidney M. and Hesse, Matthias and Strogatz, Steven},
  file = {/Users/qualia/Documents/Papers/2011 - Childs et al. - From Inflammation to Wound Healing Using a Simple Model to Understand the Functional Versatility of Murine Macrop.pdf}
}

@article{Clithero2011,
  langid = {english},
  title = {Within- and Cross-Participant Classifiers Reveal Different Neural Coding of Information},
  volume = {56},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910003447},
  doi = {10.1016/j.neuroimage.2010.03.057},
  abstract = {Analyzing distributed patterns of brain activation using multivariate pattern analysis (MVPA) has become a popular approach for using functional magnetic resonance imaging (fMRI) data to predict mental states. While the majority of studies currently build separate classifiers for each participant in the sample, in principle a single classifier can be derived from and tested on data from all participants. These two approaches, within- and cross-participant classification, rely on potentially different sources of variability and thus may provide distinct information about brain function. Here, we used both approaches to identify brain regions that contain information about passively received monetary rewards (i.e., images of currency that influenced participant payment) and social rewards (i.e., images of human faces). Our withinparticipant analyses implicated regions in the ventral visual processing stream\textemdash{}including fusiform gyrus and primary visual cortex\textemdash{}and ventromedial prefrontal cortex (VMPFC). Two key results indicate these regions may contain statistically discriminable patterns that contain different informational representations. First, cross-participant analyses implicated additional brain regions, including striatum and anterior insula. The cross-participant analyses also revealed systematic changes in predictive power across brain regions, with the pattern of change consistent with the functional properties of regions. Second, individual differences in classifier performance in VMPFC were related to individual differences in preferences between our two reward modalities. We interpret these results as reflecting a distinction between patterns showing participant-specific functional organization and those indicating aspects of brain organization that generalize across individuals.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-05},
  pages = {699-708},
  author = {Clithero, John A. and Smith, David V. and Carter, R. McKell and Huettel, Scott A.},
  file = {/Users/qualia/Documents/Papers/2011 - Clithero et al. - Within- and cross-participant classifiers reveal different neural coding of information.pdf}
}

@article{DeDeo2011,
  langid = {english},
  title = {Effective Theories for Circuits and Automata},
  volume = {21},
  issn = {1054-1500, 1089-7682},
  url = {http://aip.scitation.org/doi/10.1063/1.3640747},
  doi = {10.1063/1.3640747},
  number = {3},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  urldate = {2019-03-30},
  date = {2011-09},
  pages = {037106},
  author = {DeDeo, Simon},
  file = {/Users/qualia/Documents/Papers/2011 - DeDeo - Effective theories for circuits and automata.pdf}
}

@article{Diedrichsen2011,
  langid = {english},
  title = {Comparing the Similarity and Spatial Structure of Neural Representations: {{A}} Pattern-Component Model},
  volume = {55},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811911000796},
  doi = {10.1016/j.neuroimage.2011.01.044},
  shorttitle = {Comparing the Similarity and Spatial Structure of Neural Representations},
  abstract = {In recent years there has been growing interest in multivariate analyses of neuroimaging data, which can be used to detect distributed patterns of activity that encode an experimental factor of interest. In this setting, it has become common practice to study the correlations between patterns to make inferences about the way a brain region represents stimuli or tasks (known as representational similarity analysis). Although it would be of great interest to compare these correlations from different regions, direct comparisons are currently not possible. This is because sample correlations are strongly influenced by voxel-selection, fMRI noise, and nonspecific activation patterns, all of which can differ widely between regions. Here, we present a multivariate modeling framework in which the measured patterns are decomposed into their constituent parts. The model is based on a standard linear mixed model, in which pattern components are considered to be randomly distributed over voxels. The model allows one to estimate the true correlations of the underlying neuronal pattern components, thereby enabling comparisons between different regions or individuals. The pattern estimates also allow us to make inferences about the spatial structure of different response components. Thus, the new model provides a theoretical and analytical framework to study the structure of distributed neural representations.},
  number = {4},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-04},
  pages = {1665-1678},
  author = {Diedrichsen, J\"orn and Ridgway, Gerard R. and Friston, Karl J. and Wiestler, Tobias},
  file = {/Users/qualia/Documents/Papers/2011 - Diedrichsen et al. - Comparing the similarity and spatial structure of neural representations a pattern-component model.pdf}
}

@article{Druckmann2011,
  langid = {english},
  title = {Effective {{Stimuli}} for {{Constructing Reliable Neuron Models}}},
  volume = {7},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1002133},
  doi = {10.1371/journal.pcbi.1002133},
  abstract = {The rich dynamical nature of neurons poses major conceptual and technical challenges for unraveling their nonlinear membrane properties. Traditionally, various current waveforms have been injected at the soma to probe neuron dynamics, but the rationale for selecting specific stimuli has never been rigorously justified. The present experimental and theoretical study proposes a novel framework, inspired by learning theory, for objectively selecting the stimuli that best unravel the neuron's dynamics. The efficacy of stimuli is assessed in terms of their ability to constrain the parameter space of biophysically detailed conductance-based models that faithfully replicate the neuron's dynamics as attested by their ability to generalize well to the neuron's response to novel experimental stimuli. We used this framework to evaluate a variety of stimuli in different types of cortical neurons, ages and animals. Despite their simplicity, a set of stimuli consisting of step and ramp current pulses outperforms synaptic-like noisy stimuli in revealing the dynamics of these neurons. The general framework that we propose paves a new way for defining, evaluating and standardizing effective electrical probing of neurons and will thus lay the foundation for a much deeper understanding of the electrical nature of these highly sophisticated and non-linear devices and of the neuronal networks that they compose.},
  number = {8},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2011-08-18},
  pages = {e1002133},
  author = {Druckmann, Shaul and Berger, Thomas K. and Sch\"urmann, Felix and Hill, Sean and Markram, Henry and Segev, Idan},
  editor = {Graham, Lyle J.},
  file = {/Users/qualia/Documents/Papers/2011 - Druckmann et al. - Effective stimuli for constructing reliable neuron models.pdf}
}

@article{Forger2011,
  langid = {english},
  title = {Optimal {{Stimulus Shapes}} for {{Neuronal Excitation}}},
  volume = {7},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1002089},
  doi = {10.1371/journal.pcbi.1002089},
  abstract = {An important problem in neuronal computation is to discern how features of stimuli control the timing of action potentials. One aspect of this problem is to determine how an action potential, or spike, can be elicited with the least energy cost, e.g., a minimal amount of applied current. Here we show in the Hodgkin \& Huxley model of the action potential and in experiments on squid giant axons that: 1) spike generation in a neuron can be highly discriminatory for stimulus shape and 2) the optimal stimulus shape is dependent upon inputs to the neuron. We show how polarity and time course of postsynaptic currents determine which of these optimal stimulus shapes best excites the neuron. These results are obtained mathematically using the calculus of variations and experimentally using a stochastic search methodology. Our findings reveal a surprising complexity of computation at the single cell level that may be relevant for understanding optimization of signaling in neurons and neuronal networks.},
  number = {7},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2011-07-07},
  pages = {e1002089},
  author = {Forger, Daniel B. and Paydarfar, David and Clay, John R.},
  editor = {Morrison, Abigail},
  file = {/Users/qualia/Documents/Papers/2011 - Forger, Paydarfar, Clay - Optimal Stimulus Shapes for Neuronal Excitation.pdf}
}

@article{Foxe2011,
  langid = {english},
  title = {The {{Role}} of {{Alpha}}-{{Band Brain Oscillations}} as a {{Sensory Suppression Mechanism}} during {{Selective Attention}}},
  volume = {2},
  issn = {1664-1078},
  url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2011.00154/abstract},
  doi = {10.3389/fpsyg.2011.00154},
  abstract = {Evidence has amassed from both animal intracranial recordings and human electrophysiology that neural oscillatory mechanisms play a critical role in a number of cognitive functions such as learning, memory, feature binding and sensory gating. The wide availability of high-density electrical and magnetic recordings (64\textendash{}256 channels) over the past two decades has allowed for renewed efforts in the characterization and localization of these rhythms. A variety of cognitive effects that are associated with specific brain oscillations have been reported, which range in spectral, temporal, and spatial characteristics depending on the context. Our laboratory has focused on investigating the role of alpha-band oscillatory activity (8\textendash{}14 Hz) as a potential attentional suppression mechanism, and this particular oscillatory attention mechanism will be the focus of the current review. We discuss findings in the context of intersensory selective attention as well as intrasensory spatial and feature-based attention in the visual, auditory, and tactile domains. The weight of evidence suggests that alpha-band oscillations can be actively invoked within cortical regions across multiple sensory systems, particularly when these regions are involved in processing irrelevant or distracting information. That is, a central role for alpha seems to be as an attentional suppression mechanism when objects or features need to be specifically ignored or selected against.},
  journaltitle = {Frontiers in Psychology},
  urldate = {2019-03-30},
  date = {2011},
  author = {Foxe, John J. and Snyder, Adam C.},
  file = {/Users/qualia/Documents/Papers/2011 - Foxe, Snyder - The role of alpha-band brain oscillations as a sensory suppression mechanism during selective attention.pdf}
}

@article{Frank2012,
  langid = {english},
  title = {Mechanisms of {{Hierarchical Reinforcement Learning}} in {{Corticostriatal Circuits}} 1: {{Computational Analysis}}},
  volume = {22},
  issn = {1460-2199, 1047-3211},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhr114},
  doi = {10.1093/cercor/bhr114},
  shorttitle = {Mechanisms of {{Hierarchical Reinforcement Learning}} in {{Corticostriatal Circuits}} 1},
  abstract = {Growing evidence suggests that the prefrontal cortex (PFC) is organized hierarchically, with more anterior regions having increasingly abstract representations. How does this organization support hierarchical cognitive control and the rapid discovery of abstract action rules? We present computational models at different levels of description. A neural circuit model simulates interacting corticostriatal circuits organized hierarchically. In each circuit the basal ganglia (BG) gate frontal actions, with some striatal units gating the inputs to PFC, and others gating the outputs to influence response selection. Learning at all of these levels is accomplished via dopaminergic reward prediction error signals in each corticostriatal circuit. This functionality allows the system to exhibit conditional if-then hypothesis testing and to learn rapidly in environments with hierarchical structure. We also develop a hybrid Bayesian-RL mixture of experts (MoE) model, which can estimate the most likely hypothesis state of individual participants based on their observed sequence of choices and rewards. This model yields accurate probabilistic estimates about which hypotheses are attended by manipulating attentional states in the generative neural model and recovering them with the MoE model. This two-pronged modeling approach leads to multiple quantitative predictions that are tested with fMRI in the companion paper.},
  number = {3},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2012-03},
  pages = {509-526},
  author = {Frank, Michael J. and Badre, David},
  file = {/Users/qualia/Documents/Papers/2011 - Frank, Badre - Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1 computational analysis.pdf}
}

@article{Gilbert2011,
  langid = {english},
  title = {Decoding the {{Content}} of {{Delayed Intentions}}},
  volume = {31},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5336-10.2011},
  doi = {10.1523/JNEUROSCI.5336-10.2011},
  number = {8},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2011-02-23},
  pages = {2888-2894},
  author = {Gilbert, S. J.},
  file = {/Users/qualia/Documents/Papers/2011 - Gilbert - Decoding the content of delayed intentions.pdf}
}

@article{Gjorgjieva2011,
  langid = {english},
  title = {A Triplet Spike-Timing-Dependent Plasticity Model Generalizes the {{Bienenstock}}-{{Cooper}}-{{Munro}} Rule to Higher-Order Spatiotemporal Correlations},
  volume = {108},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1105933108},
  doi = {10.1073/pnas.1105933108},
  number = {48},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2011-11-29},
  pages = {19383-19388},
  author = {Gjorgjieva, J. and Clopath, C. and Audet, J. and Pfister, J.-P.},
  file = {/Users/qualia/Documents/Papers/2011 - Gjorgjieva et al. - A triplet spike-timing-dependent plasticity model generalizes the Bienenstock-Cooper-Munro rule to higher-ord.pdf}
}

@article{Haegens2011,
  langid = {english},
  title = {-{{Oscillations}} in the Monkey Sensorimotor Network Influence Discrimination Performance by Rhythmical Inhibition of Neuronal Spiking},
  volume = {108},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1117190108},
  doi = {10.1073/pnas.1117190108},
  number = {48},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2011-11-29},
  pages = {19377-19382},
  author = {Haegens, S. and Nacher, V. and Luna, R. and Romo, R. and Jensen, O.},
  file = {/Users/qualia/Documents/Papers/2011 - Haegens et al. - α-Oscillations in the monkey sensorimotor network influence discrimination performance by rhythmical inhibition.pdf}
}

@article{Haxby2011,
  langid = {english},
  title = {A {{Common}}, {{High}}-{{Dimensional Model}} of the {{Representational Space}} in {{Human Ventral Temporal Cortex}}},
  volume = {72},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627311007811},
  doi = {10.1016/j.neuron.2011.08.026},
  abstract = {We present a high-dimensional model of the representational space in human ventral temporal (VT) cortex in which dimensions are response-tuning functions that are common across individuals and patterns of response are modeled as weighted sums of basis patterns associated with these response tunings. We map response-pattern vectors, measured with fMRI, from individual subjects' voxel spaces into this common model space using a new method, ``hyperalignment.'' Hyperalignment parameters based on responses during one experiment\textemdash{}movie viewing\textemdash{}identified 35 common response-tuning functions that captured fine-grained distinctions among a wide range of stimuli in the movie and in two category perception experiments. Between-subject classification (BSC, multivariate pattern classification based on other subjects' data) of response-pattern vectors in common model space greatly exceeded BSC of anatomically aligned responses and matched withinsubject classification. Results indicate that population codes for complex visual stimuli in VT cortex are based on response-tuning functions that are common across individuals.},
  number = {2},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2011-10},
  pages = {404-416},
  author = {Haxby, James V. and Guntupalli, J. Swaroop and Connolly, Andrew C. and Halchenko, Yaroslav O. and Conroy, Bryan R. and Gobbini, M. Ida and Hanke, Michael and Ramadge, Peter J.},
  file = {/Users/qualia/Documents/Papers/2011 - Haxby et al. - A common, high-dimensional model of the representational space in human ventral temporal cortex.pdf}
}

@article{Hong2011,
  langid = {english},
  title = {Conformists and Contrarians in a {{Kuramoto}} Model with Identical Natural Frequencies},
  volume = {84},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.84.046202},
  doi = {10.1103/PhysRevE.84.046202},
  number = {4},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2011-10-04},
  author = {Hong, Hyunsuk and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/2011 - Hong, Strogatz - Conformists and contrarians in a Kuramoto model with identical natural frequencies.pdf}
}

@article{Jirsa2011,
  langid = {english},
  title = {Neural {{Population Modes Capture Biologically Realistic Large Scale Network Dynamics}}},
  volume = {73},
  issn = {0092-8240, 1522-9602},
  url = {http://link.springer.com/10.1007/s11538-010-9573-9},
  doi = {10.1007/s11538-010-9573-9},
  abstract = {Large scale brain networks are understood nowadays to underlie the emergence of cognitive functions, though the detailed mechanisms are hitherto unknown. The challenges in the study of large scale brain networks are amongst others their high dimensionality requiring significant computational efforts, the complex connectivity across brain areas and the associated transmission delays, as well as the stochastic nature of neuronal processes. To decrease the computational effort, neurons are clustered into neural masses, which then are approximated by reduced descriptions of population dynamics. Here, we implement a neural population mode approach (Assisi et al. in Phys. Rev. Lett. 94(1):018106, 2005; Stefanescu and Jirsa in PLoS Comput. Biol. 4(11):e1000219, 2008), which parsimoniously captures various types of population behavior. We numerically demonstrate that the reduced population mode system favorably captures the high-dimensional dynamics of neuron networks with an architecture involving homogeneous local connectivity and a large-scale, fiber-like connection with time delay.},
  number = {2},
  journaltitle = {Bulletin of Mathematical Biology},
  urldate = {2019-03-30},
  date = {2011-02},
  pages = {325-343},
  author = {Jirsa, Viktor K. and Stefanescu, Roxana A.},
  file = {/Users/qualia/Documents/Papers/2011 - Jirsa, Stefanescu - Neural Population Modes Capture Biologically Realistic Large Scale Network Dynamics.pdf}
}

@article{Kahnt2011,
  langid = {english},
  title = {Decoding Different Roles for {{vmPFC}} and {{dlPFC}} in Multi-Attribute Decision Making},
  volume = {56},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910007913},
  doi = {10.1016/j.neuroimage.2010.05.058},
  abstract = {In everyday life, successful decision making requires precise representations of expected values. However, for most behavioral options more than one attribute can be relevant in order to predict the expected reward. Thus, to make good or even optimal choices the reward predictions of multiple attributes need to be integrated into a combined expected value. Importantly, the individual attributes of such multi-attribute objects can agree or disagree in their reward prediction. Here we address where the brain encodes the combined reward prediction (averaged across attributes) and where it encodes the variability of the value predictions of the individual attributes. We acquired fMRI data while subjects performed a task in which they had to integrate reward predictions from multiple attributes into a combined value. Using time-resolved pattern recognition techniques (support vector regression) we find that (1) the combined value is encoded in distributed fMRI patterns in the ventromedial prefrontal cortex (vmPFC) and that (2) the variability of value predictions of the individual attributes is encoded in the dorsolateral prefrontal cortex (dlPFC). The combined value could be used to guide choices, whereas the variability of the value predictions of individual attributes indicates an ambiguity that results in an increased difficulty of the value-integration. These results demonstrate that the different features defining multi-attribute objects are encoded in non-overlapping brain regions and therefore suggest different roles for vmPFC and dlPFC in multi-attribute decision making. \textcopyright{} 2010 Elsevier Inc. All rights reserved.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-05},
  pages = {709-715},
  author = {Kahnt, Thorsten and Heinzle, Jakob and Park, Soyoung Q. and Haynes, John-Dylan},
  file = {/Users/qualia/Documents/Papers/2011 - Kahnt et al. - Decoding different roles for vmPFC and dlPFC in multi-attribute decision making.pdf}
}

@article{Kass2011,
  langid = {english},
  title = {Assessment of Synchrony in Multiple Neural Spike Trains Using Loglinear Point Process Models},
  volume = {5},
  issn = {1932-6157},
  url = {http://projecteuclid.org/euclid.aoas/1310562721},
  doi = {10.1214/10-AOAS429},
  issue = {2B},
  journaltitle = {The Annals of Applied Statistics},
  urldate = {2019-03-30},
  date = {2011-06},
  pages = {1262-1292},
  author = {Kass, Robert E. and Kelly, Ryan C. and Loh, Wei-Liem},
  file = {/Users/qualia/Documents/Papers/2011 - Kass, Kelly, Loh - Assessment of synchrony in multiple neural spike trains using loglinear point process models.pdf}
}

@article{Choi,
  langid = {english},
  title = {Inverse {{Reinforcement Learning}} in {{Partially Observable Environments}}},
  abstract = {Inverse reinforcement learning (IRL) is the problem of recovering the underlying reward function from the behavior of an expert. Most of the existing IRL algorithms assume that the environment is modeled as a Markov decision process (MDP), although it is desirable to handle partially observable settings in order to handle more realistic scenarios. In this paper, we present IRL algorithms for partially observable environments that can be modeled as a partially observable Markov decision process (POMDP). We deal with two cases according to the representation of the given expert's behavior, namely the case in which the expert's policy is explicitly given, and the case in which the expert's trajectories are available instead. The IRL in POMDPs poses a greater challenge than in MDPs since it is not only ill-posed due to the nature of IRL, but also computationally intractable due to the hardness in solving POMDPs. To overcome these obstacles, we present algorithms that exploit some of the classical results from the POMDP literature. Experimental results on several benchmark POMDP domains show that our work is useful for partially observable settings.},
  pages = {40},
  author = {Choi, Jaedeug and Kim, Kee-Eung and Kr, Ai Kaist Ac and Kr, Cs Kaist Ac},
  file = {/Users/qualia/Documents/Papers/2011 - Kim - Inverse Reinforcement Learning in Partially Observable Environments.pdf}
}

@article{Kriegeskorte2011,
  langid = {english},
  title = {Pattern-Information Analysis: {{From}} Stimulus Decoding to Computational-Model Testing},
  volume = {56},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811911000978},
  doi = {10.1016/j.neuroimage.2011.01.061},
  shorttitle = {Pattern-Information Analysis},
  abstract = {Pattern-information analysis has become an important new paradigm in functional imaging. Here I review and compare existing approaches with a focus on the question of what we can learn from them in terms of brain theory. The most popular and widespread method is stimulus decoding by response-pattern classification. This approach addresses the question whether activity patterns in a given region carry information about the stimulus category. Pattern classification uses generic models of the stimulus\textendash{}response relationship that do not mimic brain information processing and treats the stimulus space as categorical\textemdash{}a simplification that is often helpful, but also limiting in terms of the questions that can be addressed. We can address the question whether representations are consistent across different stimulus sets or tasks by crossdecoding, where the classifier is trained with one set of stimuli (or task) and tested with another. Beyond pattern classification, a major new direction is the integration of computational models of brain information processing into pattern-information analysis. This approach enables us to address the question to what extent competing computational models are consistent with the stimulus representations in a brain region. Two methods that test computational models are voxel receptive-field modeling and representational similarity analysis. These methods sample the stimulus (or mental-state) space more richly, estimate a separate response pattern for each stimulus, and can generalize from the stimulus sample to a stimulus population. Computational models that mimic brain information processing predict responses from stimuli. The reverse transform can be modeled to reconstruct stimuli from responses. Stimulus reconstruction is a challenging feat of engineering, but the implications of the results for brain theory are not always clear. Exploratory pattern analyses complement the confirmatory approaches mentioned so far and can reveal strong, unexpected effects that might be missed when testing only a restricted set of predefined hypotheses.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-05},
  pages = {411-421},
  author = {Kriegeskorte, Nikolaus},
  file = {/Users/qualia/Documents/Papers/2011 - Kriegeskorte - Pattern-information analysis from stimulus decoding to computational-model testing.pdf}
}

@article{Kumar2011,
  langid = {english},
  title = {The {{Role}} of {{Inhibition}} in {{Generating}} and {{Controlling Parkinson}}?S {{Disease Oscillations}} in the {{Basal Ganglia}}},
  volume = {5},
  issn = {1662-5137},
  url = {http://journal.frontiersin.org/article/10.3389/fnsys.2011.00086/abstract},
  doi = {10.3389/fnsys.2011.00086},
  shorttitle = {The {{Role}} of {{Inhibition}} in {{Generating}} and {{Controlling Parkinson}}?},
  abstract = {Movement disorders in Parkinson's disease (PD) are commonly associated with slow oscillations and increased synchrony of neuronal activity in the basal ganglia. The neural mechanisms underlying this dynamic network dysfunction, however, are only poorly understood. Here, we show that the strength of inhibitory inputs from striatum to globus pallidus external (GPe) is a key parameter controlling oscillations in the basal ganglia. Specifically, the increase in striatal activity observed in PD is sufficient to unleash the oscillations in the basal ganglia. This finding allows us to propose a unified explanation for different phenomena: absence of oscillation in the healthy state of the basal ganglia, oscillations in dopamine-depleted state and quenching of oscillations under deep-brain-stimulation (DBS). These novel insights help us to better understand and optimize the function of DBS protocols. Furthermore, studying the model behavior under transient increase of activity of the striatal neurons projecting to the indirect pathway, we are able to account for both motor impairment in PD patients and for reduced response inhibition in DBS implanted patients.},
  journaltitle = {Frontiers in Systems Neuroscience},
  urldate = {2019-03-30},
  date = {2011},
  author = {Kumar, Arvind and Cardanobile, Stefano and Rotter, Stefan and Aertsen, Ad},
  file = {/Users/qualia/Documents/Papers/2011 - Kumar et al. - The Role of Inhibition in Generating and Controlling Parkinsons Disease Oscillations in the Basal Ganglia.pdf}
}

@article{Lee2011,
  langid = {english},
  title = {Investigation of Melodic Contour Processing in the Brain Using Multivariate Pattern-Based {{fMRI}}},
  volume = {57},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811911001443},
  doi = {10.1016/j.neuroimage.2011.02.006},
  abstract = {Music perception generally involves processing the frequency relationships between successive pitches and 34 extraction of the melodic contour. Previous evidence has suggested that the `ups' and `downs' of melodic 35 contour are categorically and automatically processed, but knowledge of the brain regions that discriminate 36 different types of contour is limited. Here, we examined melodic contour discrimination using multivariate 37 pattern analysis (MVPA) of fMRI data. Twelve non-musicians were presented with various ascending and 38 descending melodic sequences while being scanned. Whole-brain MVPA was used to identify regions in 39 which the local pattern of activity accurately discriminated between contour categories. We identified three 40 distinct cortical loci: the right superior temporal sulcus (rSTS), the left inferior parietal lobule (lIPL), and the 41 anterior cingulate cortex (ACC). These results complement previous findings of melodic processing within the 42 rSTS, and extend our understanding of the way in which abstract auditory sequences are categorized by the 43 human brain.},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-07},
  pages = {293-300},
  author = {Lee, Yune-Sang and Janata, Petr and Frost, Carlton and Hanke, Michael and Granger, Richard},
  file = {/Users/qualia/Documents/Papers/2011 - Lee et al. - Investigation of melodic contour processing in the brain using multivariate pattern-based fMRI.pdf}
}

@article{Mace2011,
  langid = {english},
  title = {Functional Ultrasound Imaging of the Brain},
  volume = {8},
  issn = {1548-7091, 1548-7105},
  url = {http://www.nature.com/articles/nmeth.1641},
  doi = {10.1038/nmeth.1641},
  number = {8},
  journaltitle = {Nature Methods},
  urldate = {2019-03-30},
  date = {2011-08},
  pages = {662-664},
  author = {Mac\'e, Emilie and Montaldo, Gabriel and Cohen, Ivan and Baulac, Michel and Fink, Mathias and Tanter, Mickael},
  file = {/Users/qualia/Documents/Papers/2011 - Macé et al. - Functional ultrasound imaging of the brain.pdf}
}

@article{London2010,
  langid = {english},
  title = {Sensitivity to Perturbations in Vivo Implies High Noise and Suggests Rate Coding in Cortex},
  volume = {466},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/doifinder/10.1038/nature09086},
  doi = {10.1038/nature09086},
  abstract = {It is well known that neural activity exhibits variability, in the sense that identical sensory stimuli produce different responses, but it has been difficult to determine what this variability means. Is it noise, or does it carry important information \textendash{} about, for example, the internal state of the organism? We address this issue from the bottom up, by asking whether small perturbations to activity in cortical networks are amplified. Based on in vivo whole-cell recordings in rat barrel cortex, we find that a perturbation consisting of a single extra spike in one neuron produces \textasciitilde{}28 additional spikes in its postsynaptic targets, and we show, using simultaneous intra- and extracellular recordings, that a single spike produces a detectable increase in firing rate in the local network. Theoretical analysis indicates that this amplification leads to intrinsic, stimulusindependent variations in membrane potential on the order of {$\pm$}2.2 - 4.5 mV \textendash{} variations that are pure noise, and so carry no information at all. Therefore, for the brain to perform reliable computations, it must either use a rate code, or generate very large, fast depolarizing events, such as those proposed by the theory of synfire chains \textendash{} yet in our in vivo recordings, we found that such events were very rare. Our findings are consistent with the idea that cortex is likely to use primarily a rate code.},
  number = {7302},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2010-07-01},
  pages = {123-127},
  author = {London, Michael and Roth, Arnd and Beeren, Lisa and H\"ausser, Michael and Latham, Peter E.},
  file = {/Users/qualia/Documents/Papers/2011 - Manuscript - NIH Public Access.pdf}
}

@article{Marquand2011,
  langid = {english},
  title = {Pattern {{Classification}} of {{Working Memory Networks Reveals Differential Effects}} of {{Methylphenidate}}, {{Atomoxetine}} and {{Placebo}} in {{Healthy Volunteers}}},
  volume = {36},
  issn = {0893-133X, 1740-634X},
  url = {http://www.nature.com/articles/npp20119},
  doi = {10.1038/npp.2011.9},
  number = {6},
  journaltitle = {Neuropsychopharmacology},
  urldate = {2019-03-30},
  date = {2011-05},
  pages = {1237-1247},
  author = {Marquand, Andre F and De Simoni, Sara and O'Daly, Owen G and Williams, Steven CR and Mour\~ao-Miranda, Janaina and Mehta, Mitul A},
  file = {/Users/qualia/Documents/Papers/2011 - Marquand et al. - Pattern classification of working memory networks reveals differential effects of methylphenidate, atomoxetine,.pdf}
}

@article{Marvel2011,
  langid = {english},
  title = {Continuous-Time Model of Structural Balance},
  volume = {108},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1013213108},
  doi = {10.1073/pnas.1013213108},
  number = {5},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2011-02-01},
  pages = {1771-1776},
  author = {Marvel, Seth A. and Kleinberg, Jon and Kleinberg, Robert D. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/2011 - Marvel et al. - Continuous-time model of structural balance.pdf}
}

@article{McCarthy2011,
  langid = {english},
  title = {Striatal Origin of the Pathologic Beta Oscillations in {{Parkinson}}'s Disease},
  volume = {108},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1107748108},
  doi = {10.1073/pnas.1107748108},
  number = {28},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2011-07-12},
  pages = {11620-11625},
  author = {McCarthy, M. M. and Moore-Kochlacs, C. and Gu, X. and Boyden, E. S. and Han, X. and Kopell, N.},
  file = {/Users/qualia/Documents/Papers/2011 - McCarthy et al. - Striatal origin of the pathologic beta oscillations in Parkinson's disease.pdf}
}

@article{Meyer2011,
  langid = {english},
  title = {Seeing {{Touch Is Correlated}} with {{Content}}-{{Specific Activity}} in {{Primary Somatosensory Cortex}}},
  volume = {21},
  issn = {1460-2199, 1047-3211},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhq289},
  doi = {10.1093/cercor/bhq289},
  number = {9},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2011-09},
  pages = {2113-2121},
  author = {Meyer, Kaspar and Kaplan, Jonas T. and Essex, Ryan and Damasio, Hanna and Damasio, Antonio},
  file = {/Users/qualia/Documents/Papers/2011 - Meyer et al. - Seeing touch is correlated with content-specific activity in primary somatosensory cortex.pdf}
}

@article{Muller2011,
  langid = {english},
  title = {Spike-{{Timing Dependent Plasticity}} and {{Feed}}-{{Forward Input Oscillations Produce Precise}} and {{Invariant Spike Phase}}-{{Locking}}},
  volume = {5},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2011.00045/abstract},
  doi = {10.3389/fncom.2011.00045},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2011},
  author = {Muller, Lyle and Brette, Romain and Gutkin, Boris},
  file = {/Users/qualia/Documents/Papers/2011 - Muller, Brette, Gutkin - Spike-Timing Dependent Plasticity and Feed-Forward Input Oscillations Produce Precise and Invariant Spik.pdf}
}

@article{Naselaris2011,
  langid = {english},
  title = {Encoding and Decoding in {{fMRI}}},
  volume = {56},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910010657},
  doi = {10.1016/j.neuroimage.2010.07.073},
  abstract = {Over the past decade fMRI researchers have developed increasingly sensitive techniques for analyzing the information represented in BOLD activity. The most popular of these techniques is linear classification, a simple technique for decoding information about experimental stimuli or tasks from patterns of activity across an array of voxels. A more recent development is the voxel-based encoding model, which describes the information about the stimulus or task that is represented in the activity of single voxels. Encoding and decoding are complementary operations: encoding uses stimuli to predict activity while decoding uses activity to predict information about the stimuli. However, in practice these two operations are often confused, and their respective strengths and weaknesses have not been made clear. Here we use the concept of a linearizing feature space to clarify the relationship between encoding and decoding. We show that encoding and decoding operations can both be used to investigate some of the most common questions about how information is represented in the brain. However, focusing on encoding models offers two important advantages over decoding. First, an encoding model can in principle provide a complete functional description of a region of interest, while a decoding model can provide only a partial description. Second, while it is straightforward to derive an optimal decoding model from an encoding model it is much more difficult to derive an encoding model from a decoding model. We propose a systematic modeling approach that begins by estimating an encoding model for every voxel in a scan and ends by using the estimated encoding models to perform decoding.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-05},
  pages = {400-410},
  author = {Naselaris, Thomas and Kay, Kendrick N. and Nishimoto, Shinji and Gallant, Jack L.},
  file = {/Users/qualia/Documents/Papers/2011 - Naselaris et al. - Encoding and decoding in fMRI.pdf}
}

@article{Neymotin2011,
  langid = {english},
  title = {Synaptic Information Transfer in Computer Models of Neocortical Columns},
  volume = {30},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-010-0253-4},
  doi = {10.1007/s10827-010-0253-4},
  number = {1},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2011-02},
  pages = {69-84},
  author = {Neymotin, Samuel A. and Jacobs, Kimberle M. and Fenton, Andr\'e A. and Lytton, William W.},
  file = {/Users/qualia/Documents/Papers/2011 - Neymotin et al. - Synaptic information transfer in computer models of neocortical columns(2).pdf}
}

@article{Nishimoto2011,
  langid = {english},
  title = {Reconstructing {{Visual Experiences}} from {{Brain Activity Evoked}} by {{Natural Movies}}},
  volume = {21},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982211009377},
  doi = {10.1016/j.cub.2011.08.031},
  abstract = {Quantitative modeling of human brain activity can provide crucial insights about cortical representations [1, 2] and can form the basis for brain decoding devices [3\textendash{}5]. Recent functional magnetic resonance imaging (fMRI) studies have modeled brain activity elicited by static visual patterns and have reconstructed these patterns from brain activity [6\textendash{}8]. However, blood oxygen level-dependent (BOLD) signals measured via fMRI are very slow [9], so it has been difficult to model brain activity elicited by dynamic stimuli such as natural movies. Here we present a new motion-energy [10, 11] encoding model that largely overcomes this limitation. The model describes fast visual information and slow hemodynamics by separate components. We recorded BOLD signals in occipitotemporal visual cortex of human subjects who watched natural movies and fit the model separately to individual voxels. Visualization of the fit models reveals how early visual areas represent the information in movies. To demonstrate the power of our approach, we also constructed a Bayesian decoder [8] by combining estimated encoding models with a sampled natural movie prior. The decoder provides remarkable reconstructions of the viewed movies. These results demonstrate that dynamic brain activity measured under naturalistic conditions can be decoded using current fMRI technology.},
  number = {19},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2011-10},
  pages = {1641-1646},
  author = {Nishimoto, Shinji and Vu, An T. and Naselaris, Thomas and Benjamini, Yuval and Yu, Bin and Gallant, Jack L.},
  file = {/Users/qualia/Documents/Papers/2011 - Nishimoto et al. - Reconstructing visual experiences from brain activity evoked by natural movies.pdf}
}

@article{Niu2011,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1106.5730},
  primaryClass = {cs, math},
  langid = {english},
  title = {{{HOGWILD}}!: {{A Lock}}-{{Free Approach}} to {{Parallelizing Stochastic Gradient Descent}}},
  url = {http://arxiv.org/abs/1106.5730},
  shorttitle = {{{HOGWILD}}!},
  abstract = {Stochastic Gradient Descent (SGD) is a popular algorithm that can achieve state-of-the-art performance on a variety of machine learning tasks. Several researchers have recently proposed schemes to parallelize SGD, but all require performance-destroying memory locking and synchronization. This work aims to show using novel theoretical analysis, algorithms, and implementation that SGD can be implemented without any locking. We present an update scheme called Hogwild! which allows processors access to shared memory with the possibility of overwriting each other's work. We show that when the associated optimization problem is sparse, meaning most gradient updates only modify small parts of the decision variable, then Hogwild! achieves a nearly optimal rate of convergence. We demonstrate experimentally that Hogwild! outperforms alternative schemes that use locking by an order of magnitude.},
  urldate = {2019-03-30},
  date = {2011-06-28},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  author = {Niu, Feng and Recht, Benjamin and Re, Christopher and Wright, Stephen J.},
  file = {/Users/qualia/Documents/Papers/2011 - Niu et al. - HOGWILD! A Lock-Free Approach to Parallelizing Stochastic Gradient Descent.pdf}
}

@article{OLeary2011,
  langid = {english},
  title = {Neuronal Homeostasis: Time for a Change?: {{Neuronal}} Homeostasis: Time for a Change?},
  volume = {589},
  issn = {00223751},
  url = {http://doi.wiley.com/10.1113/jphysiol.2011.210179},
  doi = {10.1113/jphysiol.2011.210179},
  shorttitle = {Neuronal Homeostasis},
  abstract = {Homeostatic processes that regulate electrical activity in neurones are now an established aspect of physiology and rest on a large body of experimental evidence that points to roles in development, learning and memory, and disease. However, the concepts underlying homeostasis are too often summarized in ways that restrict their explanatory power and obviate important subtleties. Here, we present a review of the underlying theory of homeostasis \textendash{} control theory \textendash{} in an attempt to reconcile some existing conceptual problems in the context of neuronal physiology. In addition to clarifying the underlying theory, this review highlights the remaining challenges posed when analysing homeostatic phenomena that underlie the regulation of neuronal excitability. Moreover, we suggest approaches for future experimental and computational work that will further our understanding of neuronal homeostasis and the fundamental neurophysiological functions it serves.},
  number = {20},
  journaltitle = {The Journal of Physiology},
  urldate = {2019-03-30},
  date = {2011-10-15},
  pages = {4811-4826},
  author = {O'Leary, Timothy and Wyllie, David J. A.},
  file = {/Users/qualia/Documents/Papers/2011 - O'Leary, Wyllie - Neuronal homeostasis Time for a change.pdf}
}

@article{Ogawa2011,
  langid = {english},
  title = {Neural Representation of Observed Actions in the Parietal and Premotor Cortex},
  volume = {56},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910013352},
  doi = {10.1016/j.neuroimage.2010.10.043},
  abstract = {We investigated the neural representation of observed actions in the human parietal and premotor cortex, which comprise the action observation network or the mirror neuron system for action recognition. Participants observed object-directed hand actions, in which action as well as other properties were independently manipulated: action (grasp or touch), object (cup or bottle), perspective (1st or 3rd person), hand (right or left), and image size (large or small). We then used multi-voxel pattern analysis to determine whether each feature could be correctly decoded from regional activities. The early visual area showed significant above-chance classification accuracy, particularly high in perspective, hand, and size, consistent with pixel-wise dissimilarity of stimuli. In contrast, the highest decoding accuracy for action was observed in the anterior intraparietal sulcus (aIPS) and the ventral premotor cortex (PMv). Moreover, the decoder for action could be correctly generalized for images with high dissimilarity in the parietal and premotor region, but not in the visual area. Our study indicates that the parietal and premotor regions encode observed actions independent of retinal variations, which may subserve our capacity for invariant action recognition of others. \textcopyright{} 2010 Elsevier Inc. All rights reserved.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-05},
  pages = {728-735},
  author = {Ogawa, Kenji and Inui, Toshio},
  file = {/Users/qualia/Documents/Papers/2011 - Ogawa, Inui - Neural representation of observed actions in the parietal and premotor cortex.pdf}
}

@article{Oosterhof2011,
  langid = {english},
  title = {A Comparison of Volume-Based and Surface-Based Multi-Voxel Pattern Analysis},
  volume = {56},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910006981},
  doi = {10.1016/j.neuroimage.2010.04.270},
  abstract = {For functional magnetic resonance imaging (fMRI), multi-voxel pattern analysis (MVPA) has been shown to be a sensitive method to detect areas that encode certain stimulus dimensions. By moving a searchlight through the volume of the brain, one can continuously map the information content about the experimental conditions of interest to the brain.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-05},
  pages = {593-600},
  author = {Oosterhof, Nikolaas N. and Wiestler, Tobias and Downing, Paul E. and Diedrichsen, J\"orn},
  file = {/Users/qualia/Documents/Papers/2011 - Oosterhof et al. - A comparison of volume-based and surface-based multi-voxel pattern analysis.pdf}
}

@article{Ostojic2011,
  langid = {english},
  title = {From {{Spiking Neuron Models}} to {{Linear}}-{{Nonlinear Models}}},
  volume = {7},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1001056},
  doi = {10.1371/journal.pcbi.1001056},
  abstract = {Neurons transform time-varying inputs into action potentials emitted stochastically at a time dependent rate. The mapping from current input to output firing rate is often represented with the help of phenomenological models such as the linearnonlinear (LN) cascade, in which the output firing rate is estimated by applying to the input successively a linear temporal filter and a static non-linear transformation. These simplified models leave out the biophysical details of action potential generation. It is not a priori clear to which extent the input-output mapping of biophysically more realistic, spiking neuron models can be reduced to a simple linear-nonlinear cascade. Here we investigate this question for the leaky integrate-andfire (LIF), exponential integrate-and-fire (EIF) and conductance-based Wang-Buzsa\textasciiacute{}ki models in presence of background synaptic activity. We exploit available analytic results for these models to determine the corresponding linear filter and static non-linearity in a parameter-free form. We show that the obtained functions are identical to the linear filter and static nonlinearity determined using standard reverse correlation analysis. We then quantitatively compare the output of the corresponding linear-nonlinear cascade with numerical simulations of spiking neurons, systematically varying the parameters of input signal and background noise. We find that the LN cascade provides accurate estimates of the firing rates of spiking neurons in most of parameter space. For the EIF and Wang-Buzsa\textasciiacute{}ki models, we show that the LN cascade can be reduced to a firing rate model, the timescale of which we determine analytically. Finally we introduce an adaptive timescale rate model in which the timescale of the linear filter depends on the instantaneous firing rate. This model leads to highly accurate estimates of instantaneous firing rates.},
  number = {1},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2011-01-20},
  pages = {e1001056},
  author = {Ostojic, Srdjan and Brunel, Nicolas},
  editor = {Latham, Peter E.},
  file = {/Users/qualia/Documents/Papers/2011 - Ostojic, Brunel - From Spiking Neuron Models to Linear-Nonlinear Models.pdf}
}

@article{Pereira2011,
  langid = {english},
  title = {Information Mapping with Pattern Classifiers: {{A}} Comparative Study},
  volume = {56},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910007585},
  doi = {10.1016/j.neuroimage.2010.05.026},
  shorttitle = {Information Mapping with Pattern Classifiers},
  abstract = {Information mapping using pattern classifiers has become increasingly popular in recent years, although without a clear consensus on which classifier(s) ought to be used or how results should be tested. This paper addresses each of these questions, both analytically and through comparative analyses on five empirical datasets. We also describe how information maps in multiple class situations can provide information concerning the content of neural representations. Finally, we introduce a publically available software toolbox designed specifically for information mapping.},
  number = {2},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-05},
  pages = {476-496},
  author = {Pereira, Francisco and Botvinick, Matthew},
  file = {/Users/qualia/Documents/Papers/2011 - Pereira, Botvinick - Information mapping with pattern classifiers a comparative study.pdf}
}

@article{Pinotsis2011,
  langid = {english},
  title = {Neural Fields, Spectral Responses and Lateral Connections},
  volume = {55},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910015594},
  doi = {10.1016/j.neuroimage.2010.11.081},
  abstract = {This paper describes a neural field model for local (mesoscopic) dynamics on the cortical surface. Our focus is on sparse intrinsic connections that are characteristic of real cortical microcircuits. This sparsity is modelled with radial connectivity functions or kernels with non-central peaks. The ensuing analysis allows one to generate or predict spectral responses to known exogenous input or random fluctuations. Here, we characterise the effect of different connectivity architectures (the range, dispersion and propagation speed of intrinsic or lateral connections) and synaptic gains on spatiotemporal dynamics. Specifically, we look at spectral responses to random fluctuations and examine the ability of synaptic gain and connectivity parameters to induce Turing instabilities. We find that although the spatial deployment and speed of lateral connections can have a profound affect on the behaviour of spatial modes over different scales, only synaptic gain is capable of producing phase-transitions. We discuss the implications of these findings for the use of neural fields as generative models in dynamic causal modeling (DCM).},
  number = {1},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2011-03},
  pages = {39-48},
  author = {Pinotsis, D.A. and Friston, K.J.},
  file = {/Users/qualia/Documents/Papers/2011 - Pinotsis, Friston - Neural fields, spectral responses and lateral connections.pdf}
}

@article{Quinn2011,
  langid = {english},
  title = {Data Assimilation Using a {{GPU}} Accelerated Path Integral {{Monte Carlo}} Approach},
  volume = {230},
  issn = {00219991},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999111004347},
  doi = {10.1016/j.jcp.2011.07.015},
  abstract = {The answers to data assimilation questions can be expressed as path integrals over all possible state and parameter histories. We show how these path integrals can be evaluated numerically using a Markov Chain Monte Carlo method designed to run in parallel on a graphics processing unit (GPU). We demonstrate the application of the method to an example with a transmembrane voltage time series of a simulated neuron as an input, and using a Hodgkin\textendash{}Huxley neuron model. By taking advantage of GPU computing, we gain a parallel speedup factor of up to about 300, compared to an equivalent serial computation on a CPU, with performance increasing as the length of the observation time used for data assimilation increases.},
  number = {22},
  journaltitle = {Journal of Computational Physics},
  urldate = {2019-03-30},
  date = {2011-09},
  pages = {8168-8178},
  author = {Quinn, John C. and Abarbanel, Henry D.I.},
  file = {/Users/qualia/Documents/Papers/2011 - Quinn, Abarbanel - Data assimilation using a GPU accelerated path integral Monte Carlo approach.pdf}
}

@article{Raizada,
  langid = {english},
  title = {What {{Makes Different People's Representations Alike}}: {{Neural Similarity Space Solves}} the {{Problem}} of {{Across}}-Subject {{fMRI Decoding}}},
  volume = {24},
  number = {4},
  pages = {10},
  author = {Raizada, Rajeev D S and Connolly, Andrew C},
  file = {/Users/qualia/Documents/Papers/2012 - Raizada, Connolly - What Makes Different Peopleʼs Representations Alike Neural Similarity Space Solves the Problem of Across-su.pdf}
}

@article{Marvel2012,
  langid = {english},
  title = {Encouraging {{Moderation}}: {{Clues}} from a {{Simple Model}} of {{Ideological Conflict}}},
  volume = {109},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.109.118702},
  doi = {10.1103/PhysRevLett.109.118702},
  shorttitle = {Encouraging {{Moderation}}},
  number = {11},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2012-09-11},
  author = {Marvel, Seth A. and Hong, Hyunsuk and Papush, Anna and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/2012 - Marvel et al. - Encouraging moderation Clues from a simple model of ideological conflict.pdf}
}

@article{Massey2012,
  langid = {english},
  title = {High Resolution {{MR}} Anatomy of the Subthalamic Nucleus: {{Imaging}} at 9.{{4T}} with Histological Validation},
  volume = {59},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811911011773},
  doi = {10.1016/j.neuroimage.2011.10.016},
  shorttitle = {High Resolution {{MR}} Anatomy of the Subthalamic Nucleus},
  abstract = {Using conventional MRI the subthalamic nucleus (STN) is not clearly defined. Our objective was to define the anatomy of the STN using 9.4 T MRI of post mortem tissue with histological validation. Spin-echo (SE) and 3D gradient-echo (GE) images were obtained at 9.4 T in 8 post mortem tissue blocks and compared directly with corresponding histological slides prepared with Luxol Fast Blue/Cresyl Violet (LFB/CV) in 4 cases and Perl stain in 3. The variability of the STN anatomy was studied using internal reference points. The anatomy of the STN and surrounding structures was demonstrated in all three anatomical planes using 9.4 T MR images in concordance with LFB/CV stained histological sections. Signal hypointensity was seen in 6/8 cases in the anterior and medial STN that corresponded with regions of more intense Perl staining. There was significant variability in the volume, shape and location of the borders of the STN. Using 9.4 T MRI, the internal signal characteristics and borders of the STN are clearly defined and significant anatomical variability is apparent. Direct visualisation of the STN is possible using high field MRI and this is particularly relevant, given its anatomical variability, for planning deep brain stimulation.},
  number = {3},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2012-02},
  pages = {2035-2044},
  author = {Massey, L.A. and Miranda, M.A. and Zrinzo, L. and Al-Helli, O. and Parkes, H.G. and Thornton, J.S. and So, P.-W. and White, M.J. and Mancini, L. and Strand, C. and Holton, J.L. and Hariz, M.I. and Lees, A.J. and Revesz, T. and Yousry, T.A.},
  file = {/Users/qualia/Documents/Papers/2012 - Massey et al. - High resolution MR anatomy of the subthalamic nucleus Imaging at 9.4T with histological validation.pdf}
}

@article{Olsen2012,
  langid = {english},
  title = {Gain Control by Layer Six in Cortical Circuits of Vision},
  volume = {483},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature10835},
  doi = {10.1038/nature10835},
  number = {7387},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2012-03},
  pages = {47-52},
  author = {Olsen, Shawn R. and Bortone, Dante S. and Adesnik, Hillel and Scanziani, Massimo},
  file = {/Users/qualia/Documents/Papers/2012 - Olsen et al. - Gain control by layer six in cortical circuits of vision.pdf}
}

@article{Brogden1939,
  langid = {english},
  title = {Higher {{Order Conditioning}}},
  volume = {52},
  issn = {00029556},
  url = {https://www.jstor.org/stable/1416470?origin=crossref},
  doi = {10.2307/1416470},
  number = {4},
  journaltitle = {The American Journal of Psychology},
  urldate = {2019-03-30},
  date = {1939-10},
  pages = {579},
  author = {Brogden, W. J.},
  file = {/Users/qualia/Documents/Papers/2012 - Press - Higher Order Conditioning Author ( s ) W . J . Brogden Reviewed work ( s ) Source The American Journal of Psychology , V.pdf}
}

@article{Robinson2012,
  langid = {english},
  title = {Spike, Rate, Field, and Hybrid Methods for Treating Neuronal Dynamics and Interactions},
  volume = {205},
  issn = {01650270},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027012000337},
  doi = {10.1016/j.jneumeth.2012.01.018},
  abstract = {Spike-, rate-, and field-based approaches to neural dynamics are adapted and hybridized to provide new methods of analyzing dynamics of single neurons and large neuronal systems, to elucidate the relationships and intermediate forms between these limiting cases, and to enable faster simulations with reduced memory requirements. At the single-neuron level, the new approaches involve reformulation of dynamics in synapses, dendrites, cell bodies, and axons to enable new types of analysis, longer numerical timesteps, and demonstration that rate-based methods can predict spike times. In multineuron systems, hybrids and intermediates between spike-based and field-based coupling between neurons are used to provide stepping stones between descriptions based on pairwise spike-based interactions between neurons and ones based on neural field-based interactions within and between populations, including arbitrary spatial structure and temporal delays in the connections in general. In particular, a new neuronin-cell approach is introduced that is a hybrid between neural field theory and spiking-neuron models in analogy to particle-in-cell methods in plasma physics. This approach enables large speedups in computations while preserving spike shapes and times. Various approaches are illustrated numerically for specific cases.},
  number = {2},
  journaltitle = {Journal of Neuroscience Methods},
  urldate = {2019-03-30},
  date = {2012-04},
  pages = {283-294},
  author = {Robinson, P.A. and Kim, J.W.},
  file = {/Users/qualia/Documents/Papers/2012 - Robinson, Kim - Spike, rate, field, and hybrid methods for treating neuronal dynamics and interactions.pdf}
}

@article{Saalmann2012,
  langid = {english},
  title = {The {{Pulvinar Regulates Information Transmission Between Cortical Areas Based}} on {{Attention Demands}}},
  volume = {337},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1223082},
  doi = {10.1126/science.1223082},
  number = {6095},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2012-08-10},
  pages = {753-756},
  author = {Saalmann, Y. B. and Pinsk, M. A. and Wang, L. and Li, X. and Kastner, S.},
  file = {/Users/qualia/Documents/Papers/2012 - Saalmann et al. - The Pulvinar Regulates Information Transmission Between Cortical Areas Based on Attention Demands.pdf}
}

@article{Sedigh-Sarvestani2012,
  langid = {english},
  title = {Reconstructing {{Mammalian Sleep Dynamics}} with {{Data Assimilation}}},
  volume = {8},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1002788},
  doi = {10.1371/journal.pcbi.1002788},
  abstract = {Data assimilation is a valuable tool in the study of any complex system, where measurements are incomplete, uncertain, or both. It enables the user to take advantage of all available information including experimental measurements and shortterm model forecasts of a system. Although data assimilation has been used to study other biological systems, the study of the sleep-wake regulatory network has yet to benefit from this toolset. We present a data assimilation framework based on the unscented Kalman filter (UKF) for combining sparse measurements together with a relatively high-dimensional nonlinear computational model to estimate the state of a model of the sleep-wake regulatory system. We demonstrate with simulation studies that a few noisy variables can be used to accurately reconstruct the remaining hidden variables. We introduce a metric for ranking relative partial observability of computational models, within the UKF framework, that allows us to choose the optimal variables for measurement and also provides a methodology for optimizing framework parameters such as UKF covariance inflation. In addition, we demonstrate a parameter estimation method that allows us to track nonstationary model parameters and accommodate slow dynamics not included in the UKF filter model. Finally, we show that we can even use observed discretized sleep-state, which is not one of the model variables, to reconstruct model state and estimate unknown parameters. Sleep is implicated in many neurological disorders from epilepsy to schizophrenia, but simultaneous observation of the many brain components that regulate this behavior is difficult. We anticipate that this data assimilation framework will enable better understanding of the detailed interactions governing sleep and wake behavior and provide for better, more targeted, therapies.},
  number = {11},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2012-11-29},
  pages = {e1002788},
  author = {Sedigh-Sarvestani, Madineh and Schiff, Steven J. and Gluckman, Bruce J.},
  editor = {Gutkin, Boris S.},
  file = {/Users/qualia/Documents/Papers/2012 - Sedigh-Sarvestani, Schiff, Gluckman - Reconstructing Mammalian Sleep Dynamics with Data Assimilation.pdf}
}

@article{Shinkareva2012,
  langid = {english},
  title = {Exploring Commonalities across Participants in the Neural Representation of Objects},
  volume = {33},
  issn = {10659471},
  url = {http://doi.wiley.com/10.1002/hbm.21296},
  doi = {10.1002/hbm.21296},
  abstract = {The question of whether the neural encodings of objects are similar across different people is one of the key questions in cognitive neuroscience. This article examines the commonalities in the internal representation of objects, as measured with fMRI, across individuals in two complementary ways. First, we examine the commonalities in the internal representation of objects across people at the level of interobject distances, derived from whole brain fMRI data, and second, at the level of spatially localized anatomical brain regions that contain sufficient information for identification of object categories, without making the assumption that their voxel patterns are spatially matched in a common space. We examine the commonalities in internal representation of objects on 3T fMRI data collected while participants viewed line drawings depicting various tools and dwellings. This exploratory study revealed the extent to which the representation of individual concepts, and their mutual similarity, is shared across participants. Hum Brain Mapp 33:1375\textendash{}1383, 2012. VC 2011 Wiley Periodicals, Inc.},
  number = {6},
  journaltitle = {Human Brain Mapping},
  urldate = {2019-03-30},
  date = {2012-06},
  pages = {1375-1383},
  author = {Shinkareva, Svetlana V. and Malave, Vicente L. and Just, Marcel Adam and Mitchell, Tom M.},
  file = {/Users/qualia/Documents/Papers/2012 - Shinkareva et al. - Exploring commonalities across participants in the neural representation of objects.pdf}
}

@article{Siegel2012,
  langid = {english},
  title = {Spectral Fingerprints of Large-Scale Neuronal Interactions},
  volume = {13},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn3137},
  doi = {10.1038/nrn3137},
  abstract = {Cognition results from interactions among functionally specialized but widely distributed brain regions; however, neuroscience has so far largely focused on characterizing the function of individual brain regions and neurons therein. Here we discuss recent studies that have instead investigated the interactions between brain regions during cognitive processes by assessing correlations between neuronal oscillations in different regions of the primate cerebral cortex. These studies have opened a new window onto the large-scale circuit mechanisms underlying sensorimotor decision-making and top-down attention. We propose that frequency-specific neuronal correlations in large-scale cortical networks may be `fingerprints' of canonical neuronal computations underlying cognitive processes.},
  number = {2},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2012-02},
  pages = {121-134},
  author = {Siegel, Markus and Donner, Tobias H. and Engel, Andreas K.},
  file = {/Users/qualia/Documents/Papers/2012 - Siegel, Donner, Engel - Spectral fingerprints of large-scale neuronal interactions.pdf}
}

@article{Robert1976,
  langid = {english},
  title = {A {{Unifying Tool}} for {{Linear Multivariate Statistical Methods}}: {{The RV}}- {{Coefficient}}},
  volume = {25},
  issn = {00359254},
  url = {https://www.jstor.org/stable/2347233?origin=crossref},
  doi = {10.2307/2347233},
  shorttitle = {A {{Unifying Tool}} for {{Linear Multivariate Statistical Methods}}},
  abstract = {Considertwodata matriceosn thesamesampleofn individualsX, (p x n), Y(q x n). Fromthesematricesg,eometricarlepresentatioonfsthesampleare obtainedas two configurationosf n points,in RP and \_?q.It is shownthat the RV-coefficient (Escoufier1,970,1973)canbeusedas a measureofsimilaritoyfthetwoconfigurations, takingintoaccountthepossiblydistincmt etrictso be usedon themto measurethe distancesbetweenpoints.The purposeofthispaperis to showthatmostclassical methodsoflinearmultivariatsteatisticaalnalysiscan beinterpreteads thesearchfor optimallineartransformatioonrs, equivalentlyt,hesearchforoptimalmetricsto applyon twodatamatriceosnthesamesample;theoptimalitiys definedintermsof thesimilaritoyfthecorrespondincgonfiguratioonfspoints,whichi,n turn,callsfor themaximizatioonftheassociatedR V-coefficienTth. emethodstudiedareprincipal componentps,rincipaclomponentosfinstrumentvaalriablesm, ultivariatregression, canonicalvariables,discriminanatnalysis;theyare differentiatbeyd the possible relationshipesxistingbetweenthe two data matricesinvolvedand by additional constrainutsnderwhichthemaximumofR Vistobe obtained.It is alsoshownthatthe RV-coefficiecnatn be usedas a measureofgoodnessofa solutionto theproblemof discardinvgariables.},
  number = {3},
  journaltitle = {Applied Statistics},
  urldate = {2019-03-30},
  date = {1976},
  pages = {257},
  author = {Robert, P. and Escoufier, Y.},
  file = {/Users/qualia/Documents/Papers/2012 - Society, Statistics - Tool for Linear Multivariate A Unifying The RV-Coefficient Methods Statistical.pdf}
}

@article{Still2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1203.3271},
  langid = {english},
  title = {The Thermodynamics of Prediction},
  volume = {109},
  issn = {0031-9007, 1079-7114},
  url = {http://arxiv.org/abs/1203.3271},
  doi = {10.1103/PhysRevLett.109.120604},
  abstract = {A system responding to a stochastic driving signal can be interpreted as computing, by means of its dynamics, an implicit model of the environmental variables. The system's state retains information about past environmental fluctuations, and a fraction of this information is predictive of future ones. The remaining nonpredictive information reflects model complexity that does not improve predictive power, and thus represents the ineffectiveness of the model. We expose the fundamental equivalence between this model inefficiency and thermodynamic inefficiency, measured by dissipation. Our results hold arbitrarily far from thermodynamic equilibrium and are applicable to a wide range of systems, including biomolecular machines. They highlight a profound connection between the effective use of information and efficient thermodynamic operation: any system constructed to keep memory about its environment and to operate with maximal energetic efficiency has to be predictive.},
  number = {12},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2012-09-19},
  keywords = {Computer Science - Information Theory,Condensed Matter - Statistical Mechanics,Quantitative Biology - Quantitative Methods},
  author = {Still, Susanne and Sivak, David A. and Bell, Anthony J. and Crooks, Gavin E.},
  file = {/Users/qualia/Documents/Papers/2012 - Still et al. - Thermodynamics of prediction.pdf}
}

@article{Sokal1962,
  langid = {english},
  title = {The {{Comparison}} of {{Dendrograms}} by {{Objective Methods}}},
  volume = {11},
  issn = {00400262},
  url = {https://www.jstor.org/stable/1217208?origin=crossref},
  doi = {10.2307/1217208},
  number = {2},
  journaltitle = {Taxon},
  urldate = {2019-03-30},
  date = {1962-02},
  pages = {33},
  author = {Sokal, Robert R. and Rohlf, F. James},
  file = {/Users/qualia/Documents/Papers/2012 - Taxonomy - No Title.pdf}
}

@article{Touboul2012,
  langid = {english},
  title = {Mean-Field Equations for Stochastic Firing-Rate Neural Fields with Delays: {{Derivation}} and Noise-Induced Transitions},
  volume = {241},
  issn = {01672789},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167278912000942},
  doi = {10.1016/j.physd.2012.03.010},
  shorttitle = {Mean-Field Equations for Stochastic Firing-Rate Neural Fields with Delays},
  abstract = {In this manuscript we analyze the collective behavior of mean-field limits of large-scale, spatially extended stochastic neuronal networks with delays. Rigorously, the asymptotic regime of such systems is characterized by a very intricate stochastic delayed integro-differential McKean\textendash{}Vlasov equation that remain impenetrable, leaving the stochastic collective dynamics of such networks poorly understood. In order to study these macroscopic dynamics, we analyze networks of firing-rate neurons, i.e. with linear intrinsic dynamics and sigmoidal interactions. In that case, we prove that the solution of the mean-field equation is Gaussian, hence characterized by its two first moments, and that these two quantities satisfy a set of coupled delayed integro-differential equations. These equations are similar to usual neural field equations, and incorporate noise levels as a parameter, allowing analysis of noise-induced transitions. We identify through bifurcation analysis several qualitative transitions due to noise in the mean-field limit. In particular, stabilization of spatially homogeneous solutions, synchronized oscillations, bumps, chaotic dynamics, wave or bump splitting are exhibited and arise from static or dynamic Turing\textendash{}Hopf bifurcations. These surprising phenomena allow further exploring the role of noise in the nervous system. \textcopyright{} 2012 Elsevier B.V. All rights reserved.},
  number = {15},
  journaltitle = {Physica D: Nonlinear Phenomena},
  urldate = {2019-03-30},
  date = {2012-08},
  pages = {1223-1244},
  author = {Touboul, Jonathan},
  file = {/Users/qualia/Documents/Papers/2012 - Touboul - Mean-field equations for stochastic firing-rate neural fields with delays Derivation and noise-induced transitions.pdf}
}

@article{Turner2012,
  langid = {english},
  title = {Spatiotemporal Activity Estimation for Multivoxel Pattern Analysis with Rapid Event-Related Designs},
  volume = {62},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811912005459},
  doi = {10.1016/j.neuroimage.2012.05.057},
  abstract = {Despite growing interest in multi-voxel pattern analysis (MVPA) methods for fMRI, a major problem remains \textemdash{}that of generating estimates in rapid event-related (ER) designs, where the BOLD responses of temporally adjacent events will overlap. While this problem has been investigated for methods that reduce each event to a single parameter per voxel (Mumford et al., 2012), most of these methods make strong parametric assumptions about the shape of the hemodynamic response, and require exact knowledge of the temporal profile of the underlying neural activity. A second class of methods uses multiple parameters per event (per voxel) to capture temporal information more faithfully. In addition to enabling a more accurate estimate of ER responses, this allows for the extension of the standard classification paradigm into the temporal domain (e.g., Mour\~ao-Miranda et al., 2007). However, existing methods in this class were developed for use with block and slow ER data, and there has not yet been an exploration of how to adapt such methods to data collected using rapid ER designs. Here, we demonstrate that the use of multiple parameters preserves or improves classification accuracy, while additionally providing information on the evolution of class discrimination. Additionally, we explore an alternative to the method of Mour\~ao-Miranda et al. tailored to use in rapid ER designs that yields equivalent classification accuracies, but is better at unmixing responses to temporally adjacent events. The current work paves the way for wider adoption of spatiotemporal classification analyses, and greater use of MVPA with rapid ER designs.},
  number = {3},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2012-09},
  pages = {1429-1438},
  author = {Turner, Benjamin O. and Mumford, Jeanette A. and Poldrack, Russell A. and Ashby, F. Gregory},
  file = {/Users/qualia/Documents/Papers/2012 - Turner et al. - Spatiotemporal activity estimation for multivoxel pattern analysis with rapid event-related designs.pdf}
}

@article{Uhlhaas2012,
  langid = {english},
  title = {Neuronal {{Dynamics}} and {{Neuropsychiatric Disorders}}: {{Toward}} a {{Translational Paradigm}} for {{Dysfunctional Large}}-{{Scale Networks}}},
  volume = {75},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627312008112},
  doi = {10.1016/j.neuron.2012.09.004},
  shorttitle = {Neuronal {{Dynamics}} and {{Neuropsychiatric Disorders}}},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2012-09},
  pages = {963-980},
  author = {Uhlhaas, Peter J. and Singer, Wolf},
  file = {/Users/qualia/Documents/Papers/2012 - Uhlhaas, Singer - Neuronal Dynamics and Neuropsychiatric Disorders Toward a Translational Paradigm for Dysfunctional Large-Scale.pdf}
}

@article{Wald1947,
  langid = {english},
  title = {Foundations of a {{General Theory}} of {{Sequential Decision Functions}}},
  volume = {15},
  issn = {00129682},
  url = {https://www.jstor.org/stable/1905331?origin=crossref},
  doi = {10.2307/1905331},
  number = {4},
  journaltitle = {Econometrica},
  urldate = {2019-03-30},
  date = {1947-10},
  pages = {279},
  author = {Wald, Abraham},
  file = {/Users/qualia/Documents/Papers/2012 - Unknown - No Title.pdf}
}

@article{Vicente2012,
  langid = {english},
  title = {Looking at the {{Trees}} in the {{Central Forest}}: {{A New Pallidal}}-{{Striatal Cell Type}}},
  volume = {74},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627312005156},
  doi = {10.1016/j.neuron.2012.06.003},
  shorttitle = {Looking at the {{Trees}} in the {{Central Forest}}},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2012-06},
  pages = {967-969},
  author = {Vicente, Ana M. and Costa, Rui M.},
  file = {/Users/qualia/Documents/Papers/2012 - Vicente, Costa - Looking at the Trees in the Central Forest A New Pallidal-Striatal Cell Type.pdf}
}

@article{Vijayan2012,
  langid = {english},
  title = {Thalamic Model of Awake Alpha Oscillations and Implications for Stimulus Processing},
  volume = {109},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1215385109},
  doi = {10.1073/pnas.1215385109},
  number = {45},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2012-11-06},
  pages = {18553-18558},
  author = {Vijayan, S. and Kopell, N. J.},
  file = {/Users/qualia/Documents/Papers/2012 - Vijayan, Kopell - Thalamic model of awake alpha oscillations and implications for stimulus processing.pdf}
}

@article{Viriyopase2012,
  langid = {english},
  title = {When {{Long}}-{{Range Zero}}-{{Lag Synchronization}} Is {{Feasible}} in {{Cortical Networks}}},
  volume = {6},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2012.00049/abstract},
  doi = {10.3389/fncom.2012.00049},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2012},
  author = {Viriyopase, Atthaphon and Bojak, Ingo and Zeitler, Magteld and Gielen, Stan},
  file = {/Users/qualia/Documents/Papers/2012 - Viriyopase et al. - When Long-Range Zero-Lag Synchronization is Feasible in Cortical Networks.pdf}
}

@article{White2012,
  langid = {english},
  title = {Perceptual {{Criteria}} in the {{Human Brain}}},
  volume = {32},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1744-12.2012},
  doi = {10.1523/JNEUROSCI.1744-12.2012},
  number = {47},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2012-11-21},
  pages = {16716-16724},
  author = {White, C. N. and Mumford, J. A. and Poldrack, R. A.},
  file = {/Users/qualia/Documents/Papers/2012 - White, Mumford, Poldrack - Perceptual Criteria in the Human Brain.pdf}
}

@inproceedings{Xu2012,
  langid = {english},
  location = {{Ann Arbor, MI, USA}},
  title = {Regularized Hyperalignment of Multi-Set {{fMRI}} Data},
  isbn = {978-1-4673-0182-4 978-1-4673-0181-7},
  url = {http://ieeexplore.ieee.org/document/6319668/},
  doi = {10.1109/SSP.2012.6319668},
  abstract = {Inter-subject correspondence is an important aspect of multisubject fMRI studies. Recently, a new approach, called hyperalignment, has shown very promising results in fMRI functional alignment. Hyperalignment is based on Procrustean rotations and is connected, mathematically, to canonical correlation analysis. We review the core details of each approach, relate them through an SVD analysis, and indicate why they can yield different levels of performance. We then examine the effectiveness of regularization in mediating between the extremes of these methods. An inter-subject classification experiment based on functional aligned fMRI datasets illustrates the resulting improved performance.},
  eventtitle = {2012 {{IEEE Statistical Signal Processing Workshop}} ({{SSP}})},
  booktitle = {2012 {{IEEE Statistical Signal Processing Workshop}} ({{SSP}})},
  publisher = {{IEEE}},
  urldate = {2019-03-30},
  date = {2012-08},
  pages = {229-232},
  author = {Xu, Hao and Lorbert, Alexander and Ramadge, Peter J. and Guntupalli, J. Swaroop and Haxby, James V.},
  file = {/Users/qualia/Documents/Papers/2012 - Xu et al. - Regularized Hyperalignment of Multi-set FMRI Data.pdf}
}

@article{Zanin2012,
  langid = {english},
  title = {Permutation {{Entropy}} and {{Its Main Biomedical}} and {{Econophysics Applications}}: {{A Review}}},
  volume = {14},
  issn = {1099-4300},
  url = {http://www.mdpi.com/1099-4300/14/8/1553},
  doi = {10.3390/e14081553},
  shorttitle = {Permutation {{Entropy}} and {{Its Main Biomedical}} and {{Econophysics Applications}}},
  number = {8},
  journaltitle = {Entropy},
  urldate = {2019-03-30},
  date = {2012-08-23},
  pages = {1553-1577},
  author = {Zanin, Massimiliano and Zunino, Luciano and Rosso, Osvaldo A. and Papo, David},
  file = {/Users/qualia/Documents/Papers/2012 - Zanin et al. - Permutation entropy and its main biomedical and econophysics applications A review.pdf}
}

@article{Bargmann2013,
  langid = {english},
  title = {From the Connectome to Brain Function},
  volume = {10},
  issn = {1548-7091, 1548-7105},
  url = {http://www.nature.com/articles/nmeth.2451},
  doi = {10.1038/nmeth.2451},
  number = {6},
  journaltitle = {Nature Methods},
  urldate = {2019-03-30},
  date = {2013-06},
  pages = {483-490},
  author = {Bargmann, Cornelia I and Marder, Eve},
  file = {/Users/qualia/Documents/Papers/2013 - Bargmann, Marder - From the connectome to brain function.pdf}
}

@article{Behabadi2014,
  langid = {english},
  title = {Mechanisms Underlying Subunit Independence in Pyramidal Neuron Dendrites},
  volume = {111},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1217645111},
  doi = {10.1073/pnas.1217645111},
  number = {1},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2014-01-07},
  pages = {498-503},
  author = {Behabadi, B. F. and Mel, B. W.},
  file = {/Users/qualia/Documents/Papers/2013 - Behabadi, Mel - Mechanisms underlying subunit independence in pyramidal neuron dendrites.pdf}
}

@article{Bellemare2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1207.4708},
  langid = {english},
  title = {The {{Arcade Learning Environment}}: {{An Evaluation Platform}} for {{General Agents}}},
  volume = {47},
  issn = {1076-9757},
  url = {http://arxiv.org/abs/1207.4708},
  doi = {10.1613/jair.3912},
  shorttitle = {The {{Arcade Learning Environment}}},
  abstract = {In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.},
  journaltitle = {Journal of Artificial Intelligence Research},
  urldate = {2019-03-30},
  date = {2013-06-14},
  pages = {253-279},
  keywords = {Computer Science - Artificial Intelligence},
  author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  file = {/Users/qualia/Documents/Papers/2013 - Bellemare, Veness - The Arcade Learning Environment An Evaluation Platform for General Agents.pdf}
}

@article{Bhattacharya2013,
  langid = {english},
  title = {Implementing the Cellular Mechanisms of Synaptic Transmission in a Neural Mass Model of the Thalamo-Cortical Circuitry},
  volume = {7},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2013.00081/abstract},
  doi = {10.3389/fncom.2013.00081},
  abstract = {A novel direction to existing neural mass modeling technique is proposed where the commonly used ``alpha function'' for representing synaptic transmission is replaced by a kinetic framework of neurotransmitter and receptor dynamics. The aim is to underpin neuro-transmission dynamics associated with abnormal brain rhythms commonly observed in neurological and psychiatric disorders. An existing thalamocortical neural mass model is modified by using the kinetic framework for modeling synaptic transmission mediated by glutamatergic and GABA (gamma-aminobutyric-acid)-ergic receptors. The model output is compared qualitatively with existing literature on in vitro experimental studies of ferret thalamic slices, as well as on single-neuron-level model based studies of neuro-receptor and transmitter dynamics in the thalamocortical tissue. The results are consistent with these studies: the activation of ligand-gated GABA receptors is essential for generation of spindle waves in the model, while blocking this pathway leads to low-frequency synchronized oscillations such as observed in slow-wave sleep; the frequency of spindle oscillations increase with increased levels of post-synaptic membrane conductance for AMPA (alpha-amino-3-hydroxy-5-methyl-4-isoxazolepropionic-acid) receptors, and blocking this pathway effects a quiescent model output. In terms of computational efficiency, the simulation time is improved by a factor of 10 compared to a similar neural mass model based on alpha functions. This implies a dramatic improvement in computational resources for large-scale network simulation using this model. Thus, the model provides a platform for correlating high-level brain oscillatory activity with low-level synaptic attributes, and makes a significant contribution toward advancements in current neural mass modeling paradigm as a potential computational tool to better the understanding of brain oscillations in sickness and in health.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2013},
  author = {Bhattacharya, Basabdatta S.},
  file = {/Users/qualia/Documents/Papers/2013 - Bhattacharya - Implementing the cellular mechanisms of synaptic transmission in a neural mass model of the thalamo-cortical circu.pdf}
}

@article{Brette2013,
  langid = {english},
  title = {An Ecological Approach to Neural Computation},
  volume = {14},
  issn = {1471-2202},
  url = {https://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-14-S1-P40},
  doi = {10.1186/1471-2202-14-S1-P40},
  number = {S1},
  journaltitle = {BMC Neuroscience},
  urldate = {2019-03-30},
  date = {2013-07},
  author = {Brette, Romain},
  file = {/Users/qualia/Documents/Papers/2013 - Brette - An ecological approach to neural computation.pdf}
}

@article{Chaturvedi2013,
  langid = {english},
  title = {Artificial Neural Network Based Characterization of the Volume of Tissue Activated during Deep Brain Stimulation},
  volume = {10},
  issn = {1741-2560, 1741-2552},
  url = {http://stacks.iop.org/1741-2552/10/i=5/a=056023?key=crossref.2647fb8477dd9f8fb7cc767d8ae771ff},
  doi = {10.1088/1741-2560/10/5/056023},
  abstract = {Objective. Clinical deep brain stimulation (DBS) systems can be programmed with thousands of different stimulation parameter combinations (e.g. electrode contact(s), voltage, pulse width, frequency). Our goal was to develop novel computational tools to characterize the effects of stimulation parameter adjustment for DBS. Approach. The volume of tissue activated (VTA) represents a metric used to estimate the spatial extent of DBS for a given parameter setting. Traditional methods for calculating the VTA rely on activation function (AF)-based approaches and tend to overestimate the neural response when stimulation is applied through multiple electrode contacts. Therefore, we created a new method for VTA calculation that relied on artificial neural networks (ANNs). Main results. The ANN-based predictor provides more accurate descriptions of the spatial spread of activation compared to AF-based approaches for monopolar stimulation. In addition, the ANN was able to accurately estimate the VTA in response to multi-contact electrode configurations. Significance. The ANN-based approach may represent a useful method for fast computation of the VTA in situations with limited computational resources, such as a clinical DBS programming application on a tablet computer.},
  number = {5},
  journaltitle = {Journal of Neural Engineering},
  urldate = {2019-03-30},
  date = {2013-10-01},
  pages = {056023},
  author = {Chaturvedi, Ashutosh and Luj\'an, J Luis and McIntyre, Cameron C},
  file = {/Users/qualia/Documents/Papers/2013 - Chaturvedi, Luján, McIntyre - Artificial neural network based characterization of the volume of tissue activated during deep bra.pdf}
}

@article{Chen2013,
  langid = {english},
  title = {The {{Role}} of {{Coincidence}}-{{Detector Neurons}} in the {{Reliability}} and {{Precision}} of {{Subthreshold Signal Detection}} in {{Noise}}},
  volume = {8},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0056822},
  doi = {10.1371/journal.pone.0056822},
  abstract = {Subthreshold signal detection is an important task for animal survival in complex environments, where noise increases both the external signal response and the spontaneous spiking of neurons. The mechanism by which neurons process the coding of signals is not well understood. Here, we propose that coincidence detection, one of the ways to describe the functionality of a single neural cell, can improve the reliability and the precision of signal detection through detection of presynaptic input synchrony. Using a simplified neuronal network model composed of dozens of integrate-and-fire neurons and a single coincidence-detector neuron, we show how the network reads out the subthreshold noisy signals reliably and precisely. We find suitable pairing parameters, the threshold and the detection time window of the coincidence-detector neuron, that optimize the precision and reliability of the neuron. Furthermore, it is observed that the refractory period induces an oscillation in the spontaneous firing, but the neuron can inhibit this activity and improve the reliability and precision further. In the case of intermediate intrinsic states of the input neuron, the network responds to the input more efficiently. These results present the critical link between spiking synchrony and noisy signal transfer, which is utilized in coincidence detection, resulting in enhancement of temporally sensitive coding scheme.},
  number = {2},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2013-02-13},
  pages = {e56822},
  author = {Chen, Yueling and Zhang, Hui and Wang, Hengtong and Yu, Lianchun and Chen, Yong},
  editor = {Chacron, Maurice J.},
  file = {/Users/qualia/Documents/Papers/2013 - Chen et al. - The Role of Coincidence-Detector Neurons in the Reliability and Precision of Subthreshold Signal Detection in Noise.pdf}
}

@article{Coutanche2012,
  langid = {english},
  title = {The Advantage of Brief {{fMRI}} Acquisition Runs for Multi-Voxel Pattern Detection across Runs},
  volume = {61},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811912003643},
  doi = {10.1016/j.neuroimage.2012.03.076},
  abstract = {Functional magnetic resonance imaging (fMRI) studies are broken up into runs (or `sessions'), frequently selected to be long to minimize across-run signal variations. For investigations that use multi-voxel pattern analysis (MVPA), however, employing many short runs might improve a classifier's ability to generalize across irrelevant pattern variations and detect condition-related activity patterns. We directly tested this hypothesis by scanning participants with both long and short runs and comparing MVPA performance using data from each set of runs. Every run included presentations of faces, places, man-made objects and fruit in a blocked 1-back design. MVPA performance significantly improved from using a large number of short runs, compared to several long runs, in across-run classifications with identical amounts of data. Superior classification was found across variations in the classifier employed, feature selection procedure and region of interest. Performance improvements also extended to an information brain mapping `searchlight' procedure. These results suggest that investigators looking to maximize the detection of subtle multi-voxel patterns across runs might consider employing short fMRI runs.},
  number = {4},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2012-07},
  pages = {1113-1119},
  author = {Coutanche, Marc N. and Thompson-Schill, Sharon L.},
  file = {/Users/qualia/Documents/Papers/2013 - Coutanche, Thompson-Schill - The advantage of brief fMRI acquisition runs for multi-voxel pattern detection across runs.pdf}
}

@article{Curto2013,
  langid = {english},
  title = {Combinatorial {{Neural Codes}} from a {{Mathematical Coding Theory Perspective}}},
  volume = {25},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00459},
  doi = {10.1162/NECO_a_00459},
  number = {7},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2013-07},
  pages = {1891-1925},
  author = {Curto, Carina and Itskov, Vladimir and Morrison, Katherine and Roth, Zachary and Walker, Judy L.},
  file = {/Users/qualia/Documents/Papers/2013 - Curto et al. - Combinatorial Neural Codes from a Mathematical Coding Theory Perspective.pdf}
}

@article{Curto2013b,
  langid = {english},
  title = {The {{Neural Ring}}: {{An Algebraic Tool}} for {{Analyzing}} the {{Intrinsic Structure}} of {{Neural Codes}}},
  volume = {75},
  issn = {0092-8240, 1522-9602},
  url = {http://link.springer.com/10.1007/s11538-013-9860-3},
  doi = {10.1007/s11538-013-9860-3},
  shorttitle = {The {{Neural Ring}}},
  abstract = {Neurons in the brain represent external stimuli via neural codes. These codes often arise from stereotyped stimulus-response maps, associating to each neuron a convex receptive field. An important problem confronted by the brain is to infer properties of a represented stimulus space without knowledge of the receptive fields, using only the intrinsic structure of the neural code. How does the brain do this? To address this question, it is important to determine what stimulus space features can\textemdash{}in principle\textemdash{}be extracted from neural codes. This motivates us to define the neural ring and a related neural ideal, algebraic objects that encode the full combinatorial data of a neural code. Our main finding is that these objects can be expressed in a ``canonical form'' that directly translates to a minimal description of the receptive field structure intrinsic to the code. We also find connections to Stanley\textendash{}Reisner rings, and use ideas similar to those in the theory of monomial ideals to obtain an algorithm for computing the primary decomposition of pseudo-monomial ideals. This allows us to algorithmically extract the canonical form associated to any neural code, providing the groundwork for inferring stimulus space features from neural activity alone.},
  number = {9},
  journaltitle = {Bulletin of Mathematical Biology},
  urldate = {2019-03-30},
  date = {2013-09},
  pages = {1571-1611},
  author = {Curto, Carina and Itskov, Vladimir and Veliz-Cuba, Alan and Youngs, Nora},
  file = {/Users/qualia/Documents/Papers/2013 - Curto et al. - The Neural Ring An Algebraic Tool for Analyzing the Intrinsic Structure of Neural Codes.pdf}
}

@article{Dwork2013,
  langid = {english},
  title = {The {{Algorithmic Foundations}} of {{Differential Privacy}}},
  volume = {9},
  issn = {1551-305X, 1551-3068},
  url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-theoretical-computer-science/TCS-042},
  doi = {10.1561/0400000042},
  number = {3-4},
  journaltitle = {Foundations and Trends\textregistered{} in Theoretical Computer Science},
  urldate = {2019-03-30},
  date = {2013},
  pages = {211-407},
  author = {Dwork, Cynthia and Roth, Aaron},
  file = {/Users/qualia/Documents/Papers/2013 - Dwork, Roth - The Algorithmic Foundations of Differential Privacy.pdf}
}

@article{Fadlallah,
  langid = {english},
  title = {Weighted-{{Permutation Entropy}}: {{An Improved Complexity Measure}} for {{Time Series}}},
  pages = {8},
  author = {Fadlallah, Bilal and Pr\i{}ncipe, Jose and Chen, Badong and Keil, Andreas},
  file = {/Users/qualia/Documents/Papers/2013 - Fadlallah, Keil - Weighted-Permutation Entropy An Improved Complexity Measure for Time Series.pdf}
}

@article{Grant2013,
  langid = {english},
  title = {Simulation of {{Cortico}}-{{Basal Ganglia Oscillations}} and {{Their Suppression}} by {{Closed Loop Deep Brain Stimulation}}},
  volume = {21},
  issn = {1534-4320, 1558-0210},
  url = {http://ieeexplore.ieee.org/document/6214615/},
  doi = {10.1109/TNSRE.2012.2202403},
  abstract = {A new model of deep brain stimulation (DBS) is presented that integrates volume conduction effects with a neural model of pathological beta-band oscillations in the cortico-basal ganglia network. The model is used to test the clinical hypothesis that closed-loop control of the amplitude of DBS may be possible, based on the average rectified value of beta-band oscillations in the local field potential. Simulation of closed-loop high-frequency DBS was shown to yield energy savings, with the magnitude of the energy saved dependent on the strength of coupling between the subthalamic nucleus and the remainder of the cortico-basal ganglia network. When closed-loop DBS was applied to a strongly coupled cortico-basal ganglia network, the stimulation energy delivered over a 480 s period was reduced by up to 42\%. Greater energy reductions were observed for weakly coupled networks, as the stimulation amplitude reduced to zero once the initial desynchronization had occurred. The results provide support for the application of closed-loop high-frequency DBS based on electrophysiological biomarkers.},
  number = {4},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  urldate = {2019-03-30},
  date = {2013-07},
  pages = {584-594},
  author = {Grant, Peadar F. and Lowery, Madeleine M.},
  file = {/Users/qualia/Documents/Papers/2013 - Grant, Lowery - Simulation of cortico-basal ganglia oscillations and their suppression by closed loop deep brain stimulation.pdf}
}

@article{Gutierrez2013,
  langid = {english},
  title = {Multiple {{Mechanisms Switch}} an {{Electrically Coupled}}, {{Synaptically Inhibited Neuron}} between {{Competing Rhythmic Oscillators}}},
  volume = {77},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627313000822},
  doi = {10.1016/j.neuron.2013.01.016},
  abstract = {Rhythmic oscillations are common features of nervous systems. One of the fundamental questions posed by these rhythms is how individual neurons or groups of neurons are recruited into different network oscillations. We modeled competing fast and slow oscillators connected to a hub neuron with electrical and inhibitory synapses. We explore the patterns of coordination shown in the network as a function of the electrical coupling and inhibitory synapse strengths with the help of a novel visualization method that we call the ``parameterscape.'' The hub neuron can be switched between the fast and slow oscillators by multiple network mechanisms, indicating that a given change in network state can be achieved by degenerate cellular mechanisms. These results have importance for interpreting experiments employing optogenetic, genetic, and pharmacological manipulations to understand circuit dynamics.},
  number = {5},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2013-03},
  pages = {845-858},
  author = {Gutierrez, Gabrielle J. and O'Leary, Timothy and Marder, Eve},
  file = {/Users/qualia/Documents/Papers/2013 - Gutierrez, O'Leary, Marder - Multiple mechanisms switch an electrically coupled, synaptically inhibited neuron between competing.pdf}
}

@article{Iyer2013,
  langid = {english},
  title = {The {{Influence}} of {{Synaptic Weight Distribution}} on {{Neuronal Population Dynamics}}},
  volume = {9},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1003248},
  doi = {10.1371/journal.pcbi.1003248},
  abstract = {The manner in which different distributions of synaptic weights onto cortical neurons shape their spiking activity remains open. To characterize a homogeneous neuronal population, we use the master equation for generalized leaky integrateand-fire neurons with shot-noise synapses. We develop fast semi-analytic numerical methods to solve this equation for either current or conductance synapses, with and without synaptic depression. We show that its solutions match simulations of equivalent neuronal networks better than those of the Fokker-Planck equation and we compute bounds on the network response to non-instantaneous synapses. We apply these methods to study different synaptic weight distributions in feed-forward networks. We characterize the synaptic amplitude distributions using a set of measures, called tail weight numbers, designed to quantify the preponderance of very strong synapses. Even if synaptic amplitude distributions are equated for both the total current and average synaptic weight, distributions with sparse but strong synapses produce higher responses for small inputs, leading to a larger operating range. Furthermore, despite their small number, such synapses enable the network to respond faster and with more stability in the face of external fluctuations.},
  number = {10},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2013-10-24},
  pages = {e1003248},
  author = {Iyer, Ramakrishnan and Menon, Vilas and Buice, Michael and Koch, Christof and Mihalas, Stefan},
  editor = {Sporns, Olaf},
  file = {/Users/qualia/Documents/Papers/2013 - Iyer et al. - The Influence of Synaptic Weight Distribution on Neuronal Population Dynamics.pdf}
}

@article{Kaufman2013,
  langid = {english},
  title = {The Roles of Monkey {{M1}} Neuron Classes in Movement Preparation and Execution},
  volume = {110},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00892.2011},
  doi = {10.1152/jn.00892.2011},
  number = {4},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2013-08-15},
  pages = {817-825},
  author = {Kaufman, Matthew T. and Churchland, Mark M. and Shenoy, Krishna V.},
  file = {/Users/qualia/Documents/Papers/2013 - Kaufman, Churchland, Shenoy - The roles of monkey M1 neuron classes in movement preparation and execution.pdf}
}

@article{Khodagholy2013,
  langid = {english},
  title = {In Vivo Recordings of Brain Activity Using Organic Transistors},
  volume = {4},
  issn = {2041-1723},
  url = {http://www.nature.com/articles/ncomms2573},
  doi = {10.1038/ncomms2573},
  number = {1},
  journaltitle = {Nature Communications},
  urldate = {2019-03-30},
  date = {2013-12},
  author = {Khodagholy, Dion and Doublet, Thomas and Quilichini, Pascale and Gurfinkel, Moshe and Leleux, Pierre and Ghestem, Antoine and Ismailova, Esma and Herv\'e, Thierry and Sanaur, S\'ebastien and Bernard, Christophe and Malliaras, George G.},
  file = {/Users/qualia/Documents/Papers/2013 - Khodagholy et al. - In vivo recordings of brain activity using organic transistors.pdf}
}

@article{King2013,
  langid = {english},
  title = {Inhibitory {{Interneurons Decorrelate Excitatory Cells}} to {{Drive Sparse Code Formation}} in a {{Spiking Model}} of {{V1}}},
  volume = {33},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4188-12.2013},
  doi = {10.1523/JNEUROSCI.4188-12.2013},
  number = {13},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2013-03-27},
  pages = {5475-5485},
  author = {King, P. D. and Zylberberg, J. and DeWeese, M. R.},
  file = {/Users/qualia/Documents/Papers/2013 - King, Zylberberg, DeWeese - Inhibitory interneurons decorrelate excitatory cells to drive sparse code formation in a spiking mode.pdf}
}

@article{Lucken2013,
  langid = {english},
  title = {Desynchronization Boost by Non-Uniform Coordinated Reset Stimulation in Ensembles of Pulse-Coupled Neurons},
  volume = {7},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2013.00063/abstract},
  doi = {10.3389/fncom.2013.00063},
  abstract = {Several brain diseases are characterized by abnormal neuronal synchronization. Desynchronization of abnormal neural synchrony is theoretically compelling because of the complex dynamical mechanisms involved. We here present a novel type of coordinated reset (CR) stimulation. CR means to deliver phase resetting stimuli at different neuronal sub-populations sequentially, i.e., at times equidistantly distributed in a stimulation cycle. This uniform timing pattern seems to be intuitive and actually applies to the neural network models used for the study of CR so far. CR resets the population to an unstable cluster state from where it passes through a desynchronized transient, eventually resynchronizing if left unperturbed. In contrast, we show that the optimal stimulation times are non-uniform. Using the model of weakly pulse-coupled neurons with phase response curves, we provide an approach that enables to determine optimal stimulation timing patterns that substantially maximize the desynchronized transient time following the application of CR stimulation. This approach includes an optimization search for clusters in a low-dimensional pulse coupled map. As a consequence, model-specific non-uniformly spaced cluster states cause considerably longer desynchronization transients. Intriguingly, such a desynchronization boost with non-uniform CR stimulation can already be achieved by only slight modifications of the uniform CR timing pattern. Our results suggest that the non-uniformness of the stimulation times can be a medically valuable parameter in the calibration procedure for CR stimulation, where the latter has successfully been used in clinical and pre-clinical studies for the treatment of Parkinson's disease and tinnitus.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2013},
  author = {L\"ucken, Leonhard and Yanchuk, Serhiy and Popovych, Oleksandr V. and Tass, Peter A.},
  file = {/Users/qualia/Documents/Papers/2013 - Lücken et al. - Desynchronization boost by non-uniform coordinated reset stimulation in ensembles of pulse-coupled neurons.pdf}
}

@article{Lupyan2013,
  langid = {english},
  title = {The Difficulties of Executing Simple Algorithms: {{Why}} Brains Make Mistakes Computers Don't},
  volume = {129},
  issn = {00100277},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027713001728},
  doi = {10.1016/j.cognition.2013.08.015},
  shorttitle = {The Difficulties of Executing Simple Algorithms},
  abstract = {It is shown that educated adults routinely make errors in placing stimuli into familiar, welldefined categories such as TRIANGLE and ODD NUMBER. Scalene triangles are often rejected as instances of triangles and 798 is categorized by some as an odd number. These patterns are observed both in timed and untimed tasks, hold for people who can fully express the necessary and sufficient conditions for category membership, and for individuals with varying levels of education. A sizeable minority of people believe that 400 is more even than 798 and that an equilateral triangle is the most ``trianglest'' of triangles. Such beliefs predict how people instantiate other categories with necessary and sufficient conditions, e.g., GRANDMOTHER. I argue that the distributed and graded nature of mental representations means that human algorithms, unlike conventional computer algorithms, only approximate rule-based classification and never fully abstract from the specifics of the input. This input-sensitivity is critical to obtaining the kind of cognitive flexibility at which humans excel, but comes at the cost of generally poor abilities to perform context-free computations. If human algorithms cannot be trusted to produce unfuzzy representations of odd numbers, triangles, and grandmothers, the idea that they can be trusted to do the heavy lifting of moment-to-moment cognition that is inherent in the metaphor of mind as digital computer still common in cognitive science, needs to be seriously reconsidered.},
  number = {3},
  journaltitle = {Cognition},
  urldate = {2019-03-30},
  date = {2013-12},
  pages = {615-636},
  author = {Lupyan, Gary},
  file = {/Users/qualia/Documents/Papers/2013 - Lupyan - The difficulties of executing simple algorithms Why brains make mistakes computers don't.pdf}
}

@article{Machta2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1303.6738},
  langid = {english},
  title = {Parameter {{Space Compression Underlies Emergent Theories}} and {{Predictive Models}}},
  volume = {342},
  issn = {0036-8075, 1095-9203},
  url = {http://arxiv.org/abs/1303.6738},
  doi = {10.1126/science.1238723},
  abstract = {We report a similarity between the microscopic parameter dependance of emergent theories in physics and that of multiparameter models common in other areas of science. In both cases, predictions are possible despite large uncertainties in the microscopic parameters because these details are compressed into just a few governing parameters that are sufficient to describe relevant observables. We make this commonality explicit by examining parameter sensitivity in a hopping model of diffusion and a generalized Ising model of ferromagnetism. We trace the emergence of a smaller effective model to the development of a hierarchy of parameter importance quantified by the eigenvalues of the Fisher Information Matrix. Strikingly, the same hierarchy appears ubiquitously in models taken from diverse areas of science. We conclude that the emergence of effective continuum and universal theories in physics is due to the same parameter space hierarchy that underlies predictive modeling in other areas of science.},
  number = {6158},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2013-11-01},
  pages = {604-607},
  keywords = {Physics - Data Analysis; Statistics and Probability,Condensed Matter - Statistical Mechanics,Mathematical Physics,Quantitative Biology - Other Quantitative Biology},
  author = {Machta, Benjamin B. and Chachra, Ricky and Transtrum, Mark K. and Sethna, James P.},
  file = {/Users/qualia/Documents/Papers/2013 - Machta et al. - Parameter space compression underlies emergent theories and predictive models.pdf}
}

@article{Mante2013,
  langid = {english},
  title = {Context-Dependent Computation by Recurrent Dynamics in Prefrontal Cortex},
  volume = {503},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature12742},
  doi = {10.1038/nature12742},
  number = {7474},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2013-11},
  pages = {78-84},
  author = {Mante, Valerio and Sussillo, David and Shenoy, Krishna V. and Newsome, William T.},
  file = {/Users/qualia/Documents/Papers/2013 - Mante et al. - Context-dependent computation by recurrent dynamics in prefrontal cortex.pdf}
}

@article{Miller2013,
  langid = {english},
  title = {Cortical Circuits for the Control of Attention},
  volume = {23},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438812001857},
  doi = {10.1016/j.conb.2012.11.011},
  number = {2},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2013-04},
  pages = {216-222},
  author = {Miller, Earl K and Buschman, Timothy J},
  file = {/Users/qualia/Documents/Papers/2013 - Miller, Buschman - Cortical circuits for the control of attention.pdf}
}

@article{Munoz-Moreno2013,
  langid = {english},
  title = {A {{Magnetic Resonance Image Based Atlas}} of the {{Rabbit Brain}} for {{Automatic Parcellation}}},
  volume = {8},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0067418},
  doi = {10.1371/journal.pone.0067418},
  abstract = {Rabbit brain has been used in several works for the analysis of neurodevelopment. However, there are not specific digital rabbit brain atlases that allow an automatic identification of brain regions, which is a crucial step for various neuroimage analyses, and, instead, manual delineation of areas of interest must be performed in order to evaluate a specific structure. For this reason, we propose an atlas of the rabbit brain based on magnetic resonance imaging, including both structural and diffusion weighted, that can be used for the automatic parcellation of the rabbit brain. Ten individual atlases, as well as an average template and probabilistic maps of the anatomical regions were built. In addition, an example of automatic segmentation based on this atlas is described.},
  number = {7},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2013-07-02},
  pages = {e67418},
  author = {Mu\~noz-Moreno, Emma and Arbat-Plana, Ariadna and Batalle, Dafnis and Soria, Guadalupe and Illa, Miriam and Prats-Galino, Alberto and Eixarch, Elisenda and Gratacos, Eduard},
  editor = {Malmierca, Manuel S.},
  file = {/Users/qualia/Documents/Papers/2013 - Muñoz-Moreno et al. - A Magnetic Resonance Image Based Atlas of the Rabbit Brain for Automatic Parcellation.pdf}
}

@article{Muto2013,
  langid = {english},
  title = {Real-{{Time Visualization}} of {{Neuronal Activity}} during {{Perception}}},
  volume = {23},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S096098221300002X},
  doi = {10.1016/j.cub.2012.12.040},
  abstract = {To understand how the brain perceives the external world, it is desirable to observe neuronal activity in the brain in real time during perception. The zebrafish is a suitable model animal for fluorescence imaging studies to visualize neuronal activity because its body is transparent through the embryonic and larval stages. Imaging studies have been carried out to monitor neuronal activity in the larval spinal cord and brain using Ca2+ indicator dyes [1\textendash{}3] and DNA-encoded Ca2+ indicators, such as Cameleon [4], GFPaequorin [5], and GCaMPs [6\textendash{}12]. However, temporal and spatial resolution and sensitivity of these tools are still limited, and imaging of brain activity during perception of a natural object has not yet been demonstrated. Here we demonstrate visualization of neuronal activity in the optic tectum of larval zebrafish by genetically expressing the new version of GCaMP. First, we demonstrate Ca2+ transients in the tectum evoked by a moving spot on a display and identify direction-selective neurons. Second, we show tectal activity during perception of a natural object, a swimming paramecium, revealing a functional visuotopic map. Finally, we image the tectal responses of a free-swimming larval fish to a paramecium and thereby correlate neuronal activity in the brain with prey capture behavior.},
  number = {4},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2013-02},
  pages = {307-311},
  author = {Muto, Akira and Ohkura, Masamichi and Abe, Gembu and Nakai, Junichi and Kawakami, Koichi},
  file = {/Users/qualia/Documents/Papers/2013 - Muto et al. - Real-Time Visualization of Neuronal Activity during Perception.pdf}
}

@article{Neymotin2013,
  langid = {english},
  title = {Ih {{Tunes Theta}}/{{Gamma Oscillations}} and {{Cross}}-{{Frequency Coupling In}} an {{In Silico CA3 Model}}},
  volume = {8},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0076285},
  doi = {10.1371/journal.pone.0076285},
  abstract = {Ih channels are uniquely positioned to act as neuromodulatory control points for tuning hippocampal theta (4\textendash{}12 Hz) and gamma (w25 Hz) oscillations, oscillations which are thought to have importance for organization of information flow. Ih contributes to neuronal membrane resonance and resting membrane potential, and is modulated by second messengers. We investigated Ih oscillatory control using a multiscale computer model of hippocampal CA3, where each cell class (pyramidal, basket, and oriens-lacunosum moleculare cells), contained type-appropriate isoforms of Ih. Our model demonstrated that modulation of pyramidal and basket Ih allows tuning theta and gamma oscillation frequency and amplitude. Pyramidal Ih also controlled cross-frequency coupling (CFC) and allowed shifting gamma generation towards particular phases of the theta cycle, effected via Ih 's ability to set pyramidal excitability. Our model predicts that in vivo neuromodulatory control of Ih allows flexibly controlling CFC and the timing of gamma discharges at particular theta phases.},
  number = {10},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2013-10-18},
  pages = {e76285},
  author = {Neymotin, Samuel A. and Hilscher, Markus M. and Moulin, Thiago C. and Skolnick, Yosef and Lazarewicz, Maciej T. and Lytton, William W.},
  editor = {Cymbalyuk, Gennady},
  file = {/Users/qualia/Documents/Papers/2013 - Neymotin et al. - Ih Tunes ThetaGamma Oscillations and Cross-Frequency Coupling In an In Silico CA3 Model.pdf}
}

@article{OLeary2013,
  langid = {english},
  title = {Correlations in Ion Channel Expression Emerge from Homeostatic Tuning Rules},
  volume = {110},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1309966110},
  doi = {10.1073/pnas.1309966110},
  number = {28},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2013-07-09},
  pages = {E2645-E2654},
  author = {O'Leary, T. and Williams, A. H. and Caplan, J. S. and Marder, E.},
  file = {/Users/qualia/Documents/Papers/2013 - O'Leary et al. - Correlations in ion channel expression emerge from homeostatic tuning rules.pdf}
}

@article{Peron2013,
  langid = {english},
  title = {Subthalamic Nucleus: {{A}} Key Structure for Emotional Component Synchronization in Humans},
  volume = {37},
  issn = {01497634},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S014976341300002X},
  doi = {10.1016/j.neubiorev.2013.01.001},
  shorttitle = {Subthalamic Nucleus},
  abstract = {Affective neuroscience is concerned with identifying the neural bases of emotion. For historical and methodological reasons, models describing the brain architecture that supports emotional processes in humans have tended to neglect the basal ganglia, focusing instead on cortical and amygdalar mechanisms. Now, however, deep brain stimulation (DBS) of the subthalamic nucleus (STN), a neurosurgical treatment for Parkinson's disease and obsessive\textendash{}compulsive disorder, is helping researchers explore the possible functional role of this particular basal ganglion in emotional processes. After reviewing studies that have used DBS in this way, we propose a model in which the STN plays a crucial role in producing temporally organized neural co-activation patterns at the cortical and subcortical levels that are essential for generating emotions and related feelings.},
  number = {3},
  journaltitle = {Neuroscience \& Biobehavioral Reviews},
  urldate = {2019-03-30},
  date = {2013-03},
  pages = {358-373},
  author = {P\'eron, Julie and Fr\"uhholz, Sascha and V\'erin, Marc and Grandjean, Didier},
  file = {/Users/qualia/Documents/Papers/2013 - Péron et al. - Subthalamic nucleus A key structure for emotional component synchronization in humans.pdf}
}

@article{Pinotsis2013,
  langid = {english},
  title = {On Conductance-Based Neural Field Models},
  volume = {7},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2013.00158/abstract},
  doi = {10.3389/fncom.2013.00158},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2013},
  author = {Pinotsis, Dimitris A. and Leite, Marco and Friston, Karl J.},
  file = {/Users/qualia/Documents/Papers/2013 - Pinotsis, Leite, Friston - On conductance-based neural field models.pdf}
}

@article{Qi2013,
  langid = {english},
  title = {Firing Patterns in a Conductance-Based Neuron Model: Bifurcation, Phase Diagram, and Chaos},
  volume = {107},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-012-0520-8},
  doi = {10.1007/s00422-012-0520-8},
  shorttitle = {Firing Patterns in a Conductance-Based Neuron Model},
  abstract = {Responding to various stimuli, some neurons either remain resting or can fire several distinct patterns of action potentials, such as spiking, bursting, subthreshold oscillations, and chaotic firing. In particular, Wilson's conductance-based neocortical neuron model, derived from the Hodgkin\textendash{}Huxley model, is explored to understand underlying mechanisms of the firing patterns. Phase diagrams describing boundaries between the domains of different firing patterns are obtained via extensive numerical computations. The boundaries are further studied by standard instability analyses, which demonstrates that the chaotic neural firing could develop via period-doubling and/or periodadding cascades. Sequences of the firing patterns often observed in many neural experiments are also discussed in the phase diagram framework developed. Our results lay the groundwork for wider use of the model, especially for incorporating it into neural field modeling of the brain.},
  number = {1},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2013-02},
  pages = {15-24},
  author = {Qi, Y. and Watts, A. L. and Kim, J. W. and Robinson, P. A.},
  file = {/Users/qualia/Documents/Papers/2013 - Qi et al. - Firing patterns in a conductance-based neuron model bifurcation, phase diagram, and chaos.pdf}
}

@article{Rehan2013,
  langid = {english},
  title = {Modeling and {{Automatic Feedback Control}} of {{Tremor}}: {{Adaptive Estimation}} of {{Deep Brain Stimulation}}},
  volume = {8},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0062888},
  doi = {10.1371/journal.pone.0062888},
  shorttitle = {Modeling and {{Automatic Feedback Control}} of {{Tremor}}},
  abstract = {This paper discusses modeling and automatic feedback control of (postural and rest) tremor for adaptive-controlmethodology-based estimation of deep brain stimulation (DBS) parameters. The simplest linear oscillator-based tremor model, between stimulation amplitude and tremor, is investigated by utilizing input-output knowledge. Further, a nonlinear generalization of the oscillator-based tremor model, useful for derivation of a control strategy involving incorporation of parametric-bound knowledge, is provided. Using the Lyapunov method, a robust adaptive output feedback control law, based on measurement of the tremor signal from the fingers of a patient, is formulated to estimate the stimulation amplitude required to control the tremor. By means of the proposed control strategy, an algorithm is developed for estimation of DBS parameters such as amplitude, frequency and pulse width, which provides a framework for development of an automatic clinical device for control of motor symptoms. The DBS parameter estimation results for the proposed control scheme are verified through numerical simulations.},
  number = {4},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2013-04-24},
  pages = {e62888},
  author = {Rehan, Muhammad and Hong, Keum-Shik},
  editor = {Androulakis, Ioannis P.},
  file = {/Users/qualia/Documents/Papers/2013 - Rehan, Hong - Modeling and Automatic Feedback Control of Tremor Adaptive Estimation of Deep Brain Stimulation.pdf;/Users/qualia/Documents/Papers/2013 - Rehan, Hong - Modeling and Automatic Feedback Control of Tremor Adaptive Estimation of Deep Brain Stimulation(2).pdf}
}

@article{Riedl2013,
  langid = {english},
  title = {Practical Considerations of Permutation Entropy: {{A}} Tutorial Review},
  volume = {222},
  issn = {1951-6355, 1951-6401},
  url = {http://link.springer.com/10.1140/epjst/e2013-01862-7},
  doi = {10.1140/epjst/e2013-01862-7},
  shorttitle = {Practical Considerations of Permutation Entropy},
  abstract = {More than ten years ago Bandt and Pompe introduced a new measure to quantify complexity in measured time series. During these ten years, this measure has been modified and extended. In this review we will give a brief introduction to permutation entropy, explore the different fields of utilization where permutation entropy has been applied and provide a guide on how to choose appropriate parameters for different applications of permutation entropy.},
  number = {2},
  journaltitle = {The European Physical Journal Special Topics},
  urldate = {2019-03-30},
  date = {2013-06},
  pages = {249-262},
  author = {Riedl, M. and M\"uller, A. and Wessel, N.},
  file = {/Users/qualia/Documents/Papers/2013 - Riedl, Mller, Wessel - Practical considerations of permutation entropy A tutorial review.pdf}
}

@article{So2012,
  langid = {english},
  title = {Relative Contributions of Local Cell and Passing Fiber Activation and Silencing to Changes in Thalamic Fidelity during Deep Brain Stimulation and Lesioning: A Computational Modeling Study},
  volume = {32},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-011-0366-4},
  doi = {10.1007/s10827-011-0366-4},
  shorttitle = {Relative Contributions of Local Cell and Passing Fiber Activation and Silencing to Changes in Thalamic Fidelity during Deep Brain Stimulation and Lesioning},
  abstract = {Deep brain stimulation (DBS) and lesioning are two surgical techniques used in the treatment of advanced Parkinson's disease (PD) in patients whose symptoms are not well controlled by drugs, or who experience dyskinesias as a side effect of medications. Although these treatments have been widely practiced, the mechanisms behind DBS and lesioning are still not well understood. The subthalamic nucleus (STN) and globus pallidus pars interna (GPi) are two common targets for both DBS and lesioning. Previous studies have indicated that DBS not only affects local cells within the target, but also passing axons within neighboring regions. Using a computational model of the basal ganglia-thalamic network, we studied the relative contributions of activation and silencing of local cells (LCs) and fibers of passage (FOPs) to changes in the accuracy of information transmission through the thalamus (thalamic fidelity), which is correlated with the effectiveness of DBS. Activation of both LCs and FOPs during STN and GPi-DBS were beneficial to the outcome of stimulation. During STN and GPi lesioning, effects of silencing LCs and FOPs were different between the two types of lesioning. For STN lesioning, silencing GPi FOPs mainly contributed to its effectiveness, while silencing only STN LCs did not improve thalamic fidelity. In contrast, silencing both GPi LCs and GPe FOPs during GPi lesioning contributed to improvements in thalamic fidelity. Thus, two distinct mechanisms produced comparable improvements in thalamic function: driving the output of the basal ganglia to produce tonic inhibition and silencing the output of the basal ganglia to produce tonic disinhibition. These results show the importance of considering effects of activating or silencing fibers passing close to the nucleus when deciding upon a target location for DBS or lesioning.},
  number = {3},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2012-06},
  pages = {499-519},
  author = {So, Rosa Q. and Kent, Alexander R. and Grill, Warren M.},
  file = {/Users/qualia/Documents/Papers/2013 - Rosa Q. So, Alexander R. Kent - Relative contributions of local cell and passing fiber activation and silencing to changes in tha.pdf}
}

@article{Rowan2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1304.2266},
  primaryClass = {cs, q-bio},
  langid = {english},
  title = {Synaptic {{Scaling Balances Learning}} in a {{Spiking Model}} of {{Neocortex}}},
  url = {http://arxiv.org/abs/1304.2266},
  abstract = {Learning in the brain requires complementary mechanisms: potentiation and activity-dependent homeostatic scaling. We introduce synaptic scaling to a biologically-realistic spiking model of neocortex which can learn changes in oscillatory rhythms using STDP, and show that scaling is necessary to balance both positive and negative changes in input from potentiation and atrophy. We discuss some of the issues that arise when considering synaptic scaling in such a model, and show that scaling regulates activity whilst allowing learning to remain unaltered.},
  urldate = {2019-03-30},
  date = {2013-04-08},
  keywords = {Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  author = {Rowan, Mark and Neymotin, Samuel},
  file = {/Users/qualia/Documents/Papers/2013 - Rowan, Neymotin - Synaptic Scaling Balances Learning in a Spiking Model of Neocortex.pdf}
}

@article{Santi2014,
  langid = {english},
  title = {Quantifying the Benefits of Vehicle Pooling with Shareability Networks},
  volume = {111},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1403657111},
  doi = {10.1073/pnas.1403657111},
  number = {37},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2014-09-16},
  pages = {13290-13294},
  author = {Santi, Paolo and Resta, Giovanni and Szell, Michael and Sobolevsky, Stanislav and Strogatz, Steven H. and Ratti, Carlo},
  file = {/Users/qualia/Documents/Papers/2013 - Santi et al. - Quantifying the benefits of vehicle pooling with shareability networks.pdf}
}

@article{Saxe2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1312.6120},
  primaryClass = {cond-mat, q-bio, stat},
  langid = {english},
  title = {Exact Solutions to the Nonlinear Dynamics of Learning in Deep Linear Neural Networks},
  url = {http://arxiv.org/abs/1312.6120},
  abstract = {Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.},
  urldate = {2019-03-30},
  date = {2013-12-20},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition,Condensed Matter - Disordered Systems and Neural Networks,Computer Science - Computer Vision and Pattern Recognition},
  author = {Saxe, Andrew M. and McClelland, James L. and Ganguli, Surya},
  file = {/Users/qualia/Documents/Papers/2013 - Saxe, McClelland, Ganguli - Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.pdf}
}

@article{Schaffer2013,
  langid = {english},
  title = {A {{Complex}}-{{Valued Firing}}-{{Rate Model That Approximates}} the {{Dynamics}} of {{Spiking Networks}}},
  volume = {9},
  issn = {1553-7358},
  url = {http://dx.plos.org/10.1371/journal.pcbi.1003301},
  doi = {10.1371/journal.pcbi.1003301},
  abstract = {Firing-rate models provide an attractive approach for studying large neural networks because they can be simulated rapidly and are amenable to mathematical analysis. Traditional firing-rate models assume a simple form in which the dynamics are governed by a single time constant. These models fail to replicate certain dynamic features of populations of spiking neurons, especially those involving synchronization. We present a complex-valued firing-rate model derived from an eigenfunction expansion of the Fokker-Planck equation and apply it to the linear, quadratic and exponential integrate-andfire models. Despite being almost as simple as a traditional firing-rate description, this model can reproduce firing-rate dynamics due to partial synchronization of the action potentials in a spiking model, and it successfully predicts the transition to spike synchronization in networks of coupled excitatory and inhibitory neurons.},
  number = {10},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2013-10-31},
  pages = {e1003301},
  author = {Schaffer, Evan S. and Ostojic, Srdjan and Abbott, L. F.},
  editor = {Ermentrout, Bard},
  file = {/Users/qualia/Documents/Papers/2013 - Schaffer, Ostojic, Abbott - A Complex-Valued Firing-Rate Model That Approximates the Dynamics of Spiking Networks.pdf}
}

@article{Schillebeeckx2013,
  langid = {english},
  title = {The Missing Piece to Changing the University Culture},
  volume = {31},
  issn = {1087-0156, 1546-1696},
  url = {http://www.nature.com/articles/nbt.2706},
  doi = {10.1038/nbt.2706},
  number = {10},
  journaltitle = {Nature Biotechnology},
  urldate = {2019-03-30},
  date = {2013-10},
  pages = {938-941},
  author = {Schillebeeckx, Maximiliaan and Maricque, Brett and Lewis, Cory},
  file = {/Users/qualia/Documents/Papers/2013 - Schillebeeckx, Maricque, Lewis - The missing piece to changing the university culture.pdf}
}

@article{Schmidt2013,
  langid = {english},
  title = {Patterned {{Brain Stimulation}}, {{What}} a {{Framework}} with {{Rhythmic}} and {{Noisy Components Might Tell Us}} about {{Recovery Maximization}}},
  volume = {7},
  issn = {1662-5161},
  url = {http://journal.frontiersin.org/article/10.3389/fnhum.2013.00325/abstract},
  doi = {10.3389/fnhum.2013.00325},
  abstract = {Brain stimulation is having remarkable impact on clinical neurology. Brain stimulation can modulate neuronal activity in functionally segregated circumscribed regions of the human brain. Polarity, frequency, and noise specific stimulation can induce specific manipulations on neural activity. In contrast to neocortical stimulation, deep-brain stimulation has become a tool that can dramatically improve the impact clinicians can possibly have on movement disorders. In contrast, neocortical brain stimulation is proving to be remarkably susceptible to intrinsic brain-states. Although evidence is accumulating that brain stimulation can facilitate recovery processes in patients with cerebral stroke, the high variability of results impedes successful clinical implementation. Interestingly, recent data in healthy subjects suggests that brain-state dependent patterned stimulation might help resolve some of the intrinsic variability found in previous studies. In parallel, other studies suggest that noisy ``stochastic resonance'' (SR)-like processes are a non-negligible component in non-invasive brain stimulation studies. The hypothesis developed in this manuscript is that stimulation patterning with noisy and oscillatory components will help patients recover from stroke related deficits more reliably. To address this hypothesis we focus on two factors common to both neural computation (intrinsic variables) as well as brain stimulation (extrinsic variables): noise and oscillation. We review diverse theoretical and experimental evidence that demonstrates that subject-function specific brain-states are associated with specific oscillatory activity patterns. These states are transient and can be maintained by noisy processes. The resulting control procedures can resemble homeostatic or SR processes. In this context we try to extend awareness for inter-individual differences and the use of individualized stimulation in the recovery maximization of stroke patients.},
  journaltitle = {Frontiers in Human Neuroscience},
  urldate = {2019-03-30},
  date = {2013},
  author = {Schmidt, Sein and Scholz, Michael and Obermayer, Klaus and Brandt, Stephan A.},
  file = {/Users/qualia/Documents/Papers/2013 - Schmidt et al. - Patterned Brain Stimulation, What a Framework with Rhythmic and Noisy Components Might Tell Us about Recovery Ma.pdf}
}

@article{Serrano2013,
  langid = {english},
  title = {Gain {{Control Network Conditions}} in {{Early Sensory Coding}}},
  volume = {9},
  issn = {1553-7358},
  url = {http://dx.plos.org/10.1371/journal.pcbi.1003133},
  doi = {10.1371/journal.pcbi.1003133},
  abstract = {Gain control is essential for the proper function of any sensory system. However, the precise mechanisms for achieving effective gain control in the brain are unknown. Based on our understanding of the existence and strength of connections in the insect olfactory system, we analyze the conditions that lead to controlled gain in a randomly connected network of excitatory and inhibitory neurons. We consider two scenarios for the variation of input into the system. In the first case, the intensity of the sensory input controls the input currents to a fixed proportion of neurons of the excitatory and inhibitory populations. In the second case, increasing intensity of the sensory stimulus will both, recruit an increasing number of neurons that receive input and change the input current that they receive. Using a mean field approximation for the network activity we derive relationships between the parameters of the network that ensure that the overall level of activity of the excitatory population remains unchanged for increasing intensity of the external stimulation. We find that, first, the main parameters that regulate network gain are the probabilities of connections from the inhibitory population to the excitatory population and of the connections within the inhibitory population. Second, we show that strict gain control is not achievable in a random network in the second case, when the input recruits an increasing number of neurons. Finally, we confirm that the gain control conditions derived from the mean field approximation are valid in simulations of firing rate models and Hodgkin-Huxley conductance based models.},
  number = {7},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2013-07-18},
  pages = {e1003133},
  author = {Serrano, Eduardo and Nowotny, Thomas and Levi, Rafael and Smith, Brian H. and Huerta, Ram\'on},
  editor = {Sporns, Olaf},
  file = {/Users/qualia/Documents/Papers/2013 - Serrano et al. - Gain Control Network Conditions in Early Sensory Coding.pdf}
}

@article{Laje2013,
  langid = {english},
  title = {Robust Timing and Motor Patterns by Taming Chaos in Recurrent Neural Networks},
  volume = {16},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3405},
  doi = {10.1038/nn.3405},
  number = {7},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2013-07},
  pages = {925-933},
  author = {Laje, Rodrigo and Buonomano, Dean V},
  file = {/Users/qualia/Documents/Papers/2013 - Laje, Buonomano - Robust timing and motor patterns by taming chaos in recurrent neural networks.pdf}
}

@article{Lange2013,
  langid = {english},
  title = {Reduced {{Occipital Alpha Power Indexes Enhanced Excitability Rather}} than {{Improved Visual Perception}}},
  volume = {33},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3755-12.2013},
  doi = {10.1523/JNEUROSCI.3755-12.2013},
  number = {7},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2013-02-13},
  pages = {3212-3220},
  author = {Lange, J. and Oostenveld, R. and Fries, P.},
  file = {/Users/qualia/Documents/Papers/2013 - Lange, Oostenveld, Fries - Reduced Occipital Alpha Power Indexes Enhanced Excitability Rather than Improved Visual Perception.pdf}
}

@article{Lien2013,
  langid = {english},
  title = {Tuned Thalamic Excitation Is Amplified by Visual Cortical Circuits},
  volume = {16},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3488},
  doi = {10.1038/nn.3488},
  number = {9},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2013-09},
  pages = {1315-1323},
  author = {Lien, Anthony D and Scanziani, Massimo},
  file = {/Users/qualia/Documents/Papers/2013 - Lien, Scanziani - Tuned thalamic excitation is amplified by visual cortical circuits.pdf}
}

@article{Lisman2013,
  langid = {english},
  title = {The {{Theta}}-{{Gamma Neural Code}}},
  volume = {77},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627313002316},
  doi = {10.1016/j.neuron.2013.03.007},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2013-03},
  pages = {1002-1016},
  author = {Lisman, John E. and Jensen, Ole},
  file = {/Users/qualia/Documents/Papers/2013 - Lisman, Jensen - The θ-γ neural code.pdf}
}

@article{Siero2013,
  langid = {english},
  title = {{{BOLD Consistently Matches Electrophysiology}} in {{Human Sensorimotor Cortex}} at {{Increasing Movement Rates}}: {{A Combined 7T fMRI}} and {{ECoG Study}} on {{Neurovascular Coupling}}},
  volume = {33},
  issn = {0271-678X, 1559-7016},
  url = {http://journals.sagepub.com/doi/10.1038/jcbfm.2013.97},
  doi = {10.1038/jcbfm.2013.97},
  shorttitle = {{{BOLD Consistently Matches Electrophysiology}} in {{Human Sensorimotor Cortex}} at {{Increasing Movement Rates}}},
  number = {9},
  journaltitle = {Journal of Cerebral Blood Flow \& Metabolism},
  urldate = {2019-03-30},
  date = {2013-09},
  pages = {1448-1456},
  author = {Siero, Jeroen CW and Hermes, Dora and Hoogduin, Hans and Luijten, Peter R and Petridou, Natalia and Ramsey, Nick F},
  file = {/Users/qualia/Documents/Papers/2013 - Siero et al. - BOLD Consistently Matches Electrophysiology in Human Sensorimotor Cortex at Increasing Movement Rates A Combined 7.pdf;/Users/qualia/Documents/Papers/Siero et al. - 2013 - BOLD Consistently Matches Electrophysiology in Hum.pdf}
}

@article{Soltoggio2013,
  langid = {english},
  title = {Rare {{Neural Correlations Implement Robotic Conditioning}} with {{Delayed Rewards}} and {{Disturbances}}},
  volume = {7},
  issn = {1662-5218},
  url = {http://journal.frontiersin.org/article/10.3389/fnbot.2013.00006/abstract},
  doi = {10.3389/fnbot.2013.00006},
  abstract = {Neural conditioning associates cues and actions with following rewards. The environments in which robots operate, however, are pervaded by a variety of disturbing stimuli and uncertain timing. In particular, variable reward delays make it difficult to reconstruct which previous actions are responsible for following rewards. Such an uncertainty is handled by biological neural networks, but represents a challenge for computational models, suggesting the lack of a satisfactory theory for robotic neural conditioning. The present study demonstrates the use of rare neural correlations in making correct associations between rewards and previous cues or actions. Rare correlations are functional in selecting sparse synapses to be eligible for later weight updates if a reward occurs. The repetition of this process singles out the associating and reward-triggering pathways, and thereby copes with distal rewards. The neural network displays macro-level classical and operant conditioning, which is demonstrated in an interactive real-life human-robot interaction. The proposed mechanism models realistic conditioning in humans and animals and implements similar behaviors in neuro-robotic platforms.},
  journaltitle = {Frontiers in Neurorobotics},
  urldate = {2019-03-30},
  date = {2013},
  author = {Soltoggio, Andrea and Lemme, Andre and Reinhart, Felix and Steil, Jochen J.},
  file = {/Users/qualia/Documents/Papers/2013 - Soltoggio et al. - Rare neural correlations implement robotic conditioning with delayed rewards and disturbances.pdf;/Users/qualia/Documents/Papers/Soltoggio et al. - 2013 - Rare Neural Correlations Implement Robotic Conditi.pdf}
}

@article{Soltoggio2013a,
  langid = {english},
  title = {Solving the {{Distal Reward Problem}} with {{Rare Correlations}}},
  volume = {25},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00419},
  doi = {10.1162/NECO_a_00419},
  number = {4},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2013-04},
  pages = {940-978},
  author = {Soltoggio, Andrea and Steil, Jochen J.},
  file = {/Users/qualia/Documents/Papers/2013 - Soltoggio, Steil - Solving the distal reward problem with rare correlations.pdf;/Users/qualia/Documents/Papers/Soltoggio and Steil - 2013 - Solving the Distal Reward Problem with Rare Correl.pdf}
}

@article{Sprague2013,
  langid = {english},
  title = {Attention Modulates Spatial Priority Maps in the Human Occipital, Parietal and Frontal Cortices},
  volume = {16},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3574},
  doi = {10.1038/nn.3574},
  number = {12},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2013-12},
  pages = {1879-1887},
  author = {Sprague, Thomas C and Serences, John T},
  file = {/Users/qualia/Documents/Papers/2013 - Sprague, Serences - Attention modulates spatial priority maps in the human occipital, parietal and frontal cortices.pdf;/Users/qualia/Documents/Papers/Sprague and Serences - 2013 - Attention modulates spatial priority maps in the h.pdf}
}

@article{Storch2013,
  langid = {english},
  title = {Nonmotor Fluctuations in {{Parkinson}} Disease: {{Severity}} and Correlation with Motor Complications},
  volume = {80},
  issn = {0028-3878, 1526-632X},
  url = {http://www.neurology.org/cgi/doi/10.1212/WNL.0b013e318285c0ed},
  doi = {10.1212/WNL.0b013e318285c0ed},
  shorttitle = {Nonmotor Fluctuations in {{Parkinson}} Disease},
  abstract = {Objective: To evaluate frequency, severity, and correlation of nonmotor symptoms (NMS) with motor complications in fluctuating Parkinson disease (PD).
Methods: The Multicenter NonMotor Fluctuations in PD cross-sectional study used clinical examination of 10 NMS (dysphagia, anxiety, depression, fatigue, excessive sweating, inner restlessness, pain, concentration/attention, dizziness, bladder urgency) quantified using a visual analogue scale (VAS) in motor-defined on (NMSOn) and off state (NMSOff) combined with motor assessments and self-ratings at home in 100 patients with advanced PD.
Results: All NMS except dysphagia, excessive sweating, and bladder urgency fluctuated in conjunction to motor fluctuations with more frequent and severe symptoms in off compared to on state. The proportions of patients experiencing autonomic/sensory NMS in both motor states were similar to those with these NMS exclusively in off state (ratios 0.4\textendash{}1.3), while for mental/psychic NMS the proportions with exclusive manifestation in off state were higher (ratios 1.8\textendash{}3.1). Demographic and clinical characteristics correlated neither with NMS frequency patterns and severities nor with DNMSOn/Off severities (defined as the differences of VAS scores between on and off). Severities of NMSon, NMSOff, and DNMSOn/Off did not correlate with motor function. Presence of anxiety, depression, fatigue, and pain had negative impact on health-related quality of life (HRQOL) measured by Parkinson's Disease Questionnaire\textendash{}8 scoring independent of their occurrence with respect to motor state. Fluctuations of these NMS but not of fatigue deteriorated HRQOL.
Conclusion: Patterns of NMS fluctuations are heterogeneous and complex, but psychic NMS fluctuate more frequently and severely. Demographic parameters and motor function do not correlate with NMS or nonmotor fluctuation severities in fluctuating PD. Neurology\^a 2013;80:800\textendash{}809},
  number = {9},
  journaltitle = {Neurology},
  urldate = {2019-03-30},
  date = {2013-02-26},
  pages = {800-809},
  author = {Storch, A. and Schneider, C. B. and Wolz, M. and Sturwald, Y. and Nebe, A. and Odin, P. and Mahler, A. and Fuchs, G. and Jost, W. H. and Chaudhuri, K. R. and Koch, R. and Reichmann, H. and Ebersbach, G.},
  file = {/Users/qualia/Documents/Papers/2013 - Storch et al. - Nonmotor fluctuations in Parkinson disease Severity and correlation with motor complications.pdf;/Users/qualia/Documents/Papers/Storch et al. - 2013 - Nonmotor fluctuations in Parkinson disease Severi.pdf}
}

@article{Stocchi2005,
  langid = {english},
  title = {Intermittent vs {{Continuous Levodopa Administration}} in {{Patients With Advanced Parkinson Disease}}: {{A Clinical}} and {{Pharmacokinetic Study}}},
  volume = {62},
  issn = {0003-9942},
  url = {http://archneur.jamanetwork.com/article.aspx?doi=10.1001/archneur.62.6.905},
  doi = {10.1001/archneur.62.6.905},
  shorttitle = {Intermittent vs {{Continuous Levodopa Administration}} in {{Patients With Advanced Parkinson Disease}}},
  number = {6},
  journaltitle = {Archives of Neurology},
  urldate = {2019-03-30},
  date = {2005-06-01},
  author = {Stocchi, Fabrizio and Vacca, Laura and Ruggieri, Stefano and Olanow, C. Warren},
  file = {/Users/qualia/Documents/Papers/2013 - Study - in Patients With Advanced Parkinson Disease.pdf;/Users/qualia/Documents/Papers/Stocchi et al. - 2005 - Intermittent vs Continuous Levodopa Administration.pdf}
}

@article{Sussillo2013,
  langid = {english},
  title = {Opening the {{Black Box}}: {{Low}}-{{Dimensional Dynamics}} in {{High}}-{{Dimensional Recurrent Neural Networks}}},
  volume = {25},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00409},
  doi = {10.1162/NECO_a_00409},
  shorttitle = {Opening the {{Black Box}}},
  number = {3},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2013-03},
  pages = {626-649},
  author = {Sussillo, David and Barak, Omri},
  file = {/Users/qualia/Documents/Papers/2013 - Sussillo, Barak - Opening the black box low-dimensional dynamics in high-dimensional recurrent neural networks.pdf;/Users/qualia/Documents/Papers/Sussillo and Barak - 2013 - Opening the Black Box Low-Dimensional Dynamics in.pdf}
}

@article{Szegedy2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1312.6199},
  primaryClass = {cs},
  langid = {english},
  title = {Intriguing Properties of Neural Networks},
  url = {http://arxiv.org/abs/1312.6199},
  abstract = {Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.},
  urldate = {2019-03-30},
  date = {2013-12-20},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Computer Vision and Pattern Recognition},
  author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  file = {/Users/qualia/Documents/Papers/2013 - Szegedy, Zaremba, Sutskever - Intriguing properties of neural networks.pdf;/Users/qualia/Documents/Papers/Szegedy et al. - 2013 - Intriguing properties of neural networks.pdf}
}

@article{Tao2010,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1012.4818},
  primaryClass = {math},
  langid = {english},
  title = {Outliers in the Spectrum of Iid Matrices with Bounded Rank Perturbations},
  url = {http://arxiv.org/abs/1012.4818},
  abstract = {It is known that if one perturbs a large iid random matrix by a bounded rank error, then the majority of the eigenvalues will remain distributed according to the circular law. However, the bounded rank perturbation may also create one or more outlier eigenvalues. We show that if the perturbation is small, then the outlier eigenvalues are created next to the outlier eigenvalues of the bounded rank perturbation; but if the perturbation is large, then many more outliers can be created, and their law is governed by the zeroes of a random Laurent series with Gaussian coefficients. On the other hand, these outliers may be eliminated by enforcing a row sum condition on the final matrix.},
  urldate = {2019-03-30},
  date = {2010-12-21},
  keywords = {60B20,Mathematics - Probability},
  author = {Tao, Terence},
  file = {/Users/qualia/Documents/Papers/2013 - Tao - Outliers in the spectrum of iid matrices with bounded rank perturbations.pdf;/Users/qualia/Documents/Papers/Tao - 2010 - Outliers in the spectrum of iid matrices with boun.pdf}
}

@article{Tingley2016,
  langid = {english},
  title = {Transformation of {{Independent Oscillatory Inputs}} into {{Temporally Precise Rate Codes}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/054163},
  doi = {10.1101/054163},
  abstract = {Complex behaviors demand temporal coordination among functionally distinct brain regions. The basal forebrain's afferent and efferent structure suggests a capacity for mediating such coordination. During performance of a selective attention task, synaptic activity in this region was dominated by four amplitude-oscillations temporally organized by the phase of the slowest, a theta rhythm. Further, oscillatory amplitudes were precisely organized by task epoch and a robust input/output transform, from synchronous synaptic activity to spiking rates of basal forebrain neurons, was identified. For many neurons, spiking was temporally organized as phase precessing sequences against theta band field potential oscillations. Remarkably, theta phase precession advanced in parallel to task progression, rather than absolute spatial location or time. Together, the findings reveal a process by which associative brain regions can integrate independent oscillatory inputs and transform them into sequence-specific, rate-coded outputs that are adaptive to the pace with which organisms interact with their environment.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2016-05-18},
  author = {Tingley, David and Alexander, Andrew and Quinn, Laleh and Chiba, Andrea and Nitz, Douglas},
  file = {/Users/qualia/Documents/Papers/2013 - Tobergte, Curtis - Transformation!of!Independent!Oscillatory!Inputs!into!Temporally!Precise!Rate!Codes'.pdf;/Users/qualia/Documents/Papers/Tingley et al. - 2016 - Transformation of Independent Oscillatory Inputs i.pdf}
}

@article{Wach2013,
  langid = {english},
  title = {The Effect of 10 {{Hz}} Transcranial Alternating Current Stimulation ({{tACS}}) on Corticomuscular Coherence},
  volume = {7},
  issn = {1662-5161},
  url = {http://journal.frontiersin.org/article/10.3389/fnhum.2013.00511/abstract},
  doi = {10.3389/fnhum.2013.00511},
  journaltitle = {Frontiers in Human Neuroscience},
  urldate = {2019-03-30},
  date = {2013},
  author = {Wach, Claudia and Krause, Vanessa and Moliadze, Vera and Paulus, Walter and Schnitzler, Alfons and Pollok, Bettina},
  file = {/Users/qualia/Documents/Papers/2013 - Wach et al. - The effect of 10 Hz transcranial alternating current stimulation (tACS) on corticomuscular coherence.pdf;/Users/qualia/Documents/Papers/Wach et al. - 2013 - The effect of 10 Hz transcranial alternating curre.pdf}
}

@article{Wainrib2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1210.5082},
  langid = {english},
  title = {Topological and {{Dynamical Complexity}} of {{Random Neural Networks}}},
  volume = {110},
  issn = {0031-9007, 1079-7114},
  url = {http://arxiv.org/abs/1210.5082},
  doi = {10.1103/PhysRevLett.110.118101},
  abstract = {Random neural networks are dynamical descriptions of randomly interconnected neural units. These show a phase transition to chaos as a disorder parameter is increased. The microscopic mechanisms underlying this phase transition are unknown, and similarly to spin-glasses, shall be fundamentally related to the behavior of the system. In this Letter we investigate the explosion of complexity arising near that phase transition. We show that the mean number of equilibria undergoes a sharp transition from one equilibrium to a very large number scaling exponentially with the dimension on the system. Near criticality, we compute the exponential rate of divergence, called topological complexity. Strikingly, we show that it behaves exactly as the maximal Lyapunov exponent, a classical measure of dynamical complexity. This relationship unravels a microscopic mechanism leading to chaos which we further demonstrate on a simpler class of disordered systems, suggesting a deep and underexplored link between topological and dynamical complexity.},
  number = {11},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2013-03-11},
  keywords = {Quantitative Biology - Neurons and Cognition,Condensed Matter - Disordered Systems and Neural Networks,Mathematical Physics},
  author = {Wainrib, Gilles and Touboul, Jonathan},
  file = {/Users/qualia/Documents/Papers/2013 - Wainrib, Touboul - Topological and dynamical complexity of random neural networks.pdf;/Users/qualia/Documents/Papers/Wainrib and Touboul - 2013 - Topological and Dynamical Complexity of Random Neu.pdf}
}

@article{Wang2013,
  langid = {english},
  title = {A {{Realistic Neural Mass Model}} of the {{Cortex}} with {{Laminar}}-{{Specific Connections}} and {{Synaptic Plasticity}} \textendash{} {{Evaluation}} with {{Auditory Habituation}}},
  volume = {8},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0077876},
  doi = {10.1371/journal.pone.0077876},
  abstract = {In this work we propose a biologically realistic local cortical circuit model (LCCM), based on neural masses, that incorporates important aspects of the functional organization of the brain that have not been covered by previous models: (1) activity dependent plasticity of excitatory synaptic couplings via depleting and recycling of neurotransmitters and (2) realistic interlaminar dynamics via laminar-specific distribution of and connections between neural populations. The potential of the LCCM was demonstrated by accounting for the process of auditory habituation. The model parameters were specified using Bayesian inference. It was found that: (1) besides the major serial excitatory information pathway (layer 4 to layer 2/3 to layer 5/6), there exists a parallel ``short-cut'' pathway (layer 4 to layer 5/6), (2) the excitatory signal flow from the pyramidal cells to the inhibitory interneurons seems to be more intra-laminar while, in contrast, the inhibitory signal flow from inhibitory interneurons to the pyramidal cells seems to be both intra- and inter-laminar, and (3) the habituation rates of the connections are unsymmetrical: forward connections (from layer 4 to layer 2/3) are more strongly habituated than backward connections (from Layer 5/6 to layer 4). Our evaluation demonstrates that the novel features of the LCCM are of crucial importance for mechanistic explanations of brain function. The incorporation of these features into a mass model makes them applicable to modeling based on macroscopic data (like EEG or MEG), which are usually available in human experiments. Our LCCM is therefore a valuable building block for future realistic models of human cognitive function.},
  number = {10},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2013-10-30},
  pages = {e77876},
  author = {Wang, Peng and Kn\"osche, Thomas R.},
  editor = {Lytton, William W.},
  file = {/Users/qualia/Documents/Papers/2013 - Wang, KnÃ¶sche - A Realistic Neural Mass Model of the Cortex with Laminar-Specific Connections and Synaptic Plasticity Evaluati.pdf;/Users/qualia/Documents/Papers/Wang and Knösche - 2013 - A Realistic Neural Mass Model of the Cortex with L.pdf}
}

@article{Roux2013,
  langid = {english},
  title = {The {{Phase}} of {{Thalamic Alpha Activity Modulates Cortical Gamma}}-{{Band Activity}}: {{Evidence}} from {{Resting}}-{{State MEG Recordings}}},
  volume = {33},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5778-12.2013},
  doi = {10.1523/JNEUROSCI.5778-12.2013},
  shorttitle = {The {{Phase}} of {{Thalamic Alpha Activity Modulates Cortical Gamma}}-{{Band Activity}}},
  number = {45},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2013-11-06},
  pages = {17827-17835},
  author = {Roux, F. and Wibral, M. and Singer, W. and Aru, J. and Uhlhaas, P. J.},
  file = {/Users/qualia/Documents/Papers/2013 - Wibral et al. - The Phase of Thalamic Alpha Activity Modulates Cortical Gamma-Band Activity Evidence from Resting-State MEG Recor.pdf;/Users/qualia/Documents/Papers/Roux et al. - 2013 - The Phase of Thalamic Alpha Activity Modulates Cor.pdf}
}

@article{Yamazaki2013,
  langid = {english},
  title = {Realtime Cerebellum: {{A}} Large-Scale Spiking Network Model of the Cerebellum That Runs in Realtime Using a Graphics Processing Unit},
  volume = {47},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608013000348},
  doi = {10.1016/j.neunet.2013.01.019},
  shorttitle = {Realtime Cerebellum},
  abstract = {The cerebellum plays an essential role in adaptive motor control. Once we are able to build a cerebellar model that runs in realtime, which means that a computer simulation of 1 s in the simulated world completes within 1 s in the real world, the cerebellar model could be used as a realtime adaptive neural controller for physical hardware such as humanoid robots. In this paper, we introduce ``Realtime Cerebellum (RC)'', a new implementation of our large-scale spiking network model of the cerebellum, which was originally built to study cerebellar mechanisms for simultaneous gain and timing control and acted as a general-purpose supervised learning machine of spatiotemporal information known as reservoir computing, on a graphics processing unit (GPU). Owing to the massive parallel computing capability of a GPU, RC runs in realtime, while reproducing qualitatively the same simulation results of the Pavlovian delay eyeblink conditioning with the previous version. RC is adopted as a realtime adaptive controller of a humanoid robot, which is instructed to learn a proper timing to swing a bat to hit a flying ball online. These results suggest that RC provides a means to apply the computational power of the cerebellum as a versatile supervised learning machine towards engineering applications.},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2013-11},
  pages = {103-111},
  author = {Yamazaki, Tadashi and Igarashi, Jun},
  file = {/Users/qualia/Documents/Papers/2013 - Yamazaki, Igarashi - Realtime cerebellum A large-scale spiking network model of the cerebellum that runs in realtime using a grap.pdf;/Users/qualia/Documents/Papers/Yamazaki and Igarashi - 2013 - Realtime cerebellum A large-scale spiking network.pdf}
}

@article{Zanto2013,
  langid = {english},
  title = {Age-{{Related Changes}} in {{Expectation}}-{{Based Modulation}} of {{Motion Detectability}}},
  volume = {8},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0069766},
  doi = {10.1371/journal.pone.0069766},
  abstract = {Expecting motion in some particular direction biases sensitivity to that direction, which speeds detection of motion. However, the neural processes underlying this effect remain underexplored, especially in the context of normal aging. To address this, we examined younger and older adults' performance in a motion detection task. In separate conditions, the probability was either 50\% or 100\% that a field of dots would move coherently in the direction a participant expected (either vertically or horizontally). Expectation and aging effects were assessed via response times (RT) to detect motion and electroencephalography (EEG). In both age groups, RTs were fastest when motion was similar to the expected direction of motion. RT tuning curves exhibited a characteristic U-shape such that detection time increased with an increasing deviation from the participant's expected direction. Strikingly, EEG results showed an analogous, hyperbolic curve for N1 amplitude, reflecting neural biasing. Though the form of behavioral and EEG curves did not vary with age, older adults displayed a clear decline in the speed of detection and a corresponding reduction in EEG N1 amplitude when horizontal (but not vertical) motion was expected. Our results suggest that expectation-based detection ability varies with age and, for older adults, also with axis of motion.},
  number = {8},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2013-08-09},
  pages = {e69766},
  author = {Zanto, Theodore P. and Sekuler, Robert and Dube, Chad and Gazzaley, Adam},
  editor = {Rypma, Bart},
  file = {/Users/qualia/Documents/Papers/2013 - Zanto et al. - Age-related changes in expectation-based modulation of motion detectability.pdf;/Users/qualia/Documents/Papers/Zanto et al. - 2013 - Age-Related Changes in Expectation-Based Modulatio.pdf}
}

@article{Bastin2014,
  langid = {english},
  title = {Inhibitory Control and Error Monitoring by Human Subthalamic Neurons},
  volume = {4},
  issn = {2158-3188},
  url = {http://www.nature.com/articles/tp201473},
  doi = {10.1038/tp.2014.73},
  number = {9},
  journaltitle = {Translational Psychiatry},
  urldate = {2019-03-30},
  date = {2014-09},
  pages = {e439-e439},
  author = {Bastin, J and Polosan, M and Benis, D and Goetz, L and Bhattacharjee, M and Piallat, B and Krainik, A and Bougerol, T and Chabard\`es, S and David, O},
  file = {/Users/qualia/Documents/Papers/2014 - Bastin et al. - Inhibitory control and error monitoring by human subthalamic neurons.pdf;/Users/qualia/Documents/Papers/Bastin et al. - 2014 - Inhibitory control and error monitoring by human s.pdf}
}

@article{Brittain2014,
  langid = {english},
  title = {The Highs and Lows of Beta Activity in Cortico-Basal Ganglia Loops},
  volume = {39},
  issn = {0953816X},
  url = {http://doi.wiley.com/10.1111/ejn.12574},
  doi = {10.1111/ejn.12574},
  abstract = {Oscillatory activity in the beta (13\textendash{}30 Hz) frequency band is widespread in cortico-basal ganglia circuits, and becomes prominent in Parkinson's disease (PD). Here we develop the hypothesis that the degree of synchronization in this frequency band is a critical factor in gating computation across a population of neurons, with increases in beta band synchrony entailing a loss of information-coding space and hence computational capacity. Task and context drive this dynamic gating, so that for each state there will be an optimal level of network synchrony, and levels lower or higher than this will impair behavioural performance. Thus, both the pathological exaggeration of synchrony, as observed in PD, and the ability of interventions like deep brain stimulation (DBS) to excessively suppress synchrony can potentially lead to impairments in behavioural performance. Indeed, under physiological conditions, the manipulation of computational capacity by beta activity may itself present a mechanism of action selection and maintenance.},
  number = {11},
  journaltitle = {European Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-06},
  pages = {1951-1959},
  author = {Brittain, John-Stuart and Sharott, Andrew and Brown, Peter},
  file = {/Users/qualia/Documents/Papers/2014 - Brittain, Sharott, Brown - The highs and lows of beta activity in cortico-basal ganglia loops.pdf;/Users/qualia/Documents/Papers/2014 - Brittain, Sharott, Brown - The highs and lows of beta activity in cortico-basal ganglia loops(2).pdf;/Users/qualia/Documents/Papers/Brittain et al. - 2014 - The highs and lows of beta activity in cortico-bas 2.pdf;/Users/qualia/Documents/Papers/Brittain et al. - 2014 - The highs and lows of beta activity in cortico-bas.pdf}
}

@article{Calabresi2014,
  langid = {english},
  title = {Direct and Indirect Pathways of Basal Ganglia: A Critical Reappraisal},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3743},
  doi = {10.1038/nn.3743},
  shorttitle = {Direct and Indirect Pathways of Basal Ganglia},
  number = {8},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-08},
  pages = {1022-1030},
  author = {Calabresi, Paolo and Picconi, Barbara and Tozzi, Alessandro and Ghiglieri, Veronica and Di Filippo, Massimiliano},
  file = {/Users/qualia/Documents/Papers/2014 - Calabresi et al. - Direct and indirect pathways of basal ganglia a critical reappraisal.pdf;/Users/qualia/Documents/Papers/Calabresi et al. - 2014 - Direct and indirect pathways of basal ganglia a c.pdf}
}

@article{Cannon2014,
  langid = {english},
  title = {{{LEMS}}: A Language for Expressing Complex Biological Models in Concise and Hierarchical Form and Its Use in Underpinning {{NeuroML}} 2},
  volume = {8},
  issn = {1662-5196},
  url = {http://journal.frontiersin.org/article/10.3389/fninf.2014.00079/abstract},
  doi = {10.3389/fninf.2014.00079},
  shorttitle = {{{LEMS}}},
  abstract = {Computational models are increasingly important for studying complex neurophysiological systems. As scientific tools, it is essential that such models can be reproduced and critically evaluated by a range of scientists. However, published models are currently implemented using a diverse set of modeling approaches, simulation tools, and computer languages making them inaccessible and difficult to reproduce. Models also typically contain concepts that are tightly linked to domain-specific simulators, or depend on knowledge that is described exclusively in text-based documentation. To address these issues we have developed a compact, hierarchical, XML-based language called LEMS (Low Entropy Model Specification), that can define the structure and dynamics of a wide range of biological models in a fully machine readable format. We describe how LEMS underpins the latest version of NeuroML and show that this framework can define models of ion channels, synapses, neurons and networks. Unit handling, often a source of error when reusing models, is built into the core of the language by specifying physical quantities in models in terms of the base dimensions. We show how LEMS, together with the open source Java and Python based libraries we have developed, facilitates the generation of scripts for multiple neuronal simulators and provides a route for simulator free code generation. We establish that LEMS can be used to define models from systems biology and map them to neuroscience-domain specific simulators, enabling models to be shared between these traditionally separate disciplines. LEMS and NeuroML 2 provide a new, comprehensive framework for defining computational models of neuronal and other biological systems in a machine readable format, making them more reproducible and increasing the transparency and accessibility of their underlying structure and properties.},
  journaltitle = {Frontiers in Neuroinformatics},
  urldate = {2019-03-30},
  date = {2014-09-25},
  author = {Cannon, Robert C. and Gleeson, Padraig and Crook, Sharon and Ganapathy, Gautham and Marin, Boris and Piasini, Eugenio and Silver, R. Angus},
  file = {/Users/qualia/Documents/Papers/2014 - Cannon et al. - LEMS a language for expressing complex biological models in concise and hierarchical form and its use in underpi.pdf;/Users/qualia/Documents/Papers/Cannon et al. - 2014 - LEMS a language for expressing complex biological.pdf}
}

@article{Chaudhuri2014,
  langid = {english},
  title = {A Diversity of Localized Timescales in Network Activity},
  volume = {3},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/01239},
  doi = {10.7554/eLife.01239},
  abstract = {Neurons show diverse timescales, so that different parts of a network respond with disparate temporal dynamics. Such diversity is observed both when comparing timescales across brain areas and among cells within local populations; the underlying circuit mechanism remains unknown. We examine conditions under which spatially local connectivity can produce such diverse temporal behavior.},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2014-01-21},
  author = {Chaudhuri, Rishidev and Bernacchia, Alberto and Wang, Xiao-Jing},
  file = {/Users/qualia/Documents/Papers/2014 - Chaudhuri, Bernacchia, Wang - A diversity of localized timescales in network activity.pdf;/Users/qualia/Documents/Papers/2014 - Chaudhuri, Bernacchia, Wang - A diversity of localized timescales in network activity(2).pdf;/Users/qualia/Documents/Papers/Chaudhuri et al. - 2014 - A diversity of localized timescales in network act 2.pdf;/Users/qualia/Documents/Papers/Chaudhuri et al. - 2014 - A diversity of localized timescales in network act.pdf}
}

@article{Chung2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1412.3555},
  primaryClass = {cs},
  langid = {english},
  title = {Empirical {{Evaluation}} of {{Gated Recurrent Neural Networks}} on {{Sequence Modeling}}},
  url = {http://arxiv.org/abs/1412.3555},
  abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
  urldate = {2019-03-30},
  date = {2014-12-11},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  file = {/Users/qualia/Documents/Papers/2014 - Chung et al. - Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.pdf;/Users/qualia/Documents/Papers/Chung et al. - 2014 - Empirical Evaluation of Gated Recurrent Neural Net.pdf}
}

@article{Cohen2014,
  langid = {english},
  title = {Fluctuations in {{Oscillation Frequency Control Spike Timing}} and {{Coordinate Neural Networks}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0261-14.2014},
  doi = {10.1523/JNEUROSCI.0261-14.2014},
  number = {27},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-07-02},
  pages = {8988-8998},
  author = {Cohen, M. X.},
  file = {/Users/qualia/Documents/Papers/2014 - Cohen - Fluctuations in Oscillation Frequency Control Spike Timing.pdf;/Users/qualia/Documents/Papers/Cohen - 2014 - Fluctuations in Oscillation Frequency Control Spik.pdf}
}

@article{Cona2014,
  langid = {english},
  title = {A Thalamo-Cortical Neural Mass Model for the Simulation of Brain Rhythms during Sleep},
  volume = {37},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-013-0493-1},
  doi = {10.1007/s10827-013-0493-1},
  number = {1},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-08},
  pages = {125-148},
  author = {Cona, F. and Lacanna, M. and Ursino, M.},
  file = {/Users/qualia/Documents/Papers/2014 - Cona, Lacanna, Ursino - A thalamo-cortical neural mass model for the simulation of brain rhythms during sleep.pdf;/Users/qualia/Documents/Papers/Cona et al. - 2014 - A thalamo-cortical neural mass model for the simul.pdf}
}

@article{Damodaran2014,
  langid = {english},
  title = {Synchronized Firing of Fast-Spiking Interneurons Is Critical to Maintain Balanced Firing between Direct and Indirect Pathway Neurons of the Striatum},
  volume = {111},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00382.2013},
  doi = {10.1152/jn.00382.2013},
  number = {4},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2014-02-15},
  pages = {836-848},
  author = {Damodaran, Sriraman and Evans, Rebekah C. and Blackwell, Kim T.},
  file = {/Users/qualia/Documents/Papers/2014 - Damodaran, Evans, Blackwell - Synchronized firing of fast-spiking interneurons is critical to maintain balanced firing between di.pdf;/Users/qualia/Documents/Papers/Damodaran et al. - 2014 - Synchronized firing of fast-spiking interneurons i.pdf}
}

@article{Davis2014,
  langid = {english},
  title = {What Do Differences between Multi-Voxel and Univariate Analysis Mean? {{How}} Subject-, Voxel-, and Trial-Level Variance Impact {{fMRI}} Analysis},
  volume = {97},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811914003061},
  doi = {10.1016/j.neuroimage.2014.04.037},
  shorttitle = {What Do Differences between Multi-Voxel and Univariate Analysis Mean?},
  abstract = {Multi-voxel pattern analysis (MVPA) has led to major changes in how fMRI data are analyzed and interpreted. Many studies now report both MVPA results and results from standard univariate voxel-wise analysis, often with the goal of drawing different conclusions from each. Because MVPA results can be sensitive to latent multidimensional representations and processes whereas univariate voxel-wise analysis cannot, one conclusion that is often drawn when MVPA and univariate results differ is that the activation patterns underlying MVPA results contain a multidimensional code. In the current study, we conducted simulations to formally test this assumption. Our findings reveal that MVPA tests are sensitive to the magnitude of voxel-level variability in the effect of a condition within subjects, even when the same linear relationship is coded in all voxels. We also find that MVPA is insensitive to subject-level variability in mean activation across an ROI, which is the primary variance component of interest in many standard univariate tests. Together, these results illustrate that differences between MVPA and univariate tests do not afford conclusions about the nature or dimensionality of the neural code. Instead, targeted tests of the informational content and/or dimensionality of activation patterns are critical for drawing strong conclusions about the representational codes that are indicated by significant MVPA results.},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2014-08},
  pages = {271-283},
  author = {Davis, Tyler and LaRocque, Karen F. and Mumford, Jeanette A. and Norman, Kenneth A. and Wagner, Anthony D. and Poldrack, Russell A.},
  file = {/Users/qualia/Documents/Papers/2014 - Davis1 et al. - What Do Differences Between Multi-voxel and Univariate Analysis Mean How Subject-, Voxel-, and Trial-level Varian.pdf;/Users/qualia/Documents/Papers/Davis et al. - 2014 - What do differences between multi-voxel and univar.pdf}
}

@article{Vangel2015,
  langid = {english},
  title = {Randomly {{Spiking Dynamic Neural Fields}}},
  volume = {11},
  issn = {15504832},
  url = {http://dl.acm.org/citation.cfm?doid=2767119.2629517},
  doi = {10.1145/2629517},
  number = {4},
  journaltitle = {ACM Journal on Emerging Technologies in Computing Systems},
  urldate = {2019-03-30},
  date = {2015-04-27},
  pages = {1-26},
  author = {Vangel, Beno\^it Chappet De and Torres-huitzil, Cesar and Girau, Bernard},
  file = {/Users/qualia/Documents/Papers/2014 - de Vangel, Torres-Huitzil, Girau - Randomly spiking dynamic neural fields.pdf;/Users/qualia/Documents/Papers/Vangel et al. - 2015 - Randomly Spiking Dynamic Neural Fields.pdf}
}

@article{Deger2014,
  langid = {english},
  title = {Fluctuations and Information Filtering in Coupled Populations of Spiking Neurons with Adaptation},
  volume = {90},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.90.062704},
  doi = {10.1103/PhysRevE.90.062704},
  number = {6},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2014-12-01},
  keywords = {Quantitative Biology - Neurons and Cognition},
  author = {Deger, Moritz and Schwalger, Tilo and Naud, Richard and Gerstner, Wulfram},
  file = {/Users/qualia/Documents/Papers/2014 - Deger et al. - Dynamics of interacting finite-sized networks of spiking neurons with adaptation.pdf;/Users/qualia/Documents/Papers/2014 - Deger et al. - Dynamics of interacting finite-sized networks of spiking neurons with adaptation(2).pdf;/Users/qualia/Documents/Papers/Deger et al. - 2014 - Fluctuations and information filtering in coupled  2.pdf;/Users/qualia/Documents/Papers/Deger et al. - 2014 - Fluctuations and information filtering in coupled .pdf}
}

@article{Dreyer2014,
  langid = {english},
  title = {Three {{Mechanisms}} by Which {{Striatal Denervation Causes Breakdown}} of {{Dopamine Signaling}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1458-14.2014},
  doi = {10.1523/JNEUROSCI.1458-14.2014},
  number = {37},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-09-10},
  pages = {12444-12456},
  author = {Dreyer, J. K.},
  file = {/Users/qualia/Documents/Papers/2014 - Dreyer - Three Mechanisms by which Striatal Denervation Causes Breakdown of Dopamine Signaling.pdf;/Users/qualia/Documents/Papers/Dreyer - 2014 - Three Mechanisms by which Striatal Denervation Cau.pdf}
}

@article{Ebert2014,
  langid = {english},
  title = {Coordinated Reset Stimulation in a Large-Scale Model of the {{STN}}-{{GPe}} Circuit},
  volume = {8},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2014.00154/abstract},
  doi = {10.3389/fncom.2014.00154},
  abstract = {Synchronization of populations of neurons is a hallmark of several brain diseases. Coordinated reset (CR) stimulation is a model-based stimulation technique which specifically counteracts abnormal synchrony by desynchronization. Electrical CR stimulation, e.g., for the treatment of Parkinson's disease (PD), is administered via depth electrodes. In order to get a deeper understanding of this technique, we extended the top-down approach of previous studies and constructed a large-scale computational model of the respective brain areas. Furthermore, we took into account the spatial anatomical properties of the simulated brain structures and incorporated a detailed numerical representation of 2 {$\cdot$} 104 simulated neurons. We simulated the subthalamic nucleus (STN) and the globus pallidus externus (GPe). Connections within the STN were governed by spike-timing dependent plasticity (STDP). In this way, we modeled the physiological and pathological activity of the considered brain structures. In particular, we investigated how plasticity could be exploited and how the model could be shifted from strongly synchronized (pathological) activity to strongly desynchronized (healthy) activity of the neuronal populations via CR stimulation of the STN neurons. Furthermore, we investigated the impact of specific stimulation parameters especially the electrode position on the stimulation outcome. Our model provides a step forward toward a biophysically realistic model of the brain areas relevant to the emergence of pathological neuronal activity in PD. Furthermore, our model constitutes a test bench for the optimization of both stimulation parameters and novel electrode geometries for efficient CR stimulation.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-11-27},
  author = {Ebert, Martin and Hauptmann, Christian and Tass, Peter A.},
  file = {/Users/qualia/Documents/Papers/2014 - Ebert, Hauptmann, Tass - Coordinated reset stimulation in a large-scale model of the STN-GPe circuit.pdf;/Users/qualia/Documents/Papers/Ebert et al. - 2014 - Coordinated reset stimulation in a large-scale mod.pdf}
}

@article{Gigerenzer2008,
  langid = {english},
  title = {Why {{Heuristics Work}}},
  volume = {3},
  issn = {1745-6916, 1745-6924},
  url = {http://journals.sagepub.com/doi/10.1111/j.1745-6916.2008.00058.x},
  doi = {10.1111/j.1745-6916.2008.00058.x},
  abstract = {The adaptive toolbox is a Darwinian-inspired theory that conceives of the mind as a modular system that is composed of heuristics, their building blocks, and evolved capacities. The study of the adaptive toolbox is descriptive and analyzes the selection and structure of heuristics in social and physical environments. The study of ecological rationality is prescriptive and identifies the structure of environments in which specific heuristics either succeed or fail. Results have been used for designing heuristics and environments to improve professional decision making in the real world.},
  number = {1},
  journaltitle = {Perspectives on Psychological Science},
  urldate = {2019-03-30},
  date = {2008-01},
  pages = {20-29},
  author = {Gigerenzer, Gerd},
  file = {/Users/qualia/Documents/Papers/2014 - Gigerenzer - Work Why Heuristics.pdf;/Users/qualia/Documents/Papers/Gigerenzer - 2008 - Why Heuristics Work.pdf}
}

@article{Gollo2014,
  langid = {english},
  title = {Mechanisms of {{Zero}}-{{Lag Synchronization}} in {{Cortical Motifs}}},
  volume = {10},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1003548},
  doi = {10.1371/journal.pcbi.1003548},
  abstract = {Zero-lag synchronization between distant cortical areas has been observed in a diversity of experimental data sets and between many different regions of the brain. Several computational mechanisms have been proposed to account for such isochronous synchronization in the presence of long conduction delays: Of these, the phenomenon of ``dynamical relaying'' \textendash{}a mechanism that relies on a specific network motif \textendash{} has proven to be the most robust with respect to parameter mismatch and system noise. Surprisingly, despite a contrary belief in the community, the common driving motif is an unreliable means of establishing zero-lag synchrony. Although dynamical relaying has been validated in empirical and computational studies, the deeper dynamical mechanisms and comparison to dynamics on other motifs is lacking. By systematically comparing synchronization on a variety of small motifs, we establish that the presence of a single reciprocally connected pair \textendash{} a ``resonance pair'' \textendash{} plays a crucial role in disambiguating those motifs that foster zero-lag synchrony in the presence of conduction delays (such as dynamical relaying) from those that do not (such as the common driving triad). Remarkably, minor structural changes to the common driving motif that incorporate a reciprocal pair recover robust zerolag synchrony. The findings are observed in computational models of spiking neurons, populations of spiking neurons and neural mass models, and arise whether the oscillatory systems are periodic, chaotic, noise-free or driven by stochastic inputs. The influence of the resonance pair is also robust to parameter mismatch and asymmetrical time delays amongst the elements of the motif. We call this manner of facilitating zero-lag synchrony resonance-induced synchronization, outline the conditions for its occurrence, and propose that it may be a general mechanism to promote zero-lag synchrony in the brain.},
  number = {4},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2014-04-24},
  pages = {e1003548},
  author = {Gollo, Leonardo L. and Mirasso, Claudio and Sporns, Olaf and Breakspear, Michael},
  editor = {Gutkin, Boris S.},
  file = {/Users/qualia/Documents/Papers/2014 - Gollo et al. - Mechanisms of Zero-Lag Synchronization in Cortical Motifs.pdf;/Users/qualia/Documents/Papers/Gollo et al. - 2014 - Mechanisms of Zero-Lag Synchronization in Cortical.pdf}
}

@article{Grabska-Barwinska2014,
  langid = {english},
  title = {How Well Do Mean Field Theories of Spiking Quadratic-Integrate-and-Fire Networks Work in Realistic Parameter Regimes?},
  volume = {36},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-013-0481-5},
  doi = {10.1007/s10827-013-0481-5},
  abstract = {We use mean field techniques to compute the distribution of excitatory and inhibitory firing rates in large networks of randomly connected spiking quadratic integrate and fire neurons. These techniques are based on the assumption that activity is asynchronous and Poisson. For most parameter settings these assumptions are strongly violated; nevertheless, so long as the networks are not too synchronous, we find good agreement between mean field prediction and network simulations. Thus, much of the intuition developed for randomly connected networks in the asynchronous regime applies to mildly synchronous networks.},
  number = {3},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-06},
  pages = {469-481},
  author = {Grabska-Barwi\'nska, Agnieszka and Latham, Peter E.},
  file = {/Users/qualia/Documents/Papers/2014 - Grabska-Barwiska, Latham - How well do mean field theories of spiking quadratic-integrate-and-fire networks work in realistic par.pdf;/Users/qualia/Documents/Papers/Grabska-Barwińska and Latham - 2014 - How well do mean field theories of spiking quadrat.pdf}
}

@article{Graves2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1410.5401},
  primaryClass = {cs},
  langid = {english},
  title = {Neural {{Turing Machines}}},
  url = {http://arxiv.org/abs/1410.5401},
  abstract = {We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-toend, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
  urldate = {2019-03-30},
  date = {2014-10-20},
  keywords = {Computer Science - Neural and Evolutionary Computing},
  author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  file = {/Users/qualia/Documents/Papers/2014 - Graves, Wayne, Danihelka - Neural Turing Machines.pdf;/Users/qualia/Documents/Papers/Graves et al. - 2014 - Neural Turing Machines.pdf}
}

@article{Hebbink,
  langid = {english},
  title = {Activity Types in a Neural Mass Model},
  pages = {50},
  author = {Hebbink, Jurgen},
  file = {/Users/qualia/Documents/Papers/2014 - Hebbink - Activity types in a neural mass model.pdf;/Users/qualia/Documents/Papers/Hebbink - Activity types in a neural mass model.pdf;/Users/qualia/Zotero/storage/HJHQ5CAE/1995 - Gray et al. - A perception reveals the face of sex.pdf}
}

@article{Hennequina,
  langid = {english},
  title = {Fast {{Sampling}}-{{Based Inference}} in {{Balanced Neuronal Networks}}},
  abstract = {Multiple lines of evidence support the notion that the brain performs probabilistic inference in multiple cognitive domains, including perception and decision making. There is also evidence that probabilistic inference may be implemented in the brain through the (quasi-)stochastic activity of neural circuits, producing samples from the appropriate posterior distributions, effectively implementing a Markov chain Monte Carlo algorithm. However, time becomes a fundamental bottleneck in such sampling-based probabilistic representations: the quality of inferences depends on how fast the neural circuit generates new, uncorrelated samples from its stationary distribution (the posterior). We explore this bottleneck in a simple, linear-Gaussian latent variable model, in which posterior sampling can be achieved by stochastic neural networks with linear dynamics. The well-known Langevin sampling (LS) recipe, so far the only sampling algorithm for continuous variables of which a neural implementation has been suggested, naturally fits into this dynamical framework. However, we first show analytically and through simulations that the symmetry of the synaptic weight matrix implied by LS yields critically slow mixing when the posterior is high-dimensional. Next, using methods from control theory, we construct and inspect networks that are optimally fast, and hence orders of magnitude faster than LS, while being far more biologically plausible. In these networks, strong \textendash{} but transient \textendash{} selective amplification of external noise generates the spatially correlated activity fluctuations prescribed by the posterior. Intriguingly, although a detailed balance of excitation and inhibition is dynamically maintained, detailed balance of Markov chain steps in the resulting sampler is violated, consistent with recent findings on how statistical irreversibility can overcome the speed limitation of random walks in other domains.},
  pages = {9},
  author = {Hennequin, Guillaume and Aitchison, Laurence and Lengyel, Mate},
  file = {/Users/qualia/Documents/Papers/2014 - Hennequin, Aitchison, Lengyel - Fast Sampling-Based Inference in Balanced Neuronal Networks.pdf;/Users/qualia/Documents/Papers/Hennequin et al. - Fast Sampling-Based Inference in Balanced Neuronal.pdf}
}

@article{Higgins2014,
  langid = {english},
  title = {Memory {{Maintenance}} in {{Synapses}} with {{Calcium}}-{{Based Plasticity}} in the {{Presence}} of {{Background Activity}}},
  volume = {10},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1003834},
  doi = {10.1371/journal.pcbi.1003834},
  abstract = {Most models of learning and memory assume that memories are maintained in neuronal circuits by persistent synaptic modifications induced by specific patterns of pre- and postsynaptic activity. For this scenario to be viable, synaptic modifications must survive the ubiquitous ongoing activity present in neural circuits in vivo. In this paper, we investigate the time scales of memory maintenance in a calcium-based synaptic plasticity model that has been shown recently to be able to fit different experimental data-sets from hippocampal and neocortical preparations. We find that in the presence of background activity on the order of 1 Hz parameters that fit pyramidal layer 5 neocortical data lead to a very fast decay of synaptic efficacy, with time scales of minutes. We then identify two ways in which this memory time scale can be extended: (i) the extracellular calcium concentration in the experiments used to fit the model are larger than estimated concentrations in vivo. Lowering extracellular calcium concentration to in vivo levels leads to an increase in memory time scales of several orders of magnitude; (ii) adding a bistability mechanism so that each synapse has two stable states at sufficiently low background activity leads to a further boost in memory time scale, since memory decay is no longer described by an exponential decay from an initial state, but by an escape from a potential well. We argue that both features are expected to be present in synapses in vivo. These results are obtained first in a single synapse connecting two independent Poisson neurons, and then in simulations of a large network of excitatory and inhibitory integrate-and-fire neurons. Our results emphasise the need for studying plasticity at physiological extracellular calcium concentration, and highlight the role of synaptic bi- or multistability in the stability of learned synaptic structures.},
  number = {10},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2014-10-02},
  pages = {e1003834},
  author = {Higgins, David and Graupner, Michael and Brunel, Nicolas},
  editor = {Latham, Peter E.},
  file = {/Users/qualia/Documents/Papers/2014 - Higgins, Graupner, Brunel - Memory maintenance in synapses with calcium-based plasticity in the presence of background activity.pdf;/Users/qualia/Documents/Papers/Higgins et al. - 2014 - Memory Maintenance in Synapses with Calcium-Based .pdf}
}

@article{Holt2014,
  langid = {english},
  title = {Origins and Suppression of Oscillations in a Computational Model of {{Parkinson}}'s Disease},
  volume = {37},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-014-0523-7},
  doi = {10.1007/s10827-014-0523-7},
  abstract = {Efficacy of deep brain stimulation (DBS) for motor signs of Parkinson's disease (PD) depends in part on post-operative programming of stimulus parameters. There is a need for a systematic approach to tuning parameters based on patient physiology. We used a physiologically realistic computational model of the basal ganglia network to investigate the emergence of a 34 Hz oscillation in the PD state and its optimal suppression with DBS. Discrete time transfer functions were fit to post-stimulus time histograms (PSTHs) collected in open-loop, by simulating the pharmacological block of synaptic connections, to describe the behavior of the basal ganglia nuclei. These functions were then connected to create a mean-field model of the closed-loop system, which was analyzed to determine the origin of the emergent 34 Hz pathological oscillation. This analysis determined that the oscillation could emerge from the coupling between the globus pallidus external (GPe) and subthalamic nucleus (STN). When coupled, the two resonate with each other in the PD state but not in the healthy state. By characterizing how this oscillation is affected by subthreshold DBS pulses, we hypothesize that it is possible to predict stimulus frequencies capable of suppressing this oscillation. To characterize the response to the stimulus, we developed a new method for estimating phase response curves (PRCs) from population data. Using the population PRC we were able to predict frequencies that enhance and suppress the 34 Hz pathological oscillation. This provides a systematic approach to tuning DBS frequencies and could enable closed-loop tuning of stimulation parameters.},
  number = {3},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-12},
  pages = {505-521},
  author = {Holt, Abbey B. and Netoff, Theoden I.},
  file = {/Users/qualia/Documents/Papers/2014 - Holt, Netoff - Origins and suppression of oscillations in a computational model of Parkinson’s disease.pdf;/Users/qualia/Documents/Papers/Holt and Netoff - 2014 - Origins and suppression of oscillations in a compu.pdf}
}

@article{Huber2014,
  langid = {english},
  title = {Investigation of the Neurovascular Coupling in Positive and Negative {{BOLD}} Responses in Human Brain at {{7T}}},
  volume = {97},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811914002778},
  doi = {10.1016/j.neuroimage.2014.04.022},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2014-08},
  pages = {349-362},
  author = {Huber, Laurentius and Goense, Jozien and Kennerley, Aneurin J. and Ivanov, Dimo and Krieger, Steffen N. and Lepsien, J\"oran and Trampel, Robert and Turner, Robert and M\"oller, Harald E.},
  file = {/Users/qualia/Documents/Papers/2014 - Huber et al. - Investigation of the neurovascular coupling in positive and negative BOLD responses in human brain at 7T.pdf;/Users/qualia/Documents/Papers/Huber et al. - 2014 - Investigation of the neurovascular coupling in pos.pdf}
}

@article{Ispolatov2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1410.6403},
  langid = {english},
  title = {Chaos in High-Dimensional Dynamical Systems},
  volume = {5},
  issn = {2045-2322},
  url = {http://arxiv.org/abs/1410.6403},
  doi = {10.1038/srep12506},
  abstract = {For general dissipative dynamical systems we study what fraction of solutions exhibit chaotic behavior depending on the dimensionality \$d\$ of the phase space. We find that a system of \$d\$ globally coupled ODE's with quadratic and cubic non-linearities with random coefficients and initial conditions, the probability of a trajectory to be chaotic increases universally from \$\textbackslash{}sim 10\^\{-5\} - 10\^\{-4\}\$ for \$d=3\$ to essentially one for \$d\textbackslash{}sim 50\$. In the limit of large \$d\$, the invariant measure of the dynamical systems exhibits universal scaling that depends on the degree of non-linearity but does not depend on the choice of coefficients, and the largest Lyapunov exponent converges to a universal scaling limit. Using statistical arguments, we provide analytical explanations for the observed scaling and for the probability of chaos.},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2015-12},
  keywords = {Condensed Matter - Disordered Systems and Neural Networks,Nonlinear Sciences - Chaotic Dynamics},
  author = {Ispolatov, Iaroslav and Doebeli, Michael and Allende, Sebastian and Madhok, Vaibhav},
  file = {/Users/qualia/Documents/Papers/2014 - Ispolatov et al. - Chaos in high-dimensional dynamical systems.pdf;/Users/qualia/Documents/Papers/2015 - Ispolatov et al. - Chaos in high-dimensional dissipative dynamical systems.pdf;/Users/qualia/Documents/Papers/Ispolatov et al. - 2015 - Chaos in high-dimensional dissipative dynamical sy.pdf;/Users/qualia/Documents/Papers/Ispolatov et al. - 2015 - Chaos in high-dimensional dynamical systems.pdf}
}

@article{Jadi2014a,
  langid = {english},
  title = {Regulating {{Cortical Oscillations}} in an {{Inhibition}}-{{Stabilized Network}}},
  volume = {102},
  issn = {0018-9219, 1558-2256},
  url = {http://ieeexplore.ieee.org/document/6803063/},
  doi = {10.1109/JPROC.2014.2313113},
  abstract = {Understanding the anatomical and functional brain. Empirically testing such predictions is still challenging, architecture of the brain is essential for designing neurally and implementing the proposed coding and communication inspired intelligent systems. Theoretical and empirical studies strategies in neuromorphic systems could assist in our suggest a role for narrowband oscillations in shaping the understanding of the biological system.},
  number = {5},
  journaltitle = {Proceedings of the IEEE},
  urldate = {2019-03-30},
  date = {2014-05},
  pages = {830-842},
  author = {Jadi, Monika P. and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/2014 - Jadi, Sejnowski - Regulating Cortical Oscillation in an Inhibition-Stabilized Network.pdf;/Users/qualia/Documents/Papers/Jadi and Sejnowski - 2014 - Regulating Cortical Oscillations in an Inhibition-.pdf}
}

@article{Jin2014,
  langid = {english},
  title = {Basal Ganglia Subcircuits Distinctively Encode the Parsing and Concatenation of Action Sequences},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3632},
  doi = {10.1038/nn.3632},
  number = {3},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-03},
  pages = {423-430},
  author = {Jin, Xin and Tecuapetla, Fatuel and Costa, Rui M},
  file = {/Users/qualia/Documents/Papers/2014 - Jin, Tecuapetla, Costa - Basal ganglia subcircuits distinctively encode the parsing and concatenation of action sequences.pdf;/Users/qualia/Documents/Papers/Jin et al. - 2014 - Basal ganglia subcircuits distinctively encode the.pdf}
}

@article{Jones2014,
  langid = {english},
  title = {Analyzability, Ad Hoc Restrictions, and Excessive Flexibility of Evidence-Accumulation Models: {{Reply}} to Two Critical Commentaries.},
  volume = {121},
  issn = {1939-1471, 0033-295X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0037701},
  doi = {10.1037/a0037701},
  shorttitle = {Analyzability, Ad Hoc Restrictions, and Excessive Flexibility of Evidence-Accumulation Models},
  number = {4},
  journaltitle = {Psychological Review},
  urldate = {2019-03-30},
  date = {2014},
  pages = {689-695},
  author = {Jones, Matt and Dzhafarov, Ehtibar N.},
  file = {/Users/qualia/Documents/Papers/2014 - Jones, Dzhafarov - Analyzability, ad hoc restrictions, and excessive flexibility of evidence-accumulation models Reply to two cri.pdf;/Users/qualia/Documents/Papers/Jones and Dzhafarov - 2014 - Analyzability, ad hoc restrictions, and excessive .pdf}
}

@article{Jones2014a,
  langid = {english},
  title = {Unfalsifiability and Mutual Translatability of Major Modeling Schemes for Choice Reaction Time.},
  volume = {121},
  issn = {1939-1471, 0033-295X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0034190},
  doi = {10.1037/a0034190},
  abstract = {Much current research on speeded choice utilizes models in which the response is triggered by a stochastic process crossing a deterministic threshold. This article focuses on two such model classes, one based on continuous-time diffusion and the other on linear ballistic accumulation (LBA). Both models assume random variability in growth rates and in other model components across trials. We show that if the form of this variability is unconstrained, the models can exactly match any possible pattern of response probabilities and response time distributions. Thus, the explanatory or predictive content of these models is determined not by their structural assumptions, but rather by distributional assumptions (e.g., Gaussian distributions) that are traditionally regarded as implementation details. Selective influence assumptions (i.e., which experimental manipulations affect which model parameters) are shown to have no restrictive effect, except for the theoretically questionable assumption that speed-accuracy instructions do not affect growth rates. The second contribution of this article concerns translation of falsifiable models between universal modeling languages. Specifically, we translate the predictions of the diffusion and LBA models (with their parametric and selective influence assumptions intact) into the Grice modeling framework, in which accumulation processes are deterministic and thresholds are random variables. The Grice framework is also known to reproduce any possible pattern of response probabilities and times, and hence it can be used as a common language for comparing models. It is found that only a few simple properties of empirical data are necessary predictions of the diffusion and LBA models.},
  number = {1},
  journaltitle = {Psychological Review},
  urldate = {2019-03-30},
  date = {2014},
  pages = {1-32},
  author = {Jones, Matt and Dzhafarov, Ehtibar N.},
  file = {/Users/qualia/Documents/Papers/2014 - Jones, Dzhafarov - Unfalsifiability and mutual translatability of major modelingschemes for choice reaction time.pdf;/Users/qualia/Documents/Papers/Jones and Dzhafarov - 2014 - Unfalsifiability and mutual translatability of maj.pdf}
}

@article{Kaufman2014,
  langid = {english},
  title = {Cortical Activity in the Null Space: Permitting Preparation without Movement},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3643},
  doi = {10.1038/nn.3643},
  shorttitle = {Cortical Activity in the Null Space},
  number = {3},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-03},
  pages = {440-448},
  author = {Kaufman, Matthew T and Churchland, Mark M and Ryu, Stephen I and Shenoy, Krishna V},
  file = {/Users/qualia/Documents/Papers/2014 - Kaufman et al. - Cortical activity in the null space permitting preparation without movement.pdf;/Users/qualia/Documents/Papers/Kaufman et al. - 2014 - Cortical activity in the null space permitting pr.pdf}
}

@article{Kim2014,
  langid = {english},
  title = {Layer 6 {{Corticothalamic Neurons Activate}} a {{Cortical Output Layer}}, {{Layer}} 5a},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1325-14.2014},
  doi = {10.1523/JNEUROSCI.1325-14.2014},
  number = {29},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-07-16},
  pages = {9656-9664},
  author = {Kim, J. and Matney, C. J. and Blankenship, A. and Hestrin, S. and Brown, S. P.},
  file = {/Users/qualia/Documents/Papers/2014 - Kim et al. - Layer 6 Corticothalamic Neurons Activate a Cortical Output Layer, Layer 5a.pdf;/Users/qualia/Documents/Papers/Kim et al. - 2014 - Layer 6 Corticothalamic Neurons Activate a Cortica.pdf}
}

@article{Kingma2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1312.6114},
  primaryClass = {cs, stat},
  langid = {english},
  title = {Auto-{{Encoding Variational Bayes}}},
  url = {http://arxiv.org/abs/1312.6114},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  urldate = {2019-03-30},
  date = {2013-12-20},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  author = {Kingma, Diederik P. and Welling, Max},
  file = {/Users/qualia/Documents/Papers/2014 - Kingman, Welling - Auto-Encoding Variational Bayes.pdf;/Users/qualia/Documents/Papers/Kingma and Welling - 2013 - Auto-Encoding Variational Bayes.pdf}
}

@article{Knowlton2014,
  langid = {english},
  title = {Dynamical Estimation of Neuron and Network Properties {{III}}: Network Analysis Using Neuron Spike Times},
  volume = {108},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-014-0601-y},
  doi = {10.1007/s00422-014-0601-y},
  shorttitle = {Dynamical Estimation of Neuron and Network Properties {{III}}},
  abstract = {Estimating the behavior of a network of neurons requires accurate models of the individual neurons along with accurate characterizations of the connections among them. Whereas for a single cell, measurements of the intracellular voltage are technically feasible and sufficient to characterize a useful model of its behavior, making sufficient numbers of simultaneous intracellular measurements to characterize even small networks is infeasible. This paper builds on prior work on single neurons to explore whether knowledge of the time of spiking of neurons in a network, once the nodes (neurons) have been characterized biophysically, can provide enough information to usefully constrain the functional architecture of the network: the existence of synaptic links among neurons and their strength. Using standardized voltage and synaptic gating variable waveforms associated with a spike, we demonstrate that the functional architecture of a small network of model neurons can be established.},
  number = {3},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2014-06},
  pages = {261-273},
  author = {Knowlton, Chris and Meliza, C. Daniel and Margoliash, Daniel and Abarbanel, Henry D. I.},
  file = {/Users/qualia/Documents/Papers/2014 - Knowlton et al. - Dynamical estimation of neuron and network properties III Network analysis using neuron spike times.pdf;/Users/qualia/Documents/Papers/Knowlton et al. - 2014 - Dynamical estimation of neuron and network propert.pdf}
}

@article{Kopell2014,
  langid = {english},
  title = {Beyond the {{Connectome}}: {{The Dynome}}},
  volume = {83},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627314006916},
  doi = {10.1016/j.neuron.2014.08.016},
  shorttitle = {Beyond the {{Connectome}}},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2014-09},
  pages = {1319-1328},
  author = {Kopell, Nancy J. and Gritton, Howard J. and Whittington, Miles A. and Kramer, Mark A.},
  file = {/Users/qualia/Documents/Papers/2014 - Kopell et al. - Perspective Beyond the Connectome The Dynome.pdf;/Users/qualia/Documents/Papers/Kopell et al. - 2014 - Beyond the Connectome The Dynome.pdf}
}

@article{Kreitz2015,
  langid = {english},
  title = {Working-Memory Performance Is Related to Spatial Breadth of Attention},
  volume = {79},
  issn = {0340-0727, 1430-2772},
  url = {http://link.springer.com/10.1007/s00426-014-0633-x},
  doi = {10.1007/s00426-014-0633-x},
  abstract = {Working memory and attention are closely related constructs. Models of working memory often incorporate an attention component, and some even equate working memory and attentional control. Although some attention-related processes, including inhibitory control of response conflict and interference resolution, are strongly associated with working memory, for other aspects of attention the link is less clear. We examined the association between working-memory performance and attentional breadth, the ability to spread attention spatially. If the link between attention and working memory is broader than inhibitory and interference resolution processes, then working-memory performance might also be associated with other attentional abilities, including attentional breadth. We tested 123 participants on a variety of working-memory and attentional-breadth measures, finding a strong correlation between performances on these two types of tasks. This finding demonstrates that the link between working memory and attention extends beyond inhibitory processes.},
  number = {6},
  journaltitle = {Psychological Research},
  urldate = {2019-03-30},
  date = {2015-11},
  pages = {1034-1041},
  author = {Kreitz, Carina and Furley, Philip and Memmert, Daniel and Simons, Daniel J.},
  file = {/Users/qualia/Documents/Papers/2014 - Kreitz et al. - Working-memory performance is related to spatial breadth of attention.pdf;/Users/qualia/Documents/Papers/Kreitz et al. - 2015 - Working-memory performance is related to spatial b.pdf}
}

@article{Laing2014,
  langid = {english},
  title = {Numerical {{Bifurcation Theory}} for {{High}}-{{Dimensional Neural Models}}},
  volume = {4},
  issn = {2190-8567},
  url = {http://mathematical-neuroscience.springeropen.com/articles/10.1186/2190-8567-4-13},
  doi = {10.1186/2190-8567-4-13},
  abstract = {Numerical bifurcation theory involves finding and then following certain types of solutions of differential equations as parameters are varied, and determining whether they undergo any bifurcations (qualitative changes in behaviour). The primary technique for doing this is numerical continuation, where the solution of interest satisfies a parametrised set of algebraic equations, and branches of solutions are followed as the parameter is varied. An effective way to do this is with pseudoarclength continuation. We give an introduction to pseudo-arclength continuation and then demonstrate its use in investigating the behaviour of a number of models from the field of computational neuroscience. The models we consider are high dimensional, as they result from the discretisation of neural field models\textemdash{}nonlocal differential equations used to model macroscopic pattern formation in the cortex. We consider both stationary and moving patterns in one spatial dimension, and then translating patterns in two spatial dimensions. A variety of results from the literature are discussed, and a number of extensions of the technique are given.},
  number = {1},
  journaltitle = {The Journal of Mathematical Neuroscience},
  urldate = {2019-03-30},
  date = {2014},
  pages = {13},
  author = {Laing, Carlo R},
  file = {/Users/qualia/Documents/Papers/2014 - Laing - Numerical Bifurcation Theory for High-Dimensional Neural Models.pdf;/Users/qualia/Documents/Papers/2014 - Laing - Numerical Bifurcation Theory for High-Dimensional Neural Models(2).pdf;/Users/qualia/Documents/Papers/Laing - 2014 - Numerical Bifurcation Theory for High-Dimensional  2.pdf;/Users/qualia/Documents/Papers/Laing - 2014 - Numerical Bifurcation Theory for High-Dimensional .pdf}
}

@article{Legon2014,
  langid = {english},
  title = {Transcranial Focused Ultrasound Modulates the Activity of Primary Somatosensory Cortex in Humans},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3620},
  doi = {10.1038/nn.3620},
  number = {2},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-02},
  pages = {322-329},
  author = {Legon, Wynn and Sato, Tomokazu F and Opitz, Alexander and Mueller, Jerel and Barbour, Aaron and Williams, Amanda and Tyler, William J},
  file = {/Users/qualia/Documents/Papers/2014 - Legon et al. - Transcranial focused ultrasound modulates the activity of primary somatosensory cortex in humans.pdf;/Users/qualia/Documents/Papers/Legon et al. - 2014 - Transcranial focused ultrasound modulates the acti.pdf}
}

@article{Guise2014,
  langid = {english},
  title = {A {{Bayesian Model}} of {{Polychronicity}}},
  volume = {26},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00620},
  doi = {10.1162/NECO_a_00620},
  number = {9},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2014-09},
  pages = {2052-2073},
  author = {Guise, Mira and Knott, Alistair and Benuskova, Lubica},
  file = {/Users/qualia/Documents/Papers/2014 - Lehky et al. - Dimensionality of object representations in monkey inferotemporal cortex.pdf;/Users/qualia/Documents/Papers/Guise et al. - 2014 - A Bayesian Model of Polychronicity.pdf}
}

@article{Lainscsek2015,
  langid = {english},
  title = {Delay {{Differential Analysis}} of {{Time Series}}},
  volume = {27},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00706},
  doi = {10.1162/NECO_a_00706},
  number = {3},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2015-03},
  pages = {594-614},
  author = {Lainscsek, Claudia and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/2014 - Lehky et al. - Dimensionality of object representations in monkey inferotemporal cortex(2).pdf;/Users/qualia/Documents/Papers/Lainscsek and Sejnowski - 2015 - Delay Differential Analysis of Time Series.pdf}
}

@article{Curto2013a,
  langid = {english},
  title = {Encoding {{Binary Neural Codes}} in {{Networks}} of {{Threshold}}-{{Linear Neurons}}},
  volume = {25},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00504},
  doi = {10.1162/NECO_a_00504},
  number = {11},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2013-11},
  pages = {2858-2903},
  author = {Curto, Carina and Degeratu, Anda and Itskov, Vladimir},
  file = {/Users/qualia/Documents/Papers/2014 - Lehky et al. - Encoding Binary Neural Codes in Networks of Threshold-Linear Neurons.pdf;/Users/qualia/Documents/Papers/Curto et al. - 2013 - Encoding Binary Neural Codes in Networks of Thresh.pdf}
}

@article{Lienard2014,
  langid = {english},
  title = {A Biologically Constrained Model of the Whole Basal Ganglia Addressing the Paradoxes of Connections and Selection},
  volume = {36},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-013-0476-2},
  doi = {10.1007/s10827-013-0476-2},
  number = {3},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-06},
  pages = {445-468},
  author = {Li\'enard, Jean and Girard, Beno\^it},
  file = {/Users/qualia/Documents/Papers/2014 - Liénard, Girard - A biologically constrained model of the whole basal ganglia addressing the paradoxes of connections and select.pdf;/Users/qualia/Documents/Papers/Liénard and Girard - 2014 - A biologically constrained model of the whole basa.pdf}
}

@article{Ly2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.01064},
  primaryClass = {math, stat},
  langid = {english},
  title = {A {{Tutorial}} on {{Fisher Information}}},
  url = {http://arxiv.org/abs/1705.01064},
  abstract = {In many statistical applications that concern mathematical psychologists, the concept of Fisher information plays an important role. In this tutorial we clarify the concept of Fisher information as it manifests itself across three different statistical paradigms. First, in the frequentist paradigm, Fisher information is used to construct hypothesis tests and confidence intervals using maximum likelihood estimators; second, in the Bayesian paradigm, Fisher information is used to define a default prior; finally, in the minimum description length paradigm, Fisher information is used to measure model complexity.},
  urldate = {2019-03-30},
  date = {2017-05-02},
  keywords = {62-01; 62B10 (Primary); 62F03; 62F12; 62F15; 62B10 (Secondary),Mathematics - Statistics Theory},
  author = {Ly, Alexander and Marsman, Maarten and Verhagen, Josine and Grasman, Raoul and Wagenmakers, Eric-Jan},
  file = {/Users/qualia/Documents/Papers/2014 - Ly et al. - A Tutorial on Fisher Information.pdf;/Users/qualia/Documents/Papers/Ly et al. - 2017 - A Tutorial on Fisher Information.pdf}
}

@article{Marder2014,
  langid = {english},
  title = {Neuromodulation of {{Circuits}} with {{Variable Parameters}}: {{Single Neurons}} and {{Small Circuits Reveal Principles}} of {{State}}-{{Dependent}} and {{Robust Neuromodulation}}},
  volume = {37},
  issn = {0147-006X, 1545-4126},
  url = {http://www.annualreviews.org/doi/10.1146/annurev-neuro-071013-013958},
  doi = {10.1146/annurev-neuro-071013-013958},
  shorttitle = {Neuromodulation of {{Circuits}} with {{Variable Parameters}}},
  number = {1},
  journaltitle = {Annual Review of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-07-08},
  pages = {329-346},
  author = {Marder, Eve and O'Leary, Timothy and Shruti, Sonal},
  file = {/Users/qualia/Documents/Papers/2014 - Marder, O'Leary, Shruti - Neuromodulation of Circuits with Variable Parameters Single Neurons and Small Circuits Reveal Principle.pdf;/Users/qualia/Documents/Papers/Marder et al. - 2014 - Neuromodulation of Circuits with Variable Paramete.pdf}
}

@article{Meng2014,
  langid = {english},
  title = {A {{Unified Approach}} to {{Linking Experimental}}, {{Statistical}} and {{Computational Analysis}} of {{Spike Train Data}}},
  volume = {9},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0085269},
  doi = {10.1371/journal.pone.0085269},
  abstract = {A fundamental issue in neuroscience is how to identify the multiple biophysical mechanisms through which neurons generate observed patterns of spiking activity. In previous work, we proposed a method for linking observed patterns of spiking activity to specific biophysical mechanisms based on a state space modeling framework and a sequential Monte Carlo, or particle filter, estimation algorithm. We have shown, in simulation, that this approach is able to identify a space of simple biophysical models that were consistent with observed spiking data (and included the model that generated the data), but have yet to demonstrate the application of the method to identify realistic currents from real spike train data. Here, we apply the particle filter to spiking data recorded from rat layer V cortical neurons, and correctly identify the dynamics of an slow, intrinsic current. The underlying intrinsic current is successfully identified in four distinct neurons, even though the cells exhibit two distinct classes of spiking activity: regular spiking and bursting. This approach \textendash{} linking statistical, computational, and experimental neuroscience \textendash{} provides an effective technique to constrain detailed biophysical models to specific mechanisms consistent with observed spike train data.},
  number = {1},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2014-01-17},
  pages = {e85269},
  author = {Meng, Liang and Kramer, Mark A. and Middleton, Steven J. and Whittington, Miles A. and Eden, Uri T.},
  editor = {Chacron, Maurice J.},
  file = {/Users/qualia/Documents/Papers/2014 - Meng et al. - A unified approach to linking experimental, statistical and computational analysis of spike train data.pdf;/Users/qualia/Documents/Papers/Meng et al. - 2014 - A Unified Approach to Linking Experimental, Statis.pdf}
}

@article{Mumford2014,
  langid = {english},
  title = {The Impact of Study Design on Pattern Estimation for Single-Trial Multivariate Pattern Analysis},
  volume = {103},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S105381191400768X},
  doi = {10.1016/j.neuroimage.2014.09.026},
  abstract = {A prerequisite for a pattern analysis using functional magnetic resonance imaging (fMRI) data is estimating the patterns from time series data, which then are input into the pattern analysis. Here we focus on how the combination of study design (order and spacing of trials) with pattern estimator impacts the Type I error rate of the subsequent pattern analysis. When Type I errors are inflated, the results are no longer valid, so this work serves as a guide for designing and analyzing MVPA studies with controlled false positive rates. The MVPA strategies examined are pattern classification and similarity, utilizing single trial activation patterns from the same functional run. Primarily focusing on the Least Squares Single and Least Square All pattern estimators, we show that collinearities in the models, along with temporal autocorrelation, can cause false positive correlations between activation pattern estimates that adversely impact the false positive rates of pattern similarity and classification analyses. It may seem intuitive that increasing the interstimulus interval (ISI) would alleviate this issue, but remaining weak correlations between activation patterns persist and have a strong influence in pattern similarity analyses. Pattern similarity analyses using only activation patterns estimated from the same functional run of data are susceptible to inflated false positives unless trials are randomly ordered, with a different randomization for each subject. In other cases, where there is any structure to trial order, valid pattern similarity analysis results can only be obtained if similarity computations are restricted to pairs of activation patterns from independent runs. Likewise, for pattern classification, false positives are minimized when the testing and training sets in cross validation do not contain patterns estimated from the same run.},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2014-12},
  pages = {130-138},
  author = {Mumford, Jeanette A. and Davis, Tyler and Poldrack, Russell A.},
  file = {/Users/qualia/Documents/Papers/2014 - Mumford, Davis, Poldrack - The impact of study design on pattern estimation for single-trial multivariate pattern analysis.pdf;/Users/qualia/Documents/Papers/Mumford et al. - 2014 - The impact of study design on pattern estimation f.pdf}
}

@article{Nadim2014,
  langid = {english},
  title = {Neuromodulation of Neurons and Synapses},
  volume = {29},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814001044},
  doi = {10.1016/j.conb.2014.05.003},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2014-12},
  pages = {48-56},
  author = {Nadim, Farzan and Bucher, Dirk},
  file = {/Users/qualia/Documents/Papers/2014 - Nadim, Bucher - Neuromodulation of neurons and synapses.pdf;/Users/qualia/Documents/Papers/Nadim and Bucher - 2014 - Neuromodulation of neurons and synapses 2.pdf;/Users/qualia/Documents/Papers/Nadim and Bucher - 2014 - Neuromodulation of neurons and synapses.pdf}
}

@article{OLeary2014,
  langid = {english},
  title = {Cell {{Types}}, {{Network Homeostasis}}, and {{Pathological Compensation}} from a {{Biologically Plausible Ion Channel Expression Model}}},
  volume = {82},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S089662731400292X},
  doi = {10.1016/j.neuron.2014.04.002},
  abstract = {How do neurons develop, control, and maintain their electrical signaling properties in spite of ongoing protein turnover and perturbations to activity? From generic assumptions about the molecular biology underlying channel expression, we derive a simple model and show how it encodes an ``activity set point'' in single neurons. The model generates diverse self-regulating cell types and relates correlations in conductance expression observed in vivo to underlying channel expression rates. Synaptic as well as intrinsic conductances can be regulated to make a self-assembling central pattern generator network; thus, network-level homeostasis can emerge from cell-autonomous regulation rules. Finally, we demonstrate that the outcome of homeostatic regulation depends on the complement of ion channels expressed in cells: in some cases, loss of specific ion channels can be compensated; in others, the homeostatic mechanism itself causes pathological loss of function.},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2014-05},
  pages = {809-821},
  author = {O'Leary, Timothy and Williams, Alex H. and Franci, Alessio and Marder, Eve},
  file = {/Users/qualia/Documents/Papers/2014 - O'Leary et al. - Cell Types, Network Homeostasis, and Pathological Compensation from a Biologically Plausible Ion Channel Express.pdf;/Users/qualia/Documents/Papers/O’Leary et al. - 2014 - Cell Types, Network Homeostasis, and Pathological .pdf}
}

@article{OLeary2014a,
  langid = {english},
  title = {Temperature-Robust Neural Activity Using Feedback Control of Ion Channel Expression},
  volume = {15},
  issn = {1471-2202},
  url = {https://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-15-S1-P103},
  doi = {10.1186/1471-2202-15-S1-P103},
  number = {S1},
  journaltitle = {BMC Neuroscience},
  urldate = {2019-03-30},
  date = {2014-07},
  author = {O'Leary, Timothy and Marder, Eve},
  file = {/Users/qualia/Documents/Papers/2014 - O’Leary, Marder - Temperature-robust neural activity using feedback control of ion channel expression.pdf;/Users/qualia/Documents/Papers/O’Leary and Marder - 2014 - Temperature-robust neural activity using feedback .pdf}
}

@article{Pinotsis2014,
  langid = {english},
  title = {Neural Masses and Fields: Modeling the Dynamics of Brain Activity},
  volume = {8},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2014.00149/abstract},
  doi = {10.3389/fncom.2014.00149},
  shorttitle = {Neural Masses and Fields},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-11-17},
  author = {Pinotsis, Dimitris and Robinson, Peter and beim Graben, Peter and Friston, Karl},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2014 - Pinotsis et al. - Neural masses and fields modeling the dynamics of brain activity.pdf;/Users/qualia/Documents/Papers/Pinotsis et al. - 2014 - Neural masses and fields modeling the dynamics of.pdf}
}

@article{Potjans2014,
  langid = {english},
  title = {The {{Cell}}-{{Type Specific Cortical Microcircuit}}: {{Relating Structure}} and {{Activity}} in a {{Full}}-{{Scale Spiking Network Model}}},
  volume = {24},
  issn = {1460-2199, 1047-3211},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhs358},
  doi = {10.1093/cercor/bhs358},
  shorttitle = {The {{Cell}}-{{Type Specific Cortical Microcircuit}}},
  abstract = {In the past decade, the cell-type specific connectivity and activity of local cortical networks have been characterized experimentally to some detail. In parallel, modeling has been established as a tool to relate network structure to activity dynamics. While available comprehensive connectivity maps (Thomson, West, et al. 2002; Binzegger et al. 2004) have been used in various computational studies, prominent features of the simulated activity such as the spontaneous firing rates do not match the experimental findings. Here, we analyze the properties of these maps to compile an integrated connectivity map, which additionally incorporates insights on the specific selection of target types. Based on this integrated map, we build a full-scale spiking network model of the local cortical microcircuit. The simulated spontaneous activity is asynchronous irregular and cell-type specific firing rates are in agreement with in vivo recordings in awake animals, including the low rate of layer 2/3 excitatory cells. The interplay of excitation and inhibition captures the flow of activity through cortical layers after transient thalamic stimulation. In conclusion, the integration of a large body of the available connectivity data enables us to expose the dynamical consequences of the cortical microcircuitry.},
  number = {3},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2014-03},
  pages = {785-806},
  author = {Potjans, Tobias C. and Diesmann, Markus},
  file = {/Users/qualia/Documents/Papers/2014 - Potjans, Diesmann - The cell-type specific cortical microcircuit Relating structure and activity in a full-scale spiking network.pdf;/Users/qualia/Documents/Papers/Potjans and Diesmann - 2014 - The Cell-Type Specific Cortical Microcircuit Rela.pdf}
}

@article{Rey2014,
  langid = {english},
  title = {Using Waveform Information in Nonlinear Data Assimilation},
  volume = {90},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.90.062916},
  doi = {10.1103/PhysRevE.90.062916},
  number = {6},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2014-12-22},
  author = {Rey, Daniel and Eldridge, Michael and Morone, Uriel and Abarbanel, Henry D. I. and Parlitz, Ulrich and Schumann-Bischoff, Jan},
  file = {/Users/qualia/Documents/Papers/2014 - Rey et al. - Using waveform information in nonlinear data assimilation.pdf;/Users/qualia/Documents/Papers/Rey et al. - 2014 - Using waveform information in nonlinear data assim.pdf}
}

@inproceedings{Rocktaschel2014,
  langid = {english},
  location = {{Baltimore, MD}},
  title = {Low-{{Dimensional Embeddings}} of {{Logic}}},
  url = {http://aclweb.org/anthology/W14-2409},
  doi = {10.3115/v1/W14-2409},
  abstract = {Many machine reading approaches, from shallow information extraction to deep semantic parsing, map natural language to symbolic representations of meaning. Representations such as first-order logic capture the richness of natural language and support complex reasoning, but often fail in practice due to their reliance on logical background knowledge and the difficulty of scaling up inference. In contrast, low-dimensional embeddings (i.e. distributional representations) are efficient and enable generalization, but it is unclear how reasoning with embeddings could support the full power of symbolic representations such as first-order logic. In this proof-ofconcept paper we address this by learning embeddings that simulate the behavior of first-order logic.},
  eventtitle = {Proceedings of the {{ACL}} 2014 {{Workshop}} on {{Semantic Parsing}}},
  booktitle = {Proceedings of the {{ACL}} 2014 {{Workshop}} on {{Semantic Parsing}}},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2019-03-30},
  date = {2014},
  pages = {45-49},
  author = {Rockt\"aschel, Tim and Bo{\v s}njak, Matko and Singh, Sameer and Riedel, Sebastian},
  file = {/Users/qualia/Documents/Papers/2014 - Rocktäschel et al. - Low-Dimensional Embeddings of Logic.pdf;/Users/qualia/Documents/Papers/Rocktäschel et al. - 2014 - Low-Dimensional Embeddings of Logic.pdf}
}

@article{Timms2014,
  langid = {english},
  title = {Synchronization in Phase-Coupled {{Kuramoto}} Oscillator Networks with Axonal Delay and Synaptic Plasticity},
  volume = {89},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.89.032906},
  doi = {10.1103/PhysRevE.89.032906},
  number = {3},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2014-03-10},
  author = {Timms, L. and English, L. Q.},
  file = {/Users/qualia/Documents/Papers/2014 - Timms, English - Synchronization in phase-coupled Kuramoto oscillator networks with axonal delay and synaptic plasticity.pdf;/Users/qualia/Documents/Papers/Timms and English - 2014 - Synchronization in phase-coupled Kuramoto oscillat.pdf}
}

@article{Tria2015,
  langid = {english},
  title = {The Dynamics of Correlated Novelties},
  volume = {4},
  issn = {2045-2322},
  url = {http://www.nature.com/articles/srep05890},
  doi = {10.1038/srep05890},
  number = {1},
  journaltitle = {Scientific Reports},
  urldate = {2019-03-30},
  date = {2015-05},
  author = {Tria, F. and Loreto, V. and Servedio, V. D. P. and Strogatz, S. H.},
  file = {/Users/qualia/Documents/Papers/2014 - Tria et al. - The dynamics of correlated novelties.pdf;/Users/qualia/Documents/Papers/Tria et al. - 2015 - The dynamics of correlated novelties.pdf}
}

@article{Engelken2015,
  langid = {english},
  title = {Comment on ``{{Two}} Types of Asynchronous Activity in Networks of Excitatory and Inhibitory Spiking Neurons''},
  url = {http://biorxiv.org/lookup/doi/10.1101/017798},
  doi = {10.1101/017798},
  abstract = {Slow neural dynamics are believed to be important for behavior, learning and memory. Rate models operating in the chaotic regime show a rich dynamics at the scale of hundreds of milliseconds and provide remarkable learning capabilities. However, neurons in the brain communicate via spikes and it is a major challenge in computational neuroscience to obtain similar slow rate dynamics in networks of spiking neuron models. This question was addressed in a recent paper by Ostojic. The central claim of that paper is the existence of two states of asynchronous activity separated by a phase transition in spiking networks with fast synapses. We found that the analysis presented in the paper is factually incorrect and conceptually misleading. We provide compelling evidence that there is no such phase transition.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2015-04-09},
  author = {Engelken, Rainer and Farkhooi, Farzad and Hansel, David and van Vreeswijk, Carl and Wolf, Fred},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2014 - Unknown - Comment on Two types of asynchronous activity in networks of excitatory and inhibitory spiking neurons.pdf;/Users/qualia/Documents/Papers/Engelken et al. - 2015 - Comment on “Two types of asynchronous activity in .pdf}
}

@article{Schomburg,
  langid = {english},
  title = {{{BIOPHYSICAL AND NETWORK MECHANISMS OF HIGH FREQUENCY EXTRACELLULAR POTENTIALS IN THE RAT HIPPOCAMPUS}}},
  pages = {230},
  author = {Schomburg, Erik W},
  file = {/Users/qualia/Documents/Papers/2014 - Unknown - Thesis by.pdf;/Users/qualia/Documents/Papers/Schomburg - BIOPHYSICAL AND NETWORK MECHANISMS OF HIGH FREQUEN.pdf}
}

@article{Vogelstein2014,
  langid = {english},
  title = {Discovery of {{Brainwide Neural}}-{{Behavioral Maps}} via {{Multiscale Unsupervised Structure Learning}}},
  volume = {344},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1250298},
  doi = {10.1126/science.1250298},
  number = {6182},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2014-04-25},
  pages = {386-392},
  author = {Vogelstein, J. T. and Park, Y. and Ohyama, T. and Kerr, R. A. and Truman, J. W. and Priebe, C. E. and Zlatic, M.},
  file = {/Users/qualia/Documents/Papers/2014 - Vogelstein et al. - Discovery of Brainwide Neural-Behavioral Maps via Multiscale Unsupervised Structure Learning.pdf;/Users/qualia/Documents/Papers/Vogelstein et al. - 2014 - Discovery of Brainwide Neural-Behavioral Maps via .pdf}
}

@article{Williams2018,
  langid = {english},
  title = {Escape {{Dynamics}} in {{Learning Models}}},
  issn = {0034-6527, 1467-937X},
  url = {https://academic.oup.com/restud/advance-article/doi/10.1093/restud/rdy033/5035336},
  doi = {10.1093/restud/rdy033},
  journaltitle = {The Review of Economic Studies},
  urldate = {2019-03-30},
  date = {2018-06-09},
  author = {Williams, Noah},
  file = {/Users/qualia/Documents/Papers/2014 - Williams - Escape Dynamics in Learning Models.pdf;/Users/qualia/Documents/Papers/Williams - 2018 - Escape Dynamics in Learning Models.pdf}
}

@article{Wimmer2014,
  langid = {english},
  title = {Bump Attractor Dynamics in Prefrontal Cortex Explains Behavioral Precision in Spatial Working Memory},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3645},
  doi = {10.1038/nn.3645},
  number = {3},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-03},
  pages = {431-439},
  author = {Wimmer, Klaus and Nykamp, Duane Q and Constantinidis, Christos and Compte, Albert},
  file = {/Users/qualia/Documents/Papers/2014 - Wimmer et al. - Bump attractor dynamics in prefrontal cortex explains behavioral precision in spatial working memory.pdf;/Users/qualia/Documents/Papers/Wimmer et al. - 2014 - Bump attractor dynamics in prefrontal cortex expla.pdf}
}

@article{Yan2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1410.0736},
  primaryClass = {cs, stat},
  langid = {english},
  title = {{{HD}}-{{CNN}}: {{Hierarchical Deep Convolutional Neural Network}} for {{Large Scale Visual Recognition}}},
  url = {http://arxiv.org/abs/1410.0736},
  shorttitle = {{{HD}}-{{CNN}}},
  abstract = {In image classification, visual separability between different object categories is highly uneven, and some categories are more difficult to distinguish than others. Such difficult categories demand more dedicated classifiers. However, existing deep convolutional neural networks (CNN) are trained as flat N-way classifiers, and few efforts have been made to leverage the hierarchical structure of categories. In this paper, we introduce hierarchical deep CNNs (HD-CNNs) by embedding deep CNNs into a category hierarchy. An HD-CNN separates easy classes using a coarse category classifier while distinguishing difficult classes using fine category classifiers. During HD-CNN training, component-wise pretraining is followed by global finetuning with a multinomial logistic loss regularized by a coarse category consistency term. In addition, conditional executions of fine category classifiers and layer parameter compression make HD-CNNs scalable for large-scale visual recognition. We achieve state-of-the-art results on both CIFAR100 and large-scale ImageNet 1000-class benchmark datasets. In our experiments, we build up three different HD-CNNs and they lower the top-1 error of the standard CNNs by 2.65\%, 3.1\% and 1.1\%, respectively.},
  urldate = {2019-03-30},
  date = {2014-10-02},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  author = {Yan, Zhicheng and Zhang, Hao and Piramuthu, Robinson and Jagadeesh, Vignesh and DeCoste, Dennis and Di, Wei and Yu, Yizhou},
  file = {/Users/qualia/Documents/Papers/2014 - Yan et al. - HD-CNN Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition.pdf;/Users/qualia/Documents/Papers/Yan et al. - 2014 - HD-CNN Hierarchical Deep Convolutional Neural Net.pdf}
}

@article{Ye2014,
  langid = {english},
  title = {Estimating the Biophysical Properties of Neurons with Intracellular Calcium Dynamics},
  volume = {89},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.89.062714},
  doi = {10.1103/PhysRevE.89.062714},
  number = {6},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2014-06-26},
  author = {Ye, Jingxin and Rozdeba, Paul J. and Morone, Uriel I. and Daou, Arij and Abarbanel, Henry D. I.},
  file = {/Users/qualia/Documents/Papers/2014 - Ye, Rozdeba, Morone - Estimating the biophysical properties of neurons with intracellular calcium dynamics.pdf;/Users/qualia/Documents/Papers/Ye et al. - 2014 - Estimating the biophysical properties of neurons w.pdf}
}

@article{Yosinski2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1411.1792},
  primaryClass = {cs},
  langid = {english},
  title = {How Transferable Are Features in Deep Neural Networks?},
  url = {http://arxiv.org/abs/1411.1792},
  abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
  urldate = {2019-03-30},
  date = {2014-11-06},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  file = {/Users/qualia/Documents/Papers/2014 - Yosinski et al. - How transferable are features in deep neural networks.pdf;/Users/qualia/Documents/Papers/Yosinski et al. - 2014 - How transferable are features in deep neural netwo.pdf}
}

@article{Yu2014,
  langid = {english},
  title = {Sparse {{Coding}} and {{Lateral Inhibition Arising}} from {{Balanced}} and {{Unbalanced Dendrodendritic Excitation}} and {{Inhibition}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1834-14.2014},
  doi = {10.1523/JNEUROSCI.1834-14.2014},
  number = {41},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-10-08},
  pages = {13701-13713},
  author = {Yu, Yuguo and Migliore, Michele and Hines, Michael L. and Shepherd, Gordon M.},
  file = {/Users/qualia/Documents/Papers/2014 - Yu et al. - Sparse Coding and Lateral Inhibition Arising from Balanced and Unbalanced Dendrodendritic Excitation and Inhibition.pdf;/Users/qualia/Documents/Papers/Yu et al. - 2014 - Sparse Coding and Lateral Inhibition Arising from .pdf}
}

@article{Zandt2014,
  langid = {english},
  title = {A Neural Mass Model Based on Single Cell Dynamics to Model Pathophysiology},
  volume = {37},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-014-0517-5},
  doi = {10.1007/s10827-014-0517-5},
  abstract = {Neural mass models are successful in modeling brain rhythms as observed in macroscopic measurements such as the electroencephalogram (EEG). While the synaptic current is explicitly modeled in current models, the single cell electrophysiology is not taken into account. To allow for investigations of the effects of channel pathologies, channel blockers and ion concentrations on macroscopic activity, we formulate neural mass equations explicitly incorporating the single cell dynamics by using a bottom-up approach. The mean and variance of the firing rate and synaptic input distributions are modeled. The firing rate curve (F(I)-curve) is used as link between the single cell and macroscopic dynamics. We show that this model accurately reproduces the behavior of two populations of synaptically connected Hodgkin-Huxley neurons, also in non-steady state.},
  number = {3},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-12},
  pages = {549-568},
  author = {Zandt, Bas-Jan and Visser, Sid and van Putten, Michel J. A. M. and ten Haken, Bennie},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2014 - Zandt et al. - A neural mass model based on single cell dynamics to model pathophysiology.pdf;/Users/qualia/Documents/Papers/Zandt et al. - 2014 - A neural mass model based on single cell dynamics .pdf}
}

@article{Zhou2014,
  langid = {english},
  title = {Scaling down of Balanced Excitation and Inhibition by Active Behavioral States in Auditory Cortex},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3701},
  doi = {10.1038/nn.3701},
  number = {6},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-06},
  pages = {841-850},
  author = {Zhou, Mu and Liang, Feixue and Xiong, Xiaorui R and Li, Lu and Li, Haifu and Xiao, Zhongju and Tao, Huizhong W and Zhang, Li I},
  file = {/Users/qualia/Documents/Papers/2014 - Zhou et al. - Scaling down of balanced excitation and inhibition by active behavioral states in auditory cortex.pdf;/Users/qualia/Documents/Papers/Zhou et al. - 2014 - Scaling down of balanced excitation and inhibition.pdf}
}

@article{Aljadeff2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1509.02546},
  langid = {english},
  title = {On the Low Dimensional Dynamics of Structured Random Networks},
  volume = {93},
  issn = {2470-0045, 2470-0053},
  url = {http://arxiv.org/abs/1509.02546},
  doi = {10.1103/PhysRevE.93.022302},
  abstract = {Using a generalized random recurrent neural network model, and by extending our recently developed mean-field approach [J. Aljadeff, M. Stern, T. Sharpee, Phys. Rev. Lett. 114, 088101 (2015)], we study the relationship between the network connectivity structure and its low dimensional dynamics. Each connection in the network is a random number with mean 0 and variance that depends on pre- and post-synaptic neurons through a sufficiently smooth function \$g\$ of their identities. We find that these networks undergo a phase transition from a silent to a chaotic state at a critical point we derive as a function of \$g\$. Above the critical point, although unit activation levels are chaotic, their autocorrelation functions are restricted to a low dimensional subspace. This provides a direct link between the network's structure and some of its functional characteristics. We discuss example applications of the general results to neuroscience where we derive the support of the spectrum of connectivity matrices with heterogeneous and possibly correlated degree distributions, and to ecology where we study the stability of the cascade model for food web structure.},
  number = {2},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2016-02-05},
  keywords = {Quantitative Biology - Neurons and Cognition,Condensed Matter - Disordered Systems and Neural Networks},
  author = {Aljadeff, Johnatan and Renfrew, David and Vegu\'e, Marina and Sharpee, Tatyana O.},
  file = {/Users/qualia/Documents/Papers/2015 - Aljadeff et al. - On the low dimensional dynamics of structured random networks.pdf;/Users/qualia/Documents/Papers/Aljadeff et al. - 2016 - On the low dimensional dynamics of structured rand.pdf}
}

@article{Aljadeff2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1411.2688},
  langid = {english},
  title = {Eigenvalues of Block Structured Asymmetric Random Matrices},
  volume = {56},
  issn = {0022-2488, 1089-7658},
  url = {http://arxiv.org/abs/1411.2688},
  doi = {10.1063/1.4931476},
  abstract = {We study the spectrum of an asymmetric random matrix with block structured variances. The rows and columns of the random square matrix are divided into \$D\$ partitions with arbitrary size (linear in \$N\$). The parameters of the model are the variances of elements in each block, summarized in \$g\textbackslash{}in\textbackslash{}mathbb\{R\}\^\{D\textbackslash{}times D\}\_+\$. Using the Hermitization approach and by studying the matrix-valued Stieltjes transform we show that these matrices have a circularly symmetric spectrum, we give an explicit formula for their spectral radius and a set of implicit equations for the full density function. We discuss applications of this model to neural networks.},
  number = {10},
  journaltitle = {Journal of Mathematical Physics},
  urldate = {2019-03-30},
  date = {2015-10},
  pages = {103502},
  keywords = {Mathematics - Probability},
  author = {Aljadeff, Johnatan and Renfrew, David and Stern, Merav},
  file = {/Users/qualia/Documents/Papers/2015 - Aljadeff, Renfrew, Stern - Eigenvalues of block structured asymmetric random matrices.pdf;/Users/qualia/Documents/Papers/Aljadeff et al. - 2015 - Eigenvalues of block structured asymmetric random .pdf}
}

@article{Aljadeff2015a,
  langid = {english},
  title = {Transition to {{Chaos}} in {{Random Networks}} with {{Cell}}-{{Type}}-{{Specific Connectivity}}},
  volume = {114},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.114.088101},
  doi = {10.1103/PhysRevLett.114.088101},
  number = {8},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2015-02-23},
  author = {Aljadeff, Johnatan and Stern, Merav and Sharpee, Tatyana},
  file = {/Users/qualia/Documents/Papers/2015 - Aljadeff, Stern, Sharpee - Transition to chaos in random networks with cell-type-specific connectivity.pdf;/Users/qualia/Documents/Papers/Aljadeff et al. - 2015 - Transition to Chaos in Random Networks with Cell-T.pdf}
}

@article{Alkemade2015,
  langid = {english},
  title = {Topographic Organization of the Human and Non-Human Primate Subthalamic Nucleus},
  volume = {220},
  issn = {1863-2653, 1863-2661},
  url = {http://link.springer.com/10.1007/s00429-015-1047-2},
  doi = {10.1007/s00429-015-1047-2},
  number = {6},
  journaltitle = {Brain Structure and Function},
  urldate = {2019-03-30},
  date = {2015-11},
  pages = {3075-3086},
  author = {Alkemade, Anneke and Schnitzler, Alfons and Forstmann, Birte U.},
  file = {/Users/qualia/Documents/Papers/2015 - Alkemade, Schnitzler, Forstmann - Topographic organization of the human and non-human primate subthalamic nucleus.pdf;/Users/qualia/Documents/Papers/Alkemade et al. - 2015 - Topographic organization of the human and non-huma.pdf}
}

@article{Almeida2015,
  langid = {english},
  title = {Neural Circuit Basis of Visuo-Spatial Working Memory Precision: A Computational and Behavioral Study},
  volume = {114},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00362.2015},
  doi = {10.1152/jn.00362.2015},
  shorttitle = {Neural Circuit Basis of Visuo-Spatial Working Memory Precision},
  abstract = {The amount of information that can be retained in working-memory (WM) is limited. Limitations of WM have been the subject of intense research, especially trying to specify algorithmic models for WM. Comparatively, neural circuit perspectives have barely been used to test WM limitations in behavioral experiments. Here, we used a neuronal microcircuit model for visuo-spatial WM (vsWM) to investigate memory of several items. The model assumes that there is a topographic organization of the circuit responsible for spatial memory retention. This assumption leads to specific predictions, which we tested in psychophysics experiments. According to the model, nearby locations should be recalled with a bias, as if the two memory traces merged during the delay period. Another prediction is that the previously reported loss of memory precision for increasing number of memory items (memory load) should vanish when the distances between items are controlled for. Both predictions were confirmed experimentally. Taken together, our findings provide support for a topographic neural-circuit organization of vsWM, they suggest that interference between similar memories underlies some WM limitations, and they put forward a circuit-based explanation that reconciles previous conflicting results on the dependence of WM precision with load.},
  number = {3},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2015-09},
  pages = {1806-1818},
  author = {Almeida, Rita and Barbosa, Jo\~ao and Compte, Albert},
  file = {/Users/qualia/Documents/Papers/2015 - Almeida, Barbosa, Compte - Neural circuit basis of visuo-spatial working memory precision a computational and behavioral study.pdf;/Users/qualia/Documents/Papers/Almeida et al. - 2015 - Neural circuit basis of visuo-spatial working memo.pdf}
}

@incollection{DeLaPava2015,
  langid = {english},
  location = {{Cham}},
  title = {A {{Gaussian Process Emulator}} for {{Estimating}} the {{Volume}} of {{Tissue Activated During Deep Brain Stimulation}}},
  volume = {9117},
  isbn = {978-3-319-19389-2 978-3-319-19390-8},
  url = {http://link.springer.com/10.1007/978-3-319-19390-8_77},
  booktitle = {Pattern {{Recognition}} and {{Image Analysis}}},
  publisher = {{Springer International Publishing}},
  urldate = {2019-03-30},
  date = {2015},
  pages = {691-699},
  author = {De La Pava, Iv\'an and G\'omez, Viviana and \'Alvarez, Mauricio A. and Henao, \'Oscar A. and Daza-Santacoloma, Genaro and Orozco, \'Alvaro A.},
  editor = {Paredes, Roberto and Cardoso, Jaime S. and Pardo, Xos\'e M.},
  file = {/Users/qualia/Documents/Papers/2015 - Ángel et al. - A Gaussian Process Emulator for Estimating the Volume of Tissue Activated During Deep Brain Stimulation.pdf;/Users/qualia/Documents/Papers/De La Pava et al. - 2015 - A Gaussian Process Emulator for Estimating the Vol.pdf},
  doi = {10.1007/978-3-319-19390-8_77}
}

@article{Arnoldt2015,
  langid = {english},
  title = {Toward the {{Darwinian}} Transition: {{Switching}} between Distributed and Speciated States in a Simple Model of Early Life},
  volume = {92},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.92.052909},
  doi = {10.1103/PhysRevE.92.052909},
  shorttitle = {Toward the {{Darwinian}} Transition},
  number = {5},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2015-11-13},
  author = {Arnoldt, Hinrich and Strogatz, Steven H. and Timme, Marc},
  file = {/Users/qualia/Documents/Papers/2015 - Arnoldt, Strogatz, Timme - Toward the Darwinian transition Switching between distributed and speciated states in a simple model o.pdf;/Users/qualia/Documents/Papers/Arnoldt et al. - 2015 - Toward the Darwinian transition Switching between.pdf}
}

@article{Ay2015,
  langid = {english},
  title = {Information {{Geometry}} on {{Complexity}} and {{Stochastic Interaction}}},
  volume = {17},
  issn = {1099-4300},
  url = {http://www.mdpi.com/1099-4300/17/4/2432},
  doi = {10.3390/e17042432},
  abstract = {Interdependencies of stochastically interacting units are usually quantified by the Kullback-Leibler divergence of a stationary joint probability distribution on the set of all configurations from the corresponding factorized distribution. This is a spatial approach which does not describe the intrinsically temporal aspects of interaction. In the present paper, the setting is extended to a dynamical version where temporal interdependencies are also captured by using information geometry of Markov chain manifolds.},
  number = {4},
  journaltitle = {Entropy},
  urldate = {2019-03-30},
  date = {2015-04-21},
  pages = {2432-2458},
  author = {Ay, Nihat},
  file = {/Users/qualia/Documents/Papers/2015 - Ay - Information geometry on complexity and stochastic interaction.pdf;/Users/qualia/Documents/Papers/Ay - 2015 - Information Geometry on Complexity and Stochastic .pdf}
}

@article{Azodi-Avval2015,
  langid = {english},
  title = {Phase-Dependent Modulation as a Novel Approach for Therapeutic Brain Stimulation},
  volume = {9},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/Article/10.3389/fncom.2015.00026/abstract},
  doi = {10.3389/fncom.2015.00026},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2015-02-26},
  author = {Azodi-Avval, Ramin and Gharabaghi, Alireza},
  file = {/Users/qualia/Documents/Papers/2015 - Azodi-Avval, Gharabaghi - Phase-dependent modulation as a novel approach for therapeutic brain stimulation.pdf;/Users/qualia/Documents/Papers/Azodi-Avval and Gharabaghi - 2015 - Phase-dependent modulation as a novel approach for 2.pdf;/Users/qualia/Documents/Papers/Azodi-Avval and Gharabaghi - 2015 - Phase-dependent modulation as a novel approach for.pdf}
}

@article{Bastide2015,
  langid = {english},
  title = {Pathophysiology of {{L}}-Dopa-Induced Motor and Non-Motor Complications in {{Parkinson}}'s Disease},
  volume = {132},
  issn = {03010082},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0301008215000763},
  doi = {10.1016/j.pneurobio.2015.07.002},
  abstract = {Involuntary movements, or dyskinesia, represent a debilitating complication of levodopa (L-dopa) therapy for Parkinson's disease (PD). L-dopa-induced dyskinesia (LID) are ultimately experienced by the vast majority of patients. In addition, psychiatric conditions often manifested as compulsive behaviours, are emerging as a serious problem in the management of L-dopa therapy. The present review attempts to provide an overview of our current understanding of dyskinesia and other L-dopainduced dysfunctions, a field that dramatically evolved in the past twenty years. In view of the extensive literature on LID, there appeared a critical need to re-frame the concepts, to highlight the most suitable models, to review the central nervous system (CNS) circuitry that may be involved, and to propose a pathophysiological framework was timely and necessary. An updated review to clarify our understanding of LID and other L-dopa-related side effects was therefore timely and necessary.},
  journaltitle = {Progress in Neurobiology},
  urldate = {2019-03-30},
  date = {2015-09},
  pages = {96-168},
  author = {Bastide, Matthieu F. and Meissner, Wassilios G. and Picconi, Barbara and Fasano, Stefania and Fernagut, Pierre-Olivier and Feyder, Michael and Francardo, Veronica and Alcacer, Cristina and Ding, Yunmin and Brambilla, Riccardo and Fisone, Gilberto and Jon Stoessl, A. and Bourdenx, Mathieu and Engeln, Michel and Navailles, Sylvia and De Deurwaerd\`ere, Philippe and Ko, Wai Kin D. and Simola, Nicola and Morelli, Micaela and Groc, Laurent and Rodriguez, Maria-Cruz and Gurevich, Eugenia V. and Quik, Maryka and Morari, Michele and Mellone, Manuela and Gardoni, Fabrizio and Tronci, Elisabetta and Guehl, Dominique and Tison, Fran{\c c}ois and Crossman, Alan R. and Kang, Un Jung and Steece-Collier, Kathy and Fox, Susan and Carta, Manolo and Angela Cenci, M. and B\'ezard, Erwan},
  file = {/Users/qualia/Documents/Papers/2015 - Bastide et al. - Pathophysiology of L-dopa-induced motor and non-motor complications in Parkinson's disease.pdf;/Users/qualia/Documents/Papers/Bastide et al. - 2015 - Pathophysiology of L-dopa-induced motor and non-mo.pdf}
}

@article{Bengio2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1509.05936},
  primaryClass = {cs, q-bio},
  langid = {english},
  title = {{{STDP}} as Presynaptic Activity Times Rate of Change of Postsynaptic Activity},
  url = {http://arxiv.org/abs/1509.05936},
  abstract = {We introduce a weight update formula that is expressed only in terms of firing rates and their derivatives and that results in changes consistent with those associated with spike-timing dependent plasticity (STDP) rules and biological observations, even though the explicit timing of spikes is not needed. The new rule changes a synaptic weight in proportion to the product of the presynaptic firing rate and the temporal rate of change of activity on the postsynaptic side. These quantities are interesting for studying theoretical explanation for synaptic changes from a machine learning perspective. In particular, if neural dynamics moved neural activity towards reducing some objective function, then this STDP rule would correspond to stochastic gradient descent on that objective function.},
  urldate = {2019-03-30},
  date = {2015-09-19},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  author = {Bengio, Yoshua and Mesnard, Thomas and Fischer, Asja and Zhang, Saizheng and Wu, Yuhuai},
  file = {/Users/qualia/Documents/Papers/2015 - Bengio et al. - STDP as presynaptic activity times rate of change of postsynaptic activity.pdf;/Users/qualia/Documents/Papers/Bengio et al. - 2015 - STDP as presynaptic activity times rate of change .pdf}
}

@article{Bengio2015a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1502.04156},
  primaryClass = {cs},
  langid = {english},
  title = {Towards {{Biologically Plausible Deep Learning}}},
  url = {http://arxiv.org/abs/1502.04156},
  abstract = {Neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology. We explore more biologically plausible versions of deep representation learning, focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised, unsupervised and reinforcement learning. The starting point is that the basic learning rule believed to govern synaptic weight updates (Spike-TimingDependent Plasticity) can be interpreted as gradient descent on some objective function so long as the neuronal dynamics push firing rates towards better values of the objective function (be it supervised, unsupervised, or reward-driven). The second main idea is that this corresponds to a form of the variational EM algorithm, i.e., with approximate rather than exact posteriors, implemented by neural dynamics. Another contribution of this paper is that the gradients required for updating the hidden states in the above variational interpretation can be estimated using an approximation that only requires propagating activations forward and backward, with pairs of layers learning to form a denoising auto-encoder. Finally, we extend the theory about the probabilistic interpretation of auto-encoders to justify improved sampling schemes based on the generative interpretation of denoising auto-encoders, and we validate all these ideas on generative learning tasks.},
  urldate = {2019-03-30},
  date = {2015-02-13},
  keywords = {Computer Science - Machine Learning},
  author = {Bengio, Yoshua and Lee, Dong-Hyun and Bornschein, Jorg and Mesnard, Thomas and Lin, Zhouhan},
  file = {/Users/qualia/Documents/Papers/2015 - Bengio et al. - Towards Biologically Plausible Deep Learning.pdf;/Users/qualia/Documents/Papers/Bengio et al. - 2015 - Towards Biologically Plausible Deep Learning.pdf}
}

@article{Latimer2015,
  langid = {english},
  title = {Single-Trial Spike Trains in Parietal Cortex Reveal Discrete Steps during Decision-Making},
  volume = {349},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aaa4056},
  doi = {10.1126/science.aaa4056},
  abstract = {Neurons in the macaque lateral intraparietal (LIP) area exhibit firing rates that appear to ramp upwards or downwards during decision-making. These ramps are commonly assumed to reflect the gradual accumulation of evidence towards a decision threshold. However, the ramping in trialaveraged responses could instead arise from instantaneous jumps at different times on different trials. We examined single-trial responses in LIP using statistical methods for fitting and comparing latent dynamical spike train models. We compared models with latent spike rates governed by either continuous diffusion-to-bound dynamics or discrete ``stepping'' dynamics. Roughly three-quarters of the choice-selective neurons we recorded were better described by the stepping model. Moreover, the inferred steps carried more information about the animal's choice than spike counts.},
  number = {6244},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2015-07-10},
  pages = {184-187},
  author = {Latimer, K. W. and Yates, J. L. and Meister, M. L. R. and Huk, A. C. and Pillow, J. W.},
  file = {/Users/qualia/Documents/Papers/2015 - Biphenyls - HHS Public Access.pdf;/Users/qualia/Documents/Papers/2015 - Latimer et al. - Single-trial spike trains in parietal cortex reveal discrete steps during decision-making.pdf;/Users/qualia/Documents/Papers/Latimer et al. - 2015 - Single-trial spike trains in parietal cortex revea 2.pdf;/Users/qualia/Documents/Papers/Latimer et al. - 2015 - Single-trial spike trains in parietal cortex revea.pdf}
}

@article{Borst2015,
  langid = {english},
  title = {Common Circuit Design in Fly and Mammalian Motion Vision},
  volume = {18},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4050},
  doi = {10.1038/nn.4050},
  number = {8},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2015-08},
  pages = {1067-1076},
  author = {Borst, Alexander and Helmstaedter, Moritz},
  file = {/Users/qualia/Documents/Papers/2015 - Borst, Helmstaedter - Common circuit design in fly and mammalian motion vision.pdf;/Users/qualia/Documents/Papers/Borst and Helmstaedter - 2015 - Common circuit design in fly and mammalian motion .pdf}
}

@article{Bourdoukan,
  langid = {english},
  title = {Enforcing Balance Allows Local Supervised Learning in Spiking Recurrent Networks},
  abstract = {To predict sensory inputs or control motor trajectories, the brain must constantly learn temporal dynamics based on error feedback. However, it remains unclear how such supervised learning is implemented in biological neural networks. Learning in recurrent spiking networks is notoriously difficult because local changes in connectivity may have an unpredictable effect on the global dynamics. The most commonly used learning rules, such as temporal back-propagation, are not local and thus not biologically plausible. Furthermore, reproducing the Poisson-like statistics of neural responses requires the use of networks with balanced excitation and inhibition. Such balance is easily destroyed during learning. Using a top-down approach, we show how networks of integrate-and-fire neurons can learn arbitrary linear dynamical systems by feeding back their error as a feed-forward input. The network uses two types of recurrent connections: fast and slow. The fast connections learn to balance excitation and inhibition using a voltage-based plasticity rule. The slow connections are trained to minimize the error feedback using a current-based Hebbian learning rule. Importantly, the balance maintained by fast connections is crucial to ensure that global error signals are available locally in each neuron, in turn resulting in a local learning rule for the slow connections. This demonstrates that spiking networks can learn complex dynamics using purely local learning rules, using E/I balance as the key rather than an additional constraint. The resulting network implements a given function within the predictive coding scheme, with minimal dimensions and activity.},
  pages = {9},
  author = {Bourdoukan, Ralph and Den\`eve, Sophie},
  file = {/Users/qualia/Documents/Papers/2015 - Bourdoukan, Deneve - Enforcing balance allows local supervised learning in spiking recurrent networks.pdf;/Users/qualia/Documents/Papers/Bourdoukan and Denève - Enforcing balance allows local supervised learning.pdf}
}

@article{Busemeyer2015,
  langid = {english},
  title = {What {{Is Quantum Cognition}}, and {{How Is It Applied}} to {{Psychology}}?},
  volume = {24},
  issn = {0963-7214, 1467-8721},
  url = {http://journals.sagepub.com/doi/10.1177/0963721414568663},
  doi = {10.1177/0963721414568663},
  abstract = {Quantum cognition is a new research program that uses mathematical principles from quantum theory as a framework to explain human cognition, including judgment and decision making, concepts, reasoning, memory, and perception. This research is not concerned with whether the brain is a quantum computer. Instead, it uses quantum theory as a fresh conceptual framework and a coherent set of formal tools for explaining puzzling empirical findings in psychology. In this introduction, we focus on two quantum principles as examples to show why quantum cognition is an appealing new theoretical direction for psychology: complementarity, which suggests that some psychological measures have to be made sequentially and that the context generated by the first measure can influence responses to the next one, producing measurement order effects, and superposition, which suggests that some psychological states cannot be defined with respect to definite values but, instead, that all possible values within the superposition have some potential for being expressed. We present evidence showing how these two principles work together to provide a coherent explanation for many divergent and puzzling phenomena in psychology.},
  number = {3},
  journaltitle = {Current Directions in Psychological Science},
  urldate = {2019-03-30},
  date = {2015-06},
  pages = {163-169},
  author = {Busemeyer, Jerome R. and Wang, Zheng},
  file = {/Users/qualia/Documents/Papers/2015 - Busemeyer, Wang - What Is Quantum Cognition, and How Is It Applied to Psychology.pdf;/Users/qualia/Documents/Papers/Busemeyer and Wang - 2015 - What Is Quantum Cognition, and How Is It Applied t.pdf}
}

@article{Campbell2004,
  langid = {english},
  title = {Delayed {{Coupling Between Two Neural Network Loops}}},
  volume = {65},
  issn = {0036-1399, 1095-712X},
  url = {http://epubs.siam.org/doi/10.1137/S0036139903434833},
  doi = {10.1137/S0036139903434833},
  abstract = {Coupled loops with time delays are common in physiological systems such as neural networks. We study a Hopfield-type network that consists of a pair of one-way loops each with three neurons and two-way coupling (of either excitatory or inhibitory type) between a single neuron of each loop. Time delays are introduced in the connections between loops, and the effects of coupling strengths and delays on the network dynamics are investigated. These effects depend strongly on whether the coupling is symmetric (of the same type in both directions) or asymmetric (inhibitory in one direction and excitatory in the other). The network of six delay differential equations is studied by linear stability analysis and bifurcation theory. Loops having inherently stable zero solutions cannot be destabilized by weak coupling, regardless of the delay. Asymmetric coupling is weakly stabilizing but easily upset by delays. Symmetric coupling (if not too weak) can destabilize an inherently stable zero solution, leading to nontrivial fixed points if the gain of the neuron response function is not too negative or to oscillation otherwise. In the oscillation case, intermediate delays can restabilize the zero solution. At the borderline of the weak coupling region (symmetric or asymmetric), stability can change with delay ranges. When the coupling strengths are of the same magnitude, the oscillations of corresponding neurons in the two loops can be in phase, antiphase (symmetric coupling), or one quarter period out of phase (asymmetric coupling) depending on the delay.},
  number = {1},
  journaltitle = {SIAM Journal on Applied Mathematics},
  urldate = {2019-03-30},
  date = {2004-01},
  pages = {316-335},
  author = {Campbell, Sue Ann and Edwards, R. and van den Driessche, P.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2015 - Campbell, Edwards, van den Driessche - Delayed Coupling between Two Neural Network Loops.pdf;/Users/qualia/Documents/Papers/Campbell et al. - 2004 - Delayed Coupling Between Two Neural Network Loops.pdf}
}

@article{Cannon2015,
  langid = {english},
  title = {Neural {{Sequence Generation Using Spatiotemporal Patterns}} of {{Inhibition}}},
  volume = {11},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004581},
  doi = {10.1371/journal.pcbi.1004581},
  number = {11},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-11-04},
  pages = {e1004581},
  author = {Cannon, Jonathan and Kopell, Nancy and Gardner, Timothy and Markowitz, Jeffrey},
  editor = {Sporns, Olaf},
  file = {/Users/qualia/Documents/Papers/2015 - Cannon et al. - Neural Sequence Generation Using Spatiotemporal Patterns of Inhibition.pdf;/Users/qualia/Documents/Papers/Cannon et al. - 2015 - Neural Sequence Generation Using Spatiotemporal Pa.pdf}
}

@article{Cates2015,
  langid = {english},
  title = {Celebrating {{{\emph{Soft Matter}}}} 's 10th Anniversary: {{Testing}} the Foundations of Classical Entropy: Colloid Experiments},
  volume = {11},
  issn = {1744-683X, 1744-6848},
  url = {http://xlink.rsc.org/?DOI=C5SM01014D},
  doi = {10.1039/C5SM01014D},
  shorttitle = {Celebrating {{{\emph{Soft Matter}}}} 's 10th Anniversary},
  number = {33},
  journaltitle = {Soft Matter},
  urldate = {2019-03-30},
  date = {2015},
  pages = {6538-6546},
  author = {Cates, Michael E. and Manoharan, Vinothan N.},
  file = {/Users/qualia/Documents/Papers/2015 - Cates, Manoharan - Celebrating Soft Matter's 10th anniversary Testing the foundations of classical entropy colloid experiments(2).pdf;/Users/qualia/Documents/Papers/Cates and Manoharan - 2015 - Celebrating iSoft Matteri 's 10th anniversary 2.pdf;/Users/qualia/Documents/Papers/Cates and Manoharan - 2015 - Celebrating iSoft Matteri 's 10th anniversary.pdf}
}

@article{Chaudhuri2015,
  langid = {english},
  title = {A {{Large}}-{{Scale Circuit Mechanism}} for {{Hierarchical Dynamical Processing}} in the {{Primate Cortex}}},
  volume = {88},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315007655},
  doi = {10.1016/j.neuron.2015.09.008},
  abstract = {We developed a large-scale dynamical model of the macaque neocortex, which is based on recently acquired directed- and weighted-connectivity data from tract-tracing experiments, and which incorporates heterogeneity across areas. A hierarchy of timescales naturally emerges from this system: sensory areas show brief, transient responses to input (appropriate for sensory processing), whereas association areas integrate inputs over time and exhibit persistent activity (suitable for decision-making and working memory). The model displays multiple temporal hierarchies, as evidenced by contrasting responses to visual versus somatosensory stimulation. Moreover, slower prefrontal and temporal areas have a disproportionate impact on global brain dynamics. These findings establish a circuit mechanism for ``temporal receptive windows'' that are progressively enlarged along the cortical hierarchy, suggest an extension of time integration in decision making from local to large circuits, and should prompt a reevaluation of the analysis of functional connectivity (measured by fMRI or electroencephalography/magnetoencephalography) by taking into account interareal heterogeneity.},
  number = {2},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-10},
  pages = {419-431},
  author = {Chaudhuri, Rishidev and Knoblauch, Kenneth and Gariel, Marie-Alice and Kennedy, Henry and Wang, Xiao-Jing},
  file = {/Users/qualia/Documents/Papers/2015 - Chaudhuri et al. - A Large-Scale Circuit Mechanism for Hierarchical Dynamical Processing in the Primate Cortex.pdf;/Users/qualia/Documents/Papers/Chaudhuri et al. - 2015 - A Large-Scale Circuit Mechanism for Hierarchical D 2.pdf;/Users/qualia/Documents/Papers/Chaudhuri et al. - 2015 - A Large-Scale Circuit Mechanism for Hierarchical D.pdf}
}

@article{Cohen2015,
  langid = {english},
  title = {Serotonergic Neurons Signal Reward and Punishment on Multiple Timescales},
  volume = {4},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/06346},
  doi = {10.7554/eLife.06346},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2015-02-25},
  author = {Cohen, Jeremiah Y and Amoroso, Mackenzie W and Uchida, Naoshige},
  file = {/Users/qualia/Documents/Papers/2015 - Cohen, Amoroso, Uchida - Serotonergic neurons signal reward and punishment on multiple timescales.pdf;/Users/qualia/Documents/Papers/Cohen et al. - 2015 - Serotonergic neurons signal reward and punishment .pdf}
}

@inproceedings{Connolly2015,
  langid = {english},
  location = {{Montpellier, France}},
  title = {Guiding Deep Brain Stimulation Contact Selection Using Local Field Potentials Sensed by a Chronically Implanted Device in {{Parkinson}}'s Disease Patients},
  isbn = {978-1-4673-6389-1},
  url = {http://ieeexplore.ieee.org/document/7146754/},
  doi = {10.1109/NER.2015.7146754},
  abstract = {We have found that a set of support vector machines operating upon local field potentials sensed from an implanted DBS lead can identify the contact chosen by the physician for the patient's STN DBS therapy with 91\% accuracy. The finding is based on a small data set and thus subject to change with further data collection and crossvalidation. Nevertheless, the results suggest that an algorithm for selecting an effective contact for STN DBS based on the signals sensed from the DBS lead may be feasible.},
  eventtitle = {2015 7th {{International IEEE}}/{{EMBS Conference}} on {{Neural Engineering}} ({{NER}})},
  booktitle = {2015 7th {{International IEEE}}/{{EMBS Conference}} on {{Neural Engineering}} ({{NER}})},
  publisher = {{IEEE}},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {840-843},
  author = {Connolly, Allison T. and Kaemmerer, William F. and Dani, Siddharth and Stanslaski, Scott R. and Panken, Eric and Johnson, Matthew D. and Denison, Timothy},
  file = {/Users/qualia/Documents/Papers/2015 - Connolly et al. - Guiding Deep Brain Stimulation Contact Selection Using Local Field Potentials Sensed by a Chronically Implant.pdf;/Users/qualia/Documents/Papers/Connolly et al. - 2015 - Guiding deep brain stimulation contact selection u.pdf}
}

@article{Cossell2015,
  langid = {english},
  title = {Functional Organization of Excitatory Synaptic Strength in Primary Visual Cortex},
  volume = {518},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature14182},
  doi = {10.1038/nature14182},
  number = {7539},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2015-02},
  pages = {399-403},
  author = {Cossell, Lee and Iacaruso, Maria Florencia and Muir, Dylan R. and Houlton, Rachael and Sader, Elie N. and Ko, Ho and Hofer, Sonja B. and Mrsic-Flogel, Thomas D.},
  file = {/Users/qualia/Documents/Papers/2015 - Cossell et al. - Functional organization of excitatory synaptic strength in primary visual cortex.pdf;/Users/qualia/Documents/Papers/Cossell et al. - 2015 - Functional organization of excitatory synaptic str.pdf}
}

@article{Courbariaux2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.00363},
  primaryClass = {cs},
  langid = {english},
  title = {{{BinaryConnect}}: {{Training Deep Neural Networks}} with Binary Weights during Propagations},
  url = {http://arxiv.org/abs/1511.00363},
  shorttitle = {{{BinaryConnect}}},
  abstract = {Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great benefits to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and powerhungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN.},
  urldate = {2019-03-30},
  date = {2015-11-01},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Computer Vision and Pattern Recognition},
  author = {Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  file = {/Users/qualia/Documents/Papers/2015 - Courbariaux, Bengio, David - BinaryConnect Training Deep Neural Networks with binary weights during propagations.pdf;/Users/qualia/Documents/Papers/Courbariaux et al. - 2015 - BinaryConnect Training Deep Neural Networks with .pdf}
}

@article{Curto2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.01905},
  primaryClass = {q-bio},
  langid = {english},
  title = {What Can Topology Tell Us about the Neural Code?},
  url = {http://arxiv.org/abs/1605.01905},
  abstract = {Neuroscience is undergoing a period of rapid experimental progress and expansion. New mathematical tools, previously unknown in the neuroscience community, are now being used to tackle fundamental questions and analyze emerging data sets. Consistent with this trend, the last decade has seen an uptick in the use of topological ideas and methods in neuroscience. In this talk I will survey recent applications of topology in neuroscience, and explain why topology is an especially natural tool for understanding neural codes. Note: This is a write-up of my talk for the Current Events Bulletin, held at the 2016 Joint Math Meetings in Seattle, WA.},
  urldate = {2019-03-30},
  date = {2016-05-06},
  keywords = {Quantitative Biology - Neurons and Cognition},
  author = {Curto, Carina},
  file = {/Users/qualia/Documents/Papers/2015 - Curto - What can topology tell us about the neural code.pdf;/Users/qualia/Documents/Papers/Curto - 2016 - What can topology tell us about the neural code.pdf}
}

@article{Curto2015b,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1508.00150},
  primaryClass = {math, q-bio},
  langid = {english},
  title = {What Makes a Neural Code Convex?},
  url = {http://arxiv.org/abs/1508.00150},
  abstract = {Neural codes allow the brain to represent, process, and store information about the world. Combinatorial codes, comprised of binary patterns of neural activity, encode information via the collective behavior of populations of neurons. A code is called convex if its codewords correspond to regions defined by an arrangement of convex open sets in Euclidean space. Convex codes have been observed experimentally in many brain areas, including sensory cortices and the hippocampus, where neurons exhibit convex receptive fields. What makes a neural code convex? That is, how can we tell from the intrinsic structure of a code if there exists a corresponding arrangement of convex open sets? Using tools from combinatorics and commutative algebra, we uncover key signatures of convex and non-convex codes. In many cases, these signatures are sufficient to determine convexity, and reveal bounds on the minimal dimension of the underlying Euclidean space.},
  urldate = {2019-03-30},
  date = {2015-08-01},
  keywords = {Quantitative Biology - Neurons and Cognition,Mathematics - Combinatorics},
  author = {Curto, Carina and Gross, Elizabeth and Jeffries, Jack and Morrison, Katherine and Omar, Mohamed and Rosen, Zvi and Shiu, Anne and Youngs, Nora},
  file = {/Users/qualia/Documents/Papers/2015 - Curto et al. - What makes a neural code convex Introduction Convex neural codes.pdf;/Users/qualia/Documents/Papers/Curto et al. - 2015 - What makes a neural code convex.pdf}
}

@article{Curto2015a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.00897},
  primaryClass = {q-bio},
  langid = {english},
  title = {Pattern Completion in Symmetric Threshold-Linear Networks},
  url = {http://arxiv.org/abs/1512.00897},
  abstract = {Threshold-linear networks are a common class of firing rate models that describe recurrent interactions among neurons. Unlike their linear counterparts, these networks generically possess multiple stable fixed points (steady states), making them viable candidates for memory encoding and retrieval. In this work, we characterize stable fixed points of general threshold-linear networks with constant external drive, and discover constraints on the co-existence of fixed points involving different subsets of active neurons. In the case of symmetric networks, we prove the following antichain property: if a set of neurons {$\tau$} is the support of a stable fixed point, then no proper subset or superset of {$\tau$} can support a stable fixed point. Symmetric threshold-linear networks thus appear to be well suited for pattern completion, since the dynamics are guaranteed not to get ``stuck'' in a subset or superset of a stored pattern. We also show that for any graph G, we can construct a network whose stable fixed points correspond precisely to the maximal cliques of G. As an application, we design network decoders for place field codes, and demonstrate their efficacy for error correction and pattern completion. The proofs of our main results build on the theory of permitted sets in threshold-linear networks, including recently-developed connections to classical distance geometry.},
  urldate = {2019-03-30},
  date = {2015-12-02},
  keywords = {Quantitative Biology - Neurons and Cognition},
  author = {Curto, Carina and Morrison, Katherine},
  file = {/Users/qualia/Documents/Papers/2015 - Curto, Morrison - Pattern completion in symmetric threshold-linear networks.pdf;/Users/qualia/Documents/Papers/Curto and Morrison - 2015 - Pattern completion in symmetric threshold-linear n.pdf}
}

@article{Curto2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.00255},
  primaryClass = {q-bio},
  langid = {english},
  title = {Neural Ring Homomorphisms and Maps between Neural Codes},
  url = {http://arxiv.org/abs/1511.00255},
  abstract = {Understanding how the brain stores and processes information is central to mathematical neuroscience. Neural data is often represented as a neural code: a set of binary firing patterns C {$\subset$} \{0, 1\}n. We have previously introduced the neural ring, an algebraic object which encodes combinatorial information, in order to analyze the structure of neural codes. We now relate maps between neural codes to notions of homomorphism between the corresponding neural rings. Using three natural operations on neural codes (permutation, inclusion, deletion) as motivation, we search for a restricted class of homomorphisms which correspond to these natural operations. We choose the framework of linear-monomial module homomorphisms, and find that the class of associated code maps neatly captures these three operations, and necessarily includes two others - repetition and adding trivial neurons - which are also meaningful in a neural coding context.},
  urldate = {2019-03-30},
  date = {2015-11-01},
  keywords = {Quantitative Biology - Neurons and Cognition},
  author = {Curto, Carina and Youngs, Nora},
  file = {/Users/qualia/Documents/Papers/2015 - Curto, Youngs - Neural ring homomorphisms and maps between neural codes.pdf;/Users/qualia/Documents/Papers/Curto and Youngs - 2015 - Neural ring homomorphisms and maps between neural .pdf}
}

@article{Danziger2015,
  langid = {english},
  title = {A Neuron Model of Stochastic Resonance Using Rectangular Pulse Trains},
  volume = {38},
  issn = {0929-5313, 1573-6873},
  url = {http://link.springer.com/10.1007/s10827-014-0526-4},
  doi = {10.1007/s10827-014-0526-4},
  abstract = {Stochastic resonance (SR) is the enhanced representation of a weak input signal by the addition of an optimal level of broadband noise to a nonlinear (threshold) system. Since its discovery in the 1980s the domain of input signals shown to be applicable to SR has greatly expanded, from strictly periodic inputs to now nearly any aperiodic forcing function. The perturbations (noise) used to generate SR have also expanded, from white noise to now colored noise or vibrational forcing. This study demonstrates that a new class of perturbations can achieve SR, namely, series of stochastically generated biphasic pulse trains. Using these pulse trains as `noise' we show that a Hodgkin Huxley model neuron exhibits SR behavior when detecting weak input signals. This result is of particular interest to neuroscience because nearly all artificial neural stimulation is implemented with square current or voltage pulses rather than broadband noise, and this new method may facilitate the translation of the performance gains achievable through SR to neural prosthetics.},
  number = {1},
  journaltitle = {Journal of Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2015-02},
  pages = {53-66},
  author = {Danziger, Zachary and Grill, Warren M.},
  file = {/Users/qualia/Documents/Papers/2015 - Danzinger, Grill - A Neuron Model of Stochastic Resonance Using Rectangular Pulse Trains.pdf;/Users/qualia/Documents/Papers/Danziger and Grill - 2015 - A neuron model of stochastic resonance using recta.pdf}
}

@article{Deacon2008,
  langid = {english},
  title = {Shannon - {{Boltzmann}} - {{Darwin}}: {{Redefining}} Information ({{Part II}})},
  volume = {2008},
  issn = {1662-1425},
  url = {http://peterlang.metapress.com/openurl.asp?genre=article&id=doi:10.3726/81605_169},
  doi = {10.3726/81605_169},
  shorttitle = {Shannon - {{Boltzmann}} - {{Darwin}}},
  abstract = {A scientifically adequate theory of semiotic processes must ultimately be founded on a theory of information that can unify the physical, biological, cognitive, and computational uses of the concept. Unfortunately, no such unification exists, and more importantly, the causal status of informational content remains ambiguous as a result. Lacking this grounding, semiotic theories have tended to be predominantly phenomenological taxonomies rather than dynamical explanations of the representational processes of natural systems. This paper argues that the problem of information that prevents the development of a scientific semiotic theory is the necessity of analyzing it as a negative relationship: defined with respect to absence. This is cryptically implicit in concepts of design and function in biology, acknowledged in psychological and philosophical accounts of intentionality and content, and is explicitly formulated in the mathematical theory of communication (aka ``information theory''). Beginning from the base established by Claude Shannon, which otherwise ignores issues of content, reference, and evaluation, this two part essay explores its relationship to two other higher-order theories that are also explicitly based on an analysis of absence: Boltzmann's theory of thermodynamic entropy (in Part 1) and Darwin's theory of natural selection (in Part 2). This comparison demonstrates that these theories are both formally homologous and hierarchically interdependent. Their synthesis into a general theory of entropy and information provides the necessary grounding for theories of function and semiosis.},
  number = {2},
  journaltitle = {Cognitive Semiotics},
  urldate = {2019-03-30},
  date = {2008-01-01},
  pages = {169-196},
  author = {Deacon, Terrence W.},
  file = {/Users/qualia/Documents/Papers/2015 - Deacon - Shannon - Boltzmann — Darwin Redefining information ( Part II ).pdf;/Users/qualia/Documents/Papers/Deacon - 2008 - Shannon - Boltzmann - Darwin Redefining informati.pdf}
}

@inproceedings{Diehl2015,
  langid = {english},
  location = {{Killarney, Ireland}},
  title = {Fast-Classifying, High-Accuracy Spiking Deep Networks through Weight and Threshold Balancing},
  isbn = {978-1-4799-1960-4},
  url = {http://ieeexplore.ieee.org/document/7280696/},
  doi = {10.1109/IJCNN.2015.7280696},
  abstract = {Deep neural networks such as Convolutional Networks (ConvNets) and Deep Belief Networks (DBNs) represent the state-of-the-art for many machine learning and computer vision classification problems. To overcome the large computational cost of deep networks, spiking deep networks have recently been proposed, given the specialized hardware now available for spiking neural networks (SNNs). However, this has come at the cost of performance losses due to the conversion from analog neural networks (ANNs) without a notion of time, to sparsely firing, event-driven SNNs. Here we analyze the effects of converting deep ANNs into SNNs with respect to the choice of parameters for spiking neurons such as firing rates and thresholds. We present a set of optimization techniques to minimize performance loss in the conversion process for ConvNets and fully connected deep networks. These techniques yield networks that outperform all previous SNNs on the MNIST database to date, and many networks here are close to maximum performance after only 20 ms of simulated time. The techniques include using rectified linear units (ReLUs) with zero bias during training, and using a new weight normalization method to help regulate firing rates. Our method for converting an ANN into an SNN enables lowlatency classification with high accuracies already after the first output spike, and compared with previous SNN approaches it yields improved performance without increased training time. The presented analysis and optimization techniques boost the value of spiking deep networks as an attractive framework for neuromorphic computing platforms aimed at fast and efficient pattern recognition.},
  eventtitle = {2015 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  booktitle = {2015 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  publisher = {{IEEE}},
  urldate = {2019-03-30},
  date = {2015-07},
  pages = {1-8},
  author = {Diehl, Peter U. and Neil, Daniel and Binas, Jonathan and Cook, Matthew and Liu, Shih-Chii and Pfeiffer, Michael},
  file = {/Users/qualia/Documents/Papers/2015 - Diehl et al. - Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing.pdf;/Users/qualia/Documents/Papers/Diehl et al. - 2015 - Fast-classifying, high-accuracy spiking deep netwo.pdf}
}

@article{Ding2016,
  langid = {english},
  title = {Cortical Tracking of Hierarchical Linguistic Structures in Connected Speech},
  volume = {19},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4186},
  doi = {10.1038/nn.4186},
  number = {1},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2016-01},
  pages = {158-164},
  author = {Ding, Nai and Melloni, Lucia and Zhang, Hang and Tian, Xing and Poeppel, David},
  file = {/Users/qualia/Documents/Papers/2015 - Ding et al. - Cortical tracking of hierarchical linguistic structures in connected speech.pdf;/Users/qualia/Documents/Papers/Ding et al. - 2016 - Cortical tracking of hierarchical linguistic struc.pdf}
}

@article{Doll2015,
  langid = {english},
  title = {Model-Based Choices Involve Prospective Neural Activity},
  volume = {18},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3981},
  doi = {10.1038/nn.3981},
  number = {5},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2015-05},
  pages = {767-772},
  author = {Doll, Bradley B and Duncan, Katherine D and Simon, Dylan A and Shohamy, Daphna and Daw, Nathaniel D},
  file = {/Users/qualia/Documents/Papers/2015 - Doll et al. - Model-based choices involve prospective neural activity.pdf;/Users/qualia/Documents/Papers/Doll et al. - 2015 - Model-based choices involve prospective neural act.pdf}
}

@article{Jozefowicz,
  langid = {english},
  title = {An {{Empirical Exploration}} of {{Recurrent Network Architectures}}},
  abstract = {The Recurrent Neural Network (RNN) is an extremely powerful sequence model that is often difficult to train. The Long Short-Term Memory (LSTM) is a specific RNN architecture whose design makes it much easier to train. While wildly successful in practice, the LSTM's architecture appears to be ad-hoc so it is not clear if it is optimal, and the significance of its individual components is unclear.},
  pages = {9},
  author = {Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
  file = {/Users/qualia/Documents/Papers/2015 - Dosovitskiy, Springenberg, Brox - Learning to generate chairs with convolutional neural networks.pdf;/Users/qualia/Documents/Papers/Jozefowicz et al. - An Empirical Exploration of Recurrent Network Arch.pdf}
}

@article{Drion2015,
  langid = {english},
  title = {Ion Channel Degeneracy Enables Robust and Tunable Neuronal Firing Rates},
  volume = {112},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1516400112},
  doi = {10.1073/pnas.1516400112},
  number = {38},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2015-09-22},
  pages = {E5361-E5370},
  author = {Drion, Guillaume and O'Leary, Timothy and Marder, Eve},
  file = {/Users/qualia/Documents/Papers/2015 - Drion, O’Leary, Marder - Ion channel degeneracy enables robust and tunable neuronal firing rates.pdf;/Users/qualia/Documents/Papers/Drion et al. - 2015 - Ion channel degeneracy enables robust and tunable .pdf}
}

@article{Dunsmoor2015,
  langid = {english},
  title = {Categories, Concepts, and Conditioning: How Humans Generalize Fear},
  volume = {19},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661314002551},
  doi = {10.1016/j.tics.2014.12.003},
  shorttitle = {Categories, Concepts, and Conditioning},
  number = {2},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2015-02},
  pages = {73-77},
  author = {Dunsmoor, Joseph E. and Murphy, Gregory L.},
  file = {/Users/qualia/Documents/Papers/2015 - Dunsmoor, Murphy - Categories, concepts, and conditioning How humans generalize fear.pdf;/Users/qualia/Documents/Papers/Dunsmoor and Murphy - 2015 - Categories, concepts, and conditioning how humans.pdf}
}

@article{Duval2016,
  langid = {english},
  title = {A Brain Network Model Explaining Tremor in {{Parkinson}}'s Disease},
  volume = {85},
  issn = {09699961},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0969996115300656},
  doi = {10.1016/j.nbd.2015.10.009},
  abstract = {This paper presents a novel model of tremor in Parkinson's disease (PD) based on extensive literature review as well as novel results stemming from functional stereotactic neurosurgery for the alleviation of tremor in PD. Specifically, evidence that suggests the basal ganglia induces PD tremor via excessive inhibitory output to the thalamus and altered firing patterns which in turn generate rhythmic bursting activity of thalamic cells is presented. Then, evidence that the thalamus generates PD tremor by facilitating the generation and consolidation of rhythmic bursting activity of neurons within its nuclei is also offered. Finally, evidence that the cerebellum may modulate characteristics of PD tremor by treating it as if it was a voluntary motor behavior is presented. Accordingly, the current paper proposes that PD tremor is induced by abnormal basal ganglia activity; it is generated by the thalamus, and modulated or reinforced by the cerebellum.},
  journaltitle = {Neurobiology of Disease},
  urldate = {2019-03-30},
  date = {2016-01},
  pages = {49-59},
  author = {Duval, Christian and Daneault, Jean-Francois and Hutchison, William D. and Sadikot, Abbas F.},
  file = {/Users/qualia/Documents/Papers/2015 - Duval et al. - A brain network model explaining tremor in Parkinson's disease.pdf;/Users/qualia/Documents/Papers/Duval et al. - 2016 - A brain network model explaining tremor in Parkins.pdf}
}

@article{Ester2015,
  langid = {english},
  title = {Parietal and {{Frontal Cortex Encode Stimulus}}-{{Specific Mnemonic Representations}} during {{Visual Working Memory}}},
  volume = {87},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315006352},
  doi = {10.1016/j.neuron.2015.07.013},
  abstract = {Working memory (WM) enables the storage and manipulation of information in an active state. WM storage has long been associated with sustained increases in activation across a network of frontal and parietal cortical regions. However, recent evidence suggests that these regions primarily encode information related to general task goals rather than featureselective representations of specific memoranda. These goal-related representations are thought to provide top-down feedback that coordinates the representation of fine-grained details in early sensory areas. Here, we test this model using fMRI-based reconstructions of remembered visual details from region-level activation patterns. We could reconstruct high-fidelity representations of a remembered orientation based on activation patterns in occipital visual cortex and in several sub-regions of frontal and parietal cortex, independent of sustained increases in mean activation. These results challenge models of WM that postulate disjoint frontoparietal ``top-down control'' and posterior sensory ``feature storage'' networks.},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-08},
  pages = {893-905},
  author = {Ester, Edward F. and Sprague, Thomas C. and Serences, John T.},
  file = {/Users/qualia/Documents/Papers/2015 - Ester, Sprague, Serences - Parietal and Frontal Cortex Encode Stimulus- Specific Mnemonic Representations during Visual Working M.pdf;/Users/qualia/Documents/Papers/Ester et al. - 2015 - Parietal and Frontal Cortex Encode Stimulus-Specif.pdf}
}

@article{Feingold2015,
  langid = {english},
  title = {Bursts of Beta Oscillation Differentiate Postperformance Activity in the Striatum and Motor Cortex of Monkeys Performing Movement Tasks},
  volume = {112},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1517629112},
  doi = {10.1073/pnas.1517629112},
  number = {44},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2015-11-03},
  pages = {13687-13692},
  author = {Feingold, Joseph and Gibson, Daniel J. and DePasquale, Brian and Graybiel, Ann M.},
  file = {/Users/qualia/Documents/Papers/2015 - Feingold et al. - Bursts of beta oscillation differentiate postperformance activity in the striatum and motor cortex of monkey(2).pdf;/Users/qualia/Documents/Papers/Feingold et al. - 2015 - Bursts of beta oscillation differentiate postperfo 2.pdf;/Users/qualia/Documents/Papers/Feingold et al. - 2015 - Bursts of beta oscillation differentiate postperfo.pdf}
}

@article{Fields2015,
  langid = {english},
  title = {A New Mechanism of Nervous System Plasticity: Activity-Dependent Myelination},
  volume = {16},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn4023},
  doi = {10.1038/nrn4023},
  shorttitle = {A New Mechanism of Nervous System Plasticity},
  abstract = {The synapse is the focus of experimental research and theory on the cellular mechanisms of nervous system plasticity and learning, but recent research is expanding the consideration of plasticity into new mechanisms beyond the synapse, notably including the possibility that conduction velocity could be modifiable through changes in myelin to optimize the timing of information transmission through neural circuits. This concept emerges from a confluence of brain imaging that reveals changes in white matter in the human brain during learning, together with cellular studies showing that the process of myelination can be influenced by action potential firing in axons. This Opinion article summarizes the new research on activity-dependent myelination, explores the possible implications of these studies and outlines the potential for new research.},
  number = {12},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2015-12},
  pages = {756-767},
  author = {Fields, R. Douglas},
  file = {/Users/qualia/Documents/Papers/2015 - Fields - A new mechanism of nervous system plasticity activity-dependent myelination.pdf;/Users/qualia/Documents/Papers/Fields - 2015 - A new mechanism of nervous system plasticity acti.pdf}
}

@article{Foster2016,
  langid = {english},
  title = {The Topography of Alpha-Band Activity Tracks the Content of Spatial Working Memory},
  volume = {115},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00860.2015},
  doi = {10.1152/jn.00860.2015},
  number = {1},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2016-01},
  pages = {168-177},
  author = {Foster, Joshua J. and Sutterer, David W. and Serences, John T. and Vogel, Edward K. and Awh, Edward},
  file = {/Users/qualia/Documents/Papers/2015 - Foster et al. - The topography of alpha-band activity tracks the content of spatial working memory.pdf;/Users/qualia/Documents/Papers/Foster et al. - 2016 - The topography of alpha-band activity tracks the c 2.pdf;/Users/qualia/Documents/Papers/Foster et al. - 2016 - The topography of alpha-band activity tracks the c.pdf}
}

@article{Francois-Lavet2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.02011},
  primaryClass = {cs},
  langid = {english},
  title = {How to {{Discount Deep Reinforcement Learning}}: {{Towards New Dynamic Strategies}}},
  url = {http://arxiv.org/abs/1512.02011},
  shorttitle = {How to {{Discount Deep Reinforcement Learning}}},
  abstract = {Using deep neural nets as function approximator for reinforcement learning tasks have recently been shown to be very powerful for solving problems approaching real-world complexity such as [1]. Using these results as a benchmark, we discuss the role that the discount factor may play in the quality of the learning process of a deep Q-network (DQN). When the discount factor progressively increases up to its final value, we empirically show that it is possible to significantly reduce the number of learning steps. When used in conjunction with a varying learning rate, we empirically show that it outperforms original DQN on several experiments. We relate this phenomenon with the instabilities of neural networks when they are used in an approximate Dynamic Programming setting. We also describe the possibility to fall within a local optimum during the learning process, thus connecting our discussion with the exploration/exploitation dilemma.},
  urldate = {2019-03-30},
  date = {2015-12-07},
  keywords = {Computer Science - Machine Learning,Computer Science - Artificial Intelligence},
  author = {Fran{\c c}ois-Lavet, Vincent and Fonteneau, Raphael and Ernst, Damien},
  file = {/Users/qualia/Documents/Papers/2015 - François-Lavet, Fonteneau, Ernst - How to Discount Deep Reinforcement Learning Towards New Dynamic Strategies.pdf;/Users/qualia/Documents/Papers/François-Lavet et al. - 2015 - How to Discount Deep Reinforcement Learning Towar.pdf}
}

@article{Fransen2015,
  langid = {english},
  title = {Identifying Neuronal Oscillations Using Rhythmicity},
  volume = {118},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811915004796},
  doi = {10.1016/j.neuroimage.2015.06.003},
  abstract = {Neuronal oscillations are a characteristic feature of neuronal activity and are typically investigated through measures of power and coherence. However, neither of these measures directly reflects the distinctive feature of oscillations: their rhythmicity. Rhythmicity is the extent to which future phases can be predicted from the present one. Here, we present lagged coherence, a frequency-indexed measure that quantifies the rhythmicity of neuronal activity. We use this method to identify the sensorimotor alpha and beta rhythms in ongoing magnetoencephalographic (MEG) data, and to study their attentional modulation. Using lagged coherence, the sensorimotor rhythms become visible in ongoing activity as local rhythmicity peaks that are separated from the strong posterior activity in the same frequency bands. In contrast, using conventional power analyses, the sensorimotor rhythms cannot be identified in ongoing data, nor can they be separated from the posterior activity. We go on to show that the attentional modulation of these rhythms is also evident in lagged coherence and moreover, that in contrast to power, it can be visualised even without an experimental contrast. These findings suggest that the rhythmicity of neuronal activity is better suited to identify neuronal oscillations than the power in the same frequency band.},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2015-09},
  pages = {256-267},
  author = {Fransen, Anne M.M. and van Ede, Freek and Maris, Eric},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2015 - Fransen, van Ede, Maris - Identifying neuronal oscillations using rhythmicity.pdf;/Users/qualia/Documents/Papers/Fransen et al. - 2015 - Identifying neuronal oscillations using rhythmicit.pdf}
}

@article{Freeman2015,
  langid = {english},
  title = {Mapping Nonlinear Receptive Field Structure in Primate Retina at Single Cone Resolution},
  volume = {4},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/05241},
  doi = {10.7554/eLife.05241},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2015-10-30},
  author = {Freeman, Jeremy and Field, Greg D and Li, Peter H and Greschner, Martin and Gunning, Deborah E and Mathieson, Keith and Sher, Alexander and Litke, Alan M and Paninski, Liam and Simoncelli, Eero P and Chichilnisky, Ej},
  file = {/Users/qualia/Documents/Papers/2015 - Freeman et al. - Mapping nonlinear receptive field structure in primate retina at single cone resolution.pdf;/Users/qualia/Documents/Papers/Freeman et al. - 2015 - Mapping nonlinear receptive field structure in pri.pdf}
}

@article{Fries2015,
  langid = {english},
  title = {Rhythms for {{Cognition}}: {{Communication}} through {{Coherence}}},
  volume = {88},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315008235},
  doi = {10.1016/j.neuron.2015.09.034},
  shorttitle = {Rhythms for {{Cognition}}},
  number = {1},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-10},
  pages = {220-235},
  author = {Fries, Pascal},
  file = {/Users/qualia/Documents/Papers/2015 - Fries - Rhythms for Cognition Communication through Coherence.pdf;/Users/qualia/Documents/Papers/Fries - 2015 - Rhythms for Cognition Communication through Coher.pdf}
}

@article{Germain2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1502.03509},
  primaryClass = {cs, stat},
  langid = {english},
  title = {{{MADE}}: {{Masked Autoencoder}} for {{Distribution Estimation}}},
  url = {http://arxiv.org/abs/1502.03509},
  shorttitle = {{{MADE}}},
  abstract = {There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modification for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoder's parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with stateof-the-art tractable distribution estimators. At test time, the method is significantly faster and scales better than other autoregressive estimators.},
  urldate = {2019-03-30},
  date = {2015-02-11},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  author = {Germain, Mathieu and Gregor, Karol and Murray, Iain and Larochelle, Hugo},
  file = {/Users/qualia/Documents/Papers/2015 - Germain et al. - MADE Masked Autoencoder for Distribution Estimation.pdf;/Users/qualia/Documents/Papers/Germain et al. - 2015 - MADE Masked Autoencoder for Distribution Estimati.pdf}
}

@article{Gliske2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.01622},
  primaryClass = {q-bio},
  langid = {english},
  title = {Narrowband Oscillations from Asynchronous Neural Activity},
  url = {http://arxiv.org/abs/1512.01622},
  abstract = {We investigate the possibility that narrowband oscillations may emerge from completely asynchronous, independent neural firing. We find that a population of asynchronous neurons may produce narrowband oscillations if each neuron fires quasi-periodically, and we deduce bounds on the degree of variability in neural spike-timing which will permit the emergence of such oscillations. These results suggest a novel mechanism of neural rhythmogenesis, and they help to explain recent experimental reports of large-amplitude local field potential oscillations in the absence of neural spike-timing synchrony. Simply put, although synchrony can produce oscillations, oscillations do not always imply the existence of synchrony.},
  urldate = {2019-03-30},
  date = {2015-12-04},
  keywords = {Quantitative Biology - Neurons and Cognition},
  author = {Gliske, Stephen V. and Lim, Eugene and Holman, Katherine A. and Stacey, William C. and Fink, Christian G.},
  file = {/Users/qualia/Documents/Papers/2015 - Gliske et al. - Narrowband oscillations from asynchronous neural activity.pdf;/Users/qualia/Documents/Papers/Gliske et al. - 2015 - Narrowband oscillations from asynchronous neural a.pdf}
}

@incollection{Grill2015,
  langid = {english},
  title = {Model-Based Analysis and Design of Waveforms for Efficient Neural Stimulation},
  volume = {222},
  isbn = {978-0-444-63546-4},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0079612315001375},
  abstract = {The design space for electrical stimulation of the nervous system is extremely large, and because the response to stimulation is highly non-linear, the selection of stimulation parameters to achieve a desired response is a challenging problem. Computational models of the response of neurons to extracellular stimulation allow analysis of the effects of stimulation parameters on neural excitation and provide an approach to select or design optimal parameters of stimulation. Here, I review the use of computational models to understand the effects of stimulation waveform on the energy efficiency of neural excitation and to design novel stimulation waveforms to increase the efficiency of neural stimulation.},
  booktitle = {Progress in {{Brain Research}}},
  publisher = {{Elsevier}},
  urldate = {2019-03-30},
  date = {2015},
  pages = {147-162},
  author = {Grill, Warren M.},
  file = {/Users/qualia/Documents/Papers/2015 - Grill - Model-Based Analysis and Design of Waveforms for Efficient Neural Stimulation.pdf;/Users/qualia/Documents/Papers/Grill - 2015 - Model-based analysis and design of waveforms for e.pdf},
  doi = {10.1016/bs.pbr.2015.07.031}
}

@article{Gurney2015,
  langid = {english},
  title = {A {{New Framework}} for {{Cortico}}-{{Striatal Plasticity}}: {{Behavioural Theory Meets In Vitro Data}} at the {{Reinforcement}}-{{Action Interface}}},
  volume = {13},
  issn = {1545-7885},
  url = {https://dx.plos.org/10.1371/journal.pbio.1002034},
  doi = {10.1371/journal.pbio.1002034},
  shorttitle = {A {{New Framework}} for {{Cortico}}-{{Striatal Plasticity}}},
  abstract = {Operant learning requires that reinforcement signals interact with action representations at a suitable neural interface. Much evidence suggests that this occurs when phasic dopamine, acting as a reinforcement prediction error, gates plasticity at cortico-striatal synapses, and thereby changes the future likelihood of selecting the action(s) coded by striatal neurons. But this hypothesis faces serious challenges. First, cortico-striatal plasticity is inexplicably complex, depending on spike timing, dopamine level, and dopamine receptor type. Second, there is a credit assignment problem\textemdash{}action selection signals occur long before the consequent dopamine reinforcement signal. Third, the two types of striatal output neuron have apparently opposite effects on action selection. Whether these factors rule out the interface hypothesis and how they interact to produce reinforcement learning is unknown. We present a computational framework that addresses these challenges. We first predict the expected activity changes over an operant task for both types of action-coding striatal neuron, and show they co-operate to promote action selection in learning and compete to promote action suppression in extinction. Separately, we derive a complete model of dopamine and spike-timing dependent cortico-striatal plasticity from in vitro data. We then show this model produces the predicted activity changes necessary for learning and extinction in an operant task, a remarkable convergence of a bottom-up data-driven plasticity model with the top-down behavioural requirements of learning theory. Moreover, we show the complex dependencies of cortico-striatal plasticity are not only sufficient but necessary for learning and extinction. Validating the model, we show it can account for behavioural data describing extinction, renewal, and reacquisition, and replicate in vitro experimental data on cortico-striatal plasticity. By bridging the levels between the single synapse and behaviour, our model shows how striatum acts as the action-reinforcement interface.},
  number = {1},
  journaltitle = {PLoS Biology},
  urldate = {2019-03-30},
  date = {2015-01-06},
  pages = {e1002034},
  author = {Gurney, Kevin N. and Humphries, Mark D. and Redgrave, Peter},
  editor = {Dayan, Peter},
  file = {/Users/qualia/Documents/Papers/2015 - Gurney, Humphries, Redgrave - A New Framework for Cortico-Striatal Plasticity Behavioural Theory Meets In Vitro Data at the Reinf.pdf;/Users/qualia/Documents/Papers/Gurney et al. - 2015 - A New Framework for Cortico-Striatal Plasticity B.pdf}
}

@article{Haarnoja2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1812.05905},
  primaryClass = {cs, stat},
  langid = {english},
  title = {Soft {{Actor}}-{{Critic Algorithms}} and {{Applications}}},
  url = {http://arxiv.org/abs/1812.05905},
  abstract = {Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.},
  urldate = {2019-03-30},
  date = {2018-12-12},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence,Computer Science - Robotics},
  author = {Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  file = {/Users/qualia/Documents/Papers/2015 - Haarnoja et al. - Soft Actor-Critic Algorithms and Applications.pdf;/Users/qualia/Documents/Papers/Haarnoja et al. - 2018 - Soft Actor-Critic Algorithms and Applications.pdf}
}

@article{Harnack2015,
  langid = {english},
  title = {Stability of {{Neuronal Networks}} with {{Homeostatic Regulation}}},
  volume = {11},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004357},
  doi = {10.1371/journal.pcbi.1004357},
  number = {7},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-07-08},
  pages = {e1004357},
  author = {Harnack, Daniel and Pelko, Miha and Chaillet, Antoine and Chitour, Yacine and van Rossum, Mark C.W.},
  editor = {Gutkin, Boris S.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2015 - Harnack et al. - Stability of Neuronal Networks with Homeostatic Regulation.pdf;/Users/qualia/Documents/Papers/Harnack et al. - 2015 - Stability of Neuronal Networks with Homeostatic Re.pdf}
}

@article{zotero-2832,
  langid = {english},
  title = {Detailed Dendritic Excitatory/Inhibitory Balance through Heterosynaptic Spike-Timing-Dependent Plasticity},
  pages = {30},
  file = {/Users/qualia/Documents/Papers/2015 - Hiratani, Fukai - Detailed dendritic excitatory inhibitory balance through heterosynaptic spike-timing-dependent plasticity.pdf;/Users/qualia/Documents/Papers/Detailed dendritic excitatoryinhibitory balance t.pdf}
}

@article{Ioffe2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1502.03167},
  primaryClass = {cs},
  langid = {english},
  title = {Batch {{Normalization}}: {{Accelerating Deep Network Training}} by {{Reducing Internal Covariate Shift}}},
  url = {http://arxiv.org/abs/1502.03167},
  shorttitle = {Batch {{Normalization}}},
  abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batchnormalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
  urldate = {2019-03-30},
  date = {2015-02-10},
  keywords = {Computer Science - Machine Learning},
  author = {Ioffe, Sergey and Szegedy, Christian},
  file = {/Users/qualia/Documents/Papers/2015 - Ioffe, Szedegy - Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift.pdf;/Users/qualia/Documents/Papers/Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf}
}

@article{Jadi2014,
  langid = {english},
  title = {Cortical Oscillations Arise from Contextual Interactions That Regulate Sparse Coding},
  volume = {111},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1405300111},
  doi = {10.1073/pnas.1405300111},
  number = {18},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2014-05-06},
  pages = {6780-6785},
  author = {Jadi, M. P. and Sejnowski, T. J.},
  file = {/Users/qualia/Documents/Papers/2015 - Jadi, Sejnowski - Correction for Jadi and Sejnowski, Cortical oscillations arise from contextual interactions that regulate spars.pdf;/Users/qualia/Documents/Papers/Jadi and Sejnowski - 2014 - Cortical oscillations arise from contextual intera 2.pdf;/Users/qualia/Documents/Papers/Jadi and Sejnowski - 2014 - Cortical oscillations arise from contextual intera 3.pdf;/Users/qualia/Documents/Papers/Jadi and Sejnowski - 2014 - Cortical oscillations arise from contextual intera.pdf}
}

@article{Law2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.07825},
  primaryClass = {math, stat},
  langid = {english},
  title = {Data {{Assimilation}}: {{A Mathematical Introduction}}},
  url = {http://arxiv.org/abs/1506.07825},
  shorttitle = {Data {{Assimilation}}},
  abstract = {These notes provide a systematic mathematical treatment of the subject of data assimilation.},
  urldate = {2019-03-30},
  date = {2015-06-25},
  keywords = {Mathematics - Optimization and Control,Mathematics - Dynamical Systems,Statistics - Methodology},
  author = {Law, K. J. H. and Stuart, A. M. and Zygalakis, K. C.},
  file = {/Users/qualia/Documents/Papers/2015 - June - Data Assimilation A Mathematical Introduction.pdf;/Users/qualia/Documents/Papers/Law et al. - 2015 - Data Assimilation A Mathematical Introduction.pdf}
}

@article{Kadmon2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1508.06486},
  langid = {english},
  title = {Transition to Chaos in Random Neuronal Networks},
  volume = {5},
  issn = {2160-3308},
  url = {http://arxiv.org/abs/1508.06486},
  doi = {10.1103/PhysRevX.5.041030},
  abstract = {Firing patterns in the central nervous system often exhibit strong temporal irregularity and heterogeneity in their time averaged response properties. Previous studies suggested that these properties are outcome of an intrinsic chaotic dynamics. Indeed, simplified rate-based large neuronal networks with random synaptic connections are known to exhibit sharp transition from fixed point to chaotic dynamics when the synaptic gain is increased. However, the existence of a similar transition in neuronal circuit models with more realistic architectures and firing dynamics has not been established. In this work we investigate rate based dynamics of neuronal circuits composed of several subpopulations and random connectivity. Nonzero connections are either positive-for excitatory neurons, or negative for inhibitory ones, while single neuron output is strictly positive; in line with known constraints in many biological systems. Using Dynamic Mean Field Theory, we find the phase diagram depicting the regimes of stable fixed point, unstable dynamic and chaotic rate fluctuations. We characterize the properties of systems near the chaotic transition and show that dilute excitatory-inhibitory architectures exhibit the same onset to chaos as a network with Gaussian connectivity. Interestingly, the critical properties near transition depend on the shape of the single- neuron input-output transfer function near firing threshold. Finally, we investigate network models with spiking dynamics. When synaptic time constants are slow relative to the mean inverse firing rates, the network undergoes a sharp transition from fast spiking fluctuations and static firing rates to a state with slow chaotic rate fluctuations. When the synaptic time constants are finite, the transition becomes smooth and obeys scaling properties, similar to crossover phenomena in statistical mechanics},
  number = {4},
  journaltitle = {Physical Review X},
  urldate = {2019-03-30},
  date = {2015-11-19},
  keywords = {Quantitative Biology - Neurons and Cognition,Condensed Matter - Disordered Systems and Neural Networks,Nonlinear Sciences - Chaotic Dynamics},
  author = {Kadmon, Jonathan and Sompolinsky, Haim},
  file = {/Users/qualia/Documents/Papers/2015 - Kadmon, Sompolinsky - Transition to chaos in random neuronal networks.pdf;/Users/qualia/Documents/Papers/Kadmon and Sompolinsky - 2015 - Transition to chaos in random neuronal networks.pdf}
}

@article{Kaplan2015,
  langid = {english},
  title = {Multivariate Cross-Classification: Applying Machine Learning Techniques to Characterize Abstraction in Neural Representations},
  volume = {9},
  issn = {1662-5161},
  url = {http://www.frontiersin.org/Human_Neuroscience/10.3389/fnhum.2015.00151/abstract},
  doi = {10.3389/fnhum.2015.00151},
  shorttitle = {Multivariate Cross-Classification},
  abstract = {Here we highlight an emerging trend in the use of machine learning classifiers to test for abstraction across patterns of neural activity. When a classifier algorithm is trained on data from one cognitive context, and tested on data from another, conclusions can be drawn about the role of a given brain region in representing information that abstracts across those cognitive contexts. We call this kind of analysis Multivariate CrossClassification (MVCC), and review several domains where it has recently made an impact. MVCC has been important in establishing correspondences among neural patterns across cognitive domains, including motor-perception matching and cross-sensory matching. It has been used to test for similarity between neural patterns evoked by perception and those generated from memory. Other work has used MVCC to investigate the similarity of representations for semantic categories across different kinds of stimulus presentation, and in the presence of different cognitive demands. We use these examples to demonstrate the power of MVCC as a tool for investigating neural abstraction and discuss some important methodological issues related to its application.},
  journaltitle = {Frontiers in Human Neuroscience},
  urldate = {2019-03-30},
  date = {2015-03-25},
  author = {Kaplan, Jonas T. and Man, Kingson and Greening, Steven G.},
  file = {/Users/qualia/Documents/Papers/2015 - Kaplan, Man, Greening - Multivariate cross-classification applying machine learning techniques to characterize abstraction in neu.pdf;/Users/qualia/Documents/Papers/Kaplan et al. - 2015 - Multivariate cross-classification applying machin.pdf}
}

@article{Khodagholy2015,
  langid = {english},
  title = {{{NeuroGrid}}: Recording Action Potentials from the Surface of the Brain},
  volume = {18},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3905},
  doi = {10.1038/nn.3905},
  shorttitle = {{{NeuroGrid}}},
  number = {2},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2015-02},
  pages = {310-315},
  author = {Khodagholy, Dion and Gelinas, Jennifer N and Thesen, Thomas and Doyle, Werner and Devinsky, Orrin and Malliaras, George G and Buzs\'aki, Gy\"orgy},
  file = {/Users/qualia/Documents/Papers/2015 - Khodagholy et al. - NeuroGrid recording action potentials from the surface of the brain.pdf;/Users/qualia/Documents/Papers/Khodagholy et al. - 2015 - NeuroGrid recording action potentials from the su.pdf}
}

@article{Kumar2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.07285},
  primaryClass = {cs},
  langid = {english},
  title = {Ask {{Me Anything}}: {{Dynamic Memory Networks}} for {{Natural Language Processing}}},
  url = {http://arxiv.org/abs/1506.07285},
  shorttitle = {Ask {{Me Anything}}},
  abstract = {Most tasks in natural language processing can be cast into question answering (QA) problems over language input. We introduce the dynamic memory network (DMN), a neural network architecture which processes input sequences and questions, forms episodic memories, and generates relevant answers. Questions trigger an iterative attention process which allows the model to condition its attention on the inputs and the result of previous iterations. These results are then reasoned over in a hierarchical recurrent sequence model to generate answers. The DMN can be trained end-to-end and obtains state-of-the-art results on several types of tasks and datasets: question answering (Facebook's bAbI dataset), text classification for sentiment analysis (Stanford Sentiment Treebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). The training for these different tasks relies exclusively on trained word vector representations and input-question-answer triplets.},
  urldate = {2019-03-30},
  date = {2015-06-24},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Computation and Language},
  author = {Kumar, Ankit and Irsoy, Ozan and Ondruska, Peter and Iyyer, Mohit and Bradbury, James and Gulrajani, Ishaan and Zhong, Victor and Paulus, Romain and Socher, Richard},
  file = {/Users/qualia/Documents/Papers/2015 - Kumar et al. - Ask Me Anything Dynamic Memory Networks for Natural Language Processing.pdf;/Users/qualia/Documents/Papers/Kumar et al. - 2015 - Ask Me Anything Dynamic Memory Networks for Natur.pdf}
}

@article{Laan2017,
  langid = {english},
  title = {Echo State Networks with Multiple Read-out Modules},
  url = {http://biorxiv.org/lookup/doi/10.1101/017558},
  doi = {10.1101/017558},
  abstract = {We propose a new readout architecture for echo state networks where multiple linear readout modules are activated at distinct time points to varying degrees by a separate controller module. The controller module, like the reservoir of the echo state network, can be initialized randomly. All linear readout modules are trained through simple linear regression, which is the only adaptive step in the modified algorithm. The resulting architecture provides modest improvements on a variety of time series processing tasks (between 5 to 50\% in performance metric depending on the task studied). The novel architecture is guaranteed to perform at least as accurately as a conventional linear readout. It can be utilized as a general purpose readout method when augmentations to performance relative to the standard method is needed.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2017-03-02},
  author = {Laan, Andres and Vicente, Raul},
  file = {/Users/qualia/Documents/Papers/2015 - Laan - Echo state networks with multiple read-out modules.pdf;/Users/qualia/Documents/Papers/Laan and Vicente - 2017 - Echo state networks with multiple read-out modules.pdf}
}

@article{Lagorce2015,
  langid = {english},
  title = {{{STICK}}: {{Spike Time Interval Computational Kernel}}, a {{Framework}} for {{General Purpose Computation Using Neurons}}, {{Precise Timing}}, {{Delays}}, and {{Synchrony}}},
  volume = {27},
  issn = {0899-7667, 1530-888X},
  url = {http://www.mitpressjournals.org/doi/10.1162/NECO_a_00783},
  doi = {10.1162/NECO_a_00783},
  shorttitle = {{{STICK}}},
  number = {11},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2015-11},
  pages = {2261-2317},
  author = {Lagorce, Xavier and Benosman, Ryad},
  file = {/Users/qualia/Documents/Papers/2015 - Lagorce, Benosman - STICK Spike Time Interval Computational Kernel, a Framework for General Purpose Computation Using Neurons, Pr.pdf;/Users/qualia/Documents/Papers/Lagorce and Benosman - 2015 - STICK Spike Time Interval Computational Kernel, a.pdf}
}

@article{Legon2016,
  langid = {english},
  title = {Altered {{Prefrontal Excitation}}/{{Inhibition Balance}} and {{Prefrontal Output}}: {{Markers}} of {{Aging}} in {{Human Memory Networks}}},
  volume = {26},
  issn = {1047-3211, 1460-2199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhv200},
  doi = {10.1093/cercor/bhv200},
  shorttitle = {Altered {{Prefrontal Excitation}}/{{Inhibition Balance}} and {{Prefrontal Output}}},
  abstract = {Memory impairments and heightened prefrontal cortical (PFC) activity are hallmarks of cognitive and neurobiological human aging. While structural integrity of PFC gray matter and interregional white matter tracts are thought to impact memory processing, the balance of neurotransmitters within the PFC itself is less well understood. We used fMRI to establish wholebrain networks involved in a memory encoding task and dynamic causal models (DCMs) for fMRI to determine the causal relationships between these areas. These data revealed enhanced connectivity from PFC to medial temporal cortex that negatively correlated with recall ability. To better understand the intrinsic activity within the PFC, DCM for EEG was employed after continuous theta burst transcranial magnetic stimulation (TMS) to the PFC to assess the effect on excitatory/inhibitory (E/I) synaptic ratios and behavior. These data revealed that the young cohort had a stable E/I ratio that was unaffected by the TMS intervention, while the aged cohort exhibited lower E/I ratios driven by a greater intrinsic inhibitory tone. TMS to the aged cohort resulted in decreased intrinsic inhibition and a decrement in memory performance. These results demonstrate increased topdown influence of PFC upon medial temporal lobe in healthy aging that is associated with decreased memory and may be due to unstable local inhibitory tone within the PFC.},
  number = {11},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2016-10},
  pages = {4315-4326},
  author = {Legon, Wynn and Punzell, Steven and Dowlati, Ehsan and Adams, Sarah E. and Stiles, Alexandra B. and Moran, Rosalyn J.},
  file = {/Users/qualia/Documents/Papers/2015 - Legon et al. - Altered Prefrontal ExcitationInhibition Balance and Prefrontal Output Markers of Aging in Human Memory Networks.pdf;/Users/qualia/Documents/Papers/Legon et al. - 2016 - Altered Prefrontal ExcitationInhibition Balance a.pdf}
}

@article{Lieder,
  langid = {english},
  title = {When to Use Which Heuristic? {{A}} Rational Solution to the Strategy Selection Problem},
  pages = {1},
  author = {Lieder, Falk and Griffiths, Tom},
  file = {/Users/qualia/Documents/Papers/2015 - Lieder, Griffiths - When to use which heuristic A rational solution to the strategy selection problem.pdf;/Users/qualia/Documents/Papers/Lieder and Grifﬁths - When to use which heuristic A rational solution t.pdf}
}

@article{Lipshutz2015,
  langid = {english},
  title = {Existence, {{Uniqueness}}, and {{Stability}} of {{Slowly Oscillating Periodic Solutions}} for {{Delay Differential Equations}} with {{Nonnegativity Constraints}}},
  volume = {47},
  issn = {0036-1410, 1095-7154},
  url = {http://epubs.siam.org/doi/10.1137/140980806},
  doi = {10.1137/140980806},
  abstract = {Deterministic dynamical system models with delayed feedback and nonnegativity constraints arise in a variety of applications in science and engineering. Under certain conditions oscillatory behavior has been observed and it is of interest to know when this behavior is periodic. Here we consider one-dimensional delay differential equations with nonnegativity constraints as prototypes for such models. We obtain sufficient conditions for the existence of slowly oscillating periodic solutions (SOPS) of such equations when the delay/lag interval is long and the dynamics depend only on the current and delayed state. Under further assumptions, including possibly longer delay intervals and restricting the dynamics to depend only on the delayed state, we prove uniqueness and exponential stability for such solutions. To prove these results, we develop a theory for studying perturbations of these constrained SOPS. We illustrate our results with simple examples of biochemical reaction network models and an Internet rate control model.},
  number = {6},
  journaltitle = {SIAM Journal on Mathematical Analysis},
  urldate = {2019-03-30},
  date = {2015-01},
  pages = {4467-4535},
  author = {Lipshutz, David and Williams, Ruth J.},
  file = {/Users/qualia/Documents/Papers/2015 - Lipshutz, Williams - EXISTENCE, UNIQUENESS, AND STABILITY OF SLOWLY OSCILLATING PERIODIC SOLUTIONS FOR DELAY DIFFERENTIAL EQUATIO.pdf;/Users/qualia/Documents/Papers/Lipshutz and Williams - 2015 - Existence, Uniqueness, and Stability of Slowly Osc 2.pdf;/Users/qualia/Documents/Papers/Lipshutz and Williams - 2015 - Existence, Uniqueness, and Stability of Slowly Osc.pdf}
}

@article{Lourens2015,
  langid = {english},
  title = {Exploiting Pallidal Plasticity for Stimulation in {{Parkinson}}'s Disease},
  volume = {12},
  issn = {1741-2560, 1741-2552},
  url = {http://stacks.iop.org/1741-2552/12/i=2/a=026005?key=crossref.1a586afa341236a2dbc8863b67ea2423},
  doi = {10.1088/1741-2560/12/2/026005},
  abstract = {Objective. Continuous application of high-frequency deep brain stimulation (DBS) often effectively reduces motor symptoms of Parkinson's disease patients. While there is a growing need for more effective and less traumatic stimulation, the exact mechanism of DBS is still unknown. Here, we present a methodology to exploit the plasticity of GABAergic synapses inside the external globus pallidus (GPe) for the optimization of DBS. Approach. Assuming the existence of spike-timing-dependent plasticity (STDP) at GABAergic GPe\textendash{}GPe synapses, we simulate neural activity in a network model of the subthalamic nucleus and GPe. In particular, we test different DBS protocols in our model and quantify their influence on neural synchrony. Main results. In an exemplary set of biologically plausible model parameters, we show that STDP in the GPe has a direct influence on neural activity and especially the stability of firing patterns. STDP stabilizes both uncorrelated firing in the healthy state and correlated firing in the parkinsonian state. Alternative stimulation protocols such as coordinated reset stimulation can clearly profit from the stabilizing effect of STDP. These results are widely independent of the STDP learning rule. Significance. Once the model settings, e.g., connection architectures, have been described experimentally, our model can be adjusted and directly applied in the development of novel stimulation protocols. More efficient stimulation leads to both minimization of side effects and savings in battery power.},
  number = {2},
  journaltitle = {Journal of Neural Engineering},
  urldate = {2019-03-30},
  date = {2015-04-01},
  pages = {026005},
  author = {Lourens, Marcel A J and Schwab, Bettina C and Nirody, Jasmine A and Meijer, Hil G E and van Gils, Stephan A},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2015 - Lourens et al. - Exploiting pallidal plasticity for stimulation in Parkinson's disease.pdf;/Users/qualia/Documents/Papers/Lourens et al. - 2015 - Exploiting pallidal plasticity for stimulation in .pdf}
}

@article{Markram2015,
  langid = {english},
  title = {Reconstruction and {{Simulation}} of {{Neocortical Microcircuitry}}},
  volume = {163},
  issn = {00928674},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867415011915},
  doi = {10.1016/j.cell.2015.09.029},
  number = {2},
  journaltitle = {Cell},
  urldate = {2019-03-30},
  date = {2015-10},
  pages = {456-492},
  author = {Markram, Henry and Muller, Eilif and Ramaswamy, Srikanth and Reimann, Michael W. and Abdellah, Marwan and Sanchez, Carlos Aguado and Ailamaki, Anastasia and Alonso-Nanclares, Lidia and Antille, Nicolas and Arsever, Selim and Kahou, Guy Antoine Atenekeng and Berger, Thomas K. and Bilgili, Ahmet and Buncic, Nenad and Chalimourda, Athanassia and Chindemi, Giuseppe and Courcol, Jean-Denis and Delalondre, Fabien and Delattre, Vincent and Druckmann, Shaul and Dumusc, Raphael and Dynes, James and Eilemann, Stefan and Gal, Eyal and Gevaert, Michael Emiel and Ghobril, Jean-Pierre and Gidon, Albert and Graham, Joe W. and Gupta, Anirudh and Haenel, Valentin and Hay, Etay and Heinis, Thomas and Hernando, Juan B. and Hines, Michael and Kanari, Lida and Keller, Daniel and Kenyon, John and Khazen, Georges and Kim, Yihwa and King, James G. and Kisvarday, Zoltan and Kumbhar, Pramod and Lasserre, S\'ebastien and Le B\'e, Jean-Vincent and Magalh\~aes, Bruno R.C. and Merch\'an-P\'erez, Angel and Meystre, Julie and Morrice, Benjamin Roy and Muller, Jeffrey and Mu\~noz-C\'espedes, Alberto and Muralidhar, Shruti and Muthurasa, Keerthan and Nachbaur, Daniel and Newton, Taylor H. and Nolte, Max and Ovcharenko, Aleksandr and Palacios, Juan and Pastor, Luis and Perin, Rodrigo and Ranjan, Rajnish and Riachi, Imad and Rodr\'iguez, Jos\'e-Rodrigo and Riquelme, Juan Luis and R\"ossert, Christian and Sfyrakis, Konstantinos and Shi, Ying and Shillcock, Julian C. and Silberberg, Gilad and Silva, Ricardo and Tauheed, Farhan and Telefont, Martin and Toledo-Rodriguez, Maria and Tr\"ankler, Thomas and Van Geit, Werner and D\'iaz, Jafet Villafranca and Walker, Richard and Wang, Yun and Zaninetta, Stefano M. and DeFelipe, Javier and Hill, Sean L. and Segev, Idan and Sch\"urmann, Felix},
  file = {/Users/qualia/Documents/Papers/2015 - Markram - Reconstruction and Simulation of Neocortical Microcircuitry.pdf;/Users/qualia/Documents/Papers/Markram et al. - 2015 - Reconstruction and Simulation of Neocortical Micro.pdf}
}

@article{Marzen2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1504.04756},
  primaryClass = {cond-mat, physics:nlin, q-bio},
  langid = {english},
  title = {Time {{Resolution Dependence}} of {{Information Measures}} for {{Spiking Neurons}}: {{Atoms}}, {{Scaling}}, and {{Universality}}},
  url = {http://arxiv.org/abs/1504.04756},
  shorttitle = {Time {{Resolution Dependence}} of {{Information Measures}} for {{Spiking Neurons}}},
  abstract = {The mutual information between stimulus and spike-train response is commonly used to monitor neural coding efficiency, but neuronal computation broadly conceived requires more refined and targeted information measures of input-output joint processes. A first step towards that larger goal is to develop information measures for individual output processes, including information generation (entropy rate), stored information (statistical complexity), predictable information (excess entropy), and active information accumulation (bound information rate). We calculate these for spike trains generated by a variety of noise-driven integrate-and-fire neurons as a function of time resolution and for alternating renewal processes. We show that their time-resolution dependence reveals coarsegrained structural properties of interspike interval statistics; e.g., {$\tau$} -entropy rates that diverge less quickly than the firing rate indicate interspike interval correlations. We also find evidence that the excess entropy and regularized statistical complexity of different types of integrate-and-fire neurons are universal in the continuous-time limit in the sense that they do not depend on mechanism details. This suggests a surprising simplicity in the spike trains generated by these model neurons. Interestingly, neurons with gamma-distributed ISIs and neurons whose spike trains are alternating renewal processes do not fall into the same universality class. These results lead to two conclusions. First, the dependence of information measures on time resolution reveals mechanistic details about spike train generation. Second, information measures can be used as model selection tools for analyzing spike train processes.},
  urldate = {2019-03-30},
  date = {2015-04-18},
  keywords = {Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition,Condensed Matter - Disordered Systems and Neural Networks,Mathematics - Probability,Nonlinear Sciences - Chaotic Dynamics},
  author = {Marzen, Sarah E. and DeWeese, Michael R. and Crutchfield, James P.},
  file = {/Users/qualia/Documents/Papers/2015 - Marzen, DeWeese, Crutchfield - Time resolution dependence of information measures for spiking neurons scaling and universality.pdf;/Users/qualia/Documents/Papers/Marzen et al. - 2015 - Time Resolution Dependence of Information Measures.pdf}
}

@article{Mazzoni2015,
  langid = {english},
  title = {Computing the {{Local Field Potential}} ({{LFP}}) from {{Integrate}}-and-{{Fire Network Models}}},
  volume = {11},
  issn = {1553-7358},
  url = {http://dx.plos.org/10.1371/journal.pcbi.1004584},
  doi = {10.1371/journal.pcbi.1004584},
  abstract = {Leaky integrate-and-fire (LIF) network models are commonly used to study how the spiking dynamics of neural networks changes with stimuli, tasks or dynamic network states. However, neurophysiological studies in vivo often rather measure the mass activity of neuronal microcircuits with the local field potential (LFP). Given that LFPs are generated by spatially separated currents across the neuronal membrane, they cannot be computed directly from quantities defined in models of point-like LIF neurons. Here, we explore the best approximation for predicting the LFP based on standard output from point-neuron LIF networks. To search for this best ``LFP proxy'', we compared LFP predictions from candidate proxies based on LIF network output (e.g, firing rates, membrane potentials, synaptic currents) with ``ground-truth'' LFP obtained when the LIF network synaptic input currents were injected into an analogous three-dimensional (3D) network model of multi-compartmental neurons with realistic morphology, spatial distributions of somata and synapses. We found that a specific fixed linear combination of the LIF synaptic currents provided an accurate LFP proxy, accounting for most of the variance of the LFP time course observed in the 3D network for all recording locations. This proxy performed well over a broad set of conditions, including substantial variations of the neuronal morphologies. Our results provide a simple formula for estimating the time course of the LFP from LIF network simulations in cases where a single pyramidal population dominates the LFP generation, and thereby facilitate quantitative comparison between computational models and experimental LFP recordings in vivo.},
  number = {12},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-12-14},
  pages = {e1004584},
  author = {Mazzoni, Alberto and Lind\'en, Henrik and Cuntz, Hermann and Lansner, Anders and Panzeri, Stefano and Einevoll, Gaute T.},
  editor = {Roth, Arnd},
  file = {/Users/qualia/Documents/Papers/2015 - Mazzoni et al. - Computing the Local Field Potential (LFP) from Integrate-and-Fire Network Models.pdf;/Users/qualia/Documents/Papers/Mazzoni et al. - 2015 - Computing the Local Field Potential (LFP) from Int.pdf}
}

@article{Mostafa2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1503.02777},
  langid = {english},
  title = {Rhythmic Inhibition Allows Neural Networks to Search for Maximally Consistent States},
  volume = {27},
  issn = {0899-7667, 1530-888X},
  url = {http://arxiv.org/abs/1503.02777},
  doi = {10.1162/NECO_a_00785},
  abstract = {Gamma-band rhythmic inhibition is a ubiquitous phenomenon in neural circuits yet its computational role still remains elusive. We show that a model of Gamma-band rhythmic inhibition allows networks of coupled cortical circuit motifs to search for network configurations that best reconcile external inputs with an internal consistency model encoded in the network connectivity. We show that Hebbian plasticity allows the networks to learn the consistency model by example. The search dynamics driven by rhythmic inhibition enable the described networks to solve di cult constraint satisfaction problems without making assumptions about the form of stochastic fluctuations in the network. We show that the search dynamics are well approximated by a stochastic sampling process. We use the described networks to reproduce perceptual multi-stability phenomena with switching times that are a good match to experimental data and show that they provide a general neural framework which can be used to model other 'perceptual inference' phenomena.},
  number = {12},
  journaltitle = {Neural Computation},
  urldate = {2019-03-30},
  date = {2015-12},
  pages = {2510-2547},
  keywords = {Quantitative Biology - Neurons and Cognition},
  author = {Mostafa, Hesham and Muller, Lorenz K. and Indiveri, Giacomo},
  file = {/Users/qualia/Documents/Papers/2015 - Mostafa, Müller, Indiveri - Rhythmic Inhibition Allows Neural Networks to Search for Maximally Consistent States(2).pdf;/Users/qualia/Documents/Papers/Mostafa et al. - 2015 - Rhythmic inhibition allows neural networks to sear 2.pdf;/Users/qualia/Documents/Papers/Mostafa et al. - 2015 - Rhythmic inhibition allows neural networks to sear 3.pdf;/Users/qualia/Documents/Papers/Mostafa et al. - 2015 - Rhythmic inhibition allows neural networks to sear.pdf}
}

@article{Newhall2015,
  langid = {english},
  title = {Synchrony in Stochastically Driven Neuronal Networks with Complex Topologies},
  volume = {91},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.91.052806},
  doi = {10.1103/PhysRevE.91.052806},
  number = {5},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2015-05-11},
  author = {Newhall, Katherine A. and Shkarayev, Maxim S. and Kramer, Peter R. and Kova{\v c}i{\v c}, Gregor and Cai, David},
  file = {/Users/qualia/Documents/Papers/2015 - Newhall et al. - Synchrony in stochastically driven neuronal networks with complex topologies.pdf;/Users/qualia/Documents/Papers/Newhall et al. - 2015 - Synchrony in stochastically driven neuronal networ.pdf}
}

@article{OKeeffe2015,
  langid = {english},
  title = {Synchronization as {{Aggregation}}: {{Cluster Kinetics}} of {{Pulse}}-{{Coupled Oscillators}}},
  volume = {115},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.115.064101},
  doi = {10.1103/PhysRevLett.115.064101},
  shorttitle = {Synchronization as {{Aggregation}}},
  number = {6},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2015-08-06},
  author = {O'Keeffe, Kevin P. and Krapivsky, P. L. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/2015 - O'Keeffe, Krapivsky, Strogatz - Synchronization as Aggregation Cluster Kinetics of Pulse-Coupled Oscillators.pdf;/Users/qualia/Documents/Papers/O’Keeffe et al. - 2015 - Synchronization as Aggregation Cluster Kinetics o.pdf}
}

@article{Panzeri2015,
  langid = {english},
  title = {Neural Population Coding: Combining Insights from Microscopic and Mass Signals},
  volume = {19},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661315000030},
  doi = {10.1016/j.tics.2015.01.002},
  shorttitle = {Neural Population Coding},
  number = {3},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2015-03},
  pages = {162-172},
  author = {Panzeri, Stefano and Macke, Jakob H. and Gross, Joachim and Kayser, Christoph},
  file = {/Users/qualia/Documents/Papers/2015 - Panzeri et al. - Neural population coding combining insights from microscopic and mass signals.pdf;/Users/qualia/Documents/Papers/Panzeri et al. - 2015 - Neural population coding combining insights from .pdf}
}

@article{Papasavvas2015,
  langid = {english},
  title = {Gain Control through Divisive Inhibition Prevents Abrupt Transition to Chaos in a Neural Mass Model},
  volume = {92},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.92.032723},
  doi = {10.1103/PhysRevE.92.032723},
  number = {3},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2015-09-23},
  author = {Papasavvas, Christoforos A. and Wang, Yujiang and Trevelyan, Andrew J. and Kaiser, Marcus},
  file = {/Users/qualia/Documents/Papers/2015 - Papasavvas et al. - Gain control through divisive inhibition prevents abrupt transition to chaos in a neural mass model.pdf;/Users/qualia/Documents/Papers/Papasavvas et al. - 2015 - Gain control through divisive inhibition prevents .pdf}
}

@article{Pavlides2015,
  langid = {english},
  title = {Computational {{Models Describing Possible Mechanisms}} for {{Generation}} of {{Excessive Beta Oscillations}} in {{Parkinson}}'s {{Disease}}},
  volume = {11},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004609},
  doi = {10.1371/journal.pcbi.1004609},
  number = {12},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-12-18},
  pages = {e1004609},
  author = {Pavlides, Alex and Hogan, S. John and Bogacz, Rafal},
  editor = {Graham, Lyle J.},
  file = {/Users/qualia/Documents/Papers/2015 - Pavlides, Hogan, Bogacz - Computational Models Describing Possible Mechanisms for Generation of Excessive Beta Oscillations in.pdf;/Users/qualia/Documents/Papers/Pavlides et al. - 2015 - Computational Models Describing Possible Mechanism.pdf}
}

@article{Peterson2015,
  langid = {english},
  title = {Balanced {{Oscillatory Coupling Improves Information Flow}}},
  url = {http://biorxiv.org/lookup/doi/10.1101/030304},
  doi = {10.1101/030304},
  abstract = {All animals are able to rapidly change their behavior. The neural basis of such flexibility requires that groups of distant neural ensembles rapidly alter communications with selectivity and fidelity. Low frequency oscillations are a strong candidate for how neurons coordinate communication via the dynamic instantiation of functional networks. These dynamic networks are argued to rapidly guide the flow of information, with the presumption that stronger oscillations more strongly influence information flow. Surprisingly, there is scant evidence or theoretical support for how oscillatory activity might enhance information flow. Here we introduce a novel computational model for oscillatory neural communication and show that, rather than the strength of the oscillation, it is the balance between excitatory and inhibitory neuronal activity that has the largest effect on information flow. When coupling between an oscillation and spiking has balanced excitatory-inhibitory inputs, information flow is enhanced via improved discriminability between signal and noise. In contrast, when coupling is unbalanced, driven either by excessive excitation or inhibition, information flow is obstructed, regardless of the strength of the oscillation. A multitude of neuropathologies, including Parkinson's disease, schizophrenia, and autism, are associated with oscillatory disruptions and excitation-inhibition imbalances. Our results show that understanding the distinction between balanced and unbalanced oscillatory coupling offers a unifying mechanistic framework for understanding effective neural communication and its disruption in neuropathology.},
  journaltitle = {bioRxiv},
  urldate = {2019-03-30},
  date = {2015-10-31},
  author = {Peterson, Erik J and Voytek, Bradley},
  file = {/Users/qualia/Documents/Papers/2015 - Peterson, Voytek - Balanced Oscillatory Coupling Improves Information Flow.pdf;/Users/qualia/Documents/Papers/Peterson and Voytek - 2015 - Balanced Oscillatory Coupling Improves Information.pdf}
}

@article{Samaha2015,
  langid = {english},
  title = {The {{Speed}} of {{Alpha}}-{{Band Oscillations Predicts}} the {{Temporal Resolution}} of {{Visual Perception}}},
  volume = {25},
  issn = {09609822},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S096098221501235X},
  doi = {10.1016/j.cub.2015.10.007},
  abstract = {Evidence suggests that scalp-recorded occipital alpha-band (8\textendash{}13 Hz) oscillations reflect phasic information transfer in thalamocortical neurons projecting from lateral geniculate nucleus to visual cortex [1\textendash{}5]. In animals, the phase of ongoing alpha oscillations has been shown to modulate stimulus discrimination and neuronal spiking [6]. Human research has shown that alpha phase predicts visual perception of nearthreshold stimuli [7\textendash{}11] and subsequent neural activity [12\textendash{}14] and that the frequency of these oscillations predicts reaction times [15], as well as the maximum temporal interval necessary for perceived simultaneity [16]. These phasic effects have led to the hypothesis that conscious perception occurs in discrete temporal windows, clocked by the frequency of alpha oscillations [17\textendash{}21]. Under this hypothesis, variation in the frequency of occipital alpha oscillations should predict variation in the temporal resolution of visual perception. Specifically, when two stimuli fall within the same alpha cycle, they may be perceived as a single stimulus, resulting in perception with lower temporal resolution when alpha frequency is lower. We tested this by assessing the relationship between two-flash fusion thresholds (a measure of the temporal resolution of visual perception) and the frequency of eyes-closed and task-related alpha rhythms. We found, both between and within subjects, that faster alpha frequencies predicted more accurate flash discrimination, providing novel evidence linking alpha frequency to the temporal resolution of perception.},
  number = {22},
  journaltitle = {Current Biology},
  urldate = {2019-03-30},
  date = {2015-11},
  pages = {2985-2990},
  author = {Samaha, Jason and Postle, Bradley R.},
  file = {/Users/qualia/Documents/Papers/2015 - Samaha, Postle - The Speed of Alpha-Band Oscillations Predicts the Temporal Resolution of Visual Perception.pdf}
}

@article{Schulman2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.02438},
  primaryClass = {cs},
  langid = {english},
  title = {High-{{Dimensional Continuous Control Using Generalized Advantage Estimation}}},
  url = {http://arxiv.org/abs/1506.02438},
  abstract = {Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD({$\lambda$}). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks.},
  urldate = {2019-03-30},
  date = {2015-06-08},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics,Computer Science - Systems and Control},
  author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  file = {/Users/qualia/Documents/Papers/2015 - Schulman et al. - High-Dimensional Continuous Control Using Generalized Advantage Estimation.pdf}
}

@article{Schulman2015a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1502.05477},
  primaryClass = {cs},
  langid = {english},
  title = {Trust {{Region Policy Optimization}}},
  url = {http://arxiv.org/abs/1502.05477},
  abstract = {We describe an iterative procedure for optimizing policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified procedure, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is similar to natural policy gradient methods and is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.},
  urldate = {2019-03-30},
  date = {2015-02-19},
  keywords = {Computer Science - Machine Learning},
  author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
  file = {/Users/qualia/Documents/Papers/2015 - Schulman et al. - Trust Region Policy Optimization.pdf}
}

@article{Shimazaki,
  langid = {english},
  title = {Neurons as an {{Information}}-Theoretic {{Engine}}},
  abstract = {We show that dynamical gain modulation of neurons' stimulus response is described as an information-theoretic cycle that generates entropy associated with the stimulus-related activity from entropy produced by the modulation. To articulate this theory, we describe stimulus-evoked activity of a neural population based on the maximum entropy principle with constraints on two types of overlapping activities, one that is controlled by stimulus conditions and the other, termed internal activity, that is regulated internally in an organism. We demonstrate that modulation of the internal activity realises gain control of stimulus response, and controls stimulus information. A cycle of neural dynamics is then introduced to model information processing by the neurons during which the stimulus information is dynamically enhanced by the internal gain-modulation mechanism. Based on the conservation law for entropy production, we demonstrate that the cycle generates entropy ascribed to the stimulus-related activity using entropy supplied by the internal mechanism, analogously to a heat engine that produces work from heat. We provide an efficient cycle that achieves the highest entropic efficiency to retain the stimulus information. The theory allows us to quantify efficiency of the internal computation and its theoretical limit.},
  pages = {16},
  author = {Shimazaki, Hideaki},
  file = {/Users/qualia/Documents/Papers/2015 - Shimazaki - Neurons as an Information-theoretic Engine.pdf;/Users/qualia/Documents/Papers/Shimazaki - Neurons as an Information-theoretic Engine.pdf}
}

@article{Snyder2015,
  langid = {english},
  title = {Global Network Influences on Local Functional Connectivity},
  volume = {18},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3979},
  doi = {10.1038/nn.3979},
  number = {5},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2015-05},
  pages = {736-743},
  author = {Snyder, Adam C and Morais, Michael J and Willis, Cory M and Smith, Matthew A},
  file = {/Users/qualia/Documents/Papers/2015 - Snyder et al. - Global network influences on local functional connectivity.pdf;/Users/qualia/Documents/Papers/Snyder et al. - 2015 - Global network influences on local functional conn.pdf}
}

@article{Pluta2015,
  langid = {english},
  title = {A Direct Translaminar Inhibitory Circuit Tunes Cortical Output},
  volume = {18},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.4123},
  doi = {10.1038/nn.4123},
  number = {11},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2015-11},
  pages = {1631-1640},
  author = {Pluta, Scott and Naka, Alexander and Veit, Julia and Telian, Gregory and Yao, Lucille and Hakim, Richard and Taylor, David and Adesnik, Hillel},
  file = {/Users/qualia/Documents/Papers/2015 - Pluta et al. - A direct translaminar inhibitory circuit tunes cortical output.pdf;/Users/qualia/Documents/Papers/Pluta et al. - 2015 - A direct translaminar inhibitory circuit tunes cor.pdf}
}

@article{Robinson2015,
  langid = {english},
  title = {Short {{Stimulus}}, {{Long Response}}: {{Sodium}} and {{Calcium Dynamics Explain Persistent Neuronal Firing}}},
  volume = {13},
  issn = {1545-7885},
  url = {https://dx.plos.org/10.1371/journal.pbio.1002320},
  doi = {10.1371/journal.pbio.1002320},
  shorttitle = {Short {{Stimulus}}, {{Long Response}}},
  number = {12},
  journaltitle = {PLOS Biology},
  urldate = {2019-03-30},
  date = {2015-12-16},
  pages = {e1002320},
  author = {Robinson, Richard},
  file = {/Users/qualia/Documents/Papers/2015 - Robinson - Short Stimulus, Long Response Sodium and Calcium Dynamics Explain Persistent Neuronal Firing.pdf;/Users/qualia/Documents/Papers/Robinson - 2015 - Short Stimulus, Long Response Sodium and Calcium .pdf}
}

@article{Mochol2015,
  langid = {english},
  title = {Stochastic Transitions into Silence Cause Noise Correlations in Cortical Circuits},
  volume = {112},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1410509112},
  doi = {10.1073/pnas.1410509112},
  number = {11},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2015-03-17},
  pages = {3529-3534},
  author = {Mochol, Gabriela and Hermoso-Mendizabal, Ainhoa and Sakata, Shuzo and Harris, Kenneth D. and de la Rocha, Jaime},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/2015 - Mochol et al. - Stochastic transitions into silence cause noise correlations in cortical circuits.pdf;/Users/qualia/Documents/Papers/Mochol et al. - 2015 - Stochastic transitions into silence cause noise co.pdf}
}

@article{Burns2011,
  langid = {english},
  title = {Is {{Gamma}}-{{Band Activity}} in the {{Local Field Potential}} of {{V1 Cortex}} a "{{Clock}}" or {{Filtered Noise}}?},
  volume = {31},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0660-11.2011},
  doi = {10.1523/JNEUROSCI.0660-11.2011},
  abstract = {Gamma-band (25\textendash{}90Hz) peaks in local field potential (LFP) power spectra are present throughout the cerebral cortex and have been related to perception, attention, memory, and disorders e.g. schizophrenia and autism. It has been theorized gamma oscillations provide a `clock' for precise temporal encoding and `binding' of signals about stimulus features across brain regions. For gamma to function as a `clock' it must be autocoherent: phase and frequency conserved over a period of time. We computed phase and frequency trajectories of gamma-band bursts, using timefrequency analysis of LFPs recorded in macaque primary visual cortex (V1) during visual stimulation. The data were compared with simulations of random networks and clock signals in noise. Gamma-band bursts in LFP data were statistically indistinguishable from those found in filtered broadband noise. Therefore, V1 LFP data did not contain `clock'-like gamma-band signals. We consider possible functions for stochastic gamma-band activity, such as a synchronizing pulse signal.},
  number = {26},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2011-06-29},
  pages = {9658-9664},
  author = {Burns, S. P. and Xing, D. and Shapley, R. M.},
  file = {/Users/qualia/Documents/Papers/2012 - Manuscript - NIH Public Access(2).pdf}
}

@article{Mnih2015,
  langid = {english},
  title = {Human-Level Control through Deep Reinforcement Learning},
  volume = {518},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature14236},
  doi = {10.1038/nature14236},
  number = {7540},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2015-02},
  pages = {529-533},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  file = {/Users/qualia/Documents/Papers/2015 - Minh - Human-level control through deep reinforcement learning.pdf;/Users/qualia/Documents/Papers/Mnih et al. - 2015 - Human-level control through deep reinforcement lea.pdf}
}

@article{vanderWesthuizen2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1804.04849},
  primaryClass = {cs, stat},
  langid = {english},
  title = {The Unreasonable Effectiveness of the Forget Gate},
  url = {http://arxiv.org/abs/1804.04849},
  abstract = {Given the success of the gated recurrent unit, a natural question is whether all the gates of the long short-term memory (LSTM) network are necessary. Previous research has shown that the forget gate is one of the most important gates in the LSTM. Here we show that a forget-gate-only version of the LSTM with chronoinitialized biases, not only provides computational savings but outperforms the standard LSTM on multiple benchmark datasets and competes with some of the best contemporary models. Our proposed network, the JANET, achieves accuracies of 99\% and 92.5\% on the MNIST and pMNIST datasets, outperforming the standard LSTM which yields accuracies of 98.5\% and 91\%.},
  urldate = {2019-03-30},
  date = {2018-04-13},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  author = {van der Westhuizen, Jos and Lasenby, Joan},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/van der Westhuizen and Lasenby - 2018 - The unreasonable effectiveness of the forget gate.pdf;/Users/qualia/Zotero/storage/ZVD94T7I/van der Westhuizen and Lasenby - 2018 - The unreasonable effectiveness of the forget gate.pdf}
}

@article{Connolly2015a,
  langid = {english},
  title = {Modulations in {{Oscillatory Frequency}} and {{Coupling}} in {{Globus Pallidus}} with {{Increasing Parkinsonian Severity}}},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.4137-14.2015},
  doi = {10.1523/JNEUROSCI.4137-14.2015},
  number = {15},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2015-04-15},
  pages = {6231-6240},
  author = {Connolly, Allison T. and Jensen, Alicia L. and Bello, Edward M. and Netoff, Theoden I. and Baker, Kenneth B. and Johnson, Matthew D. and Vitek, Jerrold L.},
  file = {/Users/qualia/Documents/Papers/Connolly et al. - 2015 - Modulations in Oscillatory Frequency and Coupling .pdf;/Users/qualia/Zotero/storage/65572R6R/Connolly et al. - 2015 - Modulations in Oscillatory Frequency and Coupling .pdf}
}

@article{Ocker2014,
  langid = {english},
  title = {Kv7 Channels Regulate Pairwise Spiking Covariability in Health and Disease},
  volume = {112},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00084.2014},
  doi = {10.1152/jn.00084.2014},
  number = {2},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2014-07-15},
  pages = {340-352},
  author = {Ocker, Gabriel Koch and Doiron, Brent},
  file = {/Users/qualia/Documents/Papers/Ocker and Doiron - 2014 - Kv7 channels regulate pairwise spiking covariabili.pdf}
}

@article{Aguilera2013,
  langid = {english},
  title = {The Situated {{HKB}} Model: How Sensorimotor Spatial Coupling Can Alter Oscillatory Brain Dynamics},
  volume = {7},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2013.00117/abstract},
  doi = {10.3389/fncom.2013.00117},
  shorttitle = {The Situated {{HKB}} Model},
  abstract = {Despite the increase of both dynamic and embodied/situated approaches in cognitive science, there is still little research on how coordination dynamics under a closed sensorimotor loop might induce qualitatively different patterns of neural oscillations compared to those found in isolated systems. We take as a departure point the Haken-Kelso-Bunz (HKB) model, a generic model for dynamic coordination between two oscillatory components, which has proven useful for a vast range of applications in cognitive science and whose dynamical properties are well understood. In order to explore the properties of this model under closed sensorimotor conditions we present what we call the situated HKB model: a robotic model that performs a gradient climbing task and whose ``brain'' is modeled by the HKB equation. We solve the differential equations that define the agent-environment coupling for increasing values of the agent's sensitivity (sensor gain), finding different behavioral strategies. These results are compared with two different models: a decoupled HKB with no sensory input and a passively-coupled HKB that is also decoupled but receives a structured input generated by a situated agent. We can precisely quantify and qualitatively describe how the properties of the system, when studied in coupled conditions, radically change in a manner that cannot be deduced from the decoupled HKB models alone. We also present the notion of neurodynamic signature as the dynamic pattern that correlates with a specific behavior and we show how only a situated agent can display this signature compared to an agent that simply receives the exact same sensory input. To our knowledge, this is the first analytical solution of the HKB equation in a sensorimotor loop and qualitative and quantitative analytic comparison of spatially coupled vs. decoupled oscillatory controllers. Finally, we discuss the limitations and possible generalization of our model to contemporary neuroscience and philosophy of mind.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2013},
  author = {Aguilera, Miguel and Bedia, Manuel G. and Santos, Bruno A. and Barandiaran, Xabier E.},
  file = {/Users/qualia/Documents/Papers/Aguilera et al. - 2013 - The situated HKB model how sensorimotor spatial c.pdf}
}

@article{Stamatakis2013,
  langid = {english},
  title = {A {{Unique Population}} of {{Ventral Tegmental Area Neurons Inhibits}} the {{Lateral Habenula}} to {{Promote Reward}}},
  volume = {80},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627313007575},
  doi = {10.1016/j.neuron.2013.08.023},
  abstract = {Lateral habenula (LHb) neurons convey aversive and negative reward conditions through potent indirect inhibition of ventral tegmental area (VTA) dopaminergic neurons. Although VTA dopaminergic neurons reciprocally project to the LHb, the electrophysiological properties and the behavioral consequences associated with selective manipulations of this circuit are unknown. Here, we identify an inhibitory input to the LHb arising from a unique population of VTA neurons expressing dopaminergic markers. Optogenetic activation of this circuit resulted in no detectable dopamine release in LHb brain slices. Instead, stimulation produced GABA-mediated inhibitory synaptic transmission, which suppressed the firing of postsynaptic LHb neurons in brain slices and increased the spontaneous firing rate of VTA dopaminergic neurons in vivo. Furthermore, in vivo activation of this pathway produced reward-related phenotypes that were dependent on intra-LHb GABAA receptor signaling. These results suggest that noncanonical inhibitory signaling by these hybrid dopaminergic-GABAergic neurons act to suppress LHb output under rewarding conditions.},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2013-11},
  pages = {1039-1053},
  author = {Stamatakis, Alice M. and Jennings, Joshua H. and Ung, Randall L. and Blair, Grace A. and Weinberg, Richard J. and Neve, Rachael L. and Boyce, Frederick and Mattis, Joanna and Ramakrishnan, Charu and Deisseroth, Karl and Stuber, Garret D.},
  file = {/Users/qualia/Documents/Papers/Stamatakis et al. - 2013 - A Unique Population of Ventral Tegmental Area Neur.pdf}
}

@article{Steinberg2013,
  langid = {english},
  title = {A Causal Link between Prediction Errors, Dopamine Neurons and Learning},
  volume = {16},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3413},
  doi = {10.1038/nn.3413},
  number = {7},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2013-07},
  pages = {966-973},
  author = {Steinberg, Elizabeth E and Keiflin, Ronald and Boivin, Josiah R and Witten, Ilana B and Deisseroth, Karl and Janak, Patricia H},
  file = {/Users/qualia/Documents/Papers/Steinberg et al. - 2013 - A causal link between prediction errors, dopamine .pdf}
}

@article{Voytek2013,
  langid = {english},
  title = {A Method for Event-Related Phase/Amplitude Coupling},
  volume = {64},
  issn = {10538119},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811912009330},
  doi = {10.1016/j.neuroimage.2012.09.023},
  abstract = {Phase/amplitude coupling (PAC) is emerging as an important electrophysiological measure of local and long-distance neuronal communication. Current techniques for calculating PAC provide a numerical index that represents an average value across an arbitrarily long time period. This requires researchers to rely on block design experiments and temporal concatenation at the cost of the sub-second temporal resolution afforded by electrophysiological recordings. Here we present a method for calculating event-related phase/ amplitude coupling (ERPAC) designed to capture the temporal evolution of task-related changes in PAC across events or between distant brain regions that is applicable to human or animal electromagnetic recording.},
  journaltitle = {NeuroImage},
  urldate = {2019-03-30},
  date = {2013-01},
  pages = {416-424},
  author = {Voytek, Bradley and D'Esposito, Mark and Crone, Nathan and Knight, Robert T.},
  file = {/Users/qualia/Documents/Papers/Voytek et al. - 2013 - A method for event-related phaseamplitude couplin.pdf}
}

@article{Trujillo2013,
  langid = {english},
  title = {Altered Cortical Spectrotemporal Processing with Age-Related Hearing Loss},
  volume = {110},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00423.2013},
  doi = {10.1152/jn.00423.2013},
  number = {12},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2013-12-15},
  pages = {2873-2886},
  author = {Trujillo, Michael and Razak, Khaleel A.},
  file = {/Users/qualia/Documents/Papers/Trujillo and Razak - 2013 - Altered cortical spectrotemporal processing with a.pdf}
}

@article{Voytek2013a,
  langid = {english},
  title = {Stimulating the Aging Brain},
  volume = {73},
  issn = {03645134},
  url = {http://doi.wiley.com/10.1002/ana.23790},
  doi = {10.1002/ana.23790},
  number = {1},
  journaltitle = {Annals of Neurology},
  urldate = {2019-03-30},
  date = {2013-01},
  pages = {1-3},
  author = {Voytek, Bradley and Gazzaley, Adam},
  file = {/Users/qualia/Documents/Papers/Voytek and Gazzaley - 2013 - Stimulating the aging brain.pdf}
}

@article{Watrous2013,
  langid = {english},
  title = {Frequency-Specific Network Connectivity Increases Underlie Accurate Spatiotemporal Memory Retrieval},
  volume = {16},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3315},
  doi = {10.1038/nn.3315},
  number = {3},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2013-03},
  pages = {349-356},
  author = {Watrous, Andrew J and Tandon, Nitin and Conner, Chris R and Pieters, Thomas and Ekstrom, Arne D},
  file = {/Users/qualia/Documents/Papers/Watrous et al. - 2013 - Frequency-specific network connectivity increases .pdf}
}

@article{Xu2013,
  langid = {english},
  title = {Reduction in {{LFP}} Cross-Frequency Coupling between Theta and Gamma Rhythms Associated with Impaired {{STP}} and {{LTP}} in a Rat Model of Brain Ischemia},
  volume = {7},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2013.00027/abstract},
  doi = {10.3389/fncom.2013.00027},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2013},
  author = {Xu, Xiaxia and Zheng, Chenguang and Zhang, Tao},
  file = {/Users/qualia/Documents/Papers/Xu et al. - 2013 - Reduction in LFP cross-frequency coupling between .pdf}
}

@article{Akam2014,
  langid = {english},
  title = {Oscillatory Multiplexing of Population Codes for Selective Communication in the Mammalian Brain},
  volume = {15},
  issn = {1471-003X, 1471-0048},
  url = {http://www.nature.com/articles/nrn3668},
  doi = {10.1038/nrn3668},
  abstract = {Mammalian brains exhibit population oscillations, the structures of which vary in time and space according to behavioural state. A proposed function of these oscillations is to control the flow of signals among anatomically connected networks. However, the nature of neural coding that may support selective communication that depends on oscillations has received relatively little attention. Here, we consider the role of multiplexing, whereby multiple information streams share a common neural substrate. We suggest that multiplexing implemented through periodic modulation of firing-rate population codes enables flexible reconfiguration of effective connectivity among brain areas.},
  number = {2},
  journaltitle = {Nature Reviews Neuroscience},
  urldate = {2019-03-30},
  date = {2014-02},
  pages = {111-122},
  author = {Akam, Thomas and Kullmann, Dimitri M.},
  file = {/Users/qualia/Documents/Papers/Akam and Kullmann - 2014 - Oscillatory multiplexing of population codes for s.pdf}
}

@article{Archer,
  langid = {english},
  title = {Low-Dimensional Models of Neural Population Activity in Sensory Cortical Circuits},
  abstract = {Neural responses in visual cortex are influenced by visual stimuli and by ongoing spiking activity in local circuits. An important challenge in computational neuroscience is to develop models that can account for both of these features in large multi-neuron recordings and to reveal how stimulus representations interact with and depend on cortical dynamics. Here we introduce a statistical model of neural population activity that integrates a nonlinear receptive field model with a latent dynamical model of ongoing cortical activity. This model captures temporal dynamics and correlations due to shared stimulus drive as well as common noise. Moreover, because the nonlinear stimulus inputs are mixed by the ongoing dynamics, the model can account for a multiple idiosyncratic receptive field shapes with a small number of nonlinear inputs to a low-dimensional dynamical model. We introduce a fast estimation method using online expectation maximization with Laplace approximations, for which inference scales linearly in both population size and recording duration. We test this model to multi-channel recordings from primary visual cortex and show that it accounts for neural tuning properties as well as cross-neural correlations.},
  pages = {9},
  author = {Archer, Evan W and Koster, Urs and Pillow, Jonathan W and Macke, Jakob H},
  file = {/Users/qualia/Documents/Papers/Archer et al. - Low-dimensional models of neural population activi.pdf}
}

@article{Barbieri2014,
  langid = {english},
  title = {Stimulus {{Dependence}} of {{Local Field Potential Spectra}}: {{Experiment}} versus {{Theory}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5365-13.2014},
  doi = {10.1523/JNEUROSCI.5365-13.2014},
  shorttitle = {Stimulus {{Dependence}} of {{Local Field Potential Spectra}}},
  number = {44},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-10-29},
  pages = {14589-14605},
  author = {Barbieri, F. and Mazzoni, A. and Logothetis, N. K. and Panzeri, S. and Brunel, N.},
  file = {/Users/qualia/Documents/Papers/Barbieri et al. - 2014 - Stimulus Dependence of Local Field Potential Spect.pdf}
}

@article{Bays2014,
  langid = {english},
  title = {Noise in {{Neural Populations Accounts}} for {{Errors}} in {{Working Memory}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3204-13.2014},
  doi = {10.1523/JNEUROSCI.3204-13.2014},
  number = {10},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-03-05},
  pages = {3632-3645},
  author = {Bays, P. M.},
  file = {/Users/qualia/Documents/Papers/Bays - 2014 - Noise in Neural Populations Accounts for Errors in.pdf}
}

@article{Borgers2014,
  langid = {english},
  title = {Approximate, Not {{Perfect Synchrony Maximizes}} the {{Downstream Effectiveness}} of {{Excitatory Neuronal Ensembles}}},
  volume = {4},
  issn = {2190-8567},
  url = {http://mathematical-neuroscience.springeropen.com/articles/10.1186/2190-8567-4-10},
  doi = {10.1186/2190-8567-4-10},
  abstract = {The most basic functional role commonly ascribed to synchrony in the brain is that of amplifying excitatory neuronal signals. The reasoning is straightforward: When positive charge is injected into a leaky target neuron over a time window of positive duration, some of it will have time to leak back out before an action potential is triggered in the target, and it will in that sense be wasted. If the goal is to elicit a firing response in the target using as little charge as possible, it seems best to deliver the charge all at once, i.e., in perfect synchrony. In this article, we show that this reasoning is correct only if one assumes that the input ceases when the target crosses the firing threshold, but before it actually fires. If the input ceases later\textemdash{}for instance, in response to a feedback signal triggered by the firing of the target\textemdash{}the ``most economical'' way of delivering input (the way that requires the least total amount of input) is no longer precisely synchronous, but merely approximately so. If the target is a heterogeneous network, as it always is in the brain, then ceasing the input ``when the target crosses the firing threshold'' is not an option, because there is no single moment when the firing threshold is crossed. In this sense, precise synchrony is never optimal in the brain.},
  number = {1},
  journaltitle = {The Journal of Mathematical Neuroscience},
  urldate = {2019-03-30},
  date = {2014},
  pages = {10},
  author = {B\"orgers, Christoph and Li, Jie and Kopell, Nancy},
  file = {/Users/qualia/Documents/Papers/Börgers et al. - 2014 - Approximate, not Perfect Synchrony Maximizes the D.pdf}
}

@article{Bisio2014,
  langid = {english},
  title = {Emergence of {{Bursting Activity}} in {{Connected Neuronal Sub}}-{{Populations}}},
  volume = {9},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0107400},
  doi = {10.1371/journal.pone.0107400},
  abstract = {Uniform and modular primary hippocampal cultures from embryonic rats were grown on commercially available microelectrode arrays to investigate network activity with respect to development and integration of different neuronal populations. Modular networks consisting of two confined active and inter-connected sub-populations of neurons were realized by means of bi-compartmental polydimethylsiloxane structures. Spontaneous activity in both uniform and modular cultures was periodically monitored, from three up to eight weeks after plating. Compared to uniform cultures and despite lower cellular density, modular networks interestingly showed higher firing rates at earlier developmental stages, and network-wide firing and bursting statistics were less variable over time. Although globally less correlated than uniform cultures, modular networks exhibited also higher intra-cluster than inter-cluster correlations, thus demonstrating that segregation and integration of activity coexisted in this simple yet powerful in vitro model. Finally, the peculiar synchronized bursting activity shown by confined modular networks preferentially propagated within one of the two compartments (`dominant'), even in cases of perfect balance of firing rate between the two sub-populations. This dominance was generally maintained during the entire monitored developmental frame, thus suggesting that the implementation of this hierarchy arose from early network development.},
  number = {9},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2014-09-24},
  pages = {e107400},
  author = {Bisio, Marta and Bosca, Alessandro and Pasquale, Valentina and Berdondini, Luca and Chiappalone, Michela},
  editor = {Vasilaki, Eleni},
  file = {/Users/qualia/Documents/Papers/Bisio et al. - 2014 - Emergence of Bursting Activity in Connected Neuron.pdf}
}

@article{Brunet2014,
  langid = {english},
  title = {Gamma or No Gamma, That Is the Question},
  volume = {18},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661314002009},
  doi = {10.1016/j.tics.2014.08.006},
  number = {10},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2014-10},
  pages = {507-509},
  author = {Brunet, Nicolas and Vinck, Martin and Bosman, Conrado A. and Singer, Wolf and Fries, Pascal},
  file = {/Users/qualia/Documents/Papers/Brunet et al. - 2014 - Gamma or no gamma, that is the question.pdf}
}

@article{Doi2014,
  langid = {english},
  title = {A {{Simple Model}} of {{Optimal Population Coding}} for {{Sensory Systems}}},
  volume = {10},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1003761},
  doi = {10.1371/journal.pcbi.1003761},
  abstract = {A fundamental task of a sensory system is to infer information about the environment. It has long been suggested that an important goal of the first stage of this process is to encode the raw sensory signal efficiently by reducing its redundancy in the neural representation. Some redundancy, however, would be expected because it can provide robustness to noise inherent in the system. Encoding the raw sensory signal itself is also problematic, because it contains distortion and noise. The optimal solution would be constrained further by limited biological resources. Here, we analyze a simple theoretical model that incorporates these key aspects of sensory coding, and apply it to conditions in the retina. The model specifies the optimal way to incorporate redundancy in a population of noisy neurons, while also optimally compensating for sensory distortion and noise. Importantly, it allows an arbitrary input-to-output cell ratio between sensory units (photoreceptors) and encoding units (retinal ganglion cells), providing predictions of retinal codes at different eccentricities. Compared to earlier models based on redundancy reduction, the proposed model conveys more information about the original signal. Interestingly, redundancy reduction can be near-optimal when the number of encoding units is limited, such as in the peripheral retina. We show that there exist multiple, equally-optimal solutions whose receptive field structure and organization vary significantly. Among these, the one which maximizes the spatial locality of the computation, but not the sparsity of either synaptic weights or neural responses, is consistent with known basic properties of retinal receptive fields. The model further predicts that receptive field structure changes less with light adaptation at higher input-to-output cell ratios, such as in the periphery.},
  number = {8},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2014-08-14},
  pages = {e1003761},
  author = {Doi, Eizaburo and Lewicki, Michael S.},
  editor = {Bethge, Matthias},
  file = {/Users/qualia/Documents/Papers/Doi and Lewicki - 2014 - A Simple Model of Optimal Population Coding for Se.pdf}
}

@article{Dummer2014,
  langid = {english},
  title = {Self-Consistent Determination of the Spike-Train Power Spectrum in a Neural Network with Sparse Connectivity},
  volume = {8},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2014.00104/abstract},
  doi = {10.3389/fncom.2014.00104},
  abstract = {A major source of random variability in cortical networks is the quasi-random arrival of presynaptic action potentials from many other cells. In network studies as well as in the study of the response properties of single cells embedded in a network, synaptic background input is often approximated by Poissonian spike trains. However, the output statistics of the cells is in most cases far from being Poisson. This is inconsistent with the assumption of similar spike-train statistics for pre- and postsynaptic cells in a recurrent network. Here we tackle this problem for the popular class of integrate-and-fire neurons and study a self-consistent statistics of input and output spectra of neural spike trains. Instead of actually using a large network, we use an iterative scheme, in which we simulate a single neuron over several generations. In each of these generations, the neuron is stimulated with surrogate stochastic input that has a similar statistics as the output of the previous generation. For the surrogate input, we employ two distinct approximations: (i) a superposition of renewal spike trains with the same interspike interval density as observed in the previous generation and (ii) a Gaussian current with a power spectrum proportional to that observed in the previous generation. For input parameters that correspond to balanced input in the network, both the renewal and the Gaussian iteration procedure converge quickly and yield comparable results for the self-consistent spike-train power spectrum. We compare our results to large-scale simulations of a random sparsely connected network of leaky integrate-and-fire neurons (Brunel, 2000) and show that in the asynchronous regime close to a state of balanced synaptic input from the network, our iterative schemes provide an excellent approximations to the autocorrelation of spike trains in the recurrent network.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-09-18},
  author = {Dummer, Benjamin and Wieland, Stefan and Lindner, Benjamin},
  file = {/Users/qualia/Documents/Papers/Dummer et al. - 2014 - Self-consistent determination of the spike-train p.pdf}
}

@article{Eliasmith2014,
  langid = {english},
  title = {The Use and Abuse of Large-Scale Brain Models},
  volume = {25},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S095943881300189X},
  doi = {10.1016/j.conb.2013.09.009},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2014-04},
  pages = {1-6},
  author = {Eliasmith, Chris and Trujillo, Oliver},
  file = {/Users/qualia/Documents/Papers/Eliasmith and Trujillo - 2014 - The use and abuse of large-scale brain models.pdf}
}

@article{Fan,
  langid = {english},
  title = {{{LIBLINEAR}}: {{A Library}} for {{Large Linear Classification}}},
  abstract = {LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and linear support vector machines. We provide easy-to-use command-line tools and library calls for users and developers. Comprehensive documents are available for both beginners and advanced users. Experiments demonstrate that LIBLINEAR is very efficient on large sparse data sets.},
  pages = {29},
  author = {Fan, Rong-En and Chang, Kai-Wei and Hsieh, Cho-Jui and Wang, Xiang-Rui and Lin, Chih-Jen},
  file = {/Users/qualia/Documents/Papers/Fan et al. - LIBLINEAR A Library for Large Linear Classiﬁcatio.pdf}
}

@article{Fukunaga2014,
  langid = {english},
  title = {Independent Control of Gamma and Theta Activity by Distinct Interneuron Networks in the Olfactory Bulb},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3760},
  doi = {10.1038/nn.3760},
  number = {9},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-09},
  pages = {1208-1216},
  author = {Fukunaga, Izumi and Herb, Jan T and Kollo, Mihaly and Boyden, Edward S and Schaefer, Andreas T},
  file = {/Users/qualia/Documents/Papers/Fukunaga et al. - 2014 - Independent control of gamma and theta activity by.pdf}
}

@article{Friston2014,
  langid = {english},
  title = {The Anatomy of Choice: Dopamine and Decision-Making},
  volume = {369},
  issn = {0962-8436, 1471-2970},
  url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2013.0481},
  doi = {10.1098/rstb.2013.0481},
  shorttitle = {The Anatomy of Choice},
  number = {1655},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  urldate = {2019-03-30},
  date = {2014-09-29},
  pages = {20130481-20130481},
  author = {Friston, K. and Schwartenbeck, P. and FitzGerald, T. and Moutoussis, M. and Behrens, T. and Dolan, R. J.},
  file = {/Users/qualia/Documents/Papers/Friston et al. - 2014 - The anatomy of choice dopamine and decision-makin.pdf}
}

@article{Goodman2014,
  langid = {english},
  title = {Brian 2: Neural Simulations on a Variety of Computational Hardware},
  volume = {15},
  issn = {1471-2202},
  url = {http://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-15-S1-P199},
  doi = {10.1186/1471-2202-15-S1-P199},
  shorttitle = {Brian 2},
  issue = {Suppl 1},
  journaltitle = {BMC Neuroscience},
  urldate = {2019-03-30},
  date = {2014},
  pages = {P199},
  author = {Goodman, Dan FM and Stimberg, Marcel and Yger, Pierre and Brette, Romain},
  file = {/Users/qualia/Documents/Papers/Goodman et al. - 2014 - Brian 2 neural simulations on a variety of comput.pdf}
}

@article{Gunawardena2014,
  langid = {english},
  title = {Models in Biology: `Accurate Descriptions of Our Pathetic Thinking'},
  volume = {12},
  issn = {1741-7007},
  url = {https://bmcbiol.biomedcentral.com/articles/10.1186/1741-7007-12-29},
  doi = {10.1186/1741-7007-12-29},
  shorttitle = {Models in Biology},
  abstract = {In this essay I will sketch some ideas for how to think about models in biology. I will begin by trying to dispel the myth that quantitative modeling is somehow foreign to biology. I will then point out the distinction between forward and reverse modeling and focus thereafter on the former. Instead of going into mathematical technicalities about different varieties of models, I will focus on their logical structure, in terms of assumptions and conclusions. A model is a logical machine for deducing the latter from the former. If the model is correct, then, if you believe its assumptions, you must, as a matter of logic, also believe its conclusions. This leads to consideration of the assumptions underlying models. If these are based on fundamental physical laws, then it may be reasonable to treat the model as `predictive', in the sense that it is not subject to falsification and we can rely on its conclusions. However, at the molecular level, models are more often derived from phenomenology and guesswork. In this case, the model is a test of its assumptions and must be falsifiable. I will discuss three models from this perspective, each of which yields biological insights, and this will lead to some guidelines for prospective model builders.},
  number = {1},
  journaltitle = {BMC Biology},
  urldate = {2019-03-30},
  date = {2014-12},
  author = {Gunawardena, Jeremy},
  file = {/Users/qualia/Documents/Papers/Gunawardena - 2014 - Models in biology ‘accurate descriptions of our p.pdf}
}

@article{Gutfreund1995,
  langid = {english},
  title = {Subthreshold Oscillations and Resonant Frequency in Guinea-Pig Cortical Neurons: Physiology and Modelling.},
  volume = {483},
  issn = {00223751},
  url = {http://doi.wiley.com/10.1113/jphysiol.1995.sp020611},
  doi = {10.1113/jphysiol.1995.sp020611},
  shorttitle = {Subthreshold Oscillations and Resonant Frequency in Guinea-Pig Cortical Neurons},
  number = {3},
  journaltitle = {The Journal of Physiology},
  urldate = {2019-03-30},
  date = {1995-03-15},
  pages = {621-640},
  author = {Gutfreund, Y and {yarom}, Y and Segev, I},
  file = {/Users/qualia/Documents/Papers/Gutfreund et al. - 1995 - Subthreshold oscillations and resonant frequency i.pdf}
}

@article{Helfrich2014,
  langid = {english},
  title = {Selective {{Modulation}} of {{Interhemispheric Functional Connectivity}} by {{HD}}-{{tACS Shapes Perception}}},
  volume = {12},
  issn = {1545-7885},
  url = {http://dx.plos.org/10.1371/journal.pbio.1002031},
  doi = {10.1371/journal.pbio.1002031},
  abstract = {Oscillatory neuronal synchronization between cortical areas has been suggested to constitute a flexible mechanism to coordinate information flow in the human cerebral cortex. However, it remains unclear whether synchronized neuronal activity merely represents an epiphenomenon or whether it is causally involved in the selective gating of information. Here, we combined bilateral high-density transcranial alternating current stimulation (HD-tACS) at 40 Hz with simultaneous electroencephalographic (EEG) recordings to study immediate electrophysiological effects during the selective entrainment of oscillatory gamma-band signatures. We found that interhemispheric functional connectivity was modulated in a predictable, phase-specific way: In-phase stimulation enhanced synchronization, anti-phase stimulation impaired functional coupling. Perceptual correlates of these connectivity changes were found in an ambiguous motion task, which strongly support the functional relevance of long-range neuronal coupling. Additionally, our results revealed a decrease in oscillatory alpha power in response to the entrainment of gamma band signatures. This finding provides causal evidence for the antagonistic role of alpha and gamma oscillations in the parieto-occipital cortex and confirms that the observed gamma band modulations were physiological in nature. Our results demonstrate that synchronized cortical network activity across several spatiotemporal scales is essential for conscious perception and cognition.},
  number = {12},
  journaltitle = {PLoS Biology},
  urldate = {2019-03-30},
  date = {2014-12-30},
  pages = {e1002031},
  author = {Helfrich, Randolph F. and Knepper, Hannah and Nolte, Guido and Str\"uber, Daniel and Rach, Stefan and Herrmann, Christoph S. and Schneider, Till R. and Engel, Andreas K.},
  editor = {Jensen, Ole},
  file = {/Users/qualia/Documents/Papers/Helfrich et al. - 2014 - Selective Modulation of Interhemispheric Functiona.pdf}
}

@article{Hermes2015,
  langid = {english},
  title = {Stimulus {{Dependence}} of {{Gamma Oscillations}} in {{Human Visual Cortex}}},
  volume = {25},
  issn = {1047-3211, 1460-2199},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhu091},
  doi = {10.1093/cercor/bhu091},
  abstract = {A striking feature of some field potential recordings in visual cortex is a rhythmic oscillation within the gamma band (30\textendash{}80 Hz). These oscillations have been proposed to underlie computations in perception, attention, and information transmission. Recent studies of cortical field potentials, including human electrocorticography (ECoG), have emphasized another signal within the gamma band, a nonoscillatory, broadband signal, spanning 80\textendash{}200 Hz. It remains unclear under what conditions gamma oscillations are elicited in visual cortex, whether they are necessary and ubiquitous in visual encoding, and what relationship they have to nonoscillatory, broadband field potentials. We demonstrate that ECoG responses in human visual cortex (V1/V2/V3) can include robust narrowband gamma oscillations, and that these oscillations are reliably elicited by some spatial contrast patterns (luminance gratings) but not by others (noise patterns and many natural images). The gamma oscillations can be conspicuous and robust, but because they are absent for many stimuli, which observers can see and recognize, the oscillations are not necessary for seeing. In contrast, all visual stimuli induced broadband spectral changes in ECoG responses. Asynchronous neural signals in visual cortex, reflected in the broadband ECoG response, can support transmission of information for perception and recognition in the absence of pronounced gamma oscillations.},
  number = {9},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2015-09},
  pages = {2951-2959},
  author = {Hermes, D. and Miller, K.J. and Wandell, B.A. and Winawer, J.},
  file = {/Users/qualia/Documents/Papers/Hermes et al. - 2015 - Stimulus Dependence of Gamma Oscillations in Human.pdf}
}

@article{HertA$g2014,
  langid = {english},
  title = {Analytical Approximations of the Firing Rate of an Adaptive Exponential Integrate-and-Fire Neuron in the Presence of Synaptic Noise},
  volume = {8},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2014.00116/abstract},
  doi = {10.3389/fncom.2014.00116},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-09-18},
  author = {Hert\~A\textcurrency{}g, Loreen and Durstewitz, Daniel and Brunel, Nicolas},
  file = {/Users/qualia/Documents/Papers/HertÃ¤g et al. - 2014 - Analytical approximations of the firing rate of an.pdf}
}

@article{Srivastava,
  langid = {english},
  title = {Dropout: {{A Simple Way}} to {{Prevent Neural Networks}} from {{Overfitting}}},
  abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different ``thinned'' networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
  pages = {30},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  file = {/Users/qualia/Documents/Papers/Srivastava et al. - Dropout A Simple Way to Prevent Neural Networks f.pdf}
}

@article{Hopcroft,
  langid = {english},
  title = {Foundations of {{Data Science}}},
  pages = {414},
  author = {Hopcroft, John and Kannan, Ravindran},
  file = {/Users/qualia/Documents/Papers/Hopcroft and Kannan - Foundations of Data Science.pdf}
}

@article{Horvath2015,
  langid = {english},
  title = {Evidence That Transcranial Direct Current Stimulation ({{tDCS}}) Generates Little-to-No Reliable Neurophysiologic Effect beyond {{MEP}} Amplitude Modulation in Healthy Human Subjects: {{A}} Systematic Review},
  volume = {66},
  issn = {00283932},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0028393214004394},
  doi = {10.1016/j.neuropsychologia.2014.11.021},
  shorttitle = {Evidence That Transcranial Direct Current Stimulation ({{tDCS}}) Generates Little-to-No Reliable Neurophysiologic Effect beyond {{MEP}} Amplitude Modulation in Healthy Human Subjects},
  abstract = {Background: Transcranial direct current stimulation (tDCS) is a form of neuromodulation that is increasingly being utilized to examine and modify a number of cognitive and behavioral measures. The theoretical mechanisms by which tDCS generates these changes are predicated upon a rather large neurophysiological literature. However, a robust systematic review of this neurophysiological data has not yet been undertaken. 28 29 Keywords: 30 Transcranial direct current stimulation (tDCS) 31 Systematic review 32 Neurophysiology 33 Transcranial magnetic stimulation (TMS) 34 Event related potential (ERP) 35 Electroencephalography (EEG) Functional magnetic resonance imaging 36 (fMRI) 37 38
Methods: tDCS data in healthy adults (18\textendash{}50) from every neurophysiological outcome measure reported by at least two different research groups in the literature was collected. When possible, data was pooled and quantitatively analyzed to assess significance. When pooling was not possible, data was qualitatively compared to assess reliability.
Results: Of the 30 neurophysiological outcome measures reported by at least two different research groups, tDCS was found to have a reliable effect on only one: MEP amplitude. Interestingly, the magnitude of this effect has been significantly decreasing over the last 14 years.
Conclusion: Our systematic review does not support the idea that tDCS has a reliable neurophysiological effect beyond MEP amplitude modulation \textendash{} though important limitations of this review (and conclusion) are discussed. This work raises questions concerning the mechanistic foundations and general efficacy of this device \textendash{} the implications of which extend to the steadily increasing tDCS psychological literature.},
  journaltitle = {Neuropsychologia},
  urldate = {2019-03-30},
  date = {2015-01},
  pages = {213-236},
  author = {Horvath, Jared Cooney and Forte, Jason D. and Carter, Olivia},
  file = {/Users/qualia/Documents/Papers/Horvath et al. - 2015 - Evidence that transcranial direct current stimulat.pdf}
}

@article{Hunt2014,
  langid = {english},
  title = {Hierarchical Competitions Subserving Multi-Attribute Choice},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3836},
  doi = {10.1038/nn.3836},
  number = {11},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-11},
  pages = {1613-1622},
  author = {Hunt, Laurence T and Dolan, Raymond J and Behrens, Timothy E J},
  file = {/Users/qualia/Documents/Papers/Hunt et al. - 2014 - Hierarchical competitions subserving multi-attribu.pdf}
}

@article{Jackson2014,
  langid = {english},
  title = {Reversal of Theta Rhythm Flow through Intact Hippocampal Circuits},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3803},
  doi = {10.1038/nn.3803},
  number = {10},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-10},
  pages = {1362-1370},
  author = {Jackson, Jesse and Amilhon, B\'en\'edicte and Goutagny, Romain and Bott, Jean-Bastien and Manseau, Fr\'ed\'eric and Kortleven, Christian and Bressler, Steven L and Williams, Sylvain},
  file = {/Users/qualia/Documents/Papers/Jackson et al. - 2014 - Reversal of theta rhythm flow through intact hippo.pdf}
}

@article{Jorgensen1987,
  eprinttype = {jstor},
  eprint = {2345415},
  langid = {english},
  title = {Exponential {{Dispersion Models}}},
  volume = {49},
  abstract = {We studygeneralpropertiesof the class of exponentialdispersionmodels,whichis the multivariategeneralizationof the errordistributionof Nelder and Wedderburn's(1972) generalizedlinear models. Since any given momentgeneratingfunctiongeneratesan exponentialdispersionmodel,thereexistsa multitudeof exponentialdispersionmodels, and some new examplesare introducedG. eneral resultson convolutionand asymptotic normalityofexponentialdispersionmodelsare presentedA. symptotitcheoryis discussed, includinga new small-dispersionasymptoticframeworkw, hichextendsthe domain of applicationoflarge-sampletheoryP. roceduresforconstructinngewexponentiadl ispersion models forcorrelateddata are introduced,includingmodels forlongitudinaldata and variancecomponentsT. he resultsof the paper unifyand generalizestandardresultsfor distributionsuch as the Poisson, the binomial,the negativebinomial,the normal,the gamma,and theinverseGaussian distributions.},
  number = {2},
  journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
  date = {1987},
  pages = {127-162},
  author = {Jorgensen, Bent},
  file = {/Users/qualia/Documents/Papers/Jorgensen - 1987 - Exponential Dispersion Models.pdf}
}

@article{Kann2014,
  langid = {english},
  title = {Highly {{Energized Inhibitory Interneurons}} Are a {{Central Element}} for {{Information Processing}} in {{Cortical Networks}}},
  volume = {34},
  issn = {0271-678X, 1559-7016},
  url = {http://journals.sagepub.com/doi/10.1038/jcbfm.2014.104},
  doi = {10.1038/jcbfm.2014.104},
  number = {8},
  journaltitle = {Journal of Cerebral Blood Flow \& Metabolism},
  urldate = {2019-03-30},
  date = {2014-08},
  pages = {1270-1282},
  author = {Kann, Oliver and Papageorgiou, Ismini E and Draguhn, Andreas},
  file = {/Users/qualia/Documents/Papers/Kann et al. - 2014 - Highly Energized Inhibitory Interneurons are a Cen.pdf}
}

@article{Kelly2014,
  langid = {english},
  title = {The {{Role}} of {{Thalamic Population Synchrony}} in the {{Emergence}} of {{Cortical Feature Selectivity}}},
  volume = {10},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1003418},
  doi = {10.1371/journal.pcbi.1003418},
  abstract = {In a wide range of studies, the emergence of orientation selectivity in primary visual cortex has been attributed to a complex interaction between feed-forward thalamic input and inhibitory mechanisms at the level of cortex. Although it is well known that layer 4 cortical neurons are highly sensitive to the timing of thalamic inputs, the role of the stimulus-driven timing of thalamic inputs in cortical orientation selectivity is not well understood. Here we show that the synchronization of thalamic firing contributes directly to the orientation tuned responses of primary visual cortex in a way that optimizes the stimulus information per cortical spike. From the recorded responses of geniculate X-cells in the anesthetized cat, we synthesized thalamic sub-populations that would likely serve as the synaptic input to a common layer 4 cortical neuron based on anatomical constraints. We used this synchronized input as the driving input to an integrate-and-fire model of cortical responses and demonstrated that the tuning properties match closely to those measured in primary visual cortex. By modulating the overall level of synchronization at the preferred orientation, we show that efficiency of information transmission in the cortex is maximized for levels of synchronization which match those reported in thalamic recordings in response to naturalistic stimuli, a property which is relatively invariant to the orientation tuning width. These findings indicate evidence for a more prominent role of the feed-forward thalamic input in cortical feature selectivity based on thalamic synchronization.},
  number = {1},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2014-01-09},
  pages = {e1003418},
  author = {Kelly, Sean T. and Kremkow, Jens and Jin, Jianzhong and Wang, Yushi and Wang, Qi and Alonso, Jose-Manuel and Stanley, Garrett B.},
  editor = {Graham, Lyle J.},
  file = {/Users/qualia/Documents/Papers/Kelly et al. - 2014 - The Role of Thalamic Population Synchrony in the E.pdf}
}

@article{Kunori2014,
  langid = {english},
  title = {Voltage-{{Sensitive Dye Imaging}} of {{Primary Motor Cortex Activity Produced}} by {{Ventral Tegmental Area Stimulation}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5286-13.2014},
  doi = {10.1523/JNEUROSCI.5286-13.2014},
  number = {26},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-06-25},
  pages = {8894-8903},
  author = {Kunori, N. and Kajiwara, R. and Takashima, I.},
  file = {/Users/qualia/Documents/Papers/Kunori et al. - 2014 - Voltage-Sensitive Dye Imaging of Primary Motor Cor.pdf}
}

@article{Lajoie2014,
  langid = {english},
  title = {Structured Chaos Shapes Spike-Response Noise Entropy in Balanced Neural Networks},
  volume = {8},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2014.00123/abstract},
  doi = {10.3389/fncom.2014.00123},
  abstract = {Large networks of sparsely coupled, excitatory and inhibitory cells occur throughout the brain. For many models of these networks, a striking feature is that their dynamics are chaotic and thus, are sensitive to small perturbations. How does this chaos manifest in the neural code? Specifically, how variable are the spike patterns that such a network produces in response to an input signal? To answer this, we derive a bound for a general measure of variability\textemdash{}spike-train entropy. This leads to important insights on the variability of multi-cell spike pattern distributions in large recurrent networks of spiking neurons responding to fluctuating inputs. The analysis is based on results from random dynamical systems theory and is complemented by detailed numerical simulations. We find that the spike pattern entropy is an order of magnitude lower than what would be extrapolated from single cells. This holds despite the fact that network coupling becomes vanishingly sparse as network size grows\textemdash{}a phenomenon that depends on ``extensive chaos,'' as previously discovered for balanced networks without stimulus drive. Moreover, we show how spike pattern entropy is controlled by temporal features of the inputs. Our findings provide insight into how neural networks may encode stimuli in the presence of inherently chaotic dynamics.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-10-02},
  author = {Lajoie, Guillaume and Thivierge, Jean-Philippe and Shea-Brown, Eric},
  file = {/Users/qualia/Documents/Papers/Lajoie et al. - 2014 - Structured chaos shapes spike-response noise entro.pdf}
}

@article{Lee2014,
  langid = {english},
  title = {Interneuron Subtypes and Orientation Tuning},
  volume = {508},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature13128},
  doi = {10.1038/nature13128},
  number = {7494},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2014-04},
  pages = {E1-E2},
  author = {Lee, Seung-Hee and Kwan, Alex C. and Dan, Yang},
  file = {/Users/qualia/Documents/Papers/Lee et al. - 2014 - Interneuron subtypes and orientation tuning.pdf}
}

@article{Lee2014a,
  langid = {english},
  title = {Two {{Functionally Distinct Networks}} of {{Gap Junction}}-{{Coupled Inhibitory Neurons}} in the {{Thalamic Reticular Nucleus}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0562-14.2014},
  doi = {10.1523/JNEUROSCI.0562-14.2014},
  number = {39},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-09-24},
  pages = {13170-13182},
  author = {Lee, S.-C. and Patrick, S. L. and Richardson, K. A. and Connors, B. W.},
  file = {/Users/qualia/Documents/Papers/Lee et al. - 2014 - Two Functionally Distinct Networks of Gap Junction.pdf}
}

@article{Litwin-Kumar2014,
  langid = {english},
  title = {Formation and Maintenance of Neuronal Assemblies through Synaptic Plasticity},
  volume = {5},
  issn = {2041-1723},
  url = {http://www.nature.com/articles/ncomms6319},
  doi = {10.1038/ncomms6319},
  number = {1},
  journaltitle = {Nature Communications},
  urldate = {2019-03-30},
  date = {2014-12},
  author = {Litwin-Kumar, Ashok and Doiron, Brent},
  file = {/Users/qualia/Documents/Papers/Litwin-Kumar and Doiron - 2014 - Formation and maintenance of neuronal assemblies t.pdf}
}

@article{DeLuca2014,
  langid = {english},
  title = {Statistically Rigorous Calculations Do Not Support Common Input and Long-Term Synchronization of Motor-Unit Firings},
  volume = {112},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00725.2013},
  doi = {10.1152/jn.00725.2013},
  number = {11},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2014-12},
  pages = {2729-2744},
  author = {De Luca, Carlo J. and Kline, Joshua C.},
  file = {/Users/qualia/Documents/Papers/De Luca and Kline - 2014 - Statistically rigorous calculations do not support.pdf}
}

@article{Marcus2014,
  langid = {english},
  title = {The Atoms of Neural Computation},
  volume = {346},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1261661},
  doi = {10.1126/science.1261661},
  number = {6209},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2014-10-31},
  pages = {551-552},
  author = {Marcus, G. and Marblestone, A. and Dean, T.},
  file = {/Users/qualia/Documents/Papers/Marcus et al. - 2014 - The atoms of neural computation.pdf}
}

@article{Marder2015,
  langid = {english},
  title = {Robust Circuit Rhythms in Small Circuits Arise from Variable Circuit Components and Mechanisms},
  volume = {31},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814002128},
  doi = {10.1016/j.conb.2014.10.012},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {156-163},
  author = {Marder, Eve and Goeritz, Marie L and Otopalik, Adriane G},
  file = {/Users/qualia/Documents/Papers/Marder et al. - 2015 - Robust circuit rhythms in small circuits arise fro 2.pdf;/Users/qualia/Documents/Papers/Marder et al. - 2015 - Robust circuit rhythms in small circuits arise fro.pdf}
}

@article{Marinelli2014,
  langid = {english},
  title = {Heterogeneity of Dopamine Neuron Activity across Traits and States},
  volume = {282},
  issn = {03064522},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0306452214006071},
  doi = {10.1016/j.neuroscience.2014.07.034},
  abstract = {Midbrain dopamine neurons fire irregularly, with interspersed clusters of high-frequency spikes, commonly called `bursts'. In this review we examine such heterogeneity in activity, and provide insight into how it can participate in psychiatric conditions such as drug addiction. We first describe several techniques used to evaluate dopamine neuron activity, and comment on the different measures that each provides. We next describe the activity of dopamine neurons in `basal' conditions. Specifically, we discuss how the use of anesthesia and reduced preparations may alter aspects of dopamine cell activity, and how there is heterogeneity across species and regions. We also describe how dopamine cell firing changes throughout the peri-adolescent period and how dopamine neuron activity differs across the population. In the final section, we discuss how dopamine neuron activity changes in response to life events. First, we focus attention on drugs of abuse. Drugs themselves change firing activity through a variety of mechanisms, with effects on firing while drug is present differing from those seen after drug discontinuation. We then review how stimuli that are rewarding, aversive, or salient can evoke changes in firing rate and discharge pattern of dopamine neurons, and provide behavioral relevance of dopamine signaling. Finally, we discuss how stress can modulate dopamine neuron firing and how this may contribute to the role that stressful experiences play in psychiatric disorders such as addiction and depression.},
  journaltitle = {Neuroscience},
  urldate = {2019-03-30},
  date = {2014-12},
  pages = {176-197},
  author = {Marinelli, M. and McCutcheon, J.E.},
  file = {/Users/qualia/Documents/Papers/Marinelli and McCutcheon - 2014 - Heterogeneity of dopamine neuron activity across t.pdf}
}

@article{Mejias2014,
  langid = {english},
  title = {Differential Effects of Excitatory and Inhibitory Heterogeneity on the Gain and Asynchronous State of Sparse Cortical Networks},
  volume = {8},
  issn = {1662-5188},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2014.00107/abstract},
  doi = {10.3389/fncom.2014.00107},
  abstract = {Recent experimental and theoretical studies have highlighted the importance of cell-to-cell differences in the dynamics and functions of neural networks, such as in different types of neural coding or synchronization. It is still not known, however, how neural heterogeneity can affect cortical computations, or impact the dynamics of typical cortical circuits constituted of sparse excitatory and inhibitory networks. In this work, we analytically and numerically study the dynamics of a typical cortical circuit with a certain level of neural heterogeneity. Our circuit includes realistic features found in real cortical populations, such as network sparseness, excitatory, and inhibitory subpopulations of neurons, and different cell-to-cell heterogeneities for each type of population in the system. We find highly differentiated roles for heterogeneity, depending on the subpopulation in which it is found. In particular, while heterogeneity among excitatory neurons non-linearly increases the mean firing rate and linearizes the f-I curves, heterogeneity among inhibitory neurons may decrease the network activity level and induces divisive gain effects in the f-I curves of the excitatory cells, providing an effective gain control mechanism to influence information flow. In addition, we compute the conditions for stability of the network activity, finding that the synchronization onset is robust to inhibitory heterogeneity, but it shifts to lower input levels for higher excitatory heterogeneity. Finally, we provide an extension of recently reported heterogeneity-induced mechanisms for signal detection under rate coding, and we explore the validity of our findings when multiple sources of heterogeneity are present. These results allow for a detailed characterization of the role of neural heterogeneity in asynchronous cortical networks.},
  journaltitle = {Frontiers in Computational Neuroscience},
  urldate = {2019-03-30},
  date = {2014-09-12},
  author = {Mejias, Jorge F. and Longtin, Andr\~A\textcopyright{}},
  file = {/Users/qualia/Documents/Papers/Mejias and Longtin - 2014 - Differential effects of excitatory and inhibitory .pdf}
}

@article{Mizuseki2013,
  langid = {english},
  title = {Theta Oscillations Decrease Spike Synchrony in the Hippocampus and Entorhinal Cortex},
  volume = {369},
  issn = {0962-8436, 1471-2970},
  url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2012.0530},
  doi = {10.1098/rstb.2012.0530},
  number = {1635},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  urldate = {2019-03-30},
  date = {2013-12-23},
  pages = {20120530-20120530},
  author = {Mizuseki, K. and Buzsaki, G.},
  file = {/Users/qualia/Documents/Papers/Mizuseki and Buzsaki - 2013 - Theta oscillations decrease spike synchrony in the.pdf}
}

@article{Mishina2014,
  langid = {english},
  title = {Exploration of Genetically Encoded Voltage Indicators Based on a Chimeric Voltage Sensing Domain},
  volume = {7},
  issn = {1662-5099},
  url = {http://journal.frontiersin.org/article/10.3389/fnmol.2014.00078/abstract},
  doi = {10.3389/fnmol.2014.00078},
  abstract = {Deciphering how the brain generates cognitive function from patterns of electrical signals is one of the ultimate challenges in neuroscience. To this end, it would be highly desirable to monitor the activities of very large numbers of neurons while an animal engages in complex behaviors. Optical imaging of electrical activity using genetically encoded voltage indicators (GEVIs) has the potential to meet this challenge. Currently prevalent GEVIs are based on the voltage-sensitive fluorescent protein (VSFP) prototypical design or on the voltage-dependent state transitions of microbial opsins.We recently introduced a newVSFP design in which the voltage-sensing domain (VSD) is sandwiched between a fluorescence resonance energy transfer pair of fluorescent proteins (termed VSFP-Butterflies) and also demonstrated a series of chimeric VSD in which portions of the VSD of Ciona intestinalis voltage-sensitive phosphatase are substituted by homologous portions of a voltage-gated potassium channel subunit.These chimeric VSD had faster sensing kinetics than that of the native Ci-VSD. Here, we describe a new set of VSFPs that combine chimeric VSD with the Butterfly structure. We show that these chimeric VSFP-Butterflies can report membrane voltage oscillations of up to 200 Hz in cultured cells and report sensory evoked cortical population responses in living mice. This class of GEVIs may be suitable for imaging of brain rhythms in behaving mammalians.},
  journaltitle = {Frontiers in Molecular Neuroscience},
  urldate = {2019-03-30},
  date = {2014-09-29},
  author = {Mishina, Yukiko and Mutoh, Hiroki and Song, Chenchen and Kn\~A\textparagraph{}pfel, Thomas},
  file = {/Users/qualia/Documents/Papers/Mishina et al. - 2014 - Exploration of genetically encoded voltage indicat.pdf}
}

@article{Moca2014,
  langid = {english},
  title = {Membrane {{Resonance Enables Stable}} and {{Robust Gamma Oscillations}}},
  volume = {24},
  issn = {1460-2199, 1047-3211},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhs293},
  doi = {10.1093/cercor/bhs293},
  abstract = {Neuronal mechanisms underlying beta/gamma oscillations (20\textendash{}80 Hz) are not completely understood. Here, we show that in vivo beta/gamma oscillations in the cat visual cortex sometimes exhibit remarkably stable frequency even when inputs fluctuate dramatically. Enhanced frequency stability is associated with stronger oscillations measured in individual units and larger power in the local field potential. Simulations of neuronal circuitry demonstrate that membrane properties of inhibitory interneurons strongly determine the characteristics of emergent oscillations. Exploration of networks containing either integrator or resonator inhibitory interneurons revealed that: (i) Resonance, as opposed to integration, promotes robust oscillations with large power and stable frequency via a mechanism called RING (Resonance INduced Gamma); resonance favors synchronization by reducing phase delays between interneurons and imposes bounds on oscillation cycle duration; (ii) Stability of frequency and robustness of the oscillation also depend on the relative timing of excitatory and inhibitory volleys within the oscillation cycle; (iii) RING can reproduce characteristics of both Pyramidal INterneuron Gamma (PING) and INterneuron Gamma (ING), transcending such classifications; (iv) In RING, robust gamma oscillations are promoted by slow but are impaired by fast inputs. Results suggest that interneuronal membrane resonance can be an important ingredient for generation of robust gamma oscillations having stable frequency.},
  number = {1},
  journaltitle = {Cerebral Cortex},
  urldate = {2019-03-30},
  date = {2014-01},
  pages = {119-142},
  author = {Moca, Vasile V. and Nikoli\'c, Danko and Singer, Wolf and Mure{\c s}an, Raul C.},
  file = {/Users/qualia/Documents/Papers/Moca et al. - 2014 - Membrane Resonance Enables Stable and Robust Gamma 2.pdf;/Users/qualia/Documents/Papers/Moca et al. - 2014 - Membrane Resonance Enables Stable and Robust Gamma.pdf}
}

@article{Ostojic2014,
  langid = {english},
  title = {Two Types of Asynchronous Activity in Networks of Excitatory and Inhibitory Spiking Neurons},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3658},
  doi = {10.1038/nn.3658},
  number = {4},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-04},
  pages = {594-600},
  author = {Ostojic, Srdjan},
  file = {/Users/qualia/Documents/Papers/Ostojic - 2014 - Two types of asynchronous activity in networks of .pdf}
}

@article{Onslow2014,
  langid = {english},
  title = {A {{Canonical Circuit}} for {{Generating Phase}}-{{Amplitude Coupling}}},
  volume = {9},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0102591},
  doi = {10.1371/journal.pone.0102591},
  abstract = {Phase amplitude coupling' (PAC) in oscillatory neural activity describes a phenomenon whereby the amplitude of higher frequency activity is modulated by the phase of lower frequency activity. Such coupled oscillatory activity \textendash{} also referred to as `cross-frequency coupling' or `nested rhythms' \textendash{} has been shown to occur in a number of brain regions and at behaviorally relevant time points during cognitive tasks; this suggests functional relevance, but the circuit mechanisms of PAC generation remain unclear. In this paper we present a model of a canonical circuit for generating PAC activity, showing how interconnected excitatory and inhibitory neural populations can be periodically shifted in to and out of oscillatory firing patterns by afferent drive, hence generating higher frequency oscillations phase-locked to a lower frequency, oscillating input signal. Since many brain regions contain mutually connected excitatory-inhibitory populations receiving oscillatory input, the simplicity of the mechanism generating PAC in such networks may explain the ubiquity of PAC across diverse neural systems and behaviors. Analytic treatment of this circuit as a nonlinear dynamical system demonstrates how connection strengths and inputs to the populations can be varied in order to change the extent and nature of PAC activity, importantly which phase of the lower frequency rhythm the higher frequency activity is locked to. Consequently, this model can inform attempts to associate distinct types of PAC with different network topologies and physiologies in real data.},
  number = {8},
  journaltitle = {PLoS ONE},
  urldate = {2019-03-30},
  date = {2014-08-19},
  pages = {e102591},
  author = {Onslow, Angela C. E. and Jones, Matthew W. and Bogacz, Rafal},
  editor = {Tort, Adriano B. L.},
  file = {/Users/qualia/Documents/Papers/Onslow et al. - 2014 - A Canonical Circuit for Generating Phase-Amplitude.pdf}
}

@article{Pajevic2014,
  langid = {english},
  title = {Role of Myelin Plasticity in Oscillations and Synchrony of Neuronal Activity},
  volume = {276},
  issn = {03064522},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0306452213009470},
  doi = {10.1016/j.neuroscience.2013.11.007},
  abstract = {Conduction time is typically ignored in computational models of neural network function. Here we consider the effects of conduction delays on the synchrony of neuronal activity and neural oscillators, and evaluate the consequences of allowing conduction velocity (CV) to be regulated adaptively. We propose that CV variation, mediated by myelin, could provide an important mechanism of activity-dependent nervous system plasticity. Even small changes in CV, resulting from small changes in myelin thickness or nodal structure, could have profound effects on neuronal network function in terms of spike-time arrival, oscillation frequency, oscillator coupling, and propagation of brain waves. For example, a conduction delay of 5 ms could change interactions of two coupled oscillators at the upper end of the gamma frequency range ({$\sim$}100 Hz) from constructive to destructive interference; delays smaller than 1 ms could change the phase by 30\textdegree, significantly affecting signal amplitude. Myelin plasticity, as another form of activitydependent plasticity, is relevant not only to nervous system development but also to complex information processing tasks that involve coupling and synchrony among different brain rhythms. We use coupled oscillator models with time delays to explore the importance of adaptive time delays and adaptive synaptic strengths. The impairment of activity-dependent myelination and the loss of adaptive time delays may contribute to disorders where hyper- and hypo-synchrony of neuronal firing leads to dysfunction (e.g., dyslexia, schizophrenia, epilepsy).},
  journaltitle = {Neuroscience},
  urldate = {2019-03-30},
  date = {2014-09},
  pages = {135-147},
  author = {Pajevic, S. and Basser, P.J. and Fields, R.D.},
  file = {/Users/qualia/Documents/Papers/Pajevic et al. - 2014 - Role of myelin plasticity in oscillations and sync.pdf}
}

@article{Porter2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1403.7663},
  primaryClass = {cond-mat, physics:nlin, physics:physics},
  langid = {english},
  title = {Dynamical {{Systems}} on {{Networks}}: {{A Tutorial}}},
  url = {http://arxiv.org/abs/1403.7663},
  shorttitle = {Dynamical {{Systems}} on {{Networks}}},
  abstract = {We give a tutorial for the study of dynamical systems on networks. We focus especially on "simple" situations that are tractable analytically, because they can be very insightful and provide useful springboards for the study of more complicated scenarios. We briefly motivate why examining dynamical systems on networks is interesting and important, and we then give several fascinating examples and discuss some theoretical results. We also briefly discuss dynamical systems on dynamical (i.e., time-dependent) networks, overview software implementations, and give an outlook on the field.},
  urldate = {2019-03-30},
  date = {2014-03-29},
  keywords = {Computer Science - Social and Information Networks,Condensed Matter - Disordered Systems and Neural Networks,Nonlinear Sciences - Adaptation and Self-Organizing Systems,Condensed Matter - Statistical Mechanics,Physics - Physics and Society},
  author = {Porter, Mason A. and Gleeson, James P.},
  file = {/Users/qualia/Documents/Papers/Porter and Gleeson - 2014 - Dynamical Systems on Networks A Tutorial.pdf}
}

@article{Principe2015,
  langid = {english},
  title = {Representing and Decomposing Neural Potential Signals},
  volume = {31},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814001603},
  doi = {10.1016/j.conb.2014.07.023},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {13-17},
  author = {Principe, Jose C and Brockmeier, Austin J},
  file = {/Users/qualia/Documents/Papers/Principe and Brockmeier - 2015 - Representing and decomposing neural potential sign.pdf}
}

@article{Reato2015,
  langid = {english},
  title = {Lasting Modulation of in Vitro Oscillatory Activity with Weak Direct Current Stimulation},
  volume = {113},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00208.2014},
  doi = {10.1152/jn.00208.2014},
  number = {5},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2015-03},
  pages = {1334-1341},
  author = {Reato, Davide and Bikson, Marom and Parra, Lucas C.},
  file = {/Users/qualia/Documents/Papers/Reato et al. - 2015 - Lasting modulation of in vitro oscillatory activit.pdf}
}

@article{Ramscar2014,
  langid = {english},
  title = {The {{Myth}} of {{Cognitive Decline}}: {{Non}}-{{Linear Dynamics}} of {{Lifelong Learning}}},
  volume = {6},
  issn = {17568757},
  url = {http://doi.wiley.com/10.1111/tops.12078},
  doi = {10.1111/tops.12078},
  shorttitle = {The {{Myth}} of {{Cognitive Decline}}},
  abstract = {As adults age, their performance on many psychometric tests changes systematically, a finding that is widely taken to reveal that cognitive information-processing capacities decline across adulthood. Contrary to this, we suggest that older adults' changing performance reflects memory search demands, which escalate as experience grows. A series of simulations show how the performance patterns observed across adulthood emerge naturally in learning models as they acquire knowledge. The simulations correctly identify greater variation in the cognitive performance of older adults, and successfully predict that older adults will show greater sensitivity to fine-grained differences in the properties of test stimuli than younger adults. Our results indicate that older adults' performance on cognitive tests reflects the predictable consequences of learning on informationprocessing, and not cognitive decline. We consider the implications of this for our scientific and cultural understanding of aging.},
  number = {1},
  journaltitle = {Topics in Cognitive Science},
  urldate = {2019-03-30},
  date = {2014-01},
  pages = {5-42},
  author = {Ramscar, Michael and Hendrix, Peter and Shaoul, Cyrus and Milin, Petar and Baayen, Harald},
  file = {/Users/qualia/Documents/Papers/Ramscar et al. - 2014 - The Myth of Cognitive Decline Non-Linear Dynamics.pdf}
}

@article{Renart2014,
  langid = {english},
  title = {Variability in Neural Activity and Behavior},
  volume = {25},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814000488},
  doi = {10.1016/j.conb.2014.02.013},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2014-04},
  pages = {211-220},
  author = {Renart, Alfonso and Machens, Christian K},
  file = {/Users/qualia/Documents/Papers/Renart and Machens - 2014 - Variability in neural activity and behavior.pdf}
}

@article{Mirollo1990,
  eprinttype = {jstor},
  eprint = {2101911},
  langid = {english},
  title = {Synchronization of {{Pulse}}-{{Coupled Biological Oscillators}}},
  volume = {50},
  abstract = {A simplemodel forsynchronousfiringof biologicaloscillatorsbased on Peskin'smodel of thecardiacpacemaker[Mathematicaal spectsofheartphysiologyC,ourantInstitutoefMathematicalSciences, New York UniversityN, ew York, 1975,pp. 268-278] is studied.The model consistsof a populationof identicalintegrate-and-fiorsecillators.The couplingbetweenoscillatorsis pulsatile:whena givenoscillator fires,it pulls theothersup by a fixedamount,or bringsthemto thefiringthresholdw, hicheveris less. The main resultis thatforalmostall initialconditions,thepopulationevolvesto a statein whichall the oscillatorsare firingsynchronouslyT. he relationshipbetweenthe model and real communitiesof biologicaloscillatorsis discussed;examplesincludepopulationsofsynchronouslyflashingfirefliesc,rickets thatchirpinunison,electricallysynchronoups acemakercells,and groupsofwomenwhosemenstruaclycles become mutuallysynchronized.},
  number = {6},
  journaltitle = {SIAM Journal on Applied Mathematics},
  date = {1990},
  pages = {1645-1662},
  author = {Mirollo, Renato E. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/Mirollo and Strogatz - 1990 - Synchronization of Pulse-Coupled Biological Oscill.pdf}
}

@article{Ryglewski2014,
  langid = {english},
  title = {Dendrites Are Dispensable for Basic Motoneuron Function but Essential for Fine Tuning of Behavior},
  volume = {111},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1416247111},
  doi = {10.1073/pnas.1416247111},
  number = {50},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2014-12-16},
  pages = {18049-18054},
  author = {Ryglewski, Stefanie and Kadas, Dimitrios and Hutchinson, Katie and Schuetzler, Natalie and Vonhoff, Fernando and Duch, Carsten},
  file = {/Users/qualia/Documents/Papers/Ryglewski et al. - 2014 - Dendrites are dispensable for basic motoneuron fun.pdf}
}

@article{Saalmann2014,
  langid = {english},
  title = {Intralaminar and Medial Thalamic Influence on Cortical Synchrony, Information Transmission and Cognition},
  volume = {8},
  issn = {1662-5137},
  url = {http://journal.frontiersin.org/article/10.3389/fnsys.2014.00083/abstract},
  doi = {10.3389/fnsys.2014.00083},
  abstract = {The intralaminar and medial thalamic nuclei are part of the higher-order thalamus, which receives little sensory input, and instead forms extensive cortico-thalamo-cortical pathways. The large mediodorsal thalamic nucleus predominantly connects with the prefrontal cortex, the adjacent intralaminar nuclei connect with fronto-parietal cortex, and the midline thalamic nuclei connect with medial prefrontal cortex and medial temporal lobe. Taking into account this connectivity pattern, it is not surprising that the intralaminar and medial thalamus has been implicated in a variety of cognitive functions, including memory processing, attention and orienting, as well as reward-based behavior. This review addresses how the intralaminar and medial thalamus may regulate information transmission in cortical circuits. A key neural mechanism may involve intralaminar and medial thalamic neurons modulating the degree of synchrony between different groups of cortical neurons according to behavioral demands. Such a thalamic-mediated synchronization mechanism may give rise to large-scale integration of information across multiple cortical circuits, consequently influencing the level of arousal and consciousness. Overall, the growing evidence supports a general role for the higher-order thalamus in the control of cortical information transmission and cognitive processing.},
  journaltitle = {Frontiers in Systems Neuroscience},
  urldate = {2019-03-30},
  date = {2014-05-09},
  author = {Saalmann, Yuri B.},
  file = {/Users/qualia/Documents/Papers/Saalmann - 2014 - Intralaminar and medial thalamic influence on cort.pdf}
}

@article{Schneider2014,
  langid = {english},
  title = {Linking {{Macroscopic}} with {{Microscopic Neuroanatomy Using Synthetic Neuronal Populations}}},
  volume = {10},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1003921},
  doi = {10.1371/journal.pcbi.1003921},
  abstract = {Dendritic morphology has been shown to have a dramatic impact on neuronal function. However, population features such as the inherent variability in dendritic morphology between cells belonging to the same neuronal type are often overlooked when studying computation in neural networks. While detailed models for morphology and electrophysiology exist for many types of single neurons, the role of detailed single cell morphology in the population has not been studied quantitatively or computationally. Here we use the structural context of the neural tissue in which dendritic trees exist to drive their generation in silico. We synthesize the entire population of dentate gyrus granule cells, the most numerous cell type in the hippocampus, by growing their dendritic trees within their characteristic dendritic fields bounded by the realistic structural context of (1) the granule cell layer that contains all somata and (2) the molecular layer that contains the dendritic forest. This process enables branching statistics to be linked to larger scale neuroanatomical features. We find large differences in dendritic total length and individual path length measures as a function of location in the dentate gyrus and of somatic depth in the granule cell layer. We also predict the number of unique granule cell dendrites invading a given volume in the molecular layer. This work enables the complete population-level study of morphological properties and provides a framework to develop complex and realistic neural network models.},
  number = {10},
  journaltitle = {PLoS Computational Biology},
  urldate = {2019-03-30},
  date = {2014-10-23},
  pages = {e1003921},
  author = {Schneider, Calvin J. and Cuntz, Hermann and Soltesz, Ivan},
  editor = {Hilgetag, Claus C.},
  file = {/Users/qualia/Documents/Papers/Schneider et al. - 2014 - Linking Macroscopic with Microscopic Neuroanatomy .pdf}
}

@article{Scott2014,
  langid = {english},
  title = {Voltage {{Imaging}} of {{Waking Mouse Cortex Reveals Emergence}} of {{Critical Neuronal Dynamics}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3474-14.2014},
  doi = {10.1523/JNEUROSCI.3474-14.2014},
  number = {50},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-12-10},
  pages = {16611-16620},
  author = {Scott, G. and Fagerholm, E. D. and Mutoh, H. and Leech, R. and Sharp, D. J. and Shew, W. L. and Knopfel, T.},
  file = {/Users/qualia/Documents/Papers/Scott et al. - 2014 - Voltage Imaging of Waking Mouse Cortex Reveals Eme.pdf}
}

@article{Sharpee2014,
  langid = {english},
  title = {Toward {{Functional Classification}} of {{Neuronal Types}}},
  volume = {83},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627314007417},
  doi = {10.1016/j.neuron.2014.08.040},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2014-09},
  pages = {1329-1334},
  author = {Sharpee, Tatyana O.},
  file = {/Users/qualia/Documents/Papers/Sharpee - 2014 - Toward Functional Classification of Neuronal Types.pdf}
}

@article{Stimberg2014,
  langid = {english},
  title = {Equation-Oriented Specification of Neural Models for Simulations},
  volume = {8},
  issn = {1662-5196},
  url = {http://journal.frontiersin.org/article/10.3389/fninf.2014.00006/abstract},
  doi = {10.3389/fninf.2014.00006},
  abstract = {Simulating biological neuronal networks is a core method of research in computational neuroscience. A full specification of such a network model includes a description of the dynamics and state changes of neurons and synapses, as well as the synaptic connectivity patterns and the initial values of all parameters. A standard approach in neuronal modeling software is to build network models based on a library of pre-defined components and mechanisms; if a model component does not yet exist, it has to be defined in a special-purpose or general low-level language and potentially be compiled and linked with the simulator. Here we propose an alternative approach that allows flexible definition of models by writing textual descriptions based on mathematical notation. We demonstrate that this approach allows the definition of a wide range of models with minimal syntax. Furthermore, such explicit model descriptions allow the generation of executable code for various target languages and devices, since the description is not tied to an implementation. Finally, this approach also has advantages for readability and reproducibility, because the model description is fully explicit, and because it can be automatically parsed and transformed into formatted descriptions. The presented approach has been implemented in the Brian2 simulator.},
  journaltitle = {Frontiers in Neuroinformatics},
  urldate = {2019-03-30},
  date = {2014},
  author = {Stimberg, Marcel and Goodman, Dan F. M. and Benichoux, Victor and Brette, Romain},
  file = {/Users/qualia/Documents/Papers/Stimberg et al. - 2014 - Equation-oriented specification of neural models f.pdf}
}

@article{Tognoli2014,
  langid = {english},
  title = {Enlarging the Scope: Grasping Brain Complexity},
  volume = {8},
  issn = {1662-5137},
  url = {http://journal.frontiersin.org/article/10.3389/fnsys.2014.00122/abstract},
  doi = {10.3389/fnsys.2014.00122},
  shorttitle = {Enlarging the Scope},
  journaltitle = {Frontiers in Systems Neuroscience},
  urldate = {2019-03-30},
  date = {2014-06-25},
  author = {Tognoli, Emmanuelle and Kelso, J. A. Scott},
  file = {/Users/qualia/Documents/Papers/Tognoli and Kelso - 2014 - Enlarging the scope grasping brain complexity.pdf}
}

@article{Tompson2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1411.4280},
  primaryClass = {cs},
  langid = {english},
  title = {Efficient {{Object Localization Using Convolutional Networks}}},
  url = {http://arxiv.org/abs/1411.4280},
  abstract = {Recent state-of-the-art performance on human-body pose estimation has been achieved with Deep Convolutional Networks (ConvNets). Traditional ConvNet architectures include pooling layers which reduce computational requirements, introduce invariance and prevent over-training. These benefits of pooling come at the cost of reduced localization accuracy. We introduce a novel architecture which includes an efficient `position refinement' model that is trained to estimate the joint offset location within a small region of the image. This refinement model is jointly trained in cascade with a state-of-the-art ConvNet model [21] to achieve improved accuracy in human joint location estimation. We show that the variance of our detector approaches the variance of human annotations on the FLIC [20] dataset and outperforms all existing approaches on the MPII-human-pose dataset [1].},
  urldate = {2019-03-30},
  date = {2014-11-16},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Tompson, Jonathan and Goroshin, Ross and Jain, Arjun and LeCun, Yann and Bregler, Christopher},
  file = {/Users/qualia/Documents/Papers/Tompson et al. - 2014 - Efficient Object Localization Using Convolutional .pdf}
}

@article{Tognoli2014a,
  langid = {english},
  title = {The {{Metastable Brain}}},
  volume = {81},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627313011835},
  doi = {10.1016/j.neuron.2013.12.022},
  number = {1},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2014-01},
  pages = {35-48},
  author = {Tognoli, Emmanuelle and Kelso, J. A. Scott},
  file = {/Users/qualia/Documents/Papers/Tognoli and Kelso - 2014 - The Metastable Brain.pdf}
}

@article{Truccolo2014,
  langid = {english},
  title = {Neuronal {{Ensemble Synchrony}} during {{Human Focal Seizures}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4567-13.2014},
  doi = {10.1523/JNEUROSCI.4567-13.2014},
  number = {30},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-07-23},
  pages = {9927-9944},
  author = {Truccolo, W. and Ahmed, O. J. and Harrison, M. T. and Eskandar, E. N. and Cosgrove, G. R. and Madsen, J. R. and Blum, A. S. and Potter, N. S. and Hochberg, L. R. and Cash, S. S.},
  file = {/Users/qualia/Documents/Papers/Truccolo et al. - 2014 - Neuronal Ensemble Synchrony during Human Focal Sei.pdf}
}

@article{Goris2014,
  langid = {english},
  title = {Partitioning Neuronal Variability},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3711},
  doi = {10.1038/nn.3711},
  number = {6},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-06},
  pages = {858-865},
  author = {Goris, Robbe L T and Movshon, J Anthony and Simoncelli, Eero P},
  file = {/Users/qualia/Documents/Papers/Goris et al. - 2014 - Partitioning neuronal variability.pdf}
}

@article{vonNicolai2014,
  langid = {english},
  title = {Corticostriatal {{Coordination}} through {{Coherent Phase}}-{{Amplitude Coupling}}},
  volume = {34},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5007-13.2014},
  doi = {10.1523/JNEUROSCI.5007-13.2014},
  number = {17},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2014-04-23},
  pages = {5938-5948},
  author = {von Nicolai, C. and Engler, G. and Sharott, A. and Engel, A. K. and Moll, C. K. and Siegel, M.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/von Nicolai et al. - 2014 - Corticostriatal Coordination through Coherent Phas.pdf}
}

@article{Widmann2015,
  langid = {english},
  title = {Digital Filter Design for Electrophysiological Data \textendash{} a Practical Approach},
  volume = {250},
  issn = {01650270},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027014002866},
  doi = {10.1016/j.jneumeth.2014.08.002},
  abstract = {Background: Filtering is a ubiquitous step in the preprocessing of electroencephalographic (EEG) and magnetoencephalographic (MEG) data. Besides the intended effect of the attenuation of signal components considered as noise, filtering can also result in various unintended adverse filter effects (distortions such as smoothing) and filter artifacts.
Method: We give some practical guidelines for the evaluation of filter responses (impulse and frequency response) and the selection of filter types (high-pass/low-pass/band-pass/band-stop; finite/infinite impulse response, FIR/IIR) and filter parameters (cutoff frequencies, filter order and roll-off, ripple, delay and causality) to optimize signal-to-noise ratio and avoid or reduce signal distortions for selected electrophysiological applications.
Results: Various filter implementations in common electrophysiology software packages are introduced and discussed. Resulting filter responses are compared and evaluated.
Conclusion: We present strategies for recognizing common adverse filter effects and filter artifacts and demonstrate them in practical examples. Best practices and recommendations for the selection and reporting of filter parameters, limitations, and alternatives to filtering are discussed.},
  journaltitle = {Journal of Neuroscience Methods},
  urldate = {2019-03-30},
  date = {2015-07},
  pages = {34-46},
  author = {Widmann, Andreas and Schr\"oger, Erich and Maess, Burkhard},
  file = {/Users/qualia/Documents/Papers/Widmann et al. - 2015 - Digital filter design for electrophysiological dat.pdf}
}

@article{Womelsdorf2014,
  langid = {english},
  title = {Dynamic Circuit Motifs Underlying Rhythmic Gain Control, Gating and Integration},
  volume = {17},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3764},
  doi = {10.1038/nn.3764},
  number = {8},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2014-08},
  pages = {1031-1039},
  author = {Womelsdorf, Thilo and Valiante, Taufik A and Sahin, Ned T and Miller, Kai J and Tiesinga, Paul},
  file = {/Users/qualia/Documents/Papers/Womelsdorf et al. - 2014 - Dynamic circuit motifs underlying rhythmic gain co.pdf}
}

@article{Xue2014,
  langid = {english},
  title = {Equalizing Excitation\textendash{}Inhibition Ratios across Visual Cortical Neurons},
  volume = {511},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/doifinder/10.1038/nature13321},
  doi = {10.1038/nature13321},
  number = {7511},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2014-06-22},
  pages = {596-600},
  author = {Xue, Mingshan and Atallah, Bassam V. and Scanziani, Massimo},
  file = {/Users/qualia/Documents/Papers/Xue et al. - 2014 - Equalizing excitation–inhibition ratios across vis.pdf}
}

@article{Young2014,
  langid = {english},
  title = {Differential Effects of Aging on Dendritic Spines in Visual Cortex and Prefrontal Cortex of the Rhesus Monkey},
  volume = {274},
  issn = {03064522},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0306452214003911},
  doi = {10.1016/j.neuroscience.2014.05.008},
  journaltitle = {Neuroscience},
  urldate = {2019-03-30},
  date = {2014-08},
  pages = {33-43},
  author = {Young, M.E. and Ohm, D.T. and Dumitriu, D. and Rapp, P.R. and Morrison, J.H.},
  file = {/Users/qualia/Documents/Papers/Young et al. - 2014 - Differential effects of aging on dendritic spines .pdf}
}

@article{Anastassiou2015,
  langid = {english},
  title = {Ephaptic Coupling to Endogenous Electric Field Activity: Why Bother?},
  volume = {31},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814001809},
  doi = {10.1016/j.conb.2014.09.002},
  shorttitle = {Ephaptic Coupling to Endogenous Electric Field Activity},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {95-103},
  author = {Anastassiou, Costas A and Koch, Christof},
  file = {/Users/qualia/Documents/Papers/Anastassiou and Koch - 2015 - Ephaptic coupling to endogenous electric field act.pdf}
}

@article{Amilhon2015,
  langid = {english},
  title = {Parvalbumin {{Interneurons}} of {{Hippocampus Tune Population Activity}} at {{Theta Frequency}}},
  volume = {86},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315004341},
  doi = {10.1016/j.neuron.2015.05.027},
  abstract = {Hippocampal theta rhythm arises from a combination of recently described intrinsic theta oscillators and inputs from multiple brain areas. Interneurons expressing the markers parvalbumin (PV) and somatostatin (SOM) are leading candidates to participate in intrinsic rhythm generation and principal cell (PC) coordination in distal CA1 and subiculum. We tested their involvement by optogenetically activating and silencing PV or SOM interneurons in an intact hippocampus preparation that preserves intrinsic connections and oscillates spontaneously at theta frequencies. Despite evidence suggesting that SOM interneurons are crucial for theta, optogenetic manipulation of these interneurons modestly influenced theta rhythm. However, SOM interneurons were able to strongly modulate temporoammonic inputs. In contrast, activation of PV interneurons powerfully controlled PC network and rhythm generation optimally at 8 Hz, while continuously silencing them disrupted theta. Our results thus demonstrate a pivotal role of PV but not SOM interneurons for PC synchronization and the emergence of intrinsic hippocampal theta.},
  number = {5},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-06},
  pages = {1277-1289},
  author = {Amilhon, B\'en\'edicte and Huh, Carey Y.L. and Manseau, Fr\'ed\'eric and Ducharme, Guillaume and Nichol, Heather and Adamantidis, Antoine and Williams, Sylvain},
  file = {/Users/qualia/Documents/Papers/Amilhon et al. - 2015 - Parvalbumin Interneurons of Hippocampus Tune Popul.pdf}
}

@article{Apps2015,
  langid = {english},
  title = {Vicarious {{Reinforcement Learning Signals When Instructing Others}}},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3669-14.2015},
  doi = {10.1523/JNEUROSCI.3669-14.2015},
  number = {7},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2015-02-18},
  pages = {2904-2913},
  author = {Apps, M. A. J. and Lesage, E. and Ramnani, N.},
  file = {/Users/qualia/Documents/Papers/Apps et al. - 2015 - Vicarious Reinforcement Learning Signals When Inst.pdf}
}

@article{Beggs2015,
  langid = {english},
  title = {Editorial: {{Can There Be}} a {{Physics}} of the {{Brain}}?},
  volume = {114},
  issn = {0031-9007, 1079-7114},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.114.220001},
  doi = {10.1103/PhysRevLett.114.220001},
  shorttitle = {Editorial},
  number = {22},
  journaltitle = {Physical Review Letters},
  urldate = {2019-03-30},
  date = {2015-06-01},
  author = {Beggs, John},
  file = {/Users/qualia/Documents/Papers/Beggs - 2015 - Editorial Can There Be a Physics of the Brain.pdf}
}

@article{Bastos2015,
  langid = {english},
  title = {Communication through Coherence with Inter-Areal Delays},
  volume = {31},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814002165},
  doi = {10.1016/j.conb.2014.11.001},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {173-180},
  author = {Bastos, Andre M and Vezoli, Julien and Fries, Pascal},
  file = {/Users/qualia/Documents/Papers/Bastos et al. - 2015 - Communication through coherence with inter-areal d.pdf}
}

@article{Bosco2015,
  langid = {english},
  title = {Correlational Effect Size Benchmarks.},
  volume = {100},
  issn = {1939-1854, 0021-9010},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0038047},
  doi = {10.1037/a0038047},
  abstract = {Effect size information is essential for the scientific enterprise and plays an increasingly central role in the scientific process. We extracted 147,328 correlations and developed a hierarchical taxonomy of variables reported in Journal of Applied Psychology and Personnel Psychology from 1980 to 2010 to produce empirical effect size benchmarks at the omnibus level, for 20 common research domains, and for an even finer grained level of generality. Results indicate that the usual interpretation and classification of effect sizes as small, medium, and large bear almost no resemblance to findings in the field, because distributions of effect sizes exhibit tertile partitions at values approximately one-half to one-third those intuited by Cohen (1988). Our results offer information that can be used for research planning and design purposes, such as producing better informed non-nil hypotheses and estimating statistical power and planning sample size accordingly. We also offer information useful for understanding the relative importance of the effect sizes found in a particular study in relationship to others and which research domains have advanced more or less, given that larger effect sizes indicate a better understanding of a phenomenon. Also, our study offers information about research domains for which the investigation of moderating effects may be more fruitful and provide information that is likely to facilitate the implementation of Bayesian analysis. Finally, our study offers information that practitioners can use to evaluate the relative effectiveness of various types of interventions.},
  number = {2},
  journaltitle = {Journal of Applied Psychology},
  urldate = {2019-03-30},
  date = {2015-03},
  pages = {431-449},
  author = {Bosco, Frank A. and Aguinis, Herman and Singh, Kulraj and Field, James G. and Pierce, Charles A.},
  file = {/Users/qualia/Documents/Papers/Bosco et al. - 2015 - Correlational effect size benchmarks..pdf}
}

@article{Burke2015,
  langid = {english},
  title = {Human Intracranial High-Frequency Activity during Memory Processing: Neural Oscillations or Stochastic Volatility?},
  volume = {31},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814001810},
  doi = {10.1016/j.conb.2014.09.003},
  shorttitle = {Human Intracranial High-Frequency Activity during Memory Processing},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {104-110},
  author = {Burke, John F and Ramayya, Ashwin G and Kahana, Michael J},
  file = {/Users/qualia/Documents/Papers/Burke et al. - 2015 - Human intracranial high-frequency activity during .pdf}
}

@article{Brette2015,
  langid = {english},
  title = {What {{Is}} the {{Most Realistic Single}}-{{Compartment Model}} of {{Spike Initiation}}?},
  volume = {11},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004114},
  doi = {10.1371/journal.pcbi.1004114},
  number = {4},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-04-09},
  pages = {e1004114},
  author = {Brette, Romain},
  editor = {Pillow, Jonathan W.},
  file = {/Users/qualia/Documents/Papers/Brette - 2015 - What Is the Most Realistic Single-Compartment Mode.pdf}
}

@article{Buzsaki2015,
  langid = {english},
  title = {What Does Gamma Coherence Tell Us about Inter-Regional Neural Communication?},
  volume = {18},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3952},
  doi = {10.1038/nn.3952},
  number = {4},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {484-489},
  author = {Buzs\'aki, Gy\"orgy and Schomburg, Erik W},
  file = {/Users/qualia/Documents/Papers/Buzsáki and Schomburg - 2015 - What does gamma coherence tell us about inter-regi.pdf}
}

@article{Canavier2015,
  langid = {english},
  title = {Phase-Resetting as a Tool of Information Transmission},
  volume = {31},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814002396},
  doi = {10.1016/j.conb.2014.12.003},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {206-213},
  author = {Canavier, Carmen C},
  file = {/Users/qualia/Documents/Papers/Canavier - 2015 - Phase-resetting as a tool of information transmiss.pdf}
}

@article{Cho2015,
  langid = {english},
  title = {Gamma {{Rhythms Link Prefrontal Interneuron Dysfunction}} with {{Cognitive Inflexibility}} in {{Dlx5}}/6+/- {{Mice}}},
  volume = {85},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315001348},
  doi = {10.1016/j.neuron.2015.02.019},
  abstract = {Abnormalities in GABAergic interneurons, particularly fast-spiking interneurons (FSINs) that generate gamma (g; \$30\textendash{}120 Hz) oscillations, are hypothesized to disrupt prefrontal cortex (PFC)-dependent cognition in schizophrenia. Although g rhythms are abnormal in schizophrenia, it remains unclear whether they directly influence cognition. Mechanisms underlying schizophrenia's typical postadolescent onset also remain elusive. We addressed these issues using mice heterozygous for Dlx5/6, which regulate GABAergic interneuron development. In Dlx5/6+/\`A mice, FSINs become abnormal following adolescence, coinciding with the onset of cognitive inflexibility and deficient task-evoked g oscillations. Inhibiting PFC interneurons in control mice reproduced these deficits, whereas stimulating them at g-frequencies restored cognitive flexibility in adult Dlx5/6+/\`A mice. These pro-cognitive effects were frequency specific and persistent. These findings elucidate a mechanism whereby abnormal FSIN development may contribute to the post-adolescent onset of schizophrenia endophenotypes. Furthermore, they demonstrate a causal, potentially therapeutic, role for PFC interneuron-driven g oscillations in cognitive domains at the core of schizophrenia.},
  number = {6},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-03},
  pages = {1332-1343},
  author = {Cho, Kathleen K.A. and Hoch, Renee and Lee, Anthony T. and Patel, Tosha and Rubenstein, John L.R. and Sohal, Vikaas S.},
  file = {/Users/qualia/Documents/Papers/Cho et al. - 2015 - Gamma Rhythms Link Prefrontal Interneuron Dysfunct.pdf}
}

@article{Contractor2015,
  langid = {english},
  title = {Altered {{Neuronal}} and {{Circuit Excitability}} in {{Fragile X Syndrome}}},
  volume = {87},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315005607},
  doi = {10.1016/j.neuron.2015.06.017},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-08},
  pages = {699-715},
  author = {Contractor, Anis and Klyachko, Vitaly A. and Portera-Cailliau, Carlos},
  file = {/Users/qualia/Documents/Papers/Contractor et al. - 2015 - Altered Neuronal and Circuit Excitability in Fragi.pdf}
}

@article{deHemptinne2015,
  langid = {english},
  title = {Therapeutic Deep Brain Stimulation Reduces Cortical Phase-Amplitude Coupling in {{Parkinson}}'s Disease},
  volume = {18},
  issn = {1097-6256, 1546-1726},
  url = {http://www.nature.com/articles/nn.3997},
  doi = {10.1038/nn.3997},
  number = {5},
  journaltitle = {Nature Neuroscience},
  urldate = {2019-03-30},
  date = {2015-05},
  pages = {779-786},
  author = {de Hemptinne, Coralie and Swann, Nicole C and Ostrem, Jill L and Ryapolova-Webb, Elena S and San Luciano, Marta and Galifianakis, Nicholas B and Starr, Philip A},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/de Hemptinne et al. - 2015 - Therapeutic deep brain stimulation reduces cortica.pdf}
}

@article{Dhawale,
  langid = {english},
  title = {1 {{Automated}} Long-Term Recording and Analysis of Neural Activity in Behaving Animals},
  pages = {108},
  author = {Dhawale, Ashesh K and Poddar, Rajesh and Wolff, Steffen B E and Normand, Valentin A and \"Olveczky, Bence P},
  file = {/Users/qualia/Documents/Papers/Dhawale et al. - 1 Automated long-term recording and analysis of ne.pdf}
}

@article{Effenberger2015,
  langid = {english},
  title = {Self-Organization in {{Balanced State Networks}} by {{STDP}} and {{Homeostatic Plasticity}}},
  volume = {11},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004420},
  doi = {10.1371/journal.pcbi.1004420},
  number = {9},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-09-03},
  pages = {e1004420},
  author = {Effenberger, Felix and Jost, J\"urgen and Levina, Anna},
  editor = {Morrison, Abigail},
  file = {/Users/qualia/Documents/Papers/Effenberger et al. - 2015 - Self-organization in Balanced State Networks by ST.pdf}
}

@article{Giusti2015,
  langid = {english},
  title = {Clique Topology Reveals Intrinsic Geometric Structure in Neural Correlations},
  volume = {112},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1506407112},
  doi = {10.1073/pnas.1506407112},
  number = {44},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2015-11-03},
  pages = {13455-13460},
  author = {Giusti, Chad and Pastalkova, Eva and Curto, Carina and Itskov, Vladimir},
  file = {/Users/qualia/Documents/Papers/Giusti et al. - 2015 - Clique topology reveals intrinsic geometric struct.pdf}
}

@article{Gordus2015,
  langid = {english},
  title = {Feedback from {{Network States Generates Variability}} in a {{Probabilistic Olfactory Circuit}}},
  volume = {161},
  issn = {00928674},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867415001841},
  doi = {10.1016/j.cell.2015.02.018},
  abstract = {Variability is a prominent feature of behavior and is an active element of certain behavioral strategies. To understand how neuronal circuits control variability, we examined the propagation of sensory information in a chemotaxis circuit of C. elegans where discrete sensory inputs can drive a probabilistic behavioral response. Olfactory neurons respond to odor stimuli with rapid and reliable changes in activity, but downstream AIB interneurons respond with a probabilistic delay. The interneuron response to odor depends on the collective activity of multiple neurons\textemdash{}AIB, RIM, and AVA\textemdash{}when the odor stimulus arrives. Certain activity states of the network correlate with reliable responses to odor stimuli. Artificially generating these activity states by modifying neuronal activity increases the reliability of odor responses in interneurons and the reliability of the behavioral response to odor. The integration of sensory information with network states may represent a general mechanism for generating variability in behavior.},
  number = {2},
  journaltitle = {Cell},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {215-227},
  author = {Gordus, Andrew and Pokala, Navin and Levy, Sagi and Flavell, Steven W. and Bargmann, Cornelia I.},
  file = {/Users/qualia/Documents/Papers/Gordus et al. - 2015 - Feedback from Network States Generates Variability.pdf}
}

@article{Aflalo,
  langid = {english},
  title = {Decoding Motor Imagery from the Posterior Parietal Cortex of a Tetraplegic Human},
  pages = {6},
  author = {Aflalo, Tyson and Kellis, Spencer and Klaes, Christian and Lee, Brian and Shi, Ying and Pejsa, Kelsie and Shanfield, Kathleen and Hayes-Jackson, Stephanie and Aisen, Mindy and Heck, Christi and Liu, Charles and Andersen, Richard A},
  file = {/Users/qualia/Documents/Papers/Aflalo et al. - Decoding motor imagery from the posterior parietal.pdf}
}

@article{Hermes2015a,
  langid = {english},
  title = {Gamma Oscillations in Visual Cortex: The Stimulus Matters},
  volume = {19},
  issn = {13646613},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661314002769},
  doi = {10.1016/j.tics.2014.12.009},
  shorttitle = {Gamma Oscillations in Visual Cortex},
  number = {2},
  journaltitle = {Trends in Cognitive Sciences},
  urldate = {2019-03-30},
  date = {2015-02},
  pages = {57-58},
  author = {Hermes, Dora and Miller, Kai J. and Wandell, Brian A. and Winawer, Jonathan},
  file = {/Users/qualia/Documents/Papers/Hermes et al. - 2015 - Gamma oscillations in visual cortex the stimulus .pdf}
}

@article{Horvath2015a,
  langid = {english},
  title = {Quantitative {{Review Finds No Evidence}} of {{Cognitive Effects}} in {{Healthy Populations From Single}}-Session {{Transcranial Direct Current Stimulation}} ({{tDCS}})},
  volume = {8},
  issn = {1935861X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1935861X15008578},
  doi = {10.1016/j.brs.2015.01.400},
  abstract = {Background: Over the last 15-years, transcranial direct current stimulation (tDCS), a relatively novel form of neuromodulation, has seen a surge of popularity in both clinical and academic settings. Despite numerous claims suggesting that a single session of tDCS can modulate cognition in healthy adult populations (especially working memory and language production), the paradigms utilized and results reported in the literature are extremely variable. To address this, we conduct the largest quantitative review of the cognitive data to date.
Methods: Single-session tDCS data in healthy adults (18e50) from every cognitive outcome measure reported by at least two different research groups in the literature was collected. Outcome measures were divided into 4 broad categories: executive function, language, memory, and miscellaneous. To account for the paradigmatic variability in the literature, we undertook a three-tier analysis system; each with less-stringent inclusion criteria than the prior. Standard mean difference values with 95\% CIs were generated for included studies and pooled for each analysis.
Results: Of the 59 analyses conducted, tDCS was found to not have a significant effect on any e regardless of inclusion laxity. This includes no effect on any working memory outcome or language production task.
Conclusion: Our quantitative review does not support the idea that tDCS generates a reliable effect on cognition in healthy adults. Reasons for and limitations of this finding are discussed. This work raises important questions regarding the efficacy of tDCS, state-dependency effects, and future directions for this tool in cognitive research.},
  number = {3},
  journaltitle = {Brain Stimulation},
  urldate = {2019-03-30},
  date = {2015-05},
  pages = {535-550},
  author = {Horvath, Jared Cooney and Forte, Jason D. and Carter, Olivia},
  file = {/Users/qualia/Documents/Papers/Horvath et al. - 2015 - Quantitative Review Finds No Evidence of Cognitive.pdf}
}

@article{Hyafil2015,
  langid = {english},
  title = {Speech Encoding by Coupled Cortical Theta and Gamma Oscillations},
  volume = {4},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/06213},
  doi = {10.7554/eLife.06213},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2015-05-29},
  author = {Hyafil, Alexandre and Fontolan, Lorenzo and Kabdebon, Claire and Gutkin, Boris and Giraud, Anne-Lise},
  file = {/Users/qualia/Documents/Papers/Hyafil et al. - 2015 - Speech encoding by coupled cortical theta and gamm.pdf}
}

@article{Jorgenson2015,
  langid = {english},
  title = {The {{BRAIN Initiative}}: Developing Technology to Catalyse Neuroscience Discovery},
  volume = {370},
  issn = {0962-8436, 1471-2970},
  url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2014.0164},
  doi = {10.1098/rstb.2014.0164},
  shorttitle = {The {{BRAIN Initiative}}},
  number = {1668},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  urldate = {2019-03-30},
  date = {2015-03-30},
  pages = {20140164-20140164},
  author = {Jorgenson, L. A. and Newsome, W. T. and Anderson, D. J. and Bargmann, C. I. and Brown, E. N. and Deisseroth, K. and Donoghue, J. P. and Hudson, K. L. and Ling, G. S. F. and MacLeish, P. R. and Marder, E. and Normann, R. A. and Sanes, J. R. and Schnitzer, M. J. and Sejnowski, T. J. and Tank, D. W. and Tsien, R. Y. and Ugurbil, K. and Wingfield, J. C.},
  file = {/Users/qualia/Documents/Papers/Jorgenson et al. - 2015 - The BRAIN Initiative developing technology to cat.pdf}
}

@article{Kendal2015,
  langid = {english},
  title = {Self-Organized Criticality Attributed to a Central Limit-like Convergence Effect},
  volume = {421},
  issn = {03784371},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0378437114009868},
  doi = {10.1016/j.physa.2014.11.035},
  abstract = {Self-organized criticality is a hypothesis used to explain the origin of 1/f noise and other scaling behaviors. Despite being proposed nearly 30 years ago, no consensus exists as to its exact definition or mathematical mechanism(s). Recently, a model for 1/f noise was proposed based on a family of statistical distributions known as the Tweedie exponential dispersion models. These distributions are characterized by an inherent scale invariance that manifests as a variance to mean power law, called fluctuation scaling; they also serve as foci of convergence in a limit theorem on independent and identically distributed distributions. Fluctuation scaling can be modeled by self-similar stochastic processes that relate the variance to mean power law to 1/f noise through their correlation structure. A hypothesis is proposed whereby the effects of self-organized criticality are mathematically modeled by the Tweedie distributions and their convergence behavior as applied to selfsimilar stochastic processes. Sandpile model fluctuations are shown to manifest 1/f noise, fluctuation scaling, and to conform to the Tweedie compound Poisson distribution. The Tweedie models and their convergence theorem allow for a mechanistic explanation of 1/f noise and fluctuation scaling in phenomena conventionally attributed to self-organized criticality, thus providing a paradigm shift in our understanding of these phenomena.},
  journaltitle = {Physica A: Statistical Mechanics and its Applications},
  urldate = {2019-03-30},
  date = {2015-03},
  pages = {141-150},
  author = {Kendal, Wayne S.},
  file = {/Users/qualia/Documents/Papers/Kendal - 2015 - Self-organized criticality attributed to a central.pdf}
}

@article{Kira2015,
  langid = {english},
  title = {A {{Neural Implementation}} of {{Wald}}'s {{Sequential Probability Ratio Test}}},
  volume = {85},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315000082},
  doi = {10.1016/j.neuron.2015.01.007},
  abstract = {Difficult decisions often require evaluation of samples of evidence acquired sequentially. A sensible strategy is to accumulate evidence, weighted by its reliability, until sufficient support is attained. An optimal statistical approach would accumulate evidence in units of logarithms of likelihood ratios (logLR) to a desired level. Studies of perceptual decisions suggest that the brain approximates an analogous procedure, but a direct test of accumulation, in units of logLR, to a threshold in units of cumulative logLR is lacking. We trained rhesus monkeys to make decisions based on a sequence of evanescent, visual cues assigned different logLR, hence different reliability. Firing rates of neurons in the lateral intraparietal area (LIP) reflected the accumulation of logLR and reached a stereotyped level before the monkeys committed to a decision. The monkeys' choices and reaction times, including their variability, were explained by LIP activity in the context of accumulation of logLR to a threshold.},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-02},
  pages = {861-873},
  author = {Kira, Shinichiro and Yang, Tianming and Shadlen, Michael N.},
  file = {/Users/qualia/Documents/Papers/Kira et al. - 2015 - A Neural Implementation of Wald’s Sequential Proba.pdf}
}

@article{Kvam2015,
  langid = {english},
  title = {Interference Effects of Choice on Confidence: {{Quantum}} Characteristics of Evidence Accumulation},
  volume = {112},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1500688112},
  doi = {10.1073/pnas.1500688112},
  shorttitle = {Interference Effects of Choice on Confidence},
  number = {34},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2015-08-25},
  pages = {10645-10650},
  author = {Kvam, Peter D. and Pleskac, Timothy J. and Yu, Shuli and Busemeyer, Jerome R.},
  file = {/Users/qualia/Documents/Papers/Kvam et al. - 2015 - Interference effects of choice on confidence Quan.pdf}
}

@article{Lin2015,
  langid = {english},
  title = {The {{Nature}} of {{Shared Cortical Variability}}},
  volume = {87},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S089662731500598X},
  doi = {10.1016/j.neuron.2015.06.035},
  abstract = {Neuronal responses of sensory cortex are highly variable, and this variability is correlated across neurons. To assess how variability reflects factors shared across a neuronal population, we analyzed the activity of many simultaneously recorded neurons in visual cortex. We developed a simple model that comprises two sources of shared variability: a multiplicative gain, which uniformly scales each neuron's sensory drive, and an additive offset, which affects different neurons to different degrees. This model captured the variability of spike counts and reproduced the dependence of pairwise correlations on neuronal tuning and stimulus orientation. The relative contributions of the additive and multiplicative fluctuations could vary over time and had marked impact on population coding. These observations indicate that shared variability of neuronal populations in sensory cortex can be largely explained by two factors that modulate the whole population.},
  number = {3},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-08},
  pages = {644-656},
  author = {Lin, I-Chun and Okun, Michael and Carandini, Matteo and Harris, Kenneth D.},
  file = {/Users/qualia/Documents/Papers/Lin et al. - 2015 - The Nature of Shared Cortical Variability.pdf}
}

@article{Lowet2015,
  langid = {english},
  title = {Input-{{Dependent Frequency Modulation}} of {{Cortical Gamma Oscillations Shapes Spatial Synchronization}} and {{Enables Phase Coding}}},
  volume = {11},
  issn = {1553-7358},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1004072},
  doi = {10.1371/journal.pcbi.1004072},
  number = {2},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-02-13},
  pages = {e1004072},
  author = {Lowet, Eric and Roberts, Mark and Hadjipapas, Avgis and Peter, Alina and van der Eerden, Jan and De Weerd, Peter},
  editor = {Ermentrout, Bard},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Lowet et al. - 2015 - Input-Dependent Frequency Modulation of Cortical G.pdf}
}

@article{Moldakarimov2015,
  langid = {english},
  title = {Feedback Stabilizes Propagation of Synchronous Spiking in Cortical Neural Networks},
  volume = {112},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1500643112},
  doi = {10.1073/pnas.1500643112},
  number = {8},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-03-30},
  date = {2015-02-24},
  pages = {2545-2550},
  author = {Moldakarimov, Samat and Bazhenov, Maxim and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/Moldakarimov et al. - 2015 - Feedback stabilizes propagation of synchronous spi.pdf}
}

@article{Nelson2015,
  langid = {english},
  title = {Excitatory/{{Inhibitory Balance}} and {{Circuit Homeostasis}} in {{Autism Spectrum Disorders}}},
  volume = {87},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315006753},
  doi = {10.1016/j.neuron.2015.07.033},
  number = {4},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-08},
  pages = {684-698},
  author = {Nelson, Sacha B. and Valakh, Vera},
  file = {/Users/qualia/Documents/Papers/Nelson and Valakh - 2015 - ExcitatoryInhibitory Balance and Circuit Homeosta.pdf}
}

@article{Okun2015,
  langid = {english},
  title = {Diverse Coupling of Neurons to Populations in Sensory Cortex},
  volume = {521},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature14273},
  doi = {10.1038/nature14273},
  number = {7553},
  journaltitle = {Nature},
  urldate = {2019-03-30},
  date = {2015-05},
  pages = {511-515},
  author = {Okun, Michael and Steinmetz, Nicholas A. and Cossell, Lee and Iacaruso, M. Florencia and Ko, Ho and Barth\'o, P\'eter and Moore, Tirin and Hofer, Sonja B. and Mrsic-Flogel, Thomas D. and Carandini, Matteo and Harris, Kenneth D.},
  file = {/Users/qualia/Documents/Papers/Okun et al. - 2015 - Diverse coupling of neurons to populations in sens.pdf}
}

@article{Palmieri2015,
  langid = {english},
  title = {The Transfer Function of Neuron Spike},
  volume = {68},
  issn = {08936080},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608015000817},
  doi = {10.1016/j.neunet.2015.04.003},
  abstract = {The mathematical modeling of neuronal signals is a relevant problem in neuroscience. The complexity of the neuron behavior, however, makes this problem a particularly difficult task. Here, we propose a discrete-time linear time-invariant (LTI) model with a rational function in order to represent the neuronal spike detected by an electrode located in the surroundings of the nerve cell. The model is presented as a cascade association of two subsystems: one that generates an action potential from an input stimulus, and one that represents the medium between the cell and the electrode. The suggested approach employs system identification and signal processing concepts, and is dissociated from any considerations about the biophysical processes of the neuronal cell, providing a low-complexity alternative to model the neuronal spike. The model is validated by using in vivo experimental readings of intracellular and extracellular signals. A computational simulation of the model is presented in order to assess its proximity to the neuronal signal and to observe the variability of the estimated parameters. The implications of the results are discussed in the context of spike sorting.},
  journaltitle = {Neural Networks},
  urldate = {2019-03-30},
  date = {2015-08},
  pages = {89-95},
  author = {Palmieri, Igor and Monteiro, Luiz H.A. and Miranda, Maria D.},
  file = {/Users/qualia/Documents/Papers/Palmieri et al. - 2015 - The transfer function of neuron spike.pdf}
}

@article{Podvalny2015,
  langid = {english},
  title = {A Unifying Principle Underlying the Extracellular Field Potential Spectral Responses in the Human Cortex},
  volume = {114},
  issn = {0022-3077, 1522-1598},
  url = {http://www.physiology.org/doi/10.1152/jn.00943.2014},
  doi = {10.1152/jn.00943.2014},
  number = {1},
  journaltitle = {Journal of Neurophysiology},
  urldate = {2019-03-30},
  date = {2015-07},
  pages = {505-519},
  author = {Podvalny, Ella and Noy, Niv and Harel, Michal and Bickel, Stephan and Chechik, Gal and Schroeder, Charles E. and Mehta, Ashesh D. and Tsodyks, Misha and Malach, Rafael},
  file = {/Users/qualia/Documents/Papers/Podvalny et al. - 2015 - A unifying principle underlying the extracellular  2.pdf;/Users/qualia/Documents/Papers/Podvalny et al. - 2015 - A unifying principle underlying the extracellular .pdf}
}

@article{Ray2015,
  langid = {english},
  title = {Challenges in the Quantification and Interpretation of Spike-{{LFP}} Relationships},
  volume = {31},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814001822},
  doi = {10.1016/j.conb.2014.09.004},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {111-118},
  author = {Ray, Supratim},
  file = {/Users/qualia/Documents/Papers/Ray - 2015 - Challenges in the quantification and interpretatio.pdf}
}

@article{Pritchett2015,
  langid = {english},
  title = {For Things Needing Your Attention: The Role of Neocortical Gamma in Sensory Perception},
  volume = {31},
  issn = {09594388},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438815000343},
  doi = {10.1016/j.conb.2015.02.004},
  shorttitle = {For Things Needing Your Attention},
  journaltitle = {Current Opinion in Neurobiology},
  urldate = {2019-03-30},
  date = {2015-04},
  pages = {254-263},
  author = {Pritchett, Dominique L and Siegle, Joshua H and Deister, Christopher A and Moore, Christopher I},
  file = {/Users/qualia/Documents/Papers/Pritchett et al. - 2015 - For things needing your attention the role of neo.pdf}
}

@article{Roux2015,
  langid = {english},
  title = {Tasks for Inhibitory Interneurons in Intact Brain Circuits},
  volume = {88},
  issn = {00283908},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0028390814003189},
  doi = {10.1016/j.neuropharm.2014.09.011},
  abstract = {Synaptic inhibition, brought about by a rich variety of interneuron types, counters excitation, modulates the gain, timing, tuning, bursting properties of principal cell firing, and exerts selective filtering of synaptic excitation. At the network level, it allows for coordinating transient interactions among the principal cells to form cooperative assemblies for efficient transmission of information and routing of excitatory activity across networks, typically in the form of brain oscillations. Recent techniques based on targeted expression of neuronal activity modulators, such as optogenetics, allow physiological identification and perturbation of specific interneuron subtypes in the intact brain. Combined with large-scale recordings or imaging techniques, these approaches facilitate our understanding of the multiple roles of inhibitory interneurons in shaping circuit functions.},
  journaltitle = {Neuropharmacology},
  urldate = {2019-03-30},
  date = {2015-01},
  pages = {10-23},
  author = {Roux, Lisa and Buzs\'aki, Gy\"orgy},
  file = {/Users/qualia/Documents/Papers/Roux and Buzsáki - 2015 - Tasks for inhibitory interneurons in intact brain .pdf}
}

@article{Wilson2015a,
  langid = {english},
  title = {Is {{Model Fitting Necessary}} for {{Model}}-{{Based fMRI}}?},
  volume = {11},
  issn = {1553-7358},
  url = {http://dx.plos.org/10.1371/journal.pcbi.1004237},
  doi = {10.1371/journal.pcbi.1004237},
  abstract = {OPEN ACCESS Citation: Wilson RC, Niv Y (2015) Is Model Fitting Necessary for Model-Based fMRI?. PLoS Comput Biol 11(6): e1004237. doi:10.1371/journal.},
  number = {6},
  journaltitle = {PLOS Computational Biology},
  urldate = {2019-03-30},
  date = {2015-06-18},
  pages = {e1004237},
  author = {Wilson, Robert C. and Niv, Yael},
  editor = {Boorman, Erie Dell},
  file = {/Users/qualia/Documents/Papers/Wilson and Niv - 2015 - Is Model Fitting Necessary for Model-Based fMRI.pdf}
}

@article{Wynn2015,
  langid = {english},
  title = {{{EEG Findings}} of {{Reduced Neural Synchronization}} during {{Visual Integration}} in {{Schizophrenia}}},
  volume = {10},
  issn = {1932-6203},
  url = {https://dx.plos.org/10.1371/journal.pone.0119849},
  doi = {10.1371/journal.pone.0119849},
  number = {3},
  journaltitle = {PLOS ONE},
  urldate = {2019-03-30},
  date = {2015-03-18},
  pages = {e0119849},
  author = {Wynn, Jonathan K. and Roach, Brian J. and Lee, Junghee and Horan, William P. and Ford, Judith M. and Jimenez, Amy M. and Green, Michael F.},
  editor = {Kotz, Sonja},
  file = {/Users/qualia/Documents/Papers/Wynn et al. - 2015 - EEG Findings of Reduced Neural Synchronization dur.pdf}
}

@article{Yi2015,
  langid = {english},
  title = {Spike-Frequency Adaptation of a Two-Compartment Neuron Modulated by Extracellular Electric Fields},
  volume = {109},
  issn = {0340-1200, 1432-0770},
  url = {http://link.springer.com/10.1007/s00422-014-0642-2},
  doi = {10.1007/s00422-014-0642-2},
  number = {3},
  journaltitle = {Biological Cybernetics},
  urldate = {2019-03-30},
  date = {2015-06},
  pages = {287-306},
  author = {Yi, Guosheng and Wang, Jiang and Tsang, Kai-Ming and Wei, Xile and Deng, Bin and Han, Chunxiao},
  file = {/Users/qualia/Documents/Papers/Yi et al. - 2015 - Spike-frequency adaptation of a two-compartment ne.pdf}
}

@article{Beattie2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1612.03801},
  primaryClass = {cs},
  langid = {english},
  title = {{{DeepMind Lab}}},
  url = {http://arxiv.org/abs/1612.03801},
  abstract = {DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon. It is powered by a fast and widely recognised game engine, and tailored for effective use by the research community.},
  urldate = {2019-03-30},
  date = {2016-12-12},
  keywords = {Computer Science - Artificial Intelligence},
  author = {Beattie, Charles and Leibo, Joel Z. and Teplyashin, Denis and Ward, Tom and Wainwright, Marcus and K\"uttler, Heinrich and Lefrancq, Andrew and Green, Simon and Vald\'es, V\'ictor and Sadik, Amir and Schrittwieser, Julian and Anderson, Keith and York, Sarah and Cant, Max and Cain, Adam and Bolton, Adrian and Gaffney, Stephen and King, Helen and Hassabis, Demis and Legg, Shane and Petersen, Stig},
  file = {/Users/qualia/Documents/Papers/Beattie et al. - 2016 - DeepMind Lab.pdf}
}

@article{Zanos2015,
  langid = {english},
  title = {A {{Sensorimotor Role}} for {{Traveling Waves}} in {{Primate Visual Cortex}}},
  volume = {85},
  issn = {08966273},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627314011520},
  doi = {10.1016/j.neuron.2014.12.043},
  abstract = {Traveling waves of neural activity are frequently observed to occur in concert with the presentation of a sensory stimulus or the execution of a movement. Although such waves have been studied for decades, little is known about their function. Here we show that traveling waves in the primate extrastriate visual cortex provide a means of integrating sensory and motor signals. Specifically, we describe a traveling wave of local field potential (LFP) activity in cortical area V4 of macaque monkeys that is triggered by the execution of saccadic eye movements. These waves sweep across the V4 retinotopic map, following a consistent path from the foveal to the peripheral representations of space; their amplitudes correlate with the direction and size of each saccade. Moreover, these waves are associated with a reorganization of the postsaccadic neuronal firing patterns, which follow a similar retinotopic progression, potentially prioritizing the processing of behaviorally relevant stimuli.},
  number = {3},
  journaltitle = {Neuron},
  urldate = {2019-03-30},
  date = {2015-02},
  pages = {615-627},
  author = {Zanos, Theodoros P. and Mineault, Patrick J. and Nasiotis, Konstantinos T. and Guitton, Daniel and Pack, Christopher C.},
  file = {/Users/qualia/Documents/Papers/Zanos et al. - 2015 - A Sensorimotor Role for Traveling Waves in Primate.pdf}
}

@article{Bellemare2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1606.01868},
  primaryClass = {cs, stat},
  langid = {english},
  title = {Unifying {{Count}}-{{Based Exploration}} and {{Intrinsic Motivation}}},
  url = {http://arxiv.org/abs/1606.01868},
  abstract = {We consider an agent's uncertainty about its environment and the problem of generalizing this uncertainty across states. Specifically, we focus on the problem of exploration in non-tabular reinforcement learning. Drawing inspiration from the intrinsic motivation literature, we use density models to measure uncertainty, and propose a novel algorithm for deriving a pseudo-count from an arbitrary density model. This technique enables us to generalize count-based exploration algorithms to the non-tabular case. We apply our ideas to Atari 2600 games, providing sensible pseudo-counts from raw pixels. We transform these pseudo-counts into exploration bonuses and obtain significantly improved exploration in a number of hard games, including the infamously difficult MONTEZUMA'S REVENGE.},
  urldate = {2019-03-30},
  date = {2016-06-06},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence},
  author = {Bellemare, Marc G. and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  file = {/Users/qualia/Documents/Papers/Bellemare et al. - 2016 - Unifying Count-Based Exploration and Intrinsic Mot.pdf}
}

@article{Graves2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1704.03003},
  primaryClass = {cs},
  langid = {english},
  title = {Automated {{Curriculum Learning}} for {{Neural Networks}}},
  url = {http://arxiv.org/abs/1704.03003},
  abstract = {We introduce a method for automatically selecting the path, or syllabus, that a neural network follows through a curriculum so as to maximise learning efficiency. A measure of the amount that the network learns from each data sample is provided as a reward signal to a nonstationary multiarmed bandit algorithm, which then determines a stochastic syllabus. We consider a range of signals derived from two distinct indicators of learning progress: rate of increase in prediction accuracy, and rate of increase in network complexity. Experimental results for LSTM networks on three curricula demonstrate that our approach can significantly accelerate learning, in some cases halving the time required to attain a satisfactory performance level.},
  urldate = {2019-03-30},
  date = {2017-04-10},
  keywords = {Computer Science - Neural and Evolutionary Computing},
  author = {Graves, Alex and Bellemare, Marc G. and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  file = {/Users/qualia/Documents/Papers/Graves et al. - 2017 - Automated Curriculum Learning for Neural Networks.pdf}
}

@article{Kulkarni2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1604.06057},
  primaryClass = {cs, stat},
  langid = {english},
  title = {Hierarchical {{Deep Reinforcement Learning}}: {{Integrating Temporal Abstraction}} and {{Intrinsic Motivation}}},
  url = {http://arxiv.org/abs/1604.06057},
  shorttitle = {Hierarchical {{Deep Reinforcement Learning}}},
  abstract = {Learning goal-directed behavior in environments with sparse feedback is a major challenge for reinforcement learning algorithms. The primary difficulty arises due to insufficient exploration, resulting in an agent being unable to learn robust value functions. Intrinsically motivated agents can explore new behavior for its own sake rather than to directly solve problems. Such intrinsic behaviors could eventually help the agent solve tasks posed by the environment. We present hierarchical-DQN (h-DQN), a framework to integrate hierarchical value functions, operating at different temporal scales, with intrinsically motivated deep reinforcement learning. A top-level value function learns a policy over intrinsic goals, and a lower-level function learns a policy over atomic actions to satisfy the given goals. h-DQN allows for flexible goal specifications, such as functions over entities and relations. This provides an efficient space for exploration in complicated environments. We demonstrate the strength of our approach on two problems with very sparse, delayed feedback: (1) a complex discrete stochastic decision process, and (2) the classic ATARI game `Montezuma's Revenge'.},
  urldate = {2019-03-30},
  date = {2016-04-20},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  author = {Kulkarni, Tejas D. and Narasimhan, Karthik R. and Saeedi, Ardavan and Tenenbaum, Joshua B.},
  file = {/Users/qualia/Documents/Papers/Kulkarni et al. - 2016 - Hierarchical Deep Reinforcement Learning Integrat.pdf}
}

@article{Linderman2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1610.08466},
  primaryClass = {stat},
  langid = {english},
  title = {Recurrent Switching Linear Dynamical Systems},
  url = {http://arxiv.org/abs/1610.08466},
  abstract = {Many natural systems, such as neurons firing in the brain or basketball teams traversing a court, give rise to time series data with complex, nonlinear dynamics. We can gain insight into these systems by decomposing the data into segments that are each explained by simpler dynamic units. Building on switching linear dynamical systems (SLDS), we present a new model class that not only discovers these dynamical units, but also explains how their switching behavior depends on observations or continuous latent states. These ``recurrent'' switching linear dynamical systems provide further insight by discovering the conditions under which each unit is deployed, something that traditional SLDS models fail to do. We leverage recent algorithmic advances in approximate inference to make Bayesian inference in these models easy, fast, and scalable.},
  urldate = {2019-03-30},
  date = {2016-10-26},
  keywords = {Statistics - Machine Learning},
  author = {Linderman, Scott W. and Miller, Andrew C. and Adams, Ryan P. and Blei, David M. and Paninski, Liam and Johnson, Matthew J.},
  file = {/Users/qualia/Documents/Papers/Linderman et al. - 2016 - Recurrent switching linear dynamical systems.pdf}
}

@article{OConnor2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.08323},
  primaryClass = {cs},
  langid = {english},
  title = {Deep {{Spiking Networks}}},
  url = {http://arxiv.org/abs/1602.08323},
  abstract = {We introduce an algorithm to do backpropagation on a spiking network. Our network is "spiking" in the sense that our neurons accumulate their activation into a potential over time, and only send out a signal (a ``spike'') when this potential crosses a threshold and the neuron is reset. Neurons only update their states when receiving signals from other neurons. Total computation of the network thus scales with the number of spikes caused by an input rather than network size. We show that the spiking Multi-Layer Perceptron behaves identically, during both prediction and training, to a conventional deep network of rectified-linear units, in the limiting case where we run the spiking network for a long time. We apply this architecture to a conventional classification problem (MNIST) and achieve performance very close to that of a conventional Multi-Layer Perceptron with the same architecture. Our network is a natural architecture for learning based on streaming event-based data, and is a stepping stone towards using spiking neural networks to learn efficiently on streaming data.},
  urldate = {2019-03-30},
  date = {2016-02-26},
  keywords = {Computer Science - Neural and Evolutionary Computing,68T01,F.1.1},
  author = {O'Connor, Peter and Welling, Max},
  file = {/Users/qualia/Documents/Papers/O'Connor and Welling - 2016 - Deep Spiking Networks.pdf}
}

@article{Xiong2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1603.01417},
  primaryClass = {cs},
  langid = {english},
  title = {Dynamic {{Memory Networks}} for {{Visual}} and {{Textual Question Answering}}},
  url = {http://arxiv.org/abs/1603.01417},
  abstract = {Neural network architectures with memory and attention mechanisms exhibit certain reasoning capabilities required for question answering. One such architecture, the dynamic memory network (DMN), obtained high accuracy on a variety of language tasks. However, it was not shown whether the architecture achieves strong results for question answering when supporting facts are not marked during training or whether it could be applied to other modalities such as images. Based on an analysis of the DMN, we propose several improvements to its memory and input modules. Together with these changes we introduce a novel input module for images in order to be able to answer visual questions. Our new DMN+ model improves the state of the art on both the Visual Question Answering dataset and the bAbI-10k text question-answering dataset without supporting fact supervision.},
  urldate = {2019-03-30},
  date = {2016-03-04},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computation and Language},
  author = {Xiong, Caiming and Merity, Stephen and Socher, Richard},
  file = {/Users/qualia/Documents/Papers/Xiong et al. - 2016 - Dynamic Memory Networks for Visual and Textual Que.pdf}
}

@article{Huh2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.04698},
  primaryClass = {cs, q-bio, stat},
  langid = {english},
  title = {Gradient {{Descent}} for {{Spiking Neural Networks}}},
  url = {http://arxiv.org/abs/1706.04698},
  abstract = {Much of studies on neural computation are based on network models of static neurons that produce analog output, despite the fact that information processing in the brain is predominantly carried out by dynamic neurons that produce discrete pulses called spikes. Research in spike-based computation has been impeded by the lack of efficient supervised learning algorithm for spiking networks. Here, we present a gradient descent method for optimizing spiking network models by introducing a differentiable formulation of spiking networks and deriving the exact gradient calculation. For demonstration, we trained recurrent spiking networks on two dynamic tasks: one that requires optimizing fast ({$\approx$} millisecond) spike-based interactions for efficient encoding of information, and a delayed-memory XOR task over extended duration ({$\approx$} second). The results show that our method indeed optimizes the spiking network dynamics on the time scale of individual spikes as well as the behavioral time scales. In conclusion, our result offers a general purpose supervised learning algorithm for spiking neural networks, thus advancing further investigations on spike-based computation.},
  urldate = {2019-03-30},
  date = {2017-06-14},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  author = {Huh, Dongsung and Sejnowski, Terrence J.},
  file = {/Users/qualia/Documents/Papers/Huh and Sejnowski - 2017 - Gradient Descent for Spiking Neural Networks.pdf}
}

@article{McIntosh2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1702.01825},
  primaryClass = {q-bio, stat},
  langid = {english},
  title = {Deep {{Learning Models}} of the {{Retinal Response}} to {{Natural Scenes}}},
  url = {http://arxiv.org/abs/1702.01825},
  abstract = {A central challenge in sensory neuroscience is to understand neural computations and circuit mechanisms that underlie the encoding of ethologically relevant, natural stimuli. In multilayered neural circuits, nonlinear processes such as synaptic transmission and spiking dynamics present a significant obstacle to the creation of accurate computational models of responses to natural stimuli. Here we demonstrate that deep convolutional neural networks (CNNs) capture retinal responses to natural scenes nearly to within the variability of a cell's response, and are markedly more accurate than linear-nonlinear (LN) models and Generalized Linear Models (GLMs). Moreover, we find two additional surprising properties of CNNs: they are less susceptible to overfitting than their LN counterparts when trained on small amounts of data, and generalize better when tested on stimuli drawn from a different distribution (e.g. between natural scenes and white noise). An examination of the learned CNNs reveals several properties. First, a richer set of feature maps is necessary for predicting the responses to natural scenes compared to white noise. Second, temporally precise responses to slowly varying inputs originate from feedforward inhibition, similar to known retinal mechanisms. Third, the injection of latent noise sources in intermediate layers enables our model to capture the sub-Poisson spiking variability observed in retinal ganglion cells. Fourth, augmenting our CNNs with recurrent lateral connections enables them to capture contrast adaptation as an emergent property of accurately describing retinal responses to natural scenes. These methods can be readily generalized to other sensory modalities and stimulus ensembles. Overall, this work demonstrates that CNNs not only accurately capture sensory circuit responses to natural scenes, but also can yield information about the circuit's internal structure and function.},
  urldate = {2019-03-30},
  date = {2017-02-06},
  keywords = {Statistics - Machine Learning,Quantitative Biology - Neurons and Cognition},
  author = {McIntosh, Lane T. and Maheswaranathan, Niru and Nayebi, Aran and Ganguli, Surya and Baccus, Stephen A.},
  file = {/Users/qualia/Documents/Papers/McIntosh et al. - 2017 - Deep Learning Models of the Retinal Response to Na.pdf}
}

@article{Leike2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1711.09883},
  primaryClass = {cs},
  langid = {english},
  title = {{{AI Safety Gridworlds}}},
  url = {http://arxiv.org/abs/1711.09883},
  abstract = {We present a suite of reinforcement learning environments illustrating various safety properties of intelligent agents. These problems include safe interruptibility, avoiding side effects, absent supervisor, reward gaming, safe exploration, as well as robustness to self-modification, distributional shift, and adversaries. To measure compliance with the intended safe behavior, we equip each environment with a performance function that is hidden from the agent. This allows us to categorize AI safety problems into robustness and specification problems, depending on whether the performance function corresponds to the observed reward function. We evaluate A2C and Rainbow, two recent deep reinforcement learning agents, on our environments and show that they are not able to solve them satisfactorily.},
  urldate = {2019-03-30},
  date = {2017-11-27},
  keywords = {Computer Science - Machine Learning,Computer Science - Artificial Intelligence},
  author = {Leike, Jan and Martic, Miljan and Krakovna, Victoria and Ortega, Pedro A. and Everitt, Tom and Lefrancq, Andrew and Orseau, Laurent and Legg, Shane},
  file = {/Users/qualia/Documents/Papers/Leike et al. - 2017 - AI Safety Gridworlds.pdf}
}

@article{Sacramento2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1801.00062},
  primaryClass = {cs, q-bio},
  langid = {english},
  title = {Dendritic Error Backpropagation in Deep Cortical Microcircuits},
  url = {http://arxiv.org/abs/1801.00062},
  abstract = {Animal behaviour depends on learning to associate sensory stimuli with the desired motor command. Understanding how the brain orchestrates the necessary synaptic modifications across different brain areas has remained a longstanding puzzle. Here, we introduce a multi-area neuronal network model in which synaptic plasticity continuously adapts the network towards a global desired output. In this model synaptic learning is driven by a local dendritic prediction error that arises from a failure to predict the top-down input given the bottom-up activities. Such errors occur at apical dendrites of pyramidal neurons where both long-range excitatory feedback and local inhibitory predictions are integrated. When local inhibition fails to match excitatory feedback an error occurs which triggers plasticity at bottom-up synapses at basal dendrites of the same pyramidal neurons. We demonstrate the learning capabilities of the model in a number of tasks and show that it approximates the classical error backpropagation algorithm. Finally, complementing this cortical circuit with a disinhibitory mechanism enables attention-like stimulus denoising and generation. Our framework makes several experimental predictions on the function of dendritic integration and cortical microcircuits, is consistent with recent observations of cross-area learning, and suggests a biological implementation of deep learning.},
  urldate = {2019-03-30},
  date = {2017-12-29},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  author = {Sacramento, Jo\~ao and Costa, Rui Ponte and Bengio, Yoshua and Senn, Walter},
  file = {/Users/qualia/Documents/Papers/Sacramento et al. - 2017 - Dendritic error backpropagation in deep cortical m.pdf}
}

@article{Kaiser2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.05137},
  primaryClass = {cs, stat},
  langid = {english},
  title = {One {{Model To Learn Them All}}},
  url = {http://arxiv.org/abs/1706.05137},
  abstract = {Deep learning yields great results across many fields, from speech recognition, image classification, to translation. But for each problem, getting a deep model to work well involves research into the architecture and a long period of tuning. We present a single model that yields good results on a number of problems spanning multiple domains. In particular, this single model is trained concurrently on ImageNet, multiple translation tasks, image captioning (COCO dataset), a speech recognition corpus, and an English parsing task. Our model architecture incorporates building blocks from multiple domains. It contains convolutional layers, an attention mechanism, and sparsely-gated layers. Each of these computational blocks is crucial for a subset of the tasks we train on. Interestingly, even if a block is not crucial for a task, we observe that adding it never hurts performance and in most cases improves it on all tasks. We also show that tasks with less data benefit largely from joint training with other tasks, while performance on large tasks degrades only slightly if at all.},
  urldate = {2019-03-30},
  date = {2017-06-15},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  author = {Kaiser, Lukasz and Gomez, Aidan N. and Shazeer, Noam and Vaswani, Ashish and Parmar, Niki and Jones, Llion and Uszkoreit, Jakob},
  file = {/Users/qualia/Documents/Papers/Kaiser et al. - 2017 - One Model To Learn Them All.pdf}
}

@article{Azulay2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1805.12177},
  primaryClass = {cs},
  langid = {english},
  title = {Why Do Deep Convolutional Networks Generalize so Poorly to Small Image Transformations?},
  url = {http://arxiv.org/abs/1805.12177},
  abstract = {Deep convolutional network architectures are often assumed to guarantee generalization for small image translations and deformations. In this paper we show that modern CNNs (VGG16, ResNet50, and InceptionResNetV2) can drastically change their output when an image is translated in the image plane by a few pixels, and that this failure of generalization also happens with other realistic small image transformations. Furthermore, the deeper the network the more we see these failures to generalize. We show that these failures are related to the fact that the architecture of modern CNNs ignores the classical sampling theorem so that generalization is not guaranteed. We also show that biases in the statistics of commonly used image datasets makes it unlikely that CNNs will learn to be invariant to these transformations. Taken together our results suggest that the performance of CNNs in object recognition falls far short of the generalization capabilities of humans.},
  urldate = {2019-03-30},
  date = {2018-05-30},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Azulay, Aharon and Weiss, Yair},
  file = {/Users/qualia/Documents/Papers/Azulay and Weiss - 2018 - Why do deep convolutional networks generalize so p.pdf}
}

@article{Burda2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1808.04355},
  primaryClass = {cs, stat},
  langid = {english},
  title = {Large-{{Scale Study}} of {{Curiosity}}-{{Driven Learning}}},
  url = {http://arxiv.org/abs/1808.04355},
  abstract = {Reinforcement learning algorithms rely on carefully engineering environment rewards that are extrinsic to the agent. However, annotating each environment with hand-designed, dense rewards is not scalable, motivating the need for developing reward functions that are intrinsic to the agent. Curiosity is a type of intrinsic reward function which uses prediction error as reward signal. In this paper: (a) We perform the first large-scale study of purely curiosity-driven learning, i.e. without any extrinsic rewards, across 54 standard benchmark environments, including the Atari game suite. Our results show surprisingly good performance, and a high degree of alignment between the intrinsic curiosity objective and the handdesigned extrinsic rewards of many game environments. (b) We investigate the effect of using different feature spaces for computing prediction error and show that random features are sufficient for many popular RL game benchmarks, but learned features appear to generalize better (e.g. to novel game levels in Super Mario Bros.). (c) We demonstrate limitations of the prediction-based rewards in stochastic setups. Game-play videos and code are at https://pathak22.github. io/large-scale-curiosity/.},
  urldate = {2019-03-30},
  date = {2018-08-13},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  author = {Burda, Yuri and Edwards, Harri and Pathak, Deepak and Storkey, Amos and Darrell, Trevor and Efros, Alexei A.},
  file = {/Users/qualia/Documents/Papers/Burda et al. - 2018 - Large-Scale Study of Curiosity-Driven Learning.pdf}
}

@article{Cuccu2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.01363},
  primaryClass = {cs, stat},
  langid = {english},
  title = {Playing {{Atari}} with {{Six Neurons}}},
  url = {http://arxiv.org/abs/1806.01363},
  abstract = {Deep reinforcement learning on Atari games maps pixel directly to actions; internally, the deep neural network bears the responsibility of both extracting useful information and making decisions based on it. Aiming at devoting entire deep networks to decision making alone, we propose a new method for learning policies and compact state representations separately but simultaneously for policy approximation in reinforcement learning. State representations are generated by a novel algorithm based on Vector Quantization and Sparse Coding, trained online along with the network, and capable of growing its dictionary size over time. We also introduce new techniques allowing both the neural network and the evolution strategy to cope with varying dimensions. This enables networks of only 6 to 18 neurons to learn to play a selection of Atari games with performance comparable\textemdash{}and occasionally superior\textemdash{}to state-of-the-art techniques using evolution strategies on deep networks two orders of magnitude larger.},
  urldate = {2019-03-30},
  date = {2018-06-04},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Artificial Intelligence},
  author = {Cuccu, Giuseppe and Togelius, Julian and Cudre-Mauroux, Philippe},
  file = {/Users/qualia/Documents/Papers/Cuccu et al. - 2018 - Playing Atari with Six Neurons.pdf}
}

@article{Chen2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.10574},
  primaryClass = {cs, stat},
  langid = {english},
  title = {This {{Looks Like That}}: {{Deep Learning}} for {{Interpretable Image Recognition}}},
  url = {http://arxiv.org/abs/1806.10574},
  shorttitle = {This {{Looks Like That}}},
  abstract = {When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The algorithm thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, geologists, architects, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training, meaning that there are no labels for parts of images. We demonstrate the method on the CIFAR-10 dataset and 10 classes from the CUB200-2011 dataset.},
  urldate = {2019-03-30},
  date = {2018-06-27},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  author = {Chen, Chaofan and Li, Oscar and Tao, Chaofan and Barnett, Alina Jade and Su, Jonathan and Rudin, Cynthia},
  file = {/Users/qualia/Documents/Papers/Chen et al. - 2018 - This Looks Like That Deep Learning for Interpreta.pdf}
}

@article{Frankle2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1803.03635},
  primaryClass = {cs},
  langid = {english},
  title = {The {{Lottery Ticket Hypothesis}}: {{Finding Sparse}}, {{Trainable Neural Networks}}},
  url = {http://arxiv.org/abs/1803.03635},
  shorttitle = {The {{Lottery Ticket Hypothesis}}},
  abstract = {Recent work on neural network pruning indicates that, at training time, neural networks need to be significantly larger in size than is necessary to represent the eventual functions that they learn. This paper articulates a new hypothesis to explain this phenomenon. This conjecture, which we term the lottery ticket hypothesis, proposes that successful training depends on lucky random initialization of a smaller subcomponent of the network. Larger networks have more of these ``lottery tickets,'' meaning they are more likely to luck out with a subcomponent initialized in a configuration amenable to successful optimization.},
  urldate = {2019-03-30},
  date = {2018-03-09},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Artificial Intelligence},
  author = {Frankle, Jonathan and Carbin, Michael},
  file = {/Users/qualia/Documents/Papers/Frankle and Carbin - 2018 - The Lottery Ticket Hypothesis Finding Sparse, Tra 2.pdf;/Users/qualia/Documents/Papers/Frankle and Carbin - 2018 - The Lottery Ticket Hypothesis Finding Sparse, Tra.pdf}
}

@book{Sutton2018,
  langid = {english},
  location = {{Cambridge, Massachusetts}},
  title = {Reinforcement Learning: An Introduction},
  edition = {Second edition},
  isbn = {978-0-262-03924-6},
  shorttitle = {Reinforcement Learning},
  abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
  pagetotal = {526},
  series = {Adaptive Computation and Machine Learning Series},
  publisher = {{The MIT Press}},
  date = {2018},
  keywords = {Reinforcement learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  file = {/Users/qualia/Documents/Papers/Sutton and Barto - 2018 - Reinforcement learning an introduction.pdf}
}

@article{Peterson2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1809.03406},
  primaryClass = {cs},
  langid = {english},
  title = {Keep It Stupid Simple},
  url = {http://arxiv.org/abs/1809.03406},
  abstract = {Deep reinforcement learning can match and exceed human performance, but if even minor changes are introduced to the environment artificial networks often can't adapt. Humans meanwhile are quite adaptable. We hypothesize that this is partly because of how humans use heuristics, and partly because humans can imagine new and more challenging environments to learn from. We've developed a model of hierarchical reinforcement learning that combines both these elements into a stumbler-strategist network. We test transfer performance of this network using Wythoff's game, a gridworld environment with a known optimal strategy. We show that combining imagined play with a heuristic\textendash{}labeling each position as ``good'' or ``bad''\textendash{}both accelerates learning and promotes transfer to novel games, while also improving model interpretability.},
  urldate = {2019-03-30},
  date = {2018-09-10},
  keywords = {Computer Science - Artificial Intelligence},
  author = {Peterson, Erik J. and M\"uyesser, Necati Alp and Verstynen, Timothy and Dunovan, Kyle},
  file = {/Users/qualia/Documents/Papers/Peterson et al. - 2018 - Keep it stupid simple.pdf}
}

@article{Zhang2018a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.07937},
  primaryClass = {cs, stat},
  langid = {english},
  title = {A {{Dissection}} of {{Overfitting}} and {{Generalization}} in {{Continuous Reinforcement Learning}}},
  url = {http://arxiv.org/abs/1806.07937},
  abstract = {The risks and perils of overfitting in machine learning are well known. However most of the treatment of this, including diagnostic tools and remedies, was developed for the supervised learning case. In this work, we aim to offer new perspectives on the characterization and prevention of overfitting in deep Reinforcement Learning (RL) methods, with a particular focus on continuous domains. We examine several aspects, such as how to define and diagnose overfitting in MDPs, and how to reduce risks by injecting sufficient training diversity. This work complements recent findings on the brittleness of deep RL methods and offers practical observations for RL researchers and practitioners.},
  urldate = {2019-03-30},
  date = {2018-06-20},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence},
  author = {Zhang, Amy and Ballas, Nicolas and Pineau, Joelle},
  file = {/Users/qualia/Documents/Papers/Zhang et al. - 2018 - A Dissection of Overfitting and Generalization in .pdf}
}

@article{Tishby2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1503.02406},
  primaryClass = {cs},
  langid = {english},
  title = {Deep {{Learning}} and the {{Information Bottleneck Principle}}},
  url = {http://arxiv.org/abs/1503.02406},
  abstract = {Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.},
  urldate = {2019-03-30},
  date = {2015-03-09},
  keywords = {Computer Science - Machine Learning},
  author = {Tishby, Naftali and Zaslavsky, Noga},
  file = {/Users/qualia/Documents/Papers/Tishby and Zaslavsky - 2015 - Deep Learning and the Information Bottleneck Princ.pdf}
}

@article{Mehlhorn2015,
  langid = {english},
  title = {Unpacking the Exploration\textendash{}Exploitation Tradeoff: {{A}} Synthesis of Human and Animal Literatures.},
  volume = {2},
  issn = {2325-9973, 2325-9965},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/dec0000033},
  doi = {10.1037/dec0000033},
  shorttitle = {Unpacking the Exploration\textendash{}Exploitation Tradeoff},
  number = {3},
  journaltitle = {Decision},
  urldate = {2019-03-30},
  date = {2015-07},
  pages = {191-215},
  author = {Mehlhorn, Katja and Newell, Ben R. and Todd, Peter M. and Lee, Michael D. and Morgan, Kate and Braithwaite, Victoria A. and Hausmann, Daniel and Fiedler, Klaus and Gonzalez, Cleotilde},
  file = {/Users/qualia/Documents/Papers/Mehlhorn et al. - 2015 - Unpacking the exploration–exploitation tradeoff A.pdf}
}

@article{Mischler2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1503.00492},
  langid = {english},
  title = {On a Kinetic {{FitzHugh}}-{{Nagumo}} Model of Neuronal Network},
  volume = {342},
  issn = {0010-3616, 1432-0916},
  url = {http://arxiv.org/abs/1503.00492},
  doi = {10.1007/s00220-015-2556-9},
  abstract = {We investigate existence and uniqueness of solutions of a McKean-Vlasov evolution PDE representing the macroscopic behaviour of interacting Fitzhugh-Nagumo neurons. This equation is hypoelliptic, nonlocal and has unbounded coefficients. We prove existence of a solution to the evolution equation and non trivial stationary solutions. Moreover, we demonstrate uniqueness of the stationary solution in the weakly nonlinear regime. Eventually, using a semigroup factorisation method, we show exponential nonlinear stability in the small connectivity regime.},
  number = {3},
  journaltitle = {Communications in Mathematical Physics},
  urldate = {2019-03-30},
  date = {2016-03},
  pages = {1001-1042},
  keywords = {Mathematics - Analysis of PDEs,Mathematics - Functional Analysis,Mathematics - Spectral Theory},
  author = {Mischler, St\'ephane and Qui\~ninao, Crist\'obal and Touboul, Jonathan},
  file = {/Users/qualia/Documents/Papers/Mischler et al. - 2016 - On a kinetic FitzHugh-Nagumo model of neuronal net.pdf}
}

@article{Toupo2014,
  langid = {english},
  title = {Limit {{Cycles Sparked}} by {{Mutation}} in the {{Repeated Prisoner}}'s {{Dilemma}}},
  volume = {24},
  issn = {0218-1274, 1793-6551},
  url = {http://www.worldscientific.com/doi/abs/10.1142/S0218127414300353},
  doi = {10.1142/S0218127414300353},
  number = {12},
  journaltitle = {International Journal of Bifurcation and Chaos},
  urldate = {2019-03-30},
  date = {2014-12},
  pages = {1430035},
  author = {Toupo, Danielle F. P. and Rand, David G. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/Toupo et al. - 2014 - Limit Cycles Sparked by Mutation in the Repeated P.pdf}
}

@article{Toupo2015,
  langid = {english},
  title = {Evolutionary Game Dynamics of Controlled and Automatic Decision-Making},
  volume = {25},
  issn = {1054-1500, 1089-7682},
  url = {http://aip.scitation.org/doi/10.1063/1.4927488},
  doi = {10.1063/1.4927488},
  number = {7},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  urldate = {2019-03-30},
  date = {2015-07},
  pages = {073120},
  author = {Toupo, Danielle F. P. and Strogatz, Steven H. and Cohen, Jonathan D. and Rand, David G.},
  file = {/Users/qualia/Documents/Papers/Toupo et al. - 2015 - Evolutionary game dynamics of controlled and autom.pdf}
}

@article{Toupo2015a,
  langid = {english},
  title = {Nonlinear Dynamics of the Rock-Paper-Scissors Game with Mutations},
  volume = {91},
  issn = {1539-3755, 1550-2376},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.91.052907},
  doi = {10.1103/PhysRevE.91.052907},
  number = {5},
  journaltitle = {Physical Review E},
  urldate = {2019-03-30},
  date = {2015-05-11},
  author = {Toupo, Danielle F. P. and Strogatz, Steven H.},
  file = {/Users/qualia/Documents/Papers/Toupo and Strogatz - 2015 - Nonlinear dynamics of the rock-paper-scissors game.pdf}
}

@article{Ujfalussy2015,
  langid = {english},
  title = {Dendritic Nonlinearities Are Tuned for Efficient Spike-Based Computations in Cortical Circuits},
  volume = {4},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/10056},
  doi = {10.7554/eLife.10056},
  journaltitle = {eLife},
  urldate = {2019-03-30},
  date = {2015-12-24},
  author = {Ujfalussy, Bal\'azs B and Makara, Judit K and Branco, Tiago and Lengyel, M\'at\'e},
  file = {/Users/qualia/Documents/Papers/Ujfalussy et al. - 2015 - Dendritic nonlinearities are tuned for efficient s.pdf}
}

@article{Voytek2015c,
  langid = {english},
  title = {Age-{{Related Changes}} in 1/f {{Neural Electrophysiological Noise}}},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2332-14.2015},
  doi = {10.1523/JNEUROSCI.2332-14.2015},
  number = {38},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2015-09-23},
  pages = {13257-13265},
  author = {Voytek, B. and Kramer, M. A. and Case, J. and Lepage, K. Q. and Tempesta, Z. R. and Knight, R. T. and Gazzaley, A.},
  file = {/Users/qualia/Documents/Papers/Voytek et al. - 2015 - Age-Related Changes in 1f Neural Electrophysiolog.pdf}
}

@article{Uva2015,
  langid = {english},
  title = {Synchronous {{Inhibitory Potentials Precede Seizure}}-{{Like Events}} in {{Acute Models}} of {{Focal Limbic Seizures}}},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3692-14.2015},
  doi = {10.1523/JNEUROSCI.3692-14.2015},
  number = {7},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2015-02-18},
  pages = {3048-3055},
  author = {Uva, L. and Breschi, G. L. and Gnatkovsky, V. and Taverna, S. and de Curtis, M.},
  options = {useprefix=true},
  file = {/Users/qualia/Documents/Papers/Uva et al. - 2015 - Synchronous Inhibitory Potentials Precede Seizure-.pdf}
}

@article{McMahan2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.05629},
  primaryClass = {cs},
  langid = {english},
  title = {Communication-{{Efficient Learning}} of {{Deep Networks}} from {{Decentralized Data}}},
  url = {http://arxiv.org/abs/1602.05629},
  abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10\textendash{}100\texttimes{} as compared to synchronized stochastic gradient descent.},
  urldate = {2019-03-30},
  date = {2016-02-17},
  keywords = {Computer Science - Machine Learning},
  author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Ag\"uera},
  file = {/Users/qualia/Documents/Papers/McMahan et al. - 2016 - Communication-Efficient Learning of Deep Networks .pdf}
}

@article{Sotero2015,
  langid = {english},
  title = {Laminar {{Distribution}} of {{Phase}}-{{Amplitude Coupling}} of {{Spontaneous Current Sources}} and {{Sinks}}},
  volume = {9},
  issn = {1662-453X},
  url = {http://journal.frontiersin.org/Article/10.3389/fnins.2015.00454/abstract},
  doi = {10.3389/fnins.2015.00454},
  abstract = {Although resting-state functional connectivity is a commonly used neuroimaging paradigm, the underlying mechanisms remain unknown. Thalamo-cortical and cortico-cortical circuits generate oscillations at different frequencies during spontaneous activity. However, it remains unclear how the various rhythms interact and whether their interactions are lamina-specific. Here we investigated intra- and inter-laminar spontaneous phase-amplitude coupling (PAC). We recorded local-field potentials using laminar probes inserted in the forelimb representation of rat area S1. We then computed time-series of frequency-band- and lamina-specific current source density (CSD), and PACs of CSD for all possible pairs of the classical frequency bands in the range of 1\textendash{}150 Hz. We observed both intra- and inter-laminar spontaneous PAC. Of 18 possible combinations, 12 showed PAC, with the highest measures of interaction obtained for the pairs of the theta/gamma and delta/gamma bands. Intra- and inter-laminar PACs involving layers 2/3\textendash{}5a were higher than those involving layer 6. Current sinks (sources) in the delta band were associated with increased (decreased) amplitudes of high-frequency signals in the beta to fast gamma bands throughout layers 2/3\textendash{}6. Spontaneous sinks (sources) of the theta and alpha bands in layers 2/3\textendash{}4 were on average linked to dipoles completed by sources (sinks) in layer 6, associated with high (low) amplitudes of the beta to fast-gamma bands in the entire cortical column. Our findings show that during spontaneous activity, delta, theta, and alpha oscillations are associated with periodic excitability, which for the theta and alpha bands is lamina-dependent. They further emphasize the differences between the function of layer 6 and that of the superficial layers, and the role of layer 6 in controlling activity in those layers. Our study links theories on the involvement of PAC in resting-state functional connectivity with previous work that revealed lamina-specific anatomical thalamo-cortico-cortical connections.},
  journaltitle = {Frontiers in Neuroscience},
  urldate = {2019-03-30},
  date = {2015-12-22},
  author = {Sotero, Roberto C. and Bortel, Aleksandra and Naaman, Shmuel and Mocanu, Victor M. and Kropf, Pascal and Villeneuve, Martin and Shmuel, Amir},
  file = {/Users/qualia/Documents/Papers/Sotero et al. - 2015 - Laminar Distribution of Phase-Amplitude Coupling o.pdf}
}

@article{Salkoff2015,
  langid = {english},
  title = {Synaptic {{Mechanisms}} of {{Tight Spike Synchrony}} at {{Gamma Frequency}} in {{Cerebral Cortex}}},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0828-15.2015},
  doi = {10.1523/JNEUROSCI.0828-15.2015},
  number = {28},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2015-07-15},
  pages = {10236-10251},
  author = {Salkoff, D. B. and Zagha, E. and Yuzgec, O. and McCormick, D. A.},
  file = {/Users/qualia/Documents/Papers/Salkoff et al. - 2015 - Synaptic Mechanisms of Tight Spike Synchrony at Ga.pdf}
}

@article{Schaworonkow2015,
  langid = {english},
  title = {Power-Law Dynamics in Neuronal and Behavioral Data Introduce Spurious Correlations: {{Power}}-{{Law Dynamics}} in {{Neuronal}} and {{Behavioral Data}}},
  volume = {36},
  issn = {10659471},
  url = {http://doi.wiley.com/10.1002/hbm.22816},
  doi = {10.1002/hbm.22816},
  shorttitle = {Power-Law Dynamics in Neuronal and Behavioral Data Introduce Spurious Correlations},
  abstract = {Relating behavioral and neuroimaging measures is essential to understanding human brain function. Often, this is achieved by computing a correlation between behavioral measures, e.g., reaction times, and neurophysiological recordings, e.g., prestimulus EEG alpha-power, on a single-trial-basis. This approach treats individual trials as independent measurements and ignores the fact that data are acquired in a temporal order. It has already been shown that behavioral measures as well as neurophysiological recordings display power-law dynamics, which implies that trials are not in fact independent. Critically, computing the correlation coefficient between two measures exhibiting long-range temporal dependencies may introduce spurious correlations, thus leading to erroneous conclusions about the relationship between brain activity and behavioral measures. Here, we address data-analytic pitfalls which may arise when long-range temporal dependencies in neural as well as behavioral measures are ignored. We quantify the influence of temporal dependencies of neural and behavioral measures on the observed correlations through simulations. Results are further supported in analysis of real EEG data recorded in a simple reaction time task, where the aim is to predict the latency of responses on the basis of prestimulus alpha oscillations. We show that it is possible to "predict" reaction times from one subject on the basis of EEG activity recorded in another subject simply owing to the fact that both measures display power-law dynamics. The same is true when correlating EEG activity obtained from different subjects. A surrogatedata procedure is described which correctly tests for the presence of correlation while controlling for the effect of power-law dynamics. Hum Brain Mapp 00:000\textendash{}000, 2015. VC 2015 Wiley Periodicals, Inc.},
  number = {8},
  journaltitle = {Human Brain Mapping},
  urldate = {2019-03-30},
  date = {2015-08},
  pages = {2901-2914},
  author = {Schaworonkow, Natalie and Blythe, Duncan A.J. and Kegeles, Jewgeni and Curio, Gabriel and Nikulin, Vadim V.},
  file = {/Users/qualia/Documents/Papers/Schaworonkow et al. - 2015 - Power-law dynamics in neuronal and behavioral data.pdf}
}

@article{Schwemmer2015,
  langid = {english},
  title = {Constructing {{Precisely Computing Networks}} with {{Biophysical Spiking Neurons}}},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4951-14.2015},
  doi = {10.1523/JNEUROSCI.4951-14.2015},
  number = {28},
  journaltitle = {Journal of Neuroscience},
  urldate = {2019-03-30},
  date = {2015-07-15},
  pages = {10112-10134},
  author = {Schwemmer, M. A. and Fairhall, A. L. and Deneve, S. and Shea-Brown, E. T.},
  file = {/Users/qualia/Documents/Papers/Schwemmer et al. - 2015 - Constructing Precisely Computing Networks with Bio.pdf}
}

@article{Siegel2015,
  langid = {english},
  title = {Cortical Information Flow during Flexible Sensorimotor Decisions},
  volume = {348},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aab0551},
  doi = {10.1126/science.aab0551},
  abstract = {IT and V4 first extracted task information from the cues along with the encoding of cue identity. After this transient burst, there was a flow of sustained task information from PFC and LIP across the entire sensorimotor hierarchy.},
  number = {6241},
  journaltitle = {Science},
  urldate = {2019-03-30},
  date = {2015-06-19},
  pages = {1352-1355},
  author = {Siegel, M. and Buschman, T. J. and Miller, E. K.},
  file = {/Users/qualia/Documents/Papers/Siegel et al. - 2015 - Cortical information flow during flexible sensorim.pdf}
}

@article{Rich2019,
  langid = {english},
  title = {Lessons for Artificial Intelligence from the Study of Natural Stupidity},
  volume = {1},
  issn = {2522-5839},
  url = {http://www.nature.com/articles/s42256-019-0038-z},
  doi = {10.1038/s42256-019-0038-z},
  number = {4},
  journaltitle = {Nature Machine Intelligence},
  urldate = {2019-04-09},
  date = {2019-04},
  pages = {174-180},
  author = {Rich, Alexander S. and Gureckis, Todd M.},
  file = {/Users/qualia/Documents/Papers/Rich and Gureckis - 2019 - Lessons for artificial intelligence from the study.pdf}
}

@article{Harper2009,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {0911.1763},
  primaryClass = {cs, math},
  langid = {english},
  title = {The {{Replicator Equation}} as an {{Inference Dynamic}}},
  url = {http://arxiv.org/abs/0911.1763},
  abstract = {The replicator equation is interpreted as a continuous inference equation and a formal similarity between the discrete replicator equation and Bayesian inference is described. Further connections between inference and the replicator equation are given including a discussion of information divergences, evolutionary stability, and exponential families as solutions for the replicator dynamic, using Fisher information and information geometry.},
  urldate = {2019-04-09},
  date = {2009-11-09},
  keywords = {Computer Science - Information Theory,Mathematics - Dynamical Systems,37N25; Secondary: 62F15},
  author = {Harper, Marc},
  file = {/Users/qualia/Documents/Papers/Harper - 2009 - The Replicator Equation as an Inference Dynamic.pdf}
}

@article{Graves2017a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1704.03003},
  primaryClass = {cs},
  langid = {english},
  title = {Automated {{Curriculum Learning}} for {{Neural Networks}}},
  url = {http://arxiv.org/abs/1704.03003},
  abstract = {We introduce a method for automatically selecting the path, or syllabus, that a neural network follows through a curriculum so as to maximise learning efficiency. A measure of the amount that the network learns from each data sample is provided as a reward signal to a nonstationary multiarmed bandit algorithm, which then determines a stochastic syllabus. We consider a range of signals derived from two distinct indicators of learning progress: rate of increase in prediction accuracy, and rate of increase in network complexity. Experimental results for LSTM networks on three curricula demonstrate that our approach can significantly accelerate learning, in some cases halving the time required to attain a satisfactory performance level.},
  urldate = {2019-04-09},
  date = {2017-04-10},
  keywords = {Computer Science - Neural and Evolutionary Computing},
  author = {Graves, Alex and Bellemare, Marc G. and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  file = {/Users/qualia/Documents/Papers/Graves et al. - 2017 - Automated Curriculum Learning for Neural Networks 2.pdf}
}

@report{Razo-Mejia2019,
  langid = {english},
  title = {First-Principles Prediction of the Information Processing Capacity of a Simple Genetic Circuit},
  url = {http://biorxiv.org/lookup/doi/10.1101/594325},
  abstract = {Abstract
          
            Given the stochastic nature of gene expression, genetically identical cells exposed to the same environmental inputs will produce different outputs. This heterogeneity has consequences for how cells are able to survive in changing environments. Recent work has explored the use of information theory as a framework to understand the accuracy with which cells can ascertain the state of their surroundings. Yet the predictive power of these approaches is limited and has not been rigorously tested using precision measurements. To that end, we generate a minimal model for a simple genetic circuit in which all parameter values for the model come from independently published data sets. We then predict the information processing capacity of the genetic circuit for a suite of biophysical parameters such as protein copy number and protein-DNA affinity. We compare these parameter-free predictions with an experimental determination of the information processing capacity of
            E. coli
            cells, and find that our minimal model accurately captures the experimental data.},
  institution = {{Biophysics}},
  type = {preprint},
  urldate = {2019-04-09},
  date = {2019-03-31},
  author = {Razo-Mejia, Manuel and Phillips, Rob},
  file = {/Users/qualia/Documents/Papers/Razo-Mejia and Phillips - 2019 - First-principles prediction of the information pro.pdf},
  doi = {10.1101/594325}
}

@article{Camley2018,
  langid = {english},
  title = {Collective Gradient Sensing and Chemotaxis: Modeling and Recent Developments},
  volume = {30},
  issn = {0953-8984, 1361-648X},
  url = {http://stacks.iop.org/0953-8984/30/i=22/a=223001?key=crossref.a39232ca185b8f94627edba967149284},
  doi = {10.1088/1361-648X/aabd9f},
  shorttitle = {Collective Gradient Sensing and Chemotaxis},
  number = {22},
  journaltitle = {Journal of Physics: Condensed Matter},
  urldate = {2019-04-09},
  date = {2018-06-06},
  pages = {223001},
  author = {Camley, Brian A},
  file = {/Users/qualia/Documents/Papers/Camley - 2018 - Collective gradient sensing and chemotaxis modeli.pdf}
}

@article{Insanally2019a,
  langid = {english},
  title = {Spike-Timing-Dependent Ensemble Encoding by Non-Classically Responsive Cortical Neurons},
  volume = {8},
  issn = {2050-084X},
  url = {https://elifesciences.org/articles/42409},
  doi = {10.7554/eLife.42409},
  abstract = {Neurons recorded in behaving animals often do not discernibly respond to sensory input and are not overtly task-modulated. These non-classically responsive neurons are difficult to interpret and are typically neglected from analysis, confounding attempts to connect neural activity to perception and behavior. Here, we describe a trial-by-trial, spike-timing-based algorithm to reveal the coding capacities of these neurons in auditory and frontal cortex of behaving rats. Classically responsive and non-classically responsive cells contained significant information about sensory stimuli and behavioral decisions. Stimulus category was more accurately represented in frontal cortex than auditory cortex, via ensembles of non-classically responsive cells coordinating the behavioral meaning of spike timings on correct but not error trials. This unbiased approach allows the contribution of all recorded neurons \textendash{} particularly those without obvious task-related, trial-averaged firing rate modulation \textendash{} to be assessed for behavioral relevance on single trials.
          , 
            Neurons encode information in the form of electrical signals called spikes. Certain neurons increase the rate at which they produce spikes under specific circumstances, e.g., whenever an animal hears a particular sound. These neurons are said to be 'classically responsive'. But not all neurons behave in this way. Others produce spikes at a variable rate that does not obviously relate to the animal's behavior. These neurons are said to be 'non-classically responsive'. They are often omitted from analyses, despite typically outnumbering their classically responsive counterparts. So, what are these neurons doing?
            To find out, Insanally et al. trained rats to respond to sounds. The animals learned to poke their nose into a window whenever they heard a specific tone, and to avoid responding whenever they heard any other tone. As the rats performed the task, Insanally et al. recorded from neurons in two areas of the brain, the frontal cortex and the auditory cortex. A computer then analyzed the activity of individual neurons during each trial.
            As expected, the firing rate of non-classically responsive cells did not relate to the animals' behavior. But the timing of this firing did. The interval between spikes contained information about which tone the animals had heard and/or how they had responded. The cells worked together in groups to encode this information. Over the course of each trial, every neuron in the group varied the interval between its spikes. Eventually, the group reached a consensus, with all neurons using the same interval to represent information relevant to the task. Groups of neurons in the frontal cortex encoded more information about the category of the tone than those in the auditory cortex.
            By including all neurons \textendash{} both classically and non-classically responsive \textendash{} this model offers a more comprehensive view of how neural activity relates to behavior. This may in turn help us understand the variable and complex neural activity seen in people with sensory and cognitive disorders.},
  journaltitle = {eLife},
  urldate = {2019-04-09},
  date = {2019-01-28},
  pages = {e42409},
  author = {Insanally, Michele N and Carcea, Ioana and Field, Rachel E and Rodgers, Chris C and DePasquale, Brian and Rajan, Kanaka and DeWeese, Michael R and Albanna, Badr F and Froemke, Robert C},
  file = {/Users/qualia/Documents/Papers/Insanally et al. - 2019 - Spike-timing-dependent ensemble encoding by non-cl 2.pdf}
}

@report{Gao2017,
  langid = {english},
  title = {A Theory of Multineuronal Dimensionality, Dynamics and Measurement},
  url = {http://biorxiv.org/lookup/doi/10.1101/214262},
  abstract = {In many experiments, neuroscientists tightly control behavior, record many trials, and obtain trial-averaged firing rates from hundreds of neurons in circuits containing billions of behaviorally relevant neurons. Dimensionality reduction methods reveal a striking simplicity underlying such multi-neuronal data: they can be reduced to a low-dimensional space, and the resulting neural trajectories in this space yield a remarkably insightful dynamical portrait of circuit computation. This simplicity raises profound and timely conceptual questions. What are its origins and its implications for the complexity of neural dynamics? How would the situation change if we recorded more neurons? When, if at all, can we trust dynamical portraits obtained from measuring an infinitesimal fraction of task relevant neurons? We present a theory that answers these questions, and test it using physiological recordings from reaching monkeys. This theory reveals conceptual insights into how task complexity governs both neural dimensionality and accurate recovery of dynamic portraits, thereby providing quantitative guidelines for future large-scale experimental design.},
  institution = {{Neuroscience}},
  type = {preprint},
  urldate = {2019-04-13},
  date = {2017-11-05},
  author = {Gao, Peiran and Trautmann, Eric and Yu, Byron M. and Santhanam, Gopal and Ryu, Stephen and Shenoy, Krishna and Ganguli, Surya},
  file = {/Users/qualia/Documents/Papers/Gao et al. - 2017 - A theory of multineuronal dimensionality, dynamics.pdf},
  doi = {10.1101/214262}
}

@article{Peters2016,
  langid = {english},
  title = {Evaluating Gambles Using Dynamics},
  volume = {26},
  issn = {1054-1500, 1089-7682},
  url = {http://aip.scitation.org/doi/10.1063/1.4940236},
  doi = {10.1063/1.4940236},
  number = {2},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  urldate = {2019-04-13},
  date = {2016-02},
  pages = {023103},
  author = {Peters, O. and Gell-Mann, M.},
  file = {/Users/qualia/Documents/Papers/Peters and Gell-Mann - 2016 - Evaluating gambles using dynamics.pdf}
}

@article{Kelly1956,
  langid = {english},
  title = {A {{New Interpretation}} of {{Information Rate}}},
  journaltitle = {the bell system technical journal},
  date = {1956},
  pages = {10},
  author = {Kelly, J L},
  file = {/Users/qualia/Documents/Papers/Kelly - 1956 - A New Interpretation of Information Rate.pdf}
}

@article{Reddy2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1601.03073},
  langid = {english},
  title = {Infomax Strategies for an Optimal Balance between Exploration and Exploitation},
  volume = {163},
  issn = {0022-4715, 1572-9613},
  url = {http://arxiv.org/abs/1601.03073},
  doi = {10.1007/s10955-016-1521-0},
  abstract = {Proper balance between exploitation and exploration is what makes good decisions, which achieve high rewards like payoff or evolutionary fitness. The Infomax principle postulates that maximization of information directs the function of diverse systems, from living systems to artificial neural networks. While specific applications are successful, the validity of information as a proxy for reward remains unclear. Here, we consider the multi-armed bandit decision problem, which features arms (slot-machines) of unknown probabilities of success and a player trying to maximize cumulative payoff by choosing the sequence of arms to play. We show that an Infomax strategy (Info-p) which optimally gathers information on the highest mean reward among the arms saturates known optimal bounds and compares favorably to existing policies. The highest mean reward considered by Info-p is not the quantity actually needed for the choice of the arm to play, yet it allows for optimal tradeoffs between exploration and exploitation.},
  number = {6},
  journaltitle = {Journal of Statistical Physics},
  urldate = {2019-04-14},
  date = {2016-06},
  pages = {1454-1476},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Physics - Data Analysis; Statistics and Probability,Computer Science - Information Theory,Quantitative Biology - Populations and Evolution},
  author = {Reddy, Gautam and Celani, Antonio and Vergassola, Massimo},
  file = {/Users/qualia/Documents/Papers/Reddy et al. - 2016 - Infomax strategies for an optimal balance between .pdf}
}

@article{Borgers2005,
  langid = {english},
  title = {Background Gamma Rhythmicity and Attention in Cortical Local Circuits: {{A}} Computational Study},
  volume = {102},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0502366102},
  doi = {10.1073/pnas.0502366102},
  shorttitle = {Background Gamma Rhythmicity and Attention in Cortical Local Circuits},
  number = {19},
  journaltitle = {Proceedings of the National Academy of Sciences},
  urldate = {2019-04-17},
  date = {2005-05-10},
  pages = {7002-7007},
  author = {Borgers, C. and Epstein, S. and Kopell, N. J.},
  file = {/Users/qualia/Documents/Papers/Borgers et al. - 2005 - Background gamma rhythmicity and attention in cort.pdf}
}

@article{Hodgkin1952,
  title = {A Quantitative Description of Membrane Current and Its Application to Conduction and Excitation in Nerve},
  volume = {117},
  number = {4},
  journaltitle = {J Physiol},
  date = {1952},
  pages = {500--544},
  author = {Hodgkin, A. L. and Huxley, A. F.},
  file = {/Users/qualia/Documents/Papers/jphysiol01442-0106.pdf}
}

@article{Wang1996,
  langid = {english},
  title = {Gamma {{Oscillation}} by {{Synaptic Inhibition}} in a {{Hippocampal Interneuronal Network Model}}},
  volume = {16},
  issn = {0270-6474, 1529-2401},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.16-20-06402.1996},
  doi = {10.1523/JNEUROSCI.16-20-06402.1996},
  number = {20},
  journaltitle = {The Journal of Neuroscience},
  urldate = {2019-04-17},
  date = {1996-10-15},
  pages = {6402-6413},
  author = {Wang, Xiao-Jing and Buzs\'aki, Gy\"orgy},
  file = {/Users/qualia/Documents/Papers/Wang and Buzsáki - 1996 - Gamma Oscillation by Synaptic Inhibition in a Hipp.pdf}
}

@preamble{ "\ifdefined\DeclarePrefChars\DeclarePrefChars{'’-}\else\fi " }

